{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML_25M Classic ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "df = pd.read_csv('dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('rating', axis=1)\n",
    "Y = df['rating']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree plot\n",
    "pca = PCA(.95)\n",
    "pca.fit(X_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()\n",
    "\n",
    "print(pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaiser criterion\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('explained variance')\n",
    "plt.show()\n",
    "\n",
    "print(pca.n_components_)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=556)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'Number of training samples: {X_train.shape}')\n",
    "print(f'Number of testing samples: {X_test.shape}')\n",
    "results = pd.DataFrame(columns=['Model', 'MSE', 'RMSE', 'R2'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR with Bayesian Optimization\n",
    "def svr_cv(C, gamma, epsilon):\n",
    "    val = cross_val_score(SVR(C=C, gamma=gamma, epsilon=epsilon), X_train, Y_train, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "    return np.mean(val)\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'C': (0.1, 100), 'gamma': (0.0001, 0.1), 'epsilon': (0.1, 1)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=svr_cv,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=10,\n",
    ")   \n",
    "\n",
    "print(optimizer.max{'params'})\n",
    "\n",
    "# SVR\n",
    "svr = SVR(C=optimizer.max['params']['C'], gamma=optimizer.max['params']['gamma'], epsilon=optimizer.max['params']['epsilon'])\n",
    "svr.fit(X_train, Y_train)\n",
    "Y_pred = svr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = np.mean((Y_pred - Y_test)**2)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = svr.score(X_test, Y_test)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R2: {r2}')\n",
    "\n",
    "results = df.concat([results, pd.DataFrame({'Model': 'SVR', 'MSE': mse, 'RMSE': rmse, 'R2': r2}, index=[0])], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "\n",
    "best_n = 0\n",
    "best_mse = float('inf')\n",
    "\n",
    "for n in range(50, 55):\n",
    "    print(\"Number of trees: {}\".format(n), end='\\r')\n",
    "    rfr = RandomForestRegressor(n_estimators=n, random_state=seed)\n",
    "    rfr.fit(X_train, Y_train)\n",
    "    rfr_pred = rfr.predict(X_test)\n",
    "    mse = np.mean((rfr_pred - Y_test) ** 2)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_n = n\n",
    "\n",
    "print(f'\\n\\nBest number of trees: {best_n}')\n",
    "print(f'Best MSE: {best_mse}')\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=best_n, random_state=seed)\n",
    "rfr.fit(X_train, Y_train)\n",
    "rfr_pred = rfr.predict(X_test)\n",
    "\n",
    "# MSE and RMSE\n",
    "mse = np.mean((rfr_pred - Y_test) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "# R2\n",
    "r2 = rfr.score(X_test, Y_test)\n",
    "print(f'R2: {r2}')\n",
    "\n",
    "results = pd.concat([results, pd.DataFrame({'Model': 'Random Forest Regressor', 'MSE': mse, 'RMSE': rmse, 'R2': r2}, index=[0])], ignore_index=True)\n",
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, Y_train)\n",
    "Y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "rmse = mean_squared_error(Y_pred,Y_test)\n",
    "\n",
    "# Accuracy\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(f'MSE: {rmse}')\n",
    "print(f'R2: {r2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=0.1)\n",
    "ridge.fit(X_train, Y_train)\n",
    "ridge_pred = ridge.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mean_squared_error(ridge_pred,Y_test)\n",
    "\n",
    "# Accuracy\n",
    "r2 = r2_score(Y_test, ridge_pred)\n",
    "\n",
    "print(f'MSE: {rmse}')\n",
    "print(f'R2: {r2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso regression\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.00001) # higher value of alpha results in a more sparse model. \n",
    "lasso.fit(X_train, Y_train)\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mean_squared_error(lasso_pred,Y_test)\n",
    "\n",
    "# Accuracy\n",
    "r2 = r2_score(Y_test, lasso_pred)\n",
    "\n",
    "print(f'MSE: {rmse}')\n",
    "print(f'R2: {r2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elastic net\n",
    "from sklearn.linear_model import ElasticNet\n",
    "elasticnet = ElasticNet(alpha=0.00001, l1_ratio=0.5)\n",
    "elasticnet.fit(X_train, Y_train)\n",
    "elastic_pred = elasticnet.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mean_squared_error(elastic_pred,Y_test)\n",
    "\n",
    "# Accuracy\n",
    "r2 = r2_score(Y_test, elastic_pred)\n",
    "\n",
    "print(f'MSE: {rmse}')\n",
    "\n",
    "print(f'R2: {r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
