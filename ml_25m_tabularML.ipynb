{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import copy\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def fix_random(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower\n",
    "\n",
    "fix_random(42)\n",
    "\n",
    "# check if tabular ML folder exists\n",
    "if not os.path.exists('tabularML'):\n",
    "    os.makedirs('tabularML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# PyTorch Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 9946\n",
      "Number of validation samples: 1106\n",
      "Number of testing samples: 2764\n",
      "\n",
      "Number of features: 1128\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('rating', axis=1)\n",
    "Y = df['rating']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "Y_train = Y_train.to_numpy()\n",
    "Y_val = Y_val.to_numpy()\n",
    "Y_test = Y_test.to_numpy()\n",
    "\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_val = Y_val.reshape(-1, 1)\n",
    "\n",
    "print(f'Number of training samples: {X_train.shape[0]}')\n",
    "print(f'Number of validation samples: {X_val.shape[0]}')\n",
    "print(f'Number of testing samples: {X_test.shape[0]}')\n",
    "print(f'\\nNumber of features: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hyperparameter combinations: 72\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "nums_epochs = [200]\n",
    "batch_sizes = [32,64,128]\n",
    "patience = [10]\n",
    "n_d_a = [16,32,64]\n",
    "n_shared = [2,3]\n",
    "n_indipendent = [2,3]\n",
    "n_step = [6,7]\n",
    "gamma = [1.3]\n",
    "epsilon = [1e-8]\n",
    "\n",
    "hyperparameters = itertools.product(n_d_a, n_step,n_indipendent,n_shared, gamma, epsilon,nums_epochs, batch_sizes)\n",
    "n_comb = len(n_d_a)*len(n_step)*len(n_indipendent)*len(n_shared)*len(gamma)*len(epsilon)*len(nums_epochs)*len(batch_sizes)\n",
    "print (f'Number of hyperparameter combinations: {n_comb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_d_a, n_step,n_indipendent,n_shared, gamma, epsilon):\n",
    "    model = TabNetRegressor(\n",
    "        # n_d: the dimensionality of the output space of the feature transformer network (default 64)\n",
    "        n_d=n_d_a,\n",
    "        # n_a: the dimensionality of the output space of the attention network (default 64)\n",
    "        n_a=n_d_a,\n",
    "        # n_steps: the number of sequential steps in the attention mechanism (default 3)\n",
    "        n_steps=n_step,\n",
    "        # gamma: the scaling factor for the feature transformer network (default 1.3)\n",
    "        gamma=gamma,\n",
    "        # optimizerm name of optimizer to use (default Adam)\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        # n_independent: the number of independent feature transformer networks to use (default 2)\n",
    "        n_independent=n_indipendent,\n",
    "        # n_shared: the number of shared feature transformer networks to use (default 2)\n",
    "        n_shared=n_shared,\n",
    "        # epsilon: a small value to add to the denominator of the feature importance calculation to avoid division by zero (default 1e-15)\n",
    "        epsilon=epsilon,\n",
    "        # seed: the random seed to use for reproducibility (default None)\n",
    "        seed=42    \n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iterations 1/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.00997 | val_0_mse: 0.24733 |  0:00:25s\n",
      "epoch 1  | loss: 0.15776 | val_0_mse: 0.09191 |  0:00:49s\n",
      "epoch 2  | loss: 0.10763 | val_0_mse: 0.07695 |  0:01:13s\n",
      "epoch 3  | loss: 0.08941 | val_0_mse: 0.06675 |  0:01:37s\n",
      "epoch 4  | loss: 0.08342 | val_0_mse: 0.06043 |  0:02:01s\n",
      "epoch 5  | loss: 0.08122 | val_0_mse: 0.08044 |  0:02:25s\n",
      "epoch 6  | loss: 0.08239 | val_0_mse: 0.05855 |  0:02:48s\n",
      "epoch 7  | loss: 0.06124 | val_0_mse: 0.04539 |  0:03:12s\n",
      "epoch 8  | loss: 0.04985 | val_0_mse: 0.09366 |  0:03:35s\n",
      "epoch 9  | loss: 0.03844 | val_0_mse: 0.03029 |  0:04:00s\n",
      "epoch 10 | loss: 0.04035 | val_0_mse: 0.05782 |  0:04:23s\n",
      "epoch 11 | loss: 0.06321 | val_0_mse: 0.06593 |  0:04:49s\n",
      "epoch 12 | loss: 0.04534 | val_0_mse: 0.09602 |  0:05:13s\n",
      "epoch 13 | loss: 0.03425 | val_0_mse: 0.06167 |  0:05:36s\n",
      "epoch 14 | loss: 0.02985 | val_0_mse: 0.02868 |  0:06:00s\n",
      "epoch 15 | loss: 0.03722 | val_0_mse: 0.03081 |  0:06:24s\n",
      "epoch 16 | loss: 0.03283 | val_0_mse: 0.02466 |  0:06:47s\n",
      "epoch 17 | loss: 0.03639 | val_0_mse: 0.02275 |  0:07:11s\n",
      "epoch 18 | loss: 0.02953 | val_0_mse: 0.02718 |  0:07:34s\n",
      "epoch 19 | loss: 0.02693 | val_0_mse: 0.03947 |  0:07:58s\n",
      "epoch 20 | loss: 0.02856 | val_0_mse: 0.03062 |  0:08:21s\n",
      "epoch 21 | loss: 0.02859 | val_0_mse: 0.02644 |  0:08:45s\n",
      "epoch 22 | loss: 0.02669 | val_0_mse: 0.01406 |  0:09:09s\n",
      "epoch 23 | loss: 0.02591 | val_0_mse: 0.02492 |  0:09:32s\n",
      "epoch 24 | loss: 0.02703 | val_0_mse: 0.03038 |  0:09:56s\n",
      "epoch 25 | loss: 0.02375 | val_0_mse: 0.01268 |  0:10:19s\n",
      "epoch 26 | loss: 0.02473 | val_0_mse: 0.01506 |  0:10:43s\n",
      "epoch 27 | loss: 0.02642 | val_0_mse: 0.02    |  0:11:06s\n",
      "epoch 28 | loss: 0.02475 | val_0_mse: 0.02036 |  0:11:30s\n",
      "epoch 29 | loss: 0.02618 | val_0_mse: 0.18904 |  0:11:53s\n",
      "epoch 30 | loss: 0.02284 | val_0_mse: 0.19401 |  0:12:17s\n",
      "epoch 31 | loss: 0.02116 | val_0_mse: 0.10408 |  0:12:40s\n",
      "epoch 32 | loss: 0.02863 | val_0_mse: 0.08389 |  0:13:04s\n",
      "epoch 33 | loss: 0.02659 | val_0_mse: 0.01657 |  0:13:27s\n",
      "epoch 34 | loss: 0.02927 | val_0_mse: 0.12107 |  0:13:51s\n",
      "epoch 35 | loss: 0.02434 | val_0_mse: 0.09883 |  0:14:14s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mse = 0.01268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.011893 - Best MSE: 0.011893\n",
      "Model R2 Score: 0.946349 - Best R2 Score: 0.946349\n",
      "\n",
      "Iterations 2/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.7093  | val_0_mse: 0.37873 |  0:00:14s\n",
      "epoch 1  | loss: 0.15427 | val_0_mse: 0.07799 |  0:00:28s\n",
      "epoch 2  | loss: 0.12662 | val_0_mse: 0.06026 |  0:00:42s\n",
      "epoch 3  | loss: 0.07315 | val_0_mse: 0.05746 |  0:00:56s\n",
      "epoch 4  | loss: 0.05737 | val_0_mse: 0.04832 |  0:01:10s\n",
      "epoch 5  | loss: 0.05401 | val_0_mse: 0.05017 |  0:01:24s\n",
      "epoch 6  | loss: 0.0546  | val_0_mse: 0.05135 |  0:01:38s\n",
      "epoch 7  | loss: 0.04039 | val_0_mse: 0.0338  |  0:01:52s\n",
      "epoch 8  | loss: 0.03876 | val_0_mse: 0.03004 |  0:02:07s\n",
      "epoch 9  | loss: 0.02885 | val_0_mse: 0.03211 |  0:02:21s\n",
      "epoch 10 | loss: 0.03377 | val_0_mse: 0.01753 |  0:02:35s\n",
      "epoch 11 | loss: 0.03244 | val_0_mse: 0.01978 |  0:02:49s\n",
      "epoch 12 | loss: 0.02772 | val_0_mse: 0.04663 |  0:03:03s\n",
      "epoch 13 | loss: 0.02567 | val_0_mse: 0.02291 |  0:03:17s\n",
      "epoch 14 | loss: 0.02084 | val_0_mse: 0.01934 |  0:03:31s\n",
      "epoch 15 | loss: 0.02543 | val_0_mse: 0.01246 |  0:03:46s\n",
      "epoch 16 | loss: 0.02112 | val_0_mse: 0.01094 |  0:04:00s\n",
      "epoch 17 | loss: 0.02431 | val_0_mse: 0.01585 |  0:04:14s\n",
      "epoch 18 | loss: 0.01642 | val_0_mse: 0.05235 |  0:04:28s\n",
      "epoch 19 | loss: 0.01902 | val_0_mse: 0.01058 |  0:04:42s\n",
      "epoch 20 | loss: 0.02356 | val_0_mse: 0.04549 |  0:04:57s\n",
      "epoch 21 | loss: 0.02096 | val_0_mse: 0.02539 |  0:05:11s\n",
      "epoch 22 | loss: 0.02213 | val_0_mse: 0.01349 |  0:05:25s\n",
      "epoch 23 | loss: 0.01845 | val_0_mse: 0.02009 |  0:05:39s\n",
      "epoch 24 | loss: 0.01936 | val_0_mse: 0.01111 |  0:05:53s\n",
      "epoch 25 | loss: 0.01846 | val_0_mse: 0.00689 |  0:06:07s\n",
      "epoch 26 | loss: 0.01642 | val_0_mse: 0.04493 |  0:06:22s\n",
      "epoch 27 | loss: 0.01848 | val_0_mse: 0.00714 |  0:06:36s\n",
      "epoch 28 | loss: 0.02112 | val_0_mse: 0.0101  |  0:06:50s\n",
      "epoch 29 | loss: 0.01617 | val_0_mse: 0.01222 |  0:07:04s\n",
      "epoch 30 | loss: 0.01535 | val_0_mse: 0.01117 |  0:07:18s\n",
      "epoch 31 | loss: 0.01968 | val_0_mse: 0.02382 |  0:07:32s\n",
      "epoch 32 | loss: 0.0206  | val_0_mse: 0.03169 |  0:07:46s\n",
      "epoch 33 | loss: 0.01816 | val_0_mse: 0.02857 |  0:08:01s\n",
      "epoch 34 | loss: 0.01512 | val_0_mse: 0.0163  |  0:08:15s\n",
      "epoch 35 | loss: 0.01508 | val_0_mse: 0.01823 |  0:08:29s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mse = 0.00689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007046 - Best MSE: 0.007046\n",
      "Model R2 Score: 0.968212 - Best R2 Score: 0.968212\n",
      "\n",
      "Iterations 3/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.60696 | val_0_mse: 0.70206 |  0:00:08s\n",
      "epoch 1  | loss: 0.23767 | val_0_mse: 0.41681 |  0:00:16s\n",
      "epoch 2  | loss: 0.15    | val_0_mse: 0.13363 |  0:00:25s\n",
      "epoch 3  | loss: 0.11714 | val_0_mse: 0.12192 |  0:00:33s\n",
      "epoch 4  | loss: 0.1159  | val_0_mse: 0.08962 |  0:00:42s\n",
      "epoch 5  | loss: 0.09512 | val_0_mse: 0.0757  |  0:00:51s\n",
      "epoch 6  | loss: 0.10113 | val_0_mse: 0.08143 |  0:00:59s\n",
      "epoch 7  | loss: 0.09179 | val_0_mse: 0.07778 |  0:01:08s\n",
      "epoch 8  | loss: 0.08172 | val_0_mse: 0.0692  |  0:01:16s\n",
      "epoch 9  | loss: 0.07743 | val_0_mse: 0.06641 |  0:01:25s\n",
      "epoch 10 | loss: 0.07181 | val_0_mse: 0.05605 |  0:01:33s\n",
      "epoch 11 | loss: 0.06347 | val_0_mse: 0.05821 |  0:01:42s\n",
      "epoch 12 | loss: 0.07167 | val_0_mse: 0.06324 |  0:01:50s\n",
      "epoch 13 | loss: 0.05859 | val_0_mse: 0.0554  |  0:01:59s\n",
      "epoch 14 | loss: 0.05291 | val_0_mse: 0.04466 |  0:02:07s\n",
      "epoch 15 | loss: 0.05939 | val_0_mse: 0.04134 |  0:02:16s\n",
      "epoch 16 | loss: 0.06154 | val_0_mse: 0.04655 |  0:02:24s\n",
      "epoch 17 | loss: 0.05499 | val_0_mse: 0.04923 |  0:02:33s\n",
      "epoch 18 | loss: 0.06104 | val_0_mse: 0.0389  |  0:02:41s\n",
      "epoch 19 | loss: 0.04602 | val_0_mse: 0.04498 |  0:02:50s\n",
      "epoch 20 | loss: 0.0479  | val_0_mse: 0.03708 |  0:02:58s\n",
      "epoch 21 | loss: 0.04526 | val_0_mse: 0.0479  |  0:03:07s\n",
      "epoch 22 | loss: 0.04874 | val_0_mse: 0.03994 |  0:03:15s\n",
      "epoch 23 | loss: 0.04977 | val_0_mse: 0.05077 |  0:03:24s\n",
      "epoch 24 | loss: 0.04126 | val_0_mse: 0.03789 |  0:03:33s\n",
      "epoch 25 | loss: 0.04032 | val_0_mse: 0.03815 |  0:03:41s\n",
      "epoch 26 | loss: 0.03652 | val_0_mse: 0.0321  |  0:03:50s\n",
      "epoch 27 | loss: 0.04104 | val_0_mse: 0.02758 |  0:03:58s\n",
      "epoch 28 | loss: 0.03751 | val_0_mse: 0.02331 |  0:04:07s\n",
      "epoch 29 | loss: 0.03026 | val_0_mse: 0.05476 |  0:04:15s\n",
      "epoch 30 | loss: 0.03243 | val_0_mse: 0.02604 |  0:04:24s\n",
      "epoch 31 | loss: 0.02931 | val_0_mse: 0.04413 |  0:04:32s\n",
      "epoch 32 | loss: 0.03064 | val_0_mse: 0.03979 |  0:04:41s\n",
      "epoch 33 | loss: 0.04123 | val_0_mse: 0.0381  |  0:04:49s\n",
      "epoch 34 | loss: 0.03379 | val_0_mse: 0.03218 |  0:04:58s\n",
      "epoch 35 | loss: 0.02378 | val_0_mse: 0.01964 |  0:05:06s\n",
      "epoch 36 | loss: 0.01972 | val_0_mse: 0.01507 |  0:05:15s\n",
      "epoch 37 | loss: 0.01752 | val_0_mse: 0.01231 |  0:05:23s\n",
      "epoch 38 | loss: 0.02098 | val_0_mse: 0.01976 |  0:05:32s\n",
      "epoch 39 | loss: 0.01601 | val_0_mse: 0.01852 |  0:05:40s\n",
      "epoch 40 | loss: 0.01715 | val_0_mse: 0.00939 |  0:05:49s\n",
      "epoch 41 | loss: 0.01798 | val_0_mse: 0.01602 |  0:05:57s\n",
      "epoch 42 | loss: 0.01464 | val_0_mse: 0.0089  |  0:06:05s\n",
      "epoch 43 | loss: 0.01373 | val_0_mse: 0.03395 |  0:06:14s\n",
      "epoch 44 | loss: 0.01218 | val_0_mse: 0.01796 |  0:06:22s\n",
      "epoch 45 | loss: 0.01188 | val_0_mse: 0.0083  |  0:06:31s\n",
      "epoch 46 | loss: 0.01241 | val_0_mse: 0.01612 |  0:06:39s\n",
      "epoch 47 | loss: 0.01227 | val_0_mse: 0.01801 |  0:06:48s\n",
      "epoch 48 | loss: 0.01205 | val_0_mse: 0.01769 |  0:06:56s\n",
      "epoch 49 | loss: 0.01395 | val_0_mse: 0.04819 |  0:07:04s\n",
      "epoch 50 | loss: 0.01329 | val_0_mse: 0.02785 |  0:07:13s\n",
      "epoch 51 | loss: 0.02109 | val_0_mse: 0.04723 |  0:07:21s\n",
      "epoch 52 | loss: 0.02501 | val_0_mse: 0.01948 |  0:07:29s\n",
      "epoch 53 | loss: 0.01988 | val_0_mse: 0.01551 |  0:07:37s\n",
      "epoch 54 | loss: 0.02413 | val_0_mse: 0.02483 |  0:07:45s\n",
      "epoch 55 | loss: 0.01718 | val_0_mse: 0.01111 |  0:07:54s\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_mse = 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008292 - Best MSE: 0.007046\n",
      "Model R2 Score: 0.962594 - Best R2 Score: 0.968212\n",
      "\n",
      "Iterations 4/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.0322  | val_0_mse: 0.12472 |  0:00:26s\n",
      "epoch 1  | loss: 0.10677 | val_0_mse: 0.11044 |  0:00:53s\n",
      "epoch 2  | loss: 0.07857 | val_0_mse: 0.06037 |  0:01:19s\n",
      "epoch 3  | loss: 0.06924 | val_0_mse: 0.05551 |  0:01:46s\n",
      "epoch 4  | loss: 0.07492 | val_0_mse: 0.06128 |  0:02:13s\n",
      "epoch 5  | loss: 0.0674  | val_0_mse: 0.04948 |  0:02:39s\n",
      "epoch 6  | loss: 0.06394 | val_0_mse: 0.03717 |  0:03:06s\n",
      "epoch 7  | loss: 0.0513  | val_0_mse: 0.03261 |  0:03:33s\n",
      "epoch 8  | loss: 0.04545 | val_0_mse: 0.03265 |  0:04:00s\n",
      "epoch 9  | loss: 0.03961 | val_0_mse: 0.03605 |  0:04:26s\n",
      "epoch 10 | loss: 0.03393 | val_0_mse: 0.0216  |  0:04:53s\n",
      "epoch 11 | loss: 0.03863 | val_0_mse: 0.01199 |  0:05:20s\n",
      "epoch 12 | loss: 0.03133 | val_0_mse: 0.03793 |  0:05:46s\n",
      "epoch 13 | loss: 0.02908 | val_0_mse: 0.02137 |  0:06:13s\n",
      "epoch 14 | loss: 0.03417 | val_0_mse: 0.01094 |  0:06:39s\n",
      "epoch 15 | loss: 0.02653 | val_0_mse: 0.02428 |  0:07:06s\n",
      "epoch 16 | loss: 0.03111 | val_0_mse: 0.0193  |  0:07:33s\n",
      "epoch 17 | loss: 0.03087 | val_0_mse: 0.02434 |  0:07:59s\n",
      "epoch 18 | loss: 0.03277 | val_0_mse: 0.03177 |  0:08:26s\n",
      "epoch 19 | loss: 0.0306  | val_0_mse: 0.01985 |  0:08:53s\n",
      "epoch 20 | loss: 0.02789 | val_0_mse: 0.01734 |  0:09:19s\n",
      "epoch 21 | loss: 0.02511 | val_0_mse: 0.01276 |  0:09:46s\n",
      "epoch 22 | loss: 0.02528 | val_0_mse: 0.02562 |  0:10:13s\n",
      "epoch 23 | loss: 0.02275 | val_0_mse: 0.02545 |  0:10:39s\n",
      "epoch 24 | loss: 0.02436 | val_0_mse: 0.02339 |  0:11:06s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_mse = 0.01094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.011311 - Best MSE: 0.007046\n",
      "Model R2 Score: 0.948971 - Best R2 Score: 0.968212\n",
      "\n",
      "Iterations 5/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.7142  | val_0_mse: 0.1814  |  0:00:15s\n",
      "epoch 1  | loss: 0.13812 | val_0_mse: 0.0845  |  0:00:31s\n",
      "epoch 2  | loss: 0.11543 | val_0_mse: 0.06948 |  0:00:46s\n",
      "epoch 3  | loss: 0.10758 | val_0_mse: 0.10935 |  0:01:01s\n",
      "epoch 4  | loss: 0.08517 | val_0_mse: 0.08425 |  0:01:16s\n",
      "epoch 5  | loss: 0.07983 | val_0_mse: 0.06571 |  0:01:31s\n",
      "epoch 6  | loss: 0.07952 | val_0_mse: 0.07978 |  0:01:47s\n",
      "epoch 7  | loss: 0.07274 | val_0_mse: 0.0548  |  0:02:02s\n",
      "epoch 8  | loss: 0.05006 | val_0_mse: 0.04219 |  0:02:17s\n",
      "epoch 9  | loss: 0.03913 | val_0_mse: 0.02871 |  0:02:32s\n",
      "epoch 10 | loss: 0.03112 | val_0_mse: 0.0176  |  0:02:47s\n",
      "epoch 11 | loss: 0.032   | val_0_mse: 0.01909 |  0:03:02s\n",
      "epoch 12 | loss: 0.02665 | val_0_mse: 0.02744 |  0:03:17s\n",
      "epoch 13 | loss: 0.0249  | val_0_mse: 0.01158 |  0:03:33s\n",
      "epoch 14 | loss: 0.02881 | val_0_mse: 0.02354 |  0:03:48s\n",
      "epoch 15 | loss: 0.03064 | val_0_mse: 0.0286  |  0:04:02s\n",
      "epoch 16 | loss: 0.02257 | val_0_mse: 0.01607 |  0:04:18s\n",
      "epoch 17 | loss: 0.02007 | val_0_mse: 0.02816 |  0:04:33s\n",
      "epoch 18 | loss: 0.02109 | val_0_mse: 0.01081 |  0:04:48s\n",
      "epoch 19 | loss: 0.01773 | val_0_mse: 0.02044 |  0:05:03s\n",
      "epoch 20 | loss: 0.01736 | val_0_mse: 0.01522 |  0:05:18s\n",
      "epoch 21 | loss: 0.02062 | val_0_mse: 0.01019 |  0:05:33s\n",
      "epoch 22 | loss: 0.01657 | val_0_mse: 0.00959 |  0:05:48s\n",
      "epoch 23 | loss: 0.01553 | val_0_mse: 0.01018 |  0:06:03s\n",
      "epoch 24 | loss: 0.01699 | val_0_mse: 0.00977 |  0:06:18s\n",
      "epoch 25 | loss: 0.01834 | val_0_mse: 0.01812 |  0:06:33s\n",
      "epoch 26 | loss: 0.01789 | val_0_mse: 0.01105 |  0:06:48s\n",
      "epoch 27 | loss: 0.01538 | val_0_mse: 0.01165 |  0:07:03s\n",
      "epoch 28 | loss: 0.01749 | val_0_mse: 0.02114 |  0:07:19s\n",
      "epoch 29 | loss: 0.01789 | val_0_mse: 0.01691 |  0:07:34s\n",
      "epoch 30 | loss: 0.02016 | val_0_mse: 0.01089 |  0:07:49s\n",
      "epoch 31 | loss: 0.02051 | val_0_mse: 0.02041 |  0:08:05s\n",
      "epoch 32 | loss: 0.01468 | val_0_mse: 0.00824 |  0:08:19s\n",
      "epoch 33 | loss: 0.01572 | val_0_mse: 0.01547 |  0:08:35s\n",
      "epoch 34 | loss: 0.01546 | val_0_mse: 0.00874 |  0:08:50s\n",
      "epoch 35 | loss: 0.01388 | val_0_mse: 0.01579 |  0:09:05s\n",
      "epoch 36 | loss: 0.01404 | val_0_mse: 0.00675 |  0:09:20s\n",
      "epoch 37 | loss: 0.0171  | val_0_mse: 0.0251  |  0:09:35s\n",
      "epoch 38 | loss: 0.02278 | val_0_mse: 0.01054 |  0:09:50s\n",
      "epoch 39 | loss: 0.01768 | val_0_mse: 0.02502 |  0:10:05s\n",
      "epoch 40 | loss: 0.01556 | val_0_mse: 0.01265 |  0:10:20s\n",
      "epoch 41 | loss: 0.0151  | val_0_mse: 0.00896 |  0:10:35s\n",
      "epoch 42 | loss: 0.0154  | val_0_mse: 0.01151 |  0:10:50s\n",
      "epoch 43 | loss: 0.01392 | val_0_mse: 0.00905 |  0:11:05s\n",
      "epoch 44 | loss: 0.01656 | val_0_mse: 0.02071 |  0:11:20s\n",
      "epoch 45 | loss: 0.0167  | val_0_mse: 0.00964 |  0:11:35s\n",
      "epoch 46 | loss: 0.01399 | val_0_mse: 0.01499 |  0:11:50s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_mse = 0.00675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006991 - Best MSE: 0.006991\n",
      "Model R2 Score: 0.968461 - Best R2 Score: 0.968461\n",
      "\n",
      "Iterations 6/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.91501 | val_0_mse: 0.57152 |  0:00:08s\n",
      "epoch 1  | loss: 0.2539  | val_0_mse: 0.13418 |  0:00:17s\n",
      "epoch 2  | loss: 0.12859 | val_0_mse: 0.10908 |  0:00:26s\n",
      "epoch 3  | loss: 0.08605 | val_0_mse: 0.09569 |  0:00:35s\n",
      "epoch 4  | loss: 0.0788  | val_0_mse: 0.06572 |  0:00:44s\n",
      "epoch 5  | loss: 0.07673 | val_0_mse: 0.07612 |  0:00:53s\n",
      "epoch 6  | loss: 0.06845 | val_0_mse: 0.06675 |  0:01:01s\n",
      "epoch 7  | loss: 0.07048 | val_0_mse: 0.05866 |  0:01:10s\n",
      "epoch 8  | loss: 0.06467 | val_0_mse: 0.05762 |  0:01:19s\n",
      "epoch 9  | loss: 0.05798 | val_0_mse: 0.05584 |  0:01:28s\n",
      "epoch 10 | loss: 0.05276 | val_0_mse: 0.04129 |  0:01:36s\n",
      "epoch 11 | loss: 0.04961 | val_0_mse: 0.03993 |  0:01:45s\n",
      "epoch 12 | loss: 0.04385 | val_0_mse: 0.03242 |  0:01:54s\n",
      "epoch 13 | loss: 0.03967 | val_0_mse: 0.04237 |  0:02:03s\n",
      "epoch 14 | loss: 0.03521 | val_0_mse: 0.02485 |  0:02:12s\n",
      "epoch 15 | loss: 0.03295 | val_0_mse: 0.05112 |  0:02:20s\n",
      "epoch 16 | loss: 0.03206 | val_0_mse: 0.05616 |  0:02:29s\n",
      "epoch 17 | loss: 0.03756 | val_0_mse: 0.09204 |  0:02:38s\n",
      "epoch 18 | loss: 0.03219 | val_0_mse: 0.04809 |  0:02:47s\n",
      "epoch 19 | loss: 0.04205 | val_0_mse: 0.0333  |  0:02:56s\n",
      "epoch 20 | loss: 0.03512 | val_0_mse: 0.0245  |  0:03:05s\n",
      "epoch 21 | loss: 0.02674 | val_0_mse: 0.03153 |  0:03:13s\n",
      "epoch 22 | loss: 0.02641 | val_0_mse: 0.03194 |  0:03:22s\n",
      "epoch 23 | loss: 0.02238 | val_0_mse: 0.01356 |  0:03:31s\n",
      "epoch 24 | loss: 0.02075 | val_0_mse: 0.01844 |  0:03:40s\n",
      "epoch 25 | loss: 0.01826 | val_0_mse: 0.0241  |  0:03:48s\n",
      "epoch 26 | loss: 0.01957 | val_0_mse: 0.03284 |  0:03:58s\n",
      "epoch 27 | loss: 0.01638 | val_0_mse: 0.01472 |  0:04:06s\n",
      "epoch 28 | loss: 0.01537 | val_0_mse: 0.0103  |  0:04:15s\n",
      "epoch 29 | loss: 0.01453 | val_0_mse: 0.01091 |  0:04:24s\n",
      "epoch 30 | loss: 0.01493 | val_0_mse: 0.00885 |  0:04:33s\n",
      "epoch 31 | loss: 0.01548 | val_0_mse: 0.02515 |  0:04:42s\n",
      "epoch 32 | loss: 0.01605 | val_0_mse: 0.01341 |  0:04:51s\n",
      "epoch 33 | loss: 0.01393 | val_0_mse: 0.01235 |  0:05:00s\n",
      "epoch 34 | loss: 0.01251 | val_0_mse: 0.00849 |  0:05:08s\n",
      "epoch 35 | loss: 0.01243 | val_0_mse: 0.01438 |  0:05:17s\n",
      "epoch 36 | loss: 0.01252 | val_0_mse: 0.02539 |  0:05:26s\n",
      "epoch 37 | loss: 0.01113 | val_0_mse: 0.01965 |  0:05:35s\n",
      "epoch 38 | loss: 0.01251 | val_0_mse: 0.00739 |  0:05:43s\n",
      "epoch 39 | loss: 0.01229 | val_0_mse: 0.00737 |  0:05:52s\n",
      "epoch 40 | loss: 0.01127 | val_0_mse: 0.00729 |  0:06:01s\n",
      "epoch 41 | loss: 0.01094 | val_0_mse: 0.00739 |  0:06:10s\n",
      "epoch 42 | loss: 0.0128  | val_0_mse: 0.00741 |  0:06:19s\n",
      "epoch 43 | loss: 0.01222 | val_0_mse: 0.01261 |  0:06:28s\n",
      "epoch 44 | loss: 0.01159 | val_0_mse: 0.00991 |  0:06:36s\n",
      "epoch 45 | loss: 0.01147 | val_0_mse: 0.0118  |  0:06:45s\n",
      "epoch 46 | loss: 0.00953 | val_0_mse: 0.01007 |  0:06:54s\n",
      "epoch 47 | loss: 0.01346 | val_0_mse: 0.01701 |  0:07:03s\n",
      "epoch 48 | loss: 0.01314 | val_0_mse: 0.02405 |  0:07:12s\n",
      "epoch 49 | loss: 0.01489 | val_0_mse: 0.01229 |  0:07:20s\n",
      "epoch 50 | loss: 0.02239 | val_0_mse: 0.02391 |  0:07:29s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_mse = 0.00729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007125 - Best MSE: 0.006991\n",
      "Model R2 Score: 0.967859 - Best R2 Score: 0.968461\n",
      "\n",
      "Iterations 7/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57458 | val_0_mse: 0.08801 |  0:00:26s\n",
      "epoch 1  | loss: 0.11498 | val_0_mse: 0.09463 |  0:01:02s\n",
      "epoch 2  | loss: 0.10294 | val_0_mse: 0.07755 |  0:01:29s\n",
      "epoch 3  | loss: 0.07634 | val_0_mse: 0.06462 |  0:01:56s\n",
      "epoch 4  | loss: 0.07245 | val_0_mse: 0.08461 |  0:02:23s\n",
      "epoch 5  | loss: 0.06152 | val_0_mse: 0.04136 |  0:02:51s\n",
      "epoch 6  | loss: 0.05607 | val_0_mse: 0.04155 |  0:03:17s\n",
      "epoch 7  | loss: 0.04351 | val_0_mse: 0.02981 |  0:03:44s\n",
      "epoch 8  | loss: 0.03557 | val_0_mse: 0.0274  |  0:04:11s\n",
      "epoch 9  | loss: 0.03435 | val_0_mse: 0.03241 |  0:04:38s\n",
      "epoch 10 | loss: 0.03005 | val_0_mse: 0.038   |  0:05:04s\n",
      "epoch 11 | loss: 0.02778 | val_0_mse: 0.01356 |  0:05:31s\n",
      "epoch 12 | loss: 0.03125 | val_0_mse: 0.01034 |  0:05:58s\n",
      "epoch 13 | loss: 0.02934 | val_0_mse: 0.02493 |  0:06:25s\n",
      "epoch 14 | loss: 0.02635 | val_0_mse: 0.02422 |  0:06:51s\n",
      "epoch 15 | loss: 0.02744 | val_0_mse: 0.02278 |  0:07:18s\n",
      "epoch 16 | loss: 0.03245 | val_0_mse: 0.04373 |  0:07:45s\n",
      "epoch 17 | loss: 0.02914 | val_0_mse: 0.0205  |  0:08:11s\n",
      "epoch 18 | loss: 0.02579 | val_0_mse: 0.01454 |  0:08:38s\n",
      "epoch 19 | loss: 0.02583 | val_0_mse: 0.02778 |  0:09:05s\n",
      "epoch 20 | loss: 0.02584 | val_0_mse: 0.01189 |  0:09:31s\n",
      "epoch 21 | loss: 0.02601 | val_0_mse: 0.01341 |  0:09:58s\n",
      "epoch 22 | loss: 0.0273  | val_0_mse: 0.04138 |  0:10:25s\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_mse = 0.01034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009202 - Best MSE: 0.006991\n",
      "Model R2 Score: 0.958487 - Best R2 Score: 0.968461\n",
      "\n",
      "Iterations 8/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.95835 | val_0_mse: 0.2774  |  0:00:15s\n",
      "epoch 1  | loss: 0.17963 | val_0_mse: 0.37709 |  0:00:30s\n",
      "epoch 2  | loss: 0.15211 | val_0_mse: 0.13126 |  0:00:45s\n",
      "epoch 3  | loss: 0.12996 | val_0_mse: 0.11091 |  0:01:00s\n",
      "epoch 4  | loss: 0.12344 | val_0_mse: 0.09099 |  0:01:15s\n",
      "epoch 5  | loss: 0.10379 | val_0_mse: 0.1475  |  0:01:30s\n",
      "epoch 6  | loss: 0.09153 | val_0_mse: 0.12902 |  0:01:45s\n",
      "epoch 7  | loss: 0.09364 | val_0_mse: 0.12619 |  0:02:00s\n",
      "epoch 8  | loss: 0.06799 | val_0_mse: 0.10843 |  0:02:15s\n",
      "epoch 9  | loss: 0.07063 | val_0_mse: 0.06796 |  0:02:30s\n",
      "epoch 10 | loss: 0.04943 | val_0_mse: 0.04951 |  0:02:45s\n",
      "epoch 11 | loss: 0.04957 | val_0_mse: 0.06802 |  0:03:00s\n",
      "epoch 12 | loss: 0.03922 | val_0_mse: 0.03433 |  0:03:15s\n",
      "epoch 13 | loss: 0.03162 | val_0_mse: 0.04463 |  0:03:30s\n",
      "epoch 14 | loss: 0.03157 | val_0_mse: 0.01472 |  0:03:45s\n",
      "epoch 15 | loss: 0.03133 | val_0_mse: 0.04755 |  0:04:00s\n",
      "epoch 16 | loss: 0.03436 | val_0_mse: 0.01717 |  0:04:15s\n",
      "epoch 17 | loss: 0.03302 | val_0_mse: 0.03313 |  0:04:30s\n",
      "epoch 18 | loss: 0.03486 | val_0_mse: 0.08982 |  0:04:45s\n",
      "epoch 19 | loss: 0.03197 | val_0_mse: 0.04613 |  0:05:00s\n",
      "epoch 20 | loss: 0.03236 | val_0_mse: 0.01608 |  0:05:15s\n",
      "epoch 21 | loss: 0.02266 | val_0_mse: 0.01456 |  0:05:30s\n",
      "epoch 22 | loss: 0.02378 | val_0_mse: 0.0429  |  0:05:45s\n",
      "epoch 23 | loss: 0.02337 | val_0_mse: 0.02939 |  0:06:00s\n",
      "epoch 24 | loss: 0.02254 | val_0_mse: 0.00988 |  0:06:15s\n",
      "epoch 25 | loss: 0.02495 | val_0_mse: 0.00787 |  0:06:30s\n",
      "epoch 26 | loss: 0.01742 | val_0_mse: 0.0127  |  0:06:45s\n",
      "epoch 27 | loss: 0.01993 | val_0_mse: 0.01289 |  0:07:01s\n",
      "epoch 28 | loss: 0.01647 | val_0_mse: 0.01282 |  0:07:16s\n",
      "epoch 29 | loss: 0.01962 | val_0_mse: 0.01997 |  0:07:31s\n",
      "epoch 30 | loss: 0.01492 | val_0_mse: 0.00661 |  0:07:46s\n",
      "epoch 31 | loss: 0.01716 | val_0_mse: 0.0293  |  0:08:01s\n",
      "epoch 32 | loss: 0.01831 | val_0_mse: 0.00875 |  0:08:16s\n",
      "epoch 33 | loss: 0.01949 | val_0_mse: 0.03067 |  0:08:31s\n",
      "epoch 34 | loss: 0.01745 | val_0_mse: 0.01868 |  0:08:46s\n",
      "epoch 35 | loss: 0.01969 | val_0_mse: 0.00658 |  0:09:01s\n",
      "epoch 36 | loss: 0.01768 | val_0_mse: 0.01545 |  0:09:16s\n",
      "epoch 37 | loss: 0.01714 | val_0_mse: 0.01687 |  0:09:31s\n",
      "epoch 38 | loss: 0.01506 | val_0_mse: 0.01517 |  0:09:46s\n",
      "epoch 39 | loss: 0.01991 | val_0_mse: 0.02535 |  0:10:01s\n",
      "epoch 40 | loss: 0.01628 | val_0_mse: 0.00736 |  0:10:16s\n",
      "epoch 41 | loss: 0.01472 | val_0_mse: 0.00711 |  0:10:31s\n",
      "epoch 42 | loss: 0.01713 | val_0_mse: 0.01246 |  0:10:46s\n",
      "epoch 43 | loss: 0.01607 | val_0_mse: 0.0241  |  0:11:01s\n",
      "epoch 44 | loss: 0.01656 | val_0_mse: 0.00807 |  0:11:16s\n",
      "epoch 45 | loss: 0.02036 | val_0_mse: 0.0679  |  0:11:31s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_mse = 0.00658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006324 - Best MSE: 0.006324\n",
      "Model R2 Score: 0.971470 - Best R2 Score: 0.971470\n",
      "\n",
      "Iterations 9/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.57674 | val_0_mse: 0.90057 |  0:00:08s\n",
      "epoch 1  | loss: 0.29655 | val_0_mse: 0.16383 |  0:00:17s\n",
      "epoch 2  | loss: 0.09866 | val_0_mse: 0.15316 |  0:00:26s\n",
      "epoch 3  | loss: 0.07353 | val_0_mse: 0.1626  |  0:00:35s\n",
      "epoch 4  | loss: 0.06237 | val_0_mse: 0.11498 |  0:00:44s\n",
      "epoch 5  | loss: 0.0645  | val_0_mse: 0.08086 |  0:00:52s\n",
      "epoch 6  | loss: 0.06669 | val_0_mse: 0.05456 |  0:01:01s\n",
      "epoch 7  | loss: 0.05303 | val_0_mse: 0.05651 |  0:01:10s\n",
      "epoch 8  | loss: 0.0517  | val_0_mse: 0.03983 |  0:01:19s\n",
      "epoch 9  | loss: 0.0523  | val_0_mse: 0.04055 |  0:01:28s\n",
      "epoch 10 | loss: 0.04953 | val_0_mse: 0.04454 |  0:01:36s\n",
      "epoch 11 | loss: 0.05329 | val_0_mse: 0.04533 |  0:01:45s\n",
      "epoch 12 | loss: 0.0493  | val_0_mse: 0.03455 |  0:01:54s\n",
      "epoch 13 | loss: 0.05018 | val_0_mse: 0.04229 |  0:02:03s\n",
      "epoch 14 | loss: 0.04707 | val_0_mse: 0.03728 |  0:02:11s\n",
      "epoch 15 | loss: 0.05235 | val_0_mse: 0.03635 |  0:02:20s\n",
      "epoch 16 | loss: 0.0452  | val_0_mse: 0.03557 |  0:02:29s\n",
      "epoch 17 | loss: 0.05567 | val_0_mse: 0.05267 |  0:02:38s\n",
      "epoch 18 | loss: 0.05058 | val_0_mse: 0.04266 |  0:02:47s\n",
      "epoch 19 | loss: 0.04394 | val_0_mse: 0.03491 |  0:02:55s\n",
      "epoch 20 | loss: 0.04379 | val_0_mse: 0.04429 |  0:03:04s\n",
      "epoch 21 | loss: 0.0396  | val_0_mse: 0.03468 |  0:03:13s\n",
      "epoch 22 | loss: 0.04493 | val_0_mse: 0.03235 |  0:03:22s\n",
      "epoch 23 | loss: 0.04055 | val_0_mse: 0.04852 |  0:03:31s\n",
      "epoch 24 | loss: 0.03883 | val_0_mse: 0.03572 |  0:03:42s\n",
      "epoch 25 | loss: 0.03846 | val_0_mse: 0.02793 |  0:03:51s\n",
      "epoch 26 | loss: 0.04397 | val_0_mse: 0.02781 |  0:04:00s\n",
      "epoch 27 | loss: 0.03364 | val_0_mse: 0.02743 |  0:04:09s\n",
      "epoch 28 | loss: 0.03286 | val_0_mse: 0.02442 |  0:04:18s\n",
      "epoch 29 | loss: 0.03534 | val_0_mse: 0.05142 |  0:04:27s\n",
      "epoch 30 | loss: 0.02721 | val_0_mse: 0.021   |  0:04:35s\n",
      "epoch 31 | loss: 0.02557 | val_0_mse: 0.02773 |  0:04:44s\n",
      "epoch 32 | loss: 0.02603 | val_0_mse: 0.01574 |  0:04:55s\n",
      "epoch 33 | loss: 0.02191 | val_0_mse: 0.01619 |  0:05:03s\n",
      "epoch 34 | loss: 0.02013 | val_0_mse: 0.01761 |  0:05:12s\n",
      "epoch 35 | loss: 0.01568 | val_0_mse: 0.01566 |  0:05:21s\n",
      "epoch 36 | loss: 0.02196 | val_0_mse: 0.02252 |  0:05:30s\n",
      "epoch 37 | loss: 0.01968 | val_0_mse: 0.01073 |  0:05:38s\n",
      "epoch 38 | loss: 0.01698 | val_0_mse: 0.00923 |  0:05:47s\n",
      "epoch 39 | loss: 0.01478 | val_0_mse: 0.01397 |  0:05:56s\n",
      "epoch 40 | loss: 0.01574 | val_0_mse: 0.00869 |  0:06:05s\n",
      "epoch 41 | loss: 0.01398 | val_0_mse: 0.01043 |  0:06:15s\n",
      "epoch 42 | loss: 0.01363 | val_0_mse: 0.01357 |  0:06:24s\n",
      "epoch 43 | loss: 0.01941 | val_0_mse: 0.02117 |  0:06:33s\n",
      "epoch 44 | loss: 0.01021 | val_0_mse: 0.0071  |  0:06:41s\n",
      "epoch 45 | loss: 0.01143 | val_0_mse: 0.00719 |  0:06:50s\n",
      "epoch 46 | loss: 0.01388 | val_0_mse: 0.02635 |  0:06:59s\n",
      "epoch 47 | loss: 0.01307 | val_0_mse: 0.01666 |  0:07:08s\n",
      "epoch 48 | loss: 0.01171 | val_0_mse: 0.00595 |  0:07:17s\n",
      "epoch 49 | loss: 0.01557 | val_0_mse: 0.01037 |  0:07:26s\n",
      "epoch 50 | loss: 0.01414 | val_0_mse: 0.00847 |  0:07:35s\n",
      "epoch 51 | loss: 0.00975 | val_0_mse: 0.03731 |  0:07:44s\n",
      "epoch 52 | loss: 0.01533 | val_0_mse: 0.00721 |  0:07:53s\n",
      "epoch 53 | loss: 0.01133 | val_0_mse: 0.00506 |  0:08:02s\n",
      "epoch 54 | loss: 0.01048 | val_0_mse: 0.00766 |  0:08:11s\n",
      "epoch 55 | loss: 0.00959 | val_0_mse: 0.00667 |  0:08:19s\n",
      "epoch 56 | loss: 0.01012 | val_0_mse: 0.01365 |  0:08:28s\n",
      "epoch 57 | loss: 0.01199 | val_0_mse: 0.00519 |  0:08:37s\n",
      "epoch 58 | loss: 0.01026 | val_0_mse: 0.00788 |  0:08:47s\n",
      "epoch 59 | loss: 0.00984 | val_0_mse: 0.02385 |  0:08:56s\n",
      "epoch 60 | loss: 0.01108 | val_0_mse: 0.00617 |  0:09:05s\n",
      "epoch 61 | loss: 0.01356 | val_0_mse: 0.00673 |  0:09:14s\n",
      "epoch 62 | loss: 0.00909 | val_0_mse: 0.00528 |  0:09:23s\n",
      "epoch 63 | loss: 0.01111 | val_0_mse: 0.00665 |  0:09:31s\n",
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_mse = 0.00506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.005215 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.976475 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 10/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.77684 | val_0_mse: 0.16572 |  0:00:28s\n",
      "epoch 1  | loss: 0.15538 | val_0_mse: 0.14652 |  0:00:58s\n",
      "epoch 2  | loss: 0.12942 | val_0_mse: 0.08875 |  0:01:26s\n",
      "epoch 3  | loss: 0.10484 | val_0_mse: 0.08114 |  0:01:55s\n",
      "epoch 4  | loss: 0.09092 | val_0_mse: 0.06871 |  0:02:23s\n",
      "epoch 5  | loss: 0.08896 | val_0_mse: 0.07984 |  0:02:51s\n",
      "epoch 6  | loss: 0.08475 | val_0_mse: 0.05646 |  0:03:18s\n",
      "epoch 7  | loss: 0.08076 | val_0_mse: 0.13423 |  0:03:46s\n",
      "epoch 8  | loss: 0.07998 | val_0_mse: 0.06609 |  0:04:14s\n",
      "epoch 9  | loss: 0.07397 | val_0_mse: 0.05166 |  0:04:42s\n",
      "epoch 10 | loss: 0.06369 | val_0_mse: 0.07347 |  0:05:09s\n",
      "epoch 11 | loss: 0.04542 | val_0_mse: 0.02641 |  0:05:37s\n",
      "epoch 12 | loss: 0.04136 | val_0_mse: 0.03779 |  0:06:05s\n",
      "epoch 13 | loss: 0.03367 | val_0_mse: 0.02761 |  0:06:33s\n",
      "epoch 14 | loss: 0.03374 | val_0_mse: 0.02465 |  0:07:01s\n",
      "epoch 15 | loss: 0.03606 | val_0_mse: 0.01356 |  0:07:28s\n",
      "epoch 16 | loss: 0.0289  | val_0_mse: 0.01632 |  0:07:56s\n",
      "epoch 17 | loss: 0.03189 | val_0_mse: 0.02028 |  0:08:24s\n",
      "epoch 18 | loss: 0.02501 | val_0_mse: 0.03795 |  0:08:51s\n",
      "epoch 19 | loss: 0.02489 | val_0_mse: 0.01356 |  0:09:19s\n",
      "epoch 20 | loss: 0.0264  | val_0_mse: 0.0184  |  0:09:47s\n",
      "epoch 21 | loss: 0.02325 | val_0_mse: 0.01325 |  0:10:14s\n",
      "epoch 22 | loss: 0.02125 | val_0_mse: 0.01152 |  0:10:42s\n",
      "epoch 23 | loss: 0.02195 | val_0_mse: 0.01594 |  0:11:10s\n",
      "epoch 24 | loss: 0.02213 | val_0_mse: 0.01651 |  0:11:38s\n",
      "epoch 25 | loss: 0.01991 | val_0_mse: 0.02478 |  0:12:05s\n",
      "epoch 26 | loss: 0.02244 | val_0_mse: 0.0307  |  0:12:33s\n",
      "epoch 27 | loss: 0.02193 | val_0_mse: 0.01811 |  0:13:01s\n",
      "epoch 28 | loss: 0.02128 | val_0_mse: 0.01297 |  0:13:29s\n",
      "epoch 29 | loss: 0.02184 | val_0_mse: 0.02038 |  0:13:57s\n",
      "epoch 30 | loss: 0.02348 | val_0_mse: 0.01472 |  0:14:24s\n",
      "epoch 31 | loss: 0.021   | val_0_mse: 0.01072 |  0:14:52s\n",
      "epoch 32 | loss: 0.02242 | val_0_mse: 0.01332 |  0:15:20s\n",
      "epoch 33 | loss: 0.02075 | val_0_mse: 0.01513 |  0:15:49s\n",
      "epoch 34 | loss: 0.01805 | val_0_mse: 0.02034 |  0:16:16s\n",
      "epoch 35 | loss: 0.02219 | val_0_mse: 0.01812 |  0:16:44s\n",
      "epoch 36 | loss: 0.0207  | val_0_mse: 0.01748 |  0:17:12s\n",
      "epoch 37 | loss: 0.01839 | val_0_mse: 0.03985 |  0:17:40s\n",
      "epoch 38 | loss: 0.01833 | val_0_mse: 0.05485 |  0:18:07s\n",
      "epoch 39 | loss: 0.0178  | val_0_mse: 0.03515 |  0:18:35s\n",
      "epoch 40 | loss: 0.01927 | val_0_mse: 0.03976 |  0:19:02s\n",
      "epoch 41 | loss: 0.01947 | val_0_mse: 0.01593 |  0:19:30s\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_mse = 0.01072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.011109 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.949884 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 11/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.03858 | val_0_mse: 0.33545 |  0:00:15s\n",
      "epoch 1  | loss: 0.21911 | val_0_mse: 0.17263 |  0:00:30s\n",
      "epoch 2  | loss: 0.13633 | val_0_mse: 0.19298 |  0:00:45s\n",
      "epoch 3  | loss: 0.10738 | val_0_mse: 0.08744 |  0:01:00s\n",
      "epoch 4  | loss: 0.09541 | val_0_mse: 0.08825 |  0:01:16s\n",
      "epoch 5  | loss: 0.08832 | val_0_mse: 0.23743 |  0:01:31s\n",
      "epoch 6  | loss: 0.08394 | val_0_mse: 0.0633  |  0:01:47s\n",
      "epoch 7  | loss: 0.06788 | val_0_mse: 0.05263 |  0:02:02s\n",
      "epoch 8  | loss: 0.07118 | val_0_mse: 0.05793 |  0:02:17s\n",
      "epoch 9  | loss: 0.07517 | val_0_mse: 0.10175 |  0:02:32s\n",
      "epoch 10 | loss: 0.06307 | val_0_mse: 0.06452 |  0:02:48s\n",
      "epoch 11 | loss: 0.06699 | val_0_mse: 0.05366 |  0:03:03s\n",
      "epoch 12 | loss: 0.04518 | val_0_mse: 0.03876 |  0:03:18s\n",
      "epoch 13 | loss: 0.03653 | val_0_mse: 0.04301 |  0:03:33s\n",
      "epoch 14 | loss: 0.03546 | val_0_mse: 0.02548 |  0:03:49s\n",
      "epoch 15 | loss: 0.03388 | val_0_mse: 0.01884 |  0:04:04s\n",
      "epoch 16 | loss: 0.02752 | val_0_mse: 0.01777 |  0:04:19s\n",
      "epoch 17 | loss: 0.02824 | val_0_mse: 0.05791 |  0:04:34s\n",
      "epoch 18 | loss: 0.02695 | val_0_mse: 0.01624 |  0:04:50s\n",
      "epoch 19 | loss: 0.02586 | val_0_mse: 0.03922 |  0:05:05s\n",
      "epoch 20 | loss: 0.0243  | val_0_mse: 0.01226 |  0:05:20s\n",
      "epoch 21 | loss: 0.01864 | val_0_mse: 0.01129 |  0:05:36s\n",
      "epoch 22 | loss: 0.02207 | val_0_mse: 0.01369 |  0:05:51s\n",
      "epoch 23 | loss: 0.01896 | val_0_mse: 0.01427 |  0:06:06s\n",
      "epoch 24 | loss: 0.01913 | val_0_mse: 0.00943 |  0:06:21s\n",
      "epoch 25 | loss: 0.01885 | val_0_mse: 0.05413 |  0:06:36s\n",
      "epoch 26 | loss: 0.02015 | val_0_mse: 0.01162 |  0:06:52s\n",
      "epoch 27 | loss: 0.01911 | val_0_mse: 0.01516 |  0:07:07s\n",
      "epoch 28 | loss: 0.01599 | val_0_mse: 0.02552 |  0:07:22s\n",
      "epoch 29 | loss: 0.01685 | val_0_mse: 0.01007 |  0:07:37s\n",
      "epoch 30 | loss: 0.01604 | val_0_mse: 0.00792 |  0:07:53s\n",
      "epoch 31 | loss: 0.01497 | val_0_mse: 0.01106 |  0:08:08s\n",
      "epoch 32 | loss: 0.01607 | val_0_mse: 0.01079 |  0:08:23s\n",
      "epoch 33 | loss: 0.01665 | val_0_mse: 1.53804 |  0:08:39s\n",
      "epoch 34 | loss: 0.01454 | val_0_mse: 0.02465 |  0:08:54s\n",
      "epoch 35 | loss: 0.01809 | val_0_mse: 0.00869 |  0:09:09s\n",
      "epoch 36 | loss: 0.01268 | val_0_mse: 0.01481 |  0:09:25s\n",
      "epoch 37 | loss: 0.01507 | val_0_mse: 0.00954 |  0:09:40s\n",
      "epoch 38 | loss: 0.0161  | val_0_mse: 0.02945 |  0:09:55s\n",
      "epoch 39 | loss: 0.01749 | val_0_mse: 0.00896 |  0:10:11s\n",
      "epoch 40 | loss: 0.01653 | val_0_mse: 0.00817 |  0:10:26s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_mse = 0.00792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008784 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.960373 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 12/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.70208 | val_0_mse: 0.33373 |  0:00:09s\n",
      "epoch 1  | loss: 0.27153 | val_0_mse: 0.19291 |  0:00:18s\n",
      "epoch 2  | loss: 0.1464  | val_0_mse: 0.12456 |  0:00:27s\n",
      "epoch 3  | loss: 0.12291 | val_0_mse: 0.12573 |  0:00:37s\n",
      "epoch 4  | loss: 0.12575 | val_0_mse: 0.13644 |  0:00:46s\n",
      "epoch 5  | loss: 0.10203 | val_0_mse: 0.07834 |  0:00:55s\n",
      "epoch 6  | loss: 0.08805 | val_0_mse: 0.06289 |  0:01:04s\n",
      "epoch 7  | loss: 0.06833 | val_0_mse: 0.06506 |  0:01:14s\n",
      "epoch 8  | loss: 0.05757 | val_0_mse: 0.04269 |  0:01:23s\n",
      "epoch 9  | loss: 0.04947 | val_0_mse: 0.04623 |  0:01:32s\n",
      "epoch 10 | loss: 0.04715 | val_0_mse: 0.05258 |  0:01:41s\n",
      "epoch 11 | loss: 0.04492 | val_0_mse: 0.04439 |  0:01:51s\n",
      "epoch 12 | loss: 0.03883 | val_0_mse: 0.02361 |  0:02:00s\n",
      "epoch 13 | loss: 0.03618 | val_0_mse: 0.03027 |  0:02:09s\n",
      "epoch 14 | loss: 0.02902 | val_0_mse: 0.0197  |  0:02:18s\n",
      "epoch 15 | loss: 0.03057 | val_0_mse: 0.08094 |  0:02:28s\n",
      "epoch 16 | loss: 0.02436 | val_0_mse: 0.01842 |  0:02:37s\n",
      "epoch 17 | loss: 0.01885 | val_0_mse: 0.0117  |  0:02:46s\n",
      "epoch 18 | loss: 0.01797 | val_0_mse: 0.01177 |  0:02:56s\n",
      "epoch 19 | loss: 0.01752 | val_0_mse: 0.01198 |  0:03:05s\n",
      "epoch 20 | loss: 0.01776 | val_0_mse: 0.01027 |  0:03:14s\n",
      "epoch 21 | loss: 0.01512 | val_0_mse: 0.01108 |  0:03:23s\n",
      "epoch 22 | loss: 0.01723 | val_0_mse: 0.00854 |  0:03:33s\n",
      "epoch 23 | loss: 0.01772 | val_0_mse: 0.01251 |  0:03:42s\n",
      "epoch 24 | loss: 0.01507 | val_0_mse: 0.00959 |  0:03:51s\n",
      "epoch 25 | loss: 0.0142  | val_0_mse: 0.01096 |  0:04:00s\n",
      "epoch 26 | loss: 0.02184 | val_0_mse: 0.01839 |  0:04:09s\n",
      "epoch 27 | loss: 0.01783 | val_0_mse: 0.01244 |  0:04:19s\n",
      "epoch 28 | loss: 0.01414 | val_0_mse: 0.02047 |  0:04:28s\n",
      "epoch 29 | loss: 0.01562 | val_0_mse: 0.02231 |  0:04:37s\n",
      "epoch 30 | loss: 0.01541 | val_0_mse: 0.01843 |  0:04:46s\n",
      "epoch 31 | loss: 0.01411 | val_0_mse: 0.00982 |  0:04:56s\n",
      "epoch 32 | loss: 0.01303 | val_0_mse: 0.01328 |  0:05:05s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_mse = 0.00854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008087 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.963515 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 13/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.92862 | val_0_mse: 0.1558  |  0:00:28s\n",
      "epoch 1  | loss: 0.17521 | val_0_mse: 0.11275 |  0:00:56s\n",
      "epoch 2  | loss: 0.15096 | val_0_mse: 0.1426  |  0:01:23s\n",
      "epoch 3  | loss: 0.12381 | val_0_mse: 0.10549 |  0:01:51s\n",
      "epoch 4  | loss: 0.11287 | val_0_mse: 0.09214 |  0:02:19s\n",
      "epoch 5  | loss: 0.08751 | val_0_mse: 0.06267 |  0:02:47s\n",
      "epoch 6  | loss: 0.0751  | val_0_mse: 0.11381 |  0:03:15s\n",
      "epoch 7  | loss: 0.05774 | val_0_mse: 0.06954 |  0:03:43s\n",
      "epoch 8  | loss: 0.0513  | val_0_mse: 0.03898 |  0:04:11s\n",
      "epoch 9  | loss: 0.0449  | val_0_mse: 0.04111 |  0:04:39s\n",
      "epoch 10 | loss: 0.03598 | val_0_mse: 0.04594 |  0:05:07s\n",
      "epoch 11 | loss: 0.03631 | val_0_mse: 0.0235  |  0:05:35s\n",
      "epoch 12 | loss: 0.03405 | val_0_mse: 0.02016 |  0:06:03s\n",
      "epoch 13 | loss: 0.03132 | val_0_mse: 0.0127  |  0:06:30s\n",
      "epoch 14 | loss: 0.03114 | val_0_mse: 0.07809 |  0:06:59s\n",
      "epoch 15 | loss: 0.0284  | val_0_mse: 0.03705 |  0:07:26s\n",
      "epoch 16 | loss: 0.0273  | val_0_mse: 0.03615 |  0:07:55s\n",
      "epoch 17 | loss: 0.0237  | val_0_mse: 0.01757 |  0:08:23s\n",
      "epoch 18 | loss: 0.02403 | val_0_mse: 0.02497 |  0:08:51s\n",
      "epoch 19 | loss: 0.02511 | val_0_mse: 0.01291 |  0:09:18s\n",
      "epoch 20 | loss: 0.02309 | val_0_mse: 0.01949 |  0:09:47s\n",
      "epoch 21 | loss: 0.02445 | val_0_mse: 0.00837 |  0:10:15s\n",
      "epoch 22 | loss: 0.02325 | val_0_mse: 0.0265  |  0:10:42s\n",
      "epoch 23 | loss: 0.02349 | val_0_mse: 0.04883 |  0:11:11s\n",
      "epoch 24 | loss: 0.02685 | val_0_mse: 0.03903 |  0:11:39s\n",
      "epoch 25 | loss: 0.02228 | val_0_mse: 0.15422 |  0:12:07s\n",
      "epoch 26 | loss: 0.02564 | val_0_mse: 0.01308 |  0:12:35s\n",
      "epoch 27 | loss: 0.02148 | val_0_mse: 0.01516 |  0:13:03s\n",
      "epoch 28 | loss: 0.02587 | val_0_mse: 0.03286 |  0:13:31s\n",
      "epoch 29 | loss: 0.02122 | val_0_mse: 0.03564 |  0:13:59s\n",
      "epoch 30 | loss: 0.02023 | val_0_mse: 0.02937 |  0:14:27s\n",
      "epoch 31 | loss: 0.02052 | val_0_mse: 0.0375  |  0:14:55s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mse = 0.00837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008739 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.960574 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 14/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.27267 | val_0_mse: 0.31029 |  0:00:15s\n",
      "epoch 1  | loss: 0.21974 | val_0_mse: 0.10839 |  0:00:31s\n",
      "epoch 2  | loss: 0.14867 | val_0_mse: 0.15091 |  0:00:47s\n",
      "epoch 3  | loss: 0.12714 | val_0_mse: 0.11786 |  0:01:02s\n",
      "epoch 4  | loss: 0.11872 | val_0_mse: 0.10839 |  0:01:18s\n",
      "epoch 5  | loss: 0.11483 | val_0_mse: 0.14104 |  0:01:34s\n",
      "epoch 6  | loss: 0.09993 | val_0_mse: 0.06989 |  0:01:50s\n",
      "epoch 7  | loss: 0.08131 | val_0_mse: 0.04972 |  0:02:06s\n",
      "epoch 8  | loss: 0.05689 | val_0_mse: 0.03506 |  0:02:21s\n",
      "epoch 9  | loss: 0.04504 | val_0_mse: 0.03274 |  0:02:37s\n",
      "epoch 10 | loss: 0.04428 | val_0_mse: 0.05904 |  0:02:53s\n",
      "epoch 11 | loss: 0.03294 | val_0_mse: 0.02413 |  0:03:09s\n",
      "epoch 12 | loss: 0.03063 | val_0_mse: 0.09421 |  0:03:25s\n",
      "epoch 13 | loss: 0.03308 | val_0_mse: 0.02046 |  0:03:40s\n",
      "epoch 14 | loss: 0.04861 | val_0_mse: 0.05171 |  0:03:56s\n",
      "epoch 15 | loss: 0.03294 | val_0_mse: 0.01498 |  0:04:12s\n",
      "epoch 16 | loss: 0.02549 | val_0_mse: 0.01154 |  0:04:28s\n",
      "epoch 17 | loss: 0.02434 | val_0_mse: 0.02388 |  0:04:44s\n",
      "epoch 18 | loss: 0.03516 | val_0_mse: 0.01774 |  0:04:59s\n",
      "epoch 19 | loss: 0.02109 | val_0_mse: 0.02936 |  0:05:15s\n",
      "epoch 20 | loss: 0.02128 | val_0_mse: 0.01111 |  0:05:31s\n",
      "epoch 21 | loss: 0.02467 | val_0_mse: 0.01133 |  0:05:47s\n",
      "epoch 22 | loss: 0.02078 | val_0_mse: 0.07707 |  0:06:03s\n",
      "epoch 23 | loss: 0.02484 | val_0_mse: 0.02154 |  0:06:18s\n",
      "epoch 24 | loss: 0.01967 | val_0_mse: 0.0273  |  0:06:34s\n",
      "epoch 25 | loss: 0.01949 | val_0_mse: 0.00944 |  0:06:50s\n",
      "epoch 26 | loss: 0.0187  | val_0_mse: 0.00969 |  0:07:06s\n",
      "epoch 27 | loss: 0.02216 | val_0_mse: 0.03389 |  0:07:22s\n",
      "epoch 28 | loss: 0.02442 | val_0_mse: 0.00991 |  0:07:37s\n",
      "epoch 29 | loss: 0.01772 | val_0_mse: 0.00791 |  0:07:53s\n",
      "epoch 30 | loss: 0.01608 | val_0_mse: 0.0077  |  0:08:09s\n",
      "epoch 31 | loss: 0.01872 | val_0_mse: 0.07864 |  0:08:25s\n",
      "epoch 32 | loss: 0.0261  | val_0_mse: 0.01164 |  0:08:40s\n",
      "epoch 33 | loss: 0.01612 | val_0_mse: 0.01016 |  0:08:56s\n",
      "epoch 34 | loss: 0.02016 | val_0_mse: 0.01182 |  0:09:12s\n",
      "epoch 35 | loss: 0.01963 | val_0_mse: 0.01451 |  0:09:28s\n",
      "epoch 36 | loss: 0.01916 | val_0_mse: 0.01246 |  0:09:44s\n",
      "epoch 37 | loss: 0.02045 | val_0_mse: 0.03477 |  0:09:59s\n",
      "epoch 38 | loss: 0.02059 | val_0_mse: 0.04619 |  0:10:17s\n",
      "epoch 39 | loss: 0.01651 | val_0_mse: 0.01222 |  0:10:33s\n",
      "epoch 40 | loss: 0.01896 | val_0_mse: 0.01551 |  0:10:49s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_mse = 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008062 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.963632 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 15/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.66981 | val_0_mse: 0.86477 |  0:00:09s\n",
      "epoch 1  | loss: 0.38589 | val_0_mse: 0.25358 |  0:00:19s\n",
      "epoch 2  | loss: 0.1645  | val_0_mse: 0.21094 |  0:00:28s\n",
      "epoch 3  | loss: 0.1114  | val_0_mse: 0.10149 |  0:00:38s\n",
      "epoch 4  | loss: 0.0882  | val_0_mse: 0.11674 |  0:00:48s\n",
      "epoch 5  | loss: 0.0838  | val_0_mse: 0.06493 |  0:00:57s\n",
      "epoch 6  | loss: 0.08127 | val_0_mse: 0.08925 |  0:01:07s\n",
      "epoch 7  | loss: 0.07583 | val_0_mse: 0.05426 |  0:01:16s\n",
      "epoch 8  | loss: 0.06728 | val_0_mse: 0.05249 |  0:01:26s\n",
      "epoch 9  | loss: 0.06524 | val_0_mse: 0.04116 |  0:01:35s\n",
      "epoch 10 | loss: 0.05436 | val_0_mse: 0.04276 |  0:01:45s\n",
      "epoch 11 | loss: 0.05185 | val_0_mse: 0.03525 |  0:01:55s\n",
      "epoch 12 | loss: 0.0446  | val_0_mse: 0.03386 |  0:02:04s\n",
      "epoch 13 | loss: 0.04312 | val_0_mse: 0.03407 |  0:02:14s\n",
      "epoch 14 | loss: 0.04295 | val_0_mse: 0.03411 |  0:02:23s\n",
      "epoch 15 | loss: 0.03221 | val_0_mse: 0.02796 |  0:02:33s\n",
      "epoch 16 | loss: 0.03354 | val_0_mse: 0.0251  |  0:02:42s\n",
      "epoch 17 | loss: 0.03225 | val_0_mse: 0.0268  |  0:02:52s\n",
      "epoch 18 | loss: 0.03712 | val_0_mse: 0.02791 |  0:03:02s\n",
      "epoch 19 | loss: 0.02528 | val_0_mse: 0.02689 |  0:03:12s\n",
      "epoch 20 | loss: 0.03182 | val_0_mse: 0.02795 |  0:03:21s\n",
      "epoch 21 | loss: 0.03336 | val_0_mse: 0.02355 |  0:03:31s\n",
      "epoch 22 | loss: 0.02849 | val_0_mse: 0.03091 |  0:03:41s\n",
      "epoch 23 | loss: 0.02669 | val_0_mse: 0.02031 |  0:03:50s\n",
      "epoch 24 | loss: 0.02486 | val_0_mse: 0.01963 |  0:04:02s\n",
      "epoch 25 | loss: 0.02291 | val_0_mse: 0.0195  |  0:04:12s\n",
      "epoch 26 | loss: 0.02369 | val_0_mse: 0.04365 |  0:04:25s\n",
      "epoch 27 | loss: 0.0203  | val_0_mse: 0.0199  |  0:04:35s\n",
      "epoch 28 | loss: 0.02389 | val_0_mse: 0.01255 |  0:04:45s\n",
      "epoch 29 | loss: 0.01633 | val_0_mse: 0.01143 |  0:04:56s\n",
      "epoch 30 | loss: 0.01703 | val_0_mse: 0.0087  |  0:05:06s\n",
      "epoch 31 | loss: 0.01452 | val_0_mse: 0.02069 |  0:05:16s\n",
      "epoch 32 | loss: 0.01518 | val_0_mse: 0.0141  |  0:05:26s\n",
      "epoch 33 | loss: 0.01351 | val_0_mse: 0.00799 |  0:05:36s\n",
      "epoch 34 | loss: 0.01403 | val_0_mse: 0.00994 |  0:05:46s\n",
      "epoch 35 | loss: 0.01587 | val_0_mse: 0.01029 |  0:05:56s\n",
      "epoch 36 | loss: 0.01889 | val_0_mse: 0.01014 |  0:06:06s\n",
      "epoch 37 | loss: 0.01644 | val_0_mse: 0.01188 |  0:06:16s\n",
      "epoch 38 | loss: 0.0159  | val_0_mse: 0.00898 |  0:06:26s\n",
      "epoch 39 | loss: 0.01605 | val_0_mse: 0.04188 |  0:06:37s\n",
      "epoch 40 | loss: 0.01249 | val_0_mse: 0.01323 |  0:06:47s\n",
      "epoch 41 | loss: 0.01168 | val_0_mse: 0.00664 |  0:06:57s\n",
      "epoch 42 | loss: 0.01435 | val_0_mse: 0.01    |  0:07:07s\n",
      "epoch 43 | loss: 0.01668 | val_0_mse: 0.02372 |  0:07:17s\n",
      "epoch 44 | loss: 0.02699 | val_0_mse: 0.01611 |  0:07:27s\n",
      "epoch 45 | loss: 0.02017 | val_0_mse: 0.02921 |  0:07:37s\n",
      "epoch 46 | loss: 0.01601 | val_0_mse: 0.02336 |  0:07:47s\n",
      "epoch 47 | loss: 0.01455 | val_0_mse: 0.02596 |  0:07:57s\n",
      "epoch 48 | loss: 0.01415 | val_0_mse: 0.00972 |  0:08:07s\n",
      "epoch 49 | loss: 0.01488 | val_0_mse: 0.01634 |  0:08:17s\n",
      "epoch 50 | loss: 0.01546 | val_0_mse: 0.02599 |  0:08:27s\n",
      "epoch 51 | loss: 0.0192  | val_0_mse: 0.03158 |  0:08:37s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_mse = 0.00664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007129 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.967840 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 16/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.46883 | val_0_mse: 0.52826 |  0:00:31s\n",
      "epoch 1  | loss: 0.16932 | val_0_mse: 0.23601 |  0:01:01s\n",
      "epoch 2  | loss: 0.14584 | val_0_mse: 0.11229 |  0:01:33s\n",
      "epoch 3  | loss: 0.10042 | val_0_mse: 0.06008 |  0:02:04s\n",
      "epoch 4  | loss: 0.07923 | val_0_mse: 0.08427 |  0:02:35s\n",
      "epoch 5  | loss: 0.08689 | val_0_mse: 0.06031 |  0:03:06s\n",
      "epoch 6  | loss: 0.07675 | val_0_mse: 0.07081 |  0:03:38s\n",
      "epoch 7  | loss: 0.07226 | val_0_mse: 0.05821 |  0:04:09s\n",
      "epoch 8  | loss: 0.06945 | val_0_mse: 0.07766 |  0:04:40s\n",
      "epoch 9  | loss: 0.0624  | val_0_mse: 0.0517  |  0:05:11s\n",
      "epoch 10 | loss: 0.0573  | val_0_mse: 0.0688  |  0:05:42s\n",
      "epoch 11 | loss: 0.05431 | val_0_mse: 0.07239 |  0:06:13s\n",
      "epoch 12 | loss: 0.05618 | val_0_mse: 0.03831 |  0:06:44s\n",
      "epoch 13 | loss: 0.04871 | val_0_mse: 0.0482  |  0:07:15s\n",
      "epoch 14 | loss: 0.04652 | val_0_mse: 0.03199 |  0:07:46s\n",
      "epoch 15 | loss: 0.03903 | val_0_mse: 0.02532 |  0:08:17s\n",
      "epoch 16 | loss: 0.03579 | val_0_mse: 0.02983 |  0:08:48s\n",
      "epoch 17 | loss: 0.03189 | val_0_mse: 0.01829 |  0:09:19s\n",
      "epoch 18 | loss: 0.02755 | val_0_mse: 0.02647 |  0:09:50s\n",
      "epoch 19 | loss: 0.03565 | val_0_mse: 0.0253  |  0:10:21s\n",
      "epoch 20 | loss: 0.03329 | val_0_mse: 0.02727 |  0:10:52s\n",
      "epoch 21 | loss: 0.02613 | val_0_mse: 0.01835 |  0:11:23s\n",
      "epoch 22 | loss: 0.02659 | val_0_mse: 0.02912 |  0:11:54s\n",
      "epoch 23 | loss: 0.02968 | val_0_mse: 0.04115 |  0:12:25s\n",
      "epoch 24 | loss: 0.02537 | val_0_mse: 0.01531 |  0:12:56s\n",
      "epoch 25 | loss: 0.02716 | val_0_mse: 0.01672 |  0:13:27s\n",
      "epoch 26 | loss: 0.02555 | val_0_mse: 0.02279 |  0:13:58s\n",
      "epoch 27 | loss: 0.02218 | val_0_mse: 0.02458 |  0:14:29s\n",
      "epoch 28 | loss: 0.02348 | val_0_mse: 0.07716 |  0:15:01s\n",
      "epoch 29 | loss: 0.02194 | val_0_mse: 0.02254 |  0:15:32s\n",
      "epoch 30 | loss: 0.0213  | val_0_mse: 0.02891 |  0:16:03s\n",
      "epoch 31 | loss: 0.02445 | val_0_mse: 0.015   |  0:16:34s\n",
      "epoch 32 | loss: 0.02127 | val_0_mse: 0.04473 |  0:17:05s\n",
      "epoch 33 | loss: 0.01898 | val_0_mse: 0.01212 |  0:17:36s\n",
      "epoch 34 | loss: 0.01809 | val_0_mse: 0.00821 |  0:18:08s\n",
      "epoch 35 | loss: 0.02148 | val_0_mse: 0.01545 |  0:18:38s\n",
      "epoch 36 | loss: 0.01948 | val_0_mse: 0.07689 |  0:19:09s\n",
      "epoch 37 | loss: 0.02121 | val_0_mse: 0.0108  |  0:19:40s\n",
      "epoch 38 | loss: 0.01779 | val_0_mse: 0.02009 |  0:20:11s\n",
      "epoch 39 | loss: 0.01952 | val_0_mse: 0.02531 |  0:20:42s\n",
      "epoch 40 | loss: 0.02266 | val_0_mse: 0.04419 |  0:21:13s\n",
      "epoch 41 | loss: 0.01941 | val_0_mse: 0.03008 |  0:21:43s\n",
      "epoch 42 | loss: 0.01739 | val_0_mse: 0.02279 |  0:22:14s\n",
      "epoch 43 | loss: 0.01648 | val_0_mse: 0.01036 |  0:22:45s\n",
      "epoch 44 | loss: 0.01805 | val_0_mse: 0.03063 |  0:23:16s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_mse = 0.00821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008081 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.963544 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 17/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.89052 | val_0_mse: 0.25203 |  0:00:17s\n",
      "epoch 1  | loss: 0.21931 | val_0_mse: 0.19828 |  0:00:35s\n",
      "epoch 2  | loss: 0.15153 | val_0_mse: 0.07581 |  0:00:53s\n",
      "epoch 3  | loss: 0.11576 | val_0_mse: 0.13428 |  0:01:11s\n",
      "epoch 4  | loss: 0.10022 | val_0_mse: 0.0888  |  0:01:29s\n",
      "epoch 5  | loss: 0.08201 | val_0_mse: 0.06176 |  0:01:47s\n",
      "epoch 6  | loss: 0.07922 | val_0_mse: 0.06483 |  0:02:05s\n",
      "epoch 7  | loss: 0.06875 | val_0_mse: 0.06366 |  0:02:23s\n",
      "epoch 8  | loss: 0.0792  | val_0_mse: 0.07165 |  0:02:41s\n",
      "epoch 9  | loss: 0.07332 | val_0_mse: 0.06168 |  0:02:59s\n",
      "epoch 10 | loss: 0.07064 | val_0_mse: 0.07558 |  0:03:16s\n",
      "epoch 11 | loss: 0.05924 | val_0_mse: 0.13253 |  0:03:33s\n",
      "epoch 12 | loss: 0.06524 | val_0_mse: 0.06196 |  0:03:50s\n",
      "epoch 13 | loss: 0.06336 | val_0_mse: 0.05746 |  0:04:07s\n",
      "epoch 14 | loss: 0.05782 | val_0_mse: 0.04171 |  0:04:24s\n",
      "epoch 15 | loss: 0.04804 | val_0_mse: 0.04418 |  0:04:41s\n",
      "epoch 16 | loss: 0.04218 | val_0_mse: 0.03027 |  0:04:58s\n",
      "epoch 17 | loss: 0.03983 | val_0_mse: 0.03073 |  0:05:15s\n",
      "epoch 18 | loss: 0.03173 | val_0_mse: 0.0228  |  0:05:32s\n",
      "epoch 19 | loss: 0.03138 | val_0_mse: 0.02927 |  0:05:49s\n",
      "epoch 20 | loss: 0.03182 | val_0_mse: 0.06051 |  0:06:06s\n",
      "epoch 21 | loss: 0.0272  | val_0_mse: 0.01643 |  0:06:23s\n",
      "epoch 22 | loss: 0.02378 | val_0_mse: 0.04491 |  0:06:40s\n",
      "epoch 23 | loss: 0.02368 | val_0_mse: 0.02163 |  0:06:57s\n",
      "epoch 24 | loss: 0.02233 | val_0_mse: 0.01702 |  0:07:14s\n",
      "epoch 25 | loss: 0.02158 | val_0_mse: 0.02422 |  0:07:31s\n",
      "epoch 26 | loss: 0.0243  | val_0_mse: 0.01084 |  0:07:48s\n",
      "epoch 27 | loss: 0.02249 | val_0_mse: 0.01821 |  0:08:05s\n",
      "epoch 28 | loss: 0.02015 | val_0_mse: 0.00934 |  0:08:22s\n",
      "epoch 29 | loss: 0.01755 | val_0_mse: 0.01605 |  0:08:39s\n",
      "epoch 30 | loss: 0.02395 | val_0_mse: 0.16689 |  0:08:56s\n",
      "epoch 31 | loss: 0.01797 | val_0_mse: 0.03488 |  0:09:13s\n",
      "epoch 32 | loss: 0.01593 | val_0_mse: 0.01619 |  0:09:30s\n",
      "epoch 33 | loss: 0.01651 | val_0_mse: 0.02555 |  0:09:47s\n",
      "epoch 34 | loss: 0.01553 | val_0_mse: 0.0108  |  0:10:04s\n",
      "epoch 35 | loss: 0.0192  | val_0_mse: 0.00836 |  0:10:21s\n",
      "epoch 36 | loss: 0.01598 | val_0_mse: 0.00866 |  0:10:38s\n",
      "epoch 37 | loss: 0.01811 | val_0_mse: 0.02041 |  0:10:55s\n",
      "epoch 38 | loss: 0.01755 | val_0_mse: 0.0091  |  0:11:12s\n",
      "epoch 39 | loss: 0.01865 | val_0_mse: 0.03745 |  0:11:29s\n",
      "epoch 40 | loss: 0.01879 | val_0_mse: 0.01206 |  0:11:46s\n",
      "epoch 41 | loss: 0.01832 | val_0_mse: 0.01597 |  0:12:02s\n",
      "epoch 42 | loss: 0.01357 | val_0_mse: 0.01053 |  0:12:19s\n",
      "epoch 43 | loss: 0.02006 | val_0_mse: 0.03987 |  0:12:36s\n",
      "epoch 44 | loss: 0.01563 | val_0_mse: 0.01342 |  0:12:53s\n",
      "epoch 45 | loss: 0.01219 | val_0_mse: 0.00717 |  0:13:10s\n",
      "epoch 46 | loss: 0.01455 | val_0_mse: 0.00865 |  0:13:27s\n",
      "epoch 47 | loss: 0.01392 | val_0_mse: 0.00718 |  0:13:44s\n",
      "epoch 48 | loss: 0.01499 | val_0_mse: 0.01256 |  0:14:01s\n",
      "epoch 49 | loss: 0.01507 | val_0_mse: 0.00637 |  0:14:17s\n",
      "epoch 50 | loss: 0.01355 | val_0_mse: 0.01581 |  0:14:34s\n",
      "epoch 51 | loss: 0.01297 | val_0_mse: 0.00836 |  0:14:51s\n",
      "epoch 52 | loss: 0.01384 | val_0_mse: 0.00907 |  0:15:09s\n",
      "epoch 53 | loss: 0.01888 | val_0_mse: 0.00685 |  0:15:25s\n",
      "epoch 54 | loss: 0.0165  | val_0_mse: 0.01185 |  0:15:42s\n",
      "epoch 55 | loss: 0.01405 | val_0_mse: 0.01868 |  0:15:59s\n",
      "epoch 56 | loss: 0.01456 | val_0_mse: 0.00775 |  0:16:16s\n",
      "epoch 57 | loss: 0.01514 | val_0_mse: 0.00871 |  0:16:33s\n",
      "epoch 58 | loss: 0.01449 | val_0_mse: 0.00626 |  0:16:50s\n",
      "epoch 59 | loss: 0.01427 | val_0_mse: 0.01053 |  0:17:07s\n",
      "epoch 60 | loss: 0.01337 | val_0_mse: 0.01028 |  0:17:24s\n",
      "epoch 61 | loss: 0.01351 | val_0_mse: 0.01776 |  0:17:41s\n",
      "epoch 62 | loss: 0.0171  | val_0_mse: 0.02288 |  0:17:58s\n",
      "epoch 63 | loss: 0.01468 | val_0_mse: 0.00633 |  0:18:15s\n",
      "epoch 64 | loss: 0.01144 | val_0_mse: 0.02342 |  0:18:32s\n",
      "epoch 65 | loss: 0.01409 | val_0_mse: 0.0069  |  0:18:49s\n",
      "epoch 66 | loss: 0.01809 | val_0_mse: 0.04481 |  0:19:06s\n",
      "epoch 67 | loss: 0.01602 | val_0_mse: 0.0161  |  0:19:23s\n",
      "epoch 68 | loss: 0.01283 | val_0_mse: 0.00889 |  0:19:40s\n",
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_mse = 0.00626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006646 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.970018 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 18/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.59417 | val_0_mse: 0.50761 |  0:00:10s\n",
      "epoch 1  | loss: 0.69847 | val_0_mse: 0.18381 |  0:00:22s\n",
      "epoch 2  | loss: 0.23715 | val_0_mse: 0.30488 |  0:00:33s\n",
      "epoch 3  | loss: 0.1538  | val_0_mse: 0.13812 |  0:00:46s\n",
      "epoch 4  | loss: 0.12917 | val_0_mse: 0.09532 |  0:00:57s\n",
      "epoch 5  | loss: 0.10993 | val_0_mse: 0.07416 |  0:01:08s\n",
      "epoch 6  | loss: 0.08698 | val_0_mse: 0.08308 |  0:01:18s\n",
      "epoch 7  | loss: 0.07897 | val_0_mse: 0.08261 |  0:01:28s\n",
      "epoch 8  | loss: 0.07809 | val_0_mse: 0.06861 |  0:01:38s\n",
      "epoch 9  | loss: 0.08068 | val_0_mse: 0.07816 |  0:01:50s\n",
      "epoch 10 | loss: 0.06893 | val_0_mse: 0.06391 |  0:02:00s\n",
      "epoch 11 | loss: 0.05964 | val_0_mse: 0.05734 |  0:02:11s\n",
      "epoch 12 | loss: 0.04964 | val_0_mse: 0.04541 |  0:02:21s\n",
      "epoch 13 | loss: 0.04359 | val_0_mse: 0.04066 |  0:02:31s\n",
      "epoch 14 | loss: 0.0428  | val_0_mse: 0.04026 |  0:02:41s\n",
      "epoch 15 | loss: 0.04055 | val_0_mse: 0.03489 |  0:02:52s\n",
      "epoch 16 | loss: 0.03115 | val_0_mse: 0.02912 |  0:03:03s\n",
      "epoch 17 | loss: 0.03013 | val_0_mse: 0.01771 |  0:03:14s\n",
      "epoch 18 | loss: 0.04048 | val_0_mse: 0.02128 |  0:03:25s\n",
      "epoch 19 | loss: 0.02968 | val_0_mse: 0.034   |  0:03:36s\n",
      "epoch 20 | loss: 0.03539 | val_0_mse: 0.02072 |  0:03:47s\n",
      "epoch 21 | loss: 0.02428 | val_0_mse: 0.01497 |  0:03:57s\n",
      "epoch 22 | loss: 0.02195 | val_0_mse: 0.01343 |  0:04:08s\n",
      "epoch 23 | loss: 0.01922 | val_0_mse: 0.01206 |  0:04:18s\n",
      "epoch 24 | loss: 0.01847 | val_0_mse: 0.01325 |  0:04:28s\n",
      "epoch 25 | loss: 0.01948 | val_0_mse: 0.01226 |  0:04:38s\n",
      "epoch 26 | loss: 0.01967 | val_0_mse: 0.01171 |  0:04:49s\n",
      "epoch 27 | loss: 0.01981 | val_0_mse: 0.01171 |  0:04:59s\n",
      "epoch 28 | loss: 0.01625 | val_0_mse: 0.02269 |  0:05:09s\n",
      "epoch 29 | loss: 0.01558 | val_0_mse: 0.01125 |  0:05:21s\n",
      "epoch 30 | loss: 0.01446 | val_0_mse: 0.015   |  0:05:31s\n",
      "epoch 31 | loss: 0.01404 | val_0_mse: 0.02516 |  0:05:41s\n",
      "epoch 32 | loss: 0.01526 | val_0_mse: 0.01108 |  0:05:51s\n",
      "epoch 33 | loss: 0.01326 | val_0_mse: 0.01025 |  0:06:01s\n",
      "epoch 34 | loss: 0.01191 | val_0_mse: 0.0154  |  0:06:11s\n",
      "epoch 35 | loss: 0.01199 | val_0_mse: 0.01619 |  0:06:22s\n",
      "epoch 36 | loss: 0.01295 | val_0_mse: 0.01854 |  0:06:32s\n",
      "epoch 37 | loss: 0.01187 | val_0_mse: 0.00953 |  0:06:42s\n",
      "epoch 38 | loss: 0.01254 | val_0_mse: 0.00954 |  0:06:52s\n",
      "epoch 39 | loss: 0.01319 | val_0_mse: 0.01029 |  0:07:02s\n",
      "epoch 40 | loss: 0.01184 | val_0_mse: 0.02101 |  0:07:12s\n",
      "epoch 41 | loss: 0.01151 | val_0_mse: 0.00738 |  0:07:22s\n",
      "epoch 42 | loss: 0.00994 | val_0_mse: 0.01055 |  0:07:32s\n",
      "epoch 43 | loss: 0.01196 | val_0_mse: 0.00778 |  0:07:43s\n",
      "epoch 44 | loss: 0.01151 | val_0_mse: 0.01902 |  0:07:53s\n",
      "epoch 45 | loss: 0.01246 | val_0_mse: 0.01028 |  0:08:03s\n",
      "epoch 46 | loss: 0.01013 | val_0_mse: 0.01012 |  0:08:13s\n",
      "epoch 47 | loss: 0.01641 | val_0_mse: 0.01177 |  0:08:23s\n",
      "epoch 48 | loss: 0.01049 | val_0_mse: 0.00885 |  0:08:33s\n",
      "epoch 49 | loss: 0.01816 | val_0_mse: 0.07116 |  0:08:43s\n",
      "epoch 50 | loss: 0.01749 | val_0_mse: 0.02199 |  0:08:53s\n",
      "epoch 51 | loss: 0.01541 | val_0_mse: 0.01705 |  0:09:04s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_mse = 0.00738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006488 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.970733 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 19/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.81309 | val_0_mse: 0.12021 |  0:00:30s\n",
      "epoch 1  | loss: 0.12349 | val_0_mse: 0.07199 |  0:01:01s\n",
      "epoch 2  | loss: 0.10574 | val_0_mse: 0.16697 |  0:01:32s\n",
      "epoch 3  | loss: 0.09596 | val_0_mse: 0.09816 |  0:02:03s\n",
      "epoch 4  | loss: 0.07883 | val_0_mse: 0.05383 |  0:02:34s\n",
      "epoch 5  | loss: 0.07184 | val_0_mse: 0.05237 |  0:03:04s\n",
      "epoch 6  | loss: 0.06513 | val_0_mse: 0.04728 |  0:03:35s\n",
      "epoch 7  | loss: 0.06301 | val_0_mse: 0.03805 |  0:04:06s\n",
      "epoch 8  | loss: 0.05847 | val_0_mse: 0.05282 |  0:04:37s\n",
      "epoch 9  | loss: 0.05165 | val_0_mse: 0.03874 |  0:05:08s\n",
      "epoch 10 | loss: 0.03613 | val_0_mse: 0.04118 |  0:05:39s\n",
      "epoch 11 | loss: 0.04433 | val_0_mse: 0.0306  |  0:06:11s\n",
      "epoch 12 | loss: 0.05145 | val_0_mse: 0.02061 |  0:06:42s\n",
      "epoch 13 | loss: 0.04393 | val_0_mse: 0.01837 |  0:07:13s\n",
      "epoch 14 | loss: 0.03051 | val_0_mse: 0.03431 |  0:07:44s\n",
      "epoch 15 | loss: 0.034   | val_0_mse: 0.01669 |  0:08:15s\n",
      "epoch 16 | loss: 0.03138 | val_0_mse: 0.11073 |  0:08:45s\n",
      "epoch 17 | loss: 0.02801 | val_0_mse: 0.01894 |  0:09:16s\n",
      "epoch 18 | loss: 0.03325 | val_0_mse: 0.01945 |  0:09:47s\n",
      "epoch 19 | loss: 0.03156 | val_0_mse: 0.01925 |  0:10:18s\n",
      "epoch 20 | loss: 0.03033 | val_0_mse: 0.0162  |  0:10:49s\n",
      "epoch 21 | loss: 0.02421 | val_0_mse: 0.00806 |  0:11:19s\n",
      "epoch 22 | loss: 0.0272  | val_0_mse: 0.01996 |  0:11:50s\n",
      "epoch 23 | loss: 0.02247 | val_0_mse: 0.04426 |  0:12:21s\n",
      "epoch 24 | loss: 0.02442 | val_0_mse: 0.02567 |  0:12:52s\n",
      "epoch 25 | loss: 0.02323 | val_0_mse: 0.02371 |  0:13:23s\n",
      "epoch 26 | loss: 0.02321 | val_0_mse: 0.02529 |  0:13:54s\n",
      "epoch 27 | loss: 0.0256  | val_0_mse: 0.03575 |  0:14:25s\n",
      "epoch 28 | loss: 0.02191 | val_0_mse: 0.00786 |  0:14:56s\n",
      "epoch 29 | loss: 0.0192  | val_0_mse: 0.01362 |  0:15:26s\n",
      "epoch 30 | loss: 0.02546 | val_0_mse: 0.01584 |  0:15:57s\n",
      "epoch 31 | loss: 0.02517 | val_0_mse: 0.02883 |  0:16:28s\n",
      "epoch 32 | loss: 0.0204  | val_0_mse: 0.04463 |  0:16:59s\n",
      "epoch 33 | loss: 0.02565 | val_0_mse: 0.01955 |  0:17:30s\n",
      "epoch 34 | loss: 0.02366 | val_0_mse: 0.02014 |  0:18:01s\n",
      "epoch 35 | loss: 0.02263 | val_0_mse: 0.01905 |  0:18:32s\n",
      "epoch 36 | loss: 0.02148 | val_0_mse: 0.05092 |  0:19:03s\n",
      "epoch 37 | loss: 0.02303 | val_0_mse: 0.01841 |  0:19:33s\n",
      "epoch 38 | loss: 0.01874 | val_0_mse: 0.00922 |  0:20:04s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_mse = 0.00786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.010023 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.954784 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 20/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.39398 | val_0_mse: 0.67688 |  0:00:17s\n",
      "epoch 1  | loss: 0.20397 | val_0_mse: 0.12653 |  0:00:34s\n",
      "epoch 2  | loss: 0.12128 | val_0_mse: 0.09648 |  0:00:51s\n",
      "epoch 3  | loss: 0.10494 | val_0_mse: 0.07841 |  0:01:08s\n",
      "epoch 4  | loss: 0.09736 | val_0_mse: 0.07639 |  0:01:25s\n",
      "epoch 5  | loss: 0.086   | val_0_mse: 0.06519 |  0:01:43s\n",
      "epoch 6  | loss: 0.09059 | val_0_mse: 0.05649 |  0:02:00s\n",
      "epoch 7  | loss: 0.05777 | val_0_mse: 0.04694 |  0:02:17s\n",
      "epoch 8  | loss: 0.05511 | val_0_mse: 0.03867 |  0:02:34s\n",
      "epoch 9  | loss: 0.05864 | val_0_mse: 0.04257 |  0:02:51s\n",
      "epoch 10 | loss: 0.04433 | val_0_mse: 0.03889 |  0:03:08s\n",
      "epoch 11 | loss: 0.0506  | val_0_mse: 0.07788 |  0:03:25s\n",
      "epoch 12 | loss: 0.03993 | val_0_mse: 0.06327 |  0:03:42s\n",
      "epoch 13 | loss: 0.05461 | val_0_mse: 0.03652 |  0:03:59s\n",
      "epoch 14 | loss: 0.03444 | val_0_mse: 0.01541 |  0:04:17s\n",
      "epoch 15 | loss: 0.03323 | val_0_mse: 0.02241 |  0:04:34s\n",
      "epoch 16 | loss: 0.03134 | val_0_mse: 0.01135 |  0:04:51s\n",
      "epoch 17 | loss: 0.02673 | val_0_mse: 0.01126 |  0:05:08s\n",
      "epoch 18 | loss: 0.02831 | val_0_mse: 0.04327 |  0:05:25s\n",
      "epoch 19 | loss: 0.02276 | val_0_mse: 0.02093 |  0:05:42s\n",
      "epoch 20 | loss: 0.02547 | val_0_mse: 0.0323  |  0:05:59s\n",
      "epoch 21 | loss: 0.02541 | val_0_mse: 0.02693 |  0:06:16s\n",
      "epoch 22 | loss: 0.02181 | val_0_mse: 0.01282 |  0:06:33s\n",
      "epoch 23 | loss: 0.02404 | val_0_mse: 0.01239 |  0:06:50s\n",
      "epoch 24 | loss: 0.02323 | val_0_mse: 0.0192  |  0:07:07s\n",
      "epoch 25 | loss: 0.02217 | val_0_mse: 0.01547 |  0:07:24s\n",
      "epoch 26 | loss: 0.02191 | val_0_mse: 0.01519 |  0:07:41s\n",
      "epoch 27 | loss: 0.01943 | val_0_mse: 0.04076 |  0:07:58s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_mse = 0.01126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.011778 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.946866 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 21/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.97965 | val_0_mse: 0.61757 |  0:00:10s\n",
      "epoch 1  | loss: 0.40068 | val_0_mse: 0.28953 |  0:00:20s\n",
      "epoch 2  | loss: 0.18928 | val_0_mse: 0.13878 |  0:00:30s\n",
      "epoch 3  | loss: 0.12585 | val_0_mse: 0.09089 |  0:00:40s\n",
      "epoch 4  | loss: 0.10651 | val_0_mse: 0.08234 |  0:00:50s\n",
      "epoch 5  | loss: 0.08782 | val_0_mse: 0.07783 |  0:01:00s\n",
      "epoch 6  | loss: 0.08568 | val_0_mse: 0.09571 |  0:01:10s\n",
      "epoch 7  | loss: 0.0748  | val_0_mse: 0.08866 |  0:01:21s\n",
      "epoch 8  | loss: 0.07096 | val_0_mse: 0.06154 |  0:01:31s\n",
      "epoch 9  | loss: 0.06496 | val_0_mse: 0.08406 |  0:01:41s\n",
      "epoch 10 | loss: 0.07175 | val_0_mse: 0.06707 |  0:01:51s\n",
      "epoch 11 | loss: 0.0721  | val_0_mse: 0.08411 |  0:02:01s\n",
      "epoch 12 | loss: 0.0828  | val_0_mse: 0.07073 |  0:02:12s\n",
      "epoch 13 | loss: 0.0789  | val_0_mse: 0.06294 |  0:02:22s\n",
      "epoch 14 | loss: 0.06521 | val_0_mse: 0.06292 |  0:02:32s\n",
      "epoch 15 | loss: 0.06366 | val_0_mse: 0.05383 |  0:02:42s\n",
      "epoch 16 | loss: 0.06649 | val_0_mse: 0.05692 |  0:02:52s\n",
      "epoch 17 | loss: 0.06205 | val_0_mse: 0.06822 |  0:03:02s\n",
      "epoch 18 | loss: 0.05988 | val_0_mse: 0.06965 |  0:03:12s\n",
      "epoch 19 | loss: 0.05056 | val_0_mse: 0.05589 |  0:03:22s\n",
      "epoch 20 | loss: 0.05178 | val_0_mse: 0.06793 |  0:03:32s\n",
      "epoch 21 | loss: 0.0542  | val_0_mse: 0.05934 |  0:03:42s\n",
      "epoch 22 | loss: 0.05626 | val_0_mse: 0.05613 |  0:03:52s\n",
      "epoch 23 | loss: 0.05326 | val_0_mse: 0.05323 |  0:04:03s\n",
      "epoch 24 | loss: 0.04953 | val_0_mse: 0.07346 |  0:04:13s\n",
      "epoch 25 | loss: 0.05354 | val_0_mse: 0.07519 |  0:04:23s\n",
      "epoch 26 | loss: 0.06299 | val_0_mse: 0.04449 |  0:04:33s\n",
      "epoch 27 | loss: 0.04706 | val_0_mse: 0.05538 |  0:04:43s\n",
      "epoch 28 | loss: 0.04809 | val_0_mse: 0.04878 |  0:04:53s\n",
      "epoch 29 | loss: 0.05198 | val_0_mse: 0.04912 |  0:05:03s\n",
      "epoch 30 | loss: 0.04935 | val_0_mse: 0.0578  |  0:05:13s\n",
      "epoch 31 | loss: 0.05004 | val_0_mse: 0.04873 |  0:05:23s\n",
      "epoch 32 | loss: 0.05335 | val_0_mse: 0.05695 |  0:05:33s\n",
      "epoch 33 | loss: 0.049   | val_0_mse: 0.04333 |  0:05:44s\n",
      "epoch 34 | loss: 0.04443 | val_0_mse: 0.04683 |  0:05:54s\n",
      "epoch 35 | loss: 0.04209 | val_0_mse: 0.04156 |  0:06:04s\n",
      "epoch 36 | loss: 0.03988 | val_0_mse: 0.05523 |  0:06:14s\n",
      "epoch 37 | loss: 0.04399 | val_0_mse: 0.03575 |  0:06:24s\n",
      "epoch 38 | loss: 0.03988 | val_0_mse: 0.04615 |  0:06:34s\n",
      "epoch 39 | loss: 0.04136 | val_0_mse: 0.03351 |  0:06:44s\n",
      "epoch 40 | loss: 0.03542 | val_0_mse: 0.02735 |  0:06:54s\n",
      "epoch 41 | loss: 0.02838 | val_0_mse: 0.03496 |  0:07:04s\n",
      "epoch 42 | loss: 0.02432 | val_0_mse: 0.02422 |  0:07:15s\n",
      "epoch 43 | loss: 0.02274 | val_0_mse: 0.01774 |  0:07:25s\n",
      "epoch 44 | loss: 0.02757 | val_0_mse: 0.03336 |  0:07:35s\n",
      "epoch 45 | loss: 0.01881 | val_0_mse: 0.01534 |  0:07:45s\n",
      "epoch 46 | loss: 0.02116 | val_0_mse: 0.01444 |  0:07:55s\n",
      "epoch 47 | loss: 0.01713 | val_0_mse: 0.01349 |  0:08:05s\n",
      "epoch 48 | loss: 0.02024 | val_0_mse: 0.01127 |  0:08:15s\n",
      "epoch 49 | loss: 0.01882 | val_0_mse: 0.01474 |  0:08:25s\n",
      "epoch 50 | loss: 0.01681 | val_0_mse: 0.0112  |  0:08:36s\n",
      "epoch 51 | loss: 0.0205  | val_0_mse: 0.0194  |  0:08:46s\n",
      "epoch 52 | loss: 0.01647 | val_0_mse: 0.01171 |  0:08:56s\n",
      "epoch 53 | loss: 0.01342 | val_0_mse: 0.0103  |  0:09:06s\n",
      "epoch 54 | loss: 0.0175  | val_0_mse: 0.00957 |  0:09:16s\n",
      "epoch 55 | loss: 0.02142 | val_0_mse: 0.02459 |  0:09:26s\n",
      "epoch 56 | loss: 0.01394 | val_0_mse: 0.01016 |  0:09:36s\n",
      "epoch 57 | loss: 0.01701 | val_0_mse: 0.01837 |  0:09:47s\n",
      "epoch 58 | loss: 0.01638 | val_0_mse: 0.01085 |  0:09:57s\n",
      "epoch 59 | loss: 0.01255 | val_0_mse: 0.00946 |  0:10:07s\n",
      "epoch 60 | loss: 0.01393 | val_0_mse: 0.01138 |  0:10:17s\n",
      "epoch 61 | loss: 0.01451 | val_0_mse: 0.01054 |  0:10:27s\n",
      "epoch 62 | loss: 0.01233 | val_0_mse: 0.01202 |  0:10:38s\n",
      "epoch 63 | loss: 0.01557 | val_0_mse: 0.02318 |  0:10:48s\n",
      "epoch 64 | loss: 0.01824 | val_0_mse: 0.03541 |  0:10:58s\n",
      "epoch 65 | loss: 0.01514 | val_0_mse: 0.02347 |  0:11:08s\n",
      "epoch 66 | loss: 0.01314 | val_0_mse: 0.01934 |  0:11:18s\n",
      "epoch 67 | loss: 0.01351 | val_0_mse: 0.01197 |  0:11:28s\n",
      "epoch 68 | loss: 0.01636 | val_0_mse: 0.00891 |  0:11:39s\n",
      "epoch 69 | loss: 0.01097 | val_0_mse: 0.00641 |  0:11:49s\n",
      "epoch 70 | loss: 0.01064 | val_0_mse: 0.00989 |  0:11:59s\n",
      "epoch 71 | loss: 0.01209 | val_0_mse: 0.00874 |  0:12:09s\n",
      "epoch 72 | loss: 0.01893 | val_0_mse: 0.02307 |  0:12:19s\n",
      "epoch 73 | loss: 0.01118 | val_0_mse: 0.00856 |  0:12:29s\n",
      "epoch 74 | loss: 0.00974 | val_0_mse: 0.02315 |  0:12:39s\n",
      "epoch 75 | loss: 0.00938 | val_0_mse: 0.01199 |  0:12:49s\n",
      "epoch 76 | loss: 0.01117 | val_0_mse: 0.01136 |  0:13:00s\n",
      "epoch 77 | loss: 0.01012 | val_0_mse: 0.04165 |  0:13:10s\n",
      "epoch 78 | loss: 0.0116  | val_0_mse: 0.00852 |  0:13:20s\n",
      "epoch 79 | loss: 0.00932 | val_0_mse: 0.00705 |  0:13:30s\n",
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_mse = 0.00641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006152 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.972247 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 22/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.10105 | val_0_mse: 0.19532 |  0:00:32s\n",
      "epoch 1  | loss: 0.14562 | val_0_mse: 0.06341 |  0:01:05s\n",
      "epoch 2  | loss: 0.10294 | val_0_mse: 0.06093 |  0:01:38s\n",
      "epoch 3  | loss: 0.08454 | val_0_mse: 0.06853 |  0:02:10s\n",
      "epoch 4  | loss: 0.08002 | val_0_mse: 0.05187 |  0:02:43s\n",
      "epoch 5  | loss: 0.07568 | val_0_mse: 0.13052 |  0:03:16s\n",
      "epoch 6  | loss: 0.07387 | val_0_mse: 0.04917 |  0:03:49s\n",
      "epoch 7  | loss: 0.07358 | val_0_mse: 0.0531  |  0:04:22s\n",
      "epoch 8  | loss: 0.07037 | val_0_mse: 0.05277 |  0:04:55s\n",
      "epoch 9  | loss: 0.0729  | val_0_mse: 0.04892 |  0:05:28s\n",
      "epoch 10 | loss: 0.06892 | val_0_mse: 0.05267 |  0:06:00s\n",
      "epoch 11 | loss: 0.06518 | val_0_mse: 0.05181 |  0:06:33s\n",
      "epoch 12 | loss: 0.06363 | val_0_mse: 0.0576  |  0:07:06s\n",
      "epoch 13 | loss: 0.06762 | val_0_mse: 0.06079 |  0:07:39s\n",
      "epoch 14 | loss: 0.06449 | val_0_mse: 0.04485 |  0:08:12s\n",
      "epoch 15 | loss: 0.06096 | val_0_mse: 0.0458  |  0:08:45s\n",
      "epoch 16 | loss: 0.05807 | val_0_mse: 0.04076 |  0:09:18s\n",
      "epoch 17 | loss: 0.05194 | val_0_mse: 0.03966 |  0:09:50s\n",
      "epoch 18 | loss: 0.05008 | val_0_mse: 0.04062 |  0:10:23s\n",
      "epoch 19 | loss: 0.04452 | val_0_mse: 0.11492 |  0:10:56s\n",
      "epoch 20 | loss: 0.04831 | val_0_mse: 0.03559 |  0:11:29s\n",
      "epoch 21 | loss: 0.0388  | val_0_mse: 0.02102 |  0:12:01s\n",
      "epoch 22 | loss: 0.03522 | val_0_mse: 0.01721 |  0:12:34s\n",
      "epoch 23 | loss: 0.03425 | val_0_mse: 0.035   |  0:13:07s\n",
      "epoch 24 | loss: 0.03958 | val_0_mse: 0.12615 |  0:13:40s\n",
      "epoch 25 | loss: 0.03216 | val_0_mse: 0.04311 |  0:14:13s\n",
      "epoch 26 | loss: 0.03007 | val_0_mse: 0.02323 |  0:14:45s\n",
      "epoch 27 | loss: 0.03225 | val_0_mse: 0.02441 |  0:15:18s\n",
      "epoch 28 | loss: 0.02526 | val_0_mse: 0.02144 |  0:15:56s\n",
      "epoch 29 | loss: 0.02885 | val_0_mse: 0.02266 |  0:16:29s\n",
      "epoch 30 | loss: 0.02574 | val_0_mse: 0.09879 |  0:17:01s\n",
      "epoch 31 | loss: 0.02724 | val_0_mse: 0.0373  |  0:17:34s\n",
      "epoch 32 | loss: 0.02559 | val_0_mse: 0.0232  |  0:18:08s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_mse = 0.01721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.017711 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.920098 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 23/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.70053 | val_0_mse: 0.93874 |  0:00:18s\n",
      "epoch 1  | loss: 0.18792 | val_0_mse: 0.18649 |  0:00:35s\n",
      "epoch 2  | loss: 0.11163 | val_0_mse: 0.07144 |  0:00:53s\n",
      "epoch 3  | loss: 0.08331 | val_0_mse: 0.06373 |  0:01:10s\n",
      "epoch 4  | loss: 0.08638 | val_0_mse: 0.06425 |  0:01:28s\n",
      "epoch 5  | loss: 0.0748  | val_0_mse: 0.07804 |  0:01:46s\n",
      "epoch 6  | loss: 0.07265 | val_0_mse: 0.0635  |  0:02:03s\n",
      "epoch 7  | loss: 0.05546 | val_0_mse: 0.03874 |  0:02:21s\n",
      "epoch 8  | loss: 0.0416  | val_0_mse: 0.02743 |  0:02:38s\n",
      "epoch 9  | loss: 0.03737 | val_0_mse: 0.03213 |  0:02:56s\n",
      "epoch 10 | loss: 0.037   | val_0_mse: 0.02462 |  0:03:13s\n",
      "epoch 11 | loss: 0.03148 | val_0_mse: 0.02433 |  0:03:31s\n",
      "epoch 12 | loss: 0.03476 | val_0_mse: 0.01736 |  0:03:49s\n",
      "epoch 13 | loss: 0.02451 | val_0_mse: 0.04336 |  0:04:07s\n",
      "epoch 14 | loss: 0.0345  | val_0_mse: 0.02029 |  0:04:24s\n",
      "epoch 15 | loss: 0.02391 | val_0_mse: 0.02525 |  0:04:42s\n",
      "epoch 16 | loss: 0.02474 | val_0_mse: 0.02502 |  0:05:00s\n",
      "epoch 17 | loss: 0.02576 | val_0_mse: 0.01254 |  0:05:17s\n",
      "epoch 18 | loss: 0.02612 | val_0_mse: 0.0408  |  0:05:35s\n",
      "epoch 19 | loss: 0.02697 | val_0_mse: 0.01427 |  0:05:52s\n",
      "epoch 20 | loss: 0.01862 | val_0_mse: 0.01055 |  0:06:10s\n",
      "epoch 21 | loss: 0.02363 | val_0_mse: 0.00889 |  0:06:28s\n",
      "epoch 22 | loss: 0.01699 | val_0_mse: 0.01833 |  0:06:45s\n",
      "epoch 23 | loss: 0.02327 | val_0_mse: 0.02203 |  0:07:03s\n",
      "epoch 24 | loss: 0.02373 | val_0_mse: 0.02728 |  0:07:21s\n",
      "epoch 25 | loss: 0.01717 | val_0_mse: 0.02544 |  0:07:38s\n",
      "epoch 26 | loss: 0.02137 | val_0_mse: 0.01126 |  0:07:56s\n",
      "epoch 27 | loss: 0.02598 | val_0_mse: 0.08204 |  0:08:14s\n",
      "epoch 28 | loss: 0.02151 | val_0_mse: 0.00794 |  0:08:31s\n",
      "epoch 29 | loss: 0.0287  | val_0_mse: 0.03094 |  0:08:49s\n",
      "epoch 30 | loss: 0.02237 | val_0_mse: 0.03411 |  0:09:06s\n",
      "epoch 31 | loss: 0.02441 | val_0_mse: 0.10181 |  0:09:24s\n",
      "epoch 32 | loss: 0.01938 | val_0_mse: 0.00931 |  0:09:42s\n",
      "epoch 33 | loss: 0.01753 | val_0_mse: 0.04634 |  0:09:59s\n",
      "epoch 34 | loss: 0.02002 | val_0_mse: 0.0679  |  0:10:17s\n",
      "epoch 35 | loss: 0.01915 | val_0_mse: 0.04605 |  0:10:34s\n",
      "epoch 36 | loss: 0.01753 | val_0_mse: 0.01309 |  0:10:52s\n",
      "epoch 37 | loss: 0.01502 | val_0_mse: 0.01803 |  0:11:09s\n",
      "epoch 38 | loss: 0.02191 | val_0_mse: 0.01693 |  0:11:27s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_mse = 0.00794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008043 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.963714 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 24/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.32806 | val_0_mse: 0.42496 |  0:00:10s\n",
      "epoch 1  | loss: 0.45085 | val_0_mse: 0.37315 |  0:00:20s\n",
      "epoch 2  | loss: 0.20061 | val_0_mse: 0.27149 |  0:00:30s\n",
      "epoch 3  | loss: 0.10592 | val_0_mse: 0.12557 |  0:00:40s\n",
      "epoch 4  | loss: 0.11841 | val_0_mse: 0.1208  |  0:00:51s\n",
      "epoch 5  | loss: 0.11519 | val_0_mse: 0.13723 |  0:01:01s\n",
      "epoch 6  | loss: 0.09571 | val_0_mse: 0.07372 |  0:01:11s\n",
      "epoch 7  | loss: 0.08305 | val_0_mse: 0.06721 |  0:01:21s\n",
      "epoch 8  | loss: 0.0833  | val_0_mse: 0.07135 |  0:01:32s\n",
      "epoch 9  | loss: 0.08188 | val_0_mse: 0.0662  |  0:01:42s\n",
      "epoch 10 | loss: 0.08529 | val_0_mse: 0.06557 |  0:01:52s\n",
      "epoch 11 | loss: 0.07724 | val_0_mse: 0.06201 |  0:02:03s\n",
      "epoch 12 | loss: 0.07498 | val_0_mse: 0.05897 |  0:02:13s\n",
      "epoch 13 | loss: 0.06614 | val_0_mse: 0.05879 |  0:02:23s\n",
      "epoch 14 | loss: 0.07632 | val_0_mse: 0.06281 |  0:02:33s\n",
      "epoch 15 | loss: 0.06331 | val_0_mse: 0.05159 |  0:02:43s\n",
      "epoch 16 | loss: 0.06857 | val_0_mse: 0.0656  |  0:02:54s\n",
      "epoch 17 | loss: 0.06104 | val_0_mse: 0.04832 |  0:03:04s\n",
      "epoch 18 | loss: 0.05846 | val_0_mse: 0.11768 |  0:03:14s\n",
      "epoch 19 | loss: 0.05617 | val_0_mse: 0.07543 |  0:03:24s\n",
      "epoch 20 | loss: 0.05651 | val_0_mse: 0.12898 |  0:03:35s\n",
      "epoch 21 | loss: 0.0701  | val_0_mse: 0.0391  |  0:03:45s\n",
      "epoch 22 | loss: 0.05477 | val_0_mse: 0.04682 |  0:03:55s\n",
      "epoch 23 | loss: 0.05054 | val_0_mse: 0.05776 |  0:04:05s\n",
      "epoch 24 | loss: 0.06284 | val_0_mse: 0.05565 |  0:04:16s\n",
      "epoch 25 | loss: 0.05649 | val_0_mse: 0.0839  |  0:04:26s\n",
      "epoch 26 | loss: 0.06049 | val_0_mse: 0.04861 |  0:04:36s\n",
      "epoch 27 | loss: 0.05447 | val_0_mse: 0.04282 |  0:04:46s\n",
      "epoch 28 | loss: 0.04618 | val_0_mse: 0.03837 |  0:04:57s\n",
      "epoch 29 | loss: 0.05039 | val_0_mse: 0.06575 |  0:05:07s\n",
      "epoch 30 | loss: 0.0458  | val_0_mse: 0.03656 |  0:05:17s\n",
      "epoch 31 | loss: 0.04569 | val_0_mse: 0.03353 |  0:05:27s\n",
      "epoch 32 | loss: 0.04107 | val_0_mse: 0.03909 |  0:05:38s\n",
      "epoch 33 | loss: 0.04465 | val_0_mse: 0.029   |  0:05:48s\n",
      "epoch 34 | loss: 0.04002 | val_0_mse: 0.04179 |  0:05:58s\n",
      "epoch 35 | loss: 0.04174 | val_0_mse: 0.05094 |  0:06:09s\n",
      "epoch 36 | loss: 0.04244 | val_0_mse: 0.05155 |  0:06:19s\n",
      "epoch 37 | loss: 0.03675 | val_0_mse: 0.08605 |  0:06:29s\n",
      "epoch 38 | loss: 0.03947 | val_0_mse: 0.0276  |  0:06:39s\n",
      "epoch 39 | loss: 0.03237 | val_0_mse: 0.08304 |  0:06:50s\n",
      "epoch 40 | loss: 0.03197 | val_0_mse: 0.03    |  0:07:00s\n",
      "epoch 41 | loss: 0.03284 | val_0_mse: 0.02582 |  0:07:11s\n",
      "epoch 42 | loss: 0.03055 | val_0_mse: 0.02415 |  0:07:22s\n",
      "epoch 43 | loss: 0.03258 | val_0_mse: 0.07988 |  0:07:33s\n",
      "epoch 44 | loss: 0.03081 | val_0_mse: 0.02054 |  0:07:44s\n",
      "epoch 45 | loss: 0.02722 | val_0_mse: 0.03802 |  0:07:54s\n",
      "epoch 46 | loss: 0.02213 | val_0_mse: 0.01866 |  0:08:05s\n",
      "epoch 47 | loss: 0.02152 | val_0_mse: 0.02285 |  0:08:16s\n",
      "epoch 48 | loss: 0.02258 | val_0_mse: 0.02615 |  0:08:27s\n",
      "epoch 49 | loss: 0.01818 | val_0_mse: 0.01264 |  0:08:37s\n",
      "epoch 50 | loss: 0.01913 | val_0_mse: 0.02189 |  0:08:48s\n",
      "epoch 51 | loss: 0.02167 | val_0_mse: 0.01524 |  0:08:59s\n",
      "epoch 52 | loss: 0.02261 | val_0_mse: 0.02016 |  0:09:09s\n",
      "epoch 53 | loss: 0.0194  | val_0_mse: 0.02244 |  0:09:20s\n",
      "epoch 54 | loss: 0.01697 | val_0_mse: 0.01859 |  0:09:31s\n",
      "epoch 55 | loss: 0.01676 | val_0_mse: 0.08811 |  0:09:42s\n",
      "epoch 56 | loss: 0.01795 | val_0_mse: 0.02583 |  0:09:52s\n",
      "epoch 57 | loss: 0.0182  | val_0_mse: 0.01038 |  0:10:03s\n",
      "epoch 58 | loss: 0.01685 | val_0_mse: 0.00996 |  0:10:14s\n",
      "epoch 59 | loss: 0.01719 | val_0_mse: 0.01011 |  0:10:24s\n",
      "epoch 60 | loss: 0.01714 | val_0_mse: 0.01327 |  0:10:35s\n",
      "epoch 61 | loss: 0.01381 | val_0_mse: 0.00932 |  0:10:46s\n",
      "epoch 62 | loss: 0.01955 | val_0_mse: 0.01474 |  0:10:57s\n",
      "epoch 63 | loss: 0.01516 | val_0_mse: 0.0129  |  0:11:08s\n",
      "epoch 64 | loss: 0.01469 | val_0_mse: 0.01408 |  0:11:18s\n",
      "epoch 65 | loss: 0.01541 | val_0_mse: 0.0322  |  0:11:29s\n",
      "epoch 66 | loss: 0.03026 | val_0_mse: 0.03123 |  0:11:40s\n",
      "epoch 67 | loss: 0.02286 | val_0_mse: 0.01747 |  0:11:51s\n",
      "epoch 68 | loss: 0.01742 | val_0_mse: 0.0194  |  0:12:01s\n",
      "epoch 69 | loss: 0.01548 | val_0_mse: 0.01099 |  0:12:12s\n",
      "epoch 70 | loss: 0.01177 | val_0_mse: 0.01618 |  0:12:23s\n",
      "epoch 71 | loss: 0.01767 | val_0_mse: 0.03    |  0:12:34s\n",
      "\n",
      "Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_mse = 0.00932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009475 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.957256 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 25/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.22295 | val_0_mse: 0.11954 |  0:00:26s\n",
      "epoch 1  | loss: 0.13803 | val_0_mse: 0.0883  |  0:00:52s\n",
      "epoch 2  | loss: 0.11258 | val_0_mse: 0.07523 |  0:01:19s\n",
      "epoch 3  | loss: 0.10371 | val_0_mse: 0.07892 |  0:01:45s\n",
      "epoch 4  | loss: 0.0778  | val_0_mse: 0.05688 |  0:02:12s\n",
      "epoch 5  | loss: 0.07927 | val_0_mse: 0.05832 |  0:02:38s\n",
      "epoch 6  | loss: 0.07308 | val_0_mse: 0.05112 |  0:03:04s\n",
      "epoch 7  | loss: 0.06536 | val_0_mse: 0.03837 |  0:03:30s\n",
      "epoch 8  | loss: 0.05095 | val_0_mse: 0.02612 |  0:03:57s\n",
      "epoch 9  | loss: 0.04325 | val_0_mse: 0.02914 |  0:04:23s\n",
      "epoch 10 | loss: 0.03915 | val_0_mse: 0.02288 |  0:04:49s\n",
      "epoch 11 | loss: 0.03079 | val_0_mse: 0.01773 |  0:05:15s\n",
      "epoch 12 | loss: 0.02763 | val_0_mse: 0.05077 |  0:05:42s\n",
      "epoch 13 | loss: 0.03388 | val_0_mse: 0.0231  |  0:06:08s\n",
      "epoch 14 | loss: 0.02786 | val_0_mse: 0.04806 |  0:06:35s\n",
      "epoch 15 | loss: 0.02969 | val_0_mse: 0.02465 |  0:07:01s\n",
      "epoch 16 | loss: 0.02563 | val_0_mse: 0.00981 |  0:07:27s\n",
      "epoch 17 | loss: 0.02874 | val_0_mse: 0.01601 |  0:07:54s\n",
      "epoch 18 | loss: 0.02763 | val_0_mse: 0.01152 |  0:08:20s\n",
      "epoch 19 | loss: 0.02659 | val_0_mse: 0.00993 |  0:08:46s\n",
      "epoch 20 | loss: 0.02823 | val_0_mse: 0.05381 |  0:09:12s\n",
      "epoch 21 | loss: 0.025   | val_0_mse: 0.02856 |  0:09:38s\n",
      "epoch 22 | loss: 0.02338 | val_0_mse: 0.02817 |  0:10:05s\n",
      "epoch 23 | loss: 0.02665 | val_0_mse: 0.13685 |  0:10:31s\n",
      "epoch 24 | loss: 0.0242  | val_0_mse: 0.0223  |  0:10:58s\n",
      "epoch 25 | loss: 0.02665 | val_0_mse: 0.0169  |  0:11:24s\n",
      "epoch 26 | loss: 0.02242 | val_0_mse: 0.05808 |  0:11:50s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_mse = 0.00981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009061 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.959121 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 26/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.49669 | val_0_mse: 0.16941 |  0:00:16s\n",
      "epoch 1  | loss: 0.17869 | val_0_mse: 0.109   |  0:00:33s\n",
      "epoch 2  | loss: 0.12258 | val_0_mse: 0.07039 |  0:00:50s\n",
      "epoch 3  | loss: 0.09677 | val_0_mse: 0.14684 |  0:01:07s\n",
      "epoch 4  | loss: 0.08842 | val_0_mse: 0.06791 |  0:01:24s\n",
      "epoch 5  | loss: 0.07194 | val_0_mse: 0.06506 |  0:01:41s\n",
      "epoch 6  | loss: 0.06811 | val_0_mse: 0.05707 |  0:01:58s\n",
      "epoch 7  | loss: 0.0565  | val_0_mse: 0.13225 |  0:02:15s\n",
      "epoch 8  | loss: 0.04448 | val_0_mse: 0.05724 |  0:02:32s\n",
      "epoch 9  | loss: 0.0378  | val_0_mse: 0.02034 |  0:02:49s\n",
      "epoch 10 | loss: 0.03372 | val_0_mse: 0.01676 |  0:03:06s\n",
      "epoch 11 | loss: 0.02382 | val_0_mse: 0.01769 |  0:03:23s\n",
      "epoch 12 | loss: 0.02441 | val_0_mse: 0.01902 |  0:03:40s\n",
      "epoch 13 | loss: 0.02357 | val_0_mse: 0.01696 |  0:03:57s\n",
      "epoch 14 | loss: 0.01629 | val_0_mse: 0.01655 |  0:04:14s\n",
      "epoch 15 | loss: 0.0172  | val_0_mse: 0.02695 |  0:04:31s\n",
      "epoch 16 | loss: 0.02035 | val_0_mse: 0.00941 |  0:04:48s\n",
      "epoch 17 | loss: 0.01773 | val_0_mse: 0.00756 |  0:05:05s\n",
      "epoch 18 | loss: 0.02015 | val_0_mse: 0.03164 |  0:05:22s\n",
      "epoch 19 | loss: 0.01849 | val_0_mse: 0.0131  |  0:05:39s\n",
      "epoch 20 | loss: 0.01819 | val_0_mse: 0.01827 |  0:05:56s\n",
      "epoch 21 | loss: 0.01914 | val_0_mse: 0.00792 |  0:06:13s\n",
      "epoch 22 | loss: 0.01715 | val_0_mse: 0.01382 |  0:06:29s\n",
      "epoch 23 | loss: 0.01542 | val_0_mse: 0.02176 |  0:06:46s\n",
      "epoch 24 | loss: 0.01436 | val_0_mse: 0.03453 |  0:07:03s\n",
      "epoch 25 | loss: 0.01703 | val_0_mse: 0.00661 |  0:07:20s\n",
      "epoch 26 | loss: 0.01283 | val_0_mse: 0.01788 |  0:07:37s\n",
      "epoch 27 | loss: 0.01797 | val_0_mse: 0.03567 |  0:07:54s\n",
      "epoch 28 | loss: 0.01739 | val_0_mse: 0.0304  |  0:08:11s\n",
      "epoch 29 | loss: 0.01628 | val_0_mse: 0.00646 |  0:08:28s\n",
      "epoch 30 | loss: 0.01858 | val_0_mse: 0.03923 |  0:08:45s\n",
      "epoch 31 | loss: 0.01497 | val_0_mse: 0.02011 |  0:09:02s\n",
      "epoch 32 | loss: 0.01288 | val_0_mse: 0.01126 |  0:09:19s\n",
      "epoch 33 | loss: 0.01228 | val_0_mse: 0.02903 |  0:09:36s\n",
      "epoch 34 | loss: 0.01374 | val_0_mse: 0.00633 |  0:09:53s\n",
      "epoch 35 | loss: 0.01439 | val_0_mse: 0.01815 |  0:10:10s\n",
      "epoch 36 | loss: 0.01394 | val_0_mse: 0.01996 |  0:10:27s\n",
      "epoch 37 | loss: 0.01513 | val_0_mse: 0.00812 |  0:10:43s\n",
      "epoch 38 | loss: 0.01466 | val_0_mse: 0.02259 |  0:11:00s\n",
      "epoch 39 | loss: 0.01337 | val_0_mse: 0.00862 |  0:11:18s\n",
      "epoch 40 | loss: 0.01274 | val_0_mse: 0.01052 |  0:11:34s\n",
      "epoch 41 | loss: 0.01159 | val_0_mse: 0.00948 |  0:11:51s\n",
      "epoch 42 | loss: 0.01825 | val_0_mse: 0.01475 |  0:12:08s\n",
      "epoch 43 | loss: 0.01363 | val_0_mse: 0.02382 |  0:12:25s\n",
      "epoch 44 | loss: 0.01474 | val_0_mse: 0.07124 |  0:12:42s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_mse = 0.00633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006810 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.969278 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 27/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.05534 | val_0_mse: 0.35982 |  0:00:10s\n",
      "epoch 1  | loss: 0.29693 | val_0_mse: 0.33213 |  0:00:20s\n",
      "epoch 2  | loss: 0.10997 | val_0_mse: 0.15132 |  0:00:30s\n",
      "epoch 3  | loss: 0.10132 | val_0_mse: 0.17957 |  0:00:40s\n",
      "epoch 4  | loss: 0.07688 | val_0_mse: 0.14274 |  0:00:50s\n",
      "epoch 5  | loss: 0.07196 | val_0_mse: 0.0974  |  0:01:00s\n",
      "epoch 6  | loss: 0.07988 | val_0_mse: 0.05406 |  0:01:10s\n",
      "epoch 7  | loss: 0.06848 | val_0_mse: 0.05873 |  0:01:20s\n",
      "epoch 8  | loss: 0.06879 | val_0_mse: 0.07751 |  0:01:30s\n",
      "epoch 9  | loss: 0.0748  | val_0_mse: 0.07117 |  0:01:40s\n",
      "epoch 10 | loss: 0.0641  | val_0_mse: 0.04794 |  0:01:50s\n",
      "epoch 11 | loss: 0.05675 | val_0_mse: 0.07138 |  0:01:59s\n",
      "epoch 12 | loss: 0.05591 | val_0_mse: 0.04861 |  0:02:09s\n",
      "epoch 13 | loss: 0.05056 | val_0_mse: 0.04819 |  0:02:19s\n",
      "epoch 14 | loss: 0.05114 | val_0_mse: 0.05789 |  0:02:29s\n",
      "epoch 15 | loss: 0.05035 | val_0_mse: 0.03278 |  0:02:39s\n",
      "epoch 16 | loss: 0.04269 | val_0_mse: 0.03557 |  0:02:49s\n",
      "epoch 17 | loss: 0.04234 | val_0_mse: 0.04633 |  0:03:00s\n",
      "epoch 18 | loss: 0.04066 | val_0_mse: 0.03176 |  0:03:10s\n",
      "epoch 19 | loss: 0.03576 | val_0_mse: 0.03122 |  0:03:20s\n",
      "epoch 20 | loss: 0.03764 | val_0_mse: 0.03671 |  0:03:30s\n",
      "epoch 21 | loss: 0.03583 | val_0_mse: 0.02016 |  0:03:40s\n",
      "epoch 22 | loss: 0.02711 | val_0_mse: 0.02466 |  0:03:50s\n",
      "epoch 23 | loss: 0.02712 | val_0_mse: 0.04128 |  0:04:00s\n",
      "epoch 24 | loss: 0.0292  | val_0_mse: 0.04841 |  0:04:10s\n",
      "epoch 25 | loss: 0.03473 | val_0_mse: 0.0226  |  0:04:19s\n",
      "epoch 26 | loss: 0.02803 | val_0_mse: 0.02224 |  0:04:30s\n",
      "epoch 27 | loss: 0.02079 | val_0_mse: 0.03745 |  0:04:40s\n",
      "epoch 28 | loss: 0.01886 | val_0_mse: 0.0204  |  0:04:50s\n",
      "epoch 29 | loss: 0.02119 | val_0_mse: 0.02149 |  0:04:59s\n",
      "epoch 30 | loss: 0.02213 | val_0_mse: 0.01339 |  0:05:09s\n",
      "epoch 31 | loss: 0.01666 | val_0_mse: 0.01666 |  0:05:19s\n",
      "epoch 32 | loss: 0.0196  | val_0_mse: 0.01161 |  0:05:30s\n",
      "epoch 33 | loss: 0.01703 | val_0_mse: 0.01537 |  0:05:41s\n",
      "epoch 34 | loss: 0.01682 | val_0_mse: 0.00924 |  0:05:51s\n",
      "epoch 35 | loss: 0.01232 | val_0_mse: 0.00957 |  0:06:01s\n",
      "epoch 36 | loss: 0.01353 | val_0_mse: 0.00769 |  0:06:11s\n",
      "epoch 37 | loss: 0.01309 | val_0_mse: 0.02762 |  0:06:21s\n",
      "epoch 38 | loss: 0.0153  | val_0_mse: 0.01429 |  0:06:31s\n",
      "epoch 39 | loss: 0.0215  | val_0_mse: 0.03581 |  0:06:41s\n",
      "epoch 40 | loss: 0.02398 | val_0_mse: 0.02337 |  0:06:51s\n",
      "epoch 41 | loss: 0.01892 | val_0_mse: 0.01102 |  0:07:01s\n",
      "epoch 42 | loss: 0.01511 | val_0_mse: 0.01568 |  0:07:11s\n",
      "epoch 43 | loss: 0.01428 | val_0_mse: 0.00884 |  0:07:22s\n",
      "epoch 44 | loss: 0.02084 | val_0_mse: 0.01678 |  0:07:32s\n",
      "epoch 45 | loss: 0.01294 | val_0_mse: 0.01543 |  0:07:42s\n",
      "epoch 46 | loss: 0.018   | val_0_mse: 0.00927 |  0:07:52s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_mse = 0.00769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007415 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.966547 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 28/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.95407 | val_0_mse: 0.21419 |  0:00:28s\n",
      "epoch 1  | loss: 0.13748 | val_0_mse: 0.09964 |  0:00:56s\n",
      "epoch 2  | loss: 0.11645 | val_0_mse: 0.06606 |  0:01:25s\n",
      "epoch 3  | loss: 0.08379 | val_0_mse: 0.07568 |  0:01:53s\n",
      "epoch 4  | loss: 0.07811 | val_0_mse: 0.16364 |  0:02:21s\n",
      "epoch 5  | loss: 0.07906 | val_0_mse: 0.04546 |  0:02:50s\n",
      "epoch 6  | loss: 0.08106 | val_0_mse: 0.04397 |  0:03:18s\n",
      "epoch 7  | loss: 0.06105 | val_0_mse: 0.05192 |  0:03:46s\n",
      "epoch 8  | loss: 0.05204 | val_0_mse: 0.08211 |  0:04:15s\n",
      "epoch 9  | loss: 0.04383 | val_0_mse: 0.02755 |  0:04:43s\n",
      "epoch 10 | loss: 0.03929 | val_0_mse: 0.04199 |  0:05:11s\n",
      "epoch 11 | loss: 0.0307  | val_0_mse: 0.01243 |  0:05:40s\n",
      "epoch 12 | loss: 0.0307  | val_0_mse: 0.00974 |  0:06:08s\n",
      "epoch 13 | loss: 0.02662 | val_0_mse: 0.00938 |  0:06:36s\n",
      "epoch 14 | loss: 0.02858 | val_0_mse: 0.01691 |  0:07:05s\n",
      "epoch 15 | loss: 0.02277 | val_0_mse: 0.02829 |  0:07:33s\n",
      "epoch 16 | loss: 0.02509 | val_0_mse: 0.01318 |  0:08:01s\n",
      "epoch 17 | loss: 0.02417 | val_0_mse: 0.03317 |  0:08:30s\n",
      "epoch 18 | loss: 0.02182 | val_0_mse: 0.01104 |  0:08:58s\n",
      "epoch 19 | loss: 0.02196 | val_0_mse: 0.02196 |  0:09:27s\n",
      "epoch 20 | loss: 0.02627 | val_0_mse: 0.0321  |  0:09:55s\n",
      "epoch 21 | loss: 0.02457 | val_0_mse: 0.02548 |  0:10:23s\n",
      "epoch 22 | loss: 0.02694 | val_0_mse: 0.01593 |  0:10:52s\n",
      "epoch 23 | loss: 0.02338 | val_0_mse: 0.01185 |  0:11:20s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_mse = 0.00938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009838 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.955619 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 29/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.23796 | val_0_mse: 0.20087 |  0:00:18s\n",
      "epoch 1  | loss: 0.23985 | val_0_mse: 0.3316  |  0:00:37s\n",
      "epoch 2  | loss: 0.14663 | val_0_mse: 0.08308 |  0:00:55s\n",
      "epoch 3  | loss: 0.10808 | val_0_mse: 0.09107 |  0:01:14s\n",
      "epoch 4  | loss: 0.0795  | val_0_mse: 0.12349 |  0:01:32s\n",
      "epoch 5  | loss: 0.08098 | val_0_mse: 0.06715 |  0:01:51s\n",
      "epoch 6  | loss: 0.07504 | val_0_mse: 0.05465 |  0:02:09s\n",
      "epoch 7  | loss: 0.07033 | val_0_mse: 0.06278 |  0:02:28s\n",
      "epoch 8  | loss: 0.06138 | val_0_mse: 0.05463 |  0:02:46s\n",
      "epoch 9  | loss: 0.06077 | val_0_mse: 0.06529 |  0:03:05s\n",
      "epoch 10 | loss: 0.05415 | val_0_mse: 0.05016 |  0:03:24s\n",
      "epoch 11 | loss: 0.05242 | val_0_mse: 0.0821  |  0:03:42s\n",
      "epoch 12 | loss: 0.05098 | val_0_mse: 0.05081 |  0:04:00s\n",
      "epoch 13 | loss: 0.05076 | val_0_mse: 0.03413 |  0:04:19s\n",
      "epoch 14 | loss: 0.06004 | val_0_mse: 0.04005 |  0:04:37s\n",
      "epoch 15 | loss: 0.04401 | val_0_mse: 0.03776 |  0:04:56s\n",
      "epoch 16 | loss: 0.044   | val_0_mse: 0.02736 |  0:05:15s\n",
      "epoch 17 | loss: 0.03192 | val_0_mse: 0.0382  |  0:05:33s\n",
      "epoch 18 | loss: 0.04233 | val_0_mse: 0.04662 |  0:05:52s\n",
      "epoch 19 | loss: 0.04371 | val_0_mse: 0.05176 |  0:06:10s\n",
      "epoch 20 | loss: 0.03143 | val_0_mse: 0.02075 |  0:06:29s\n",
      "epoch 21 | loss: 0.02875 | val_0_mse: 0.01562 |  0:06:47s\n",
      "epoch 22 | loss: 0.02357 | val_0_mse: 0.01664 |  0:07:06s\n",
      "epoch 23 | loss: 0.02594 | val_0_mse: 0.0245  |  0:07:24s\n",
      "epoch 24 | loss: 0.02508 | val_0_mse: 0.01204 |  0:07:43s\n",
      "epoch 25 | loss: 0.02642 | val_0_mse: 0.01093 |  0:08:02s\n",
      "epoch 26 | loss: 0.01974 | val_0_mse: 0.03484 |  0:08:20s\n",
      "epoch 27 | loss: 0.01912 | val_0_mse: 0.01688 |  0:08:39s\n",
      "epoch 28 | loss: 0.01777 | val_0_mse: 0.01765 |  0:08:57s\n",
      "epoch 29 | loss: 0.02188 | val_0_mse: 0.01329 |  0:09:16s\n",
      "epoch 30 | loss: 0.01908 | val_0_mse: 0.00924 |  0:09:35s\n",
      "epoch 31 | loss: 0.01908 | val_0_mse: 0.0101  |  0:09:54s\n",
      "epoch 32 | loss: 0.02766 | val_0_mse: 0.12591 |  0:10:12s\n",
      "epoch 33 | loss: 0.02975 | val_0_mse: 0.01668 |  0:10:31s\n",
      "epoch 34 | loss: 0.02371 | val_0_mse: 0.02185 |  0:10:50s\n",
      "epoch 35 | loss: 0.02324 | val_0_mse: 0.03284 |  0:11:08s\n",
      "epoch 36 | loss: 0.01986 | val_0_mse: 0.14233 |  0:11:27s\n",
      "epoch 37 | loss: 0.02248 | val_0_mse: 0.06662 |  0:11:46s\n",
      "epoch 38 | loss: 0.02333 | val_0_mse: 0.23265 |  0:12:04s\n",
      "epoch 39 | loss: 0.02561 | val_0_mse: 0.01527 |  0:12:23s\n",
      "epoch 40 | loss: 0.02081 | val_0_mse: 0.01337 |  0:12:41s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_mse = 0.00924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009263 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.958213 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 30/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.29938 | val_0_mse: 0.63859 |  0:00:10s\n",
      "epoch 1  | loss: 0.36451 | val_0_mse: 0.12539 |  0:00:21s\n",
      "epoch 2  | loss: 0.12258 | val_0_mse: 0.1695  |  0:00:32s\n",
      "epoch 3  | loss: 0.09769 | val_0_mse: 0.14462 |  0:00:43s\n",
      "epoch 4  | loss: 0.08605 | val_0_mse: 0.07606 |  0:00:53s\n",
      "epoch 5  | loss: 0.0867  | val_0_mse: 0.0707  |  0:01:04s\n",
      "epoch 6  | loss: 0.0801  | val_0_mse: 0.06885 |  0:01:15s\n",
      "epoch 7  | loss: 0.07379 | val_0_mse: 0.06228 |  0:01:26s\n",
      "epoch 8  | loss: 0.07323 | val_0_mse: 0.08618 |  0:01:37s\n",
      "epoch 9  | loss: 0.07282 | val_0_mse: 0.06656 |  0:01:47s\n",
      "epoch 10 | loss: 0.07414 | val_0_mse: 0.06011 |  0:01:58s\n",
      "epoch 11 | loss: 0.06198 | val_0_mse: 0.04958 |  0:02:09s\n",
      "epoch 12 | loss: 0.05823 | val_0_mse: 0.06213 |  0:02:20s\n",
      "epoch 13 | loss: 0.0595  | val_0_mse: 0.04888 |  0:02:31s\n",
      "epoch 14 | loss: 0.05676 | val_0_mse: 0.06419 |  0:02:42s\n",
      "epoch 15 | loss: 0.05231 | val_0_mse: 0.04323 |  0:02:52s\n",
      "epoch 16 | loss: 0.05214 | val_0_mse: 0.05265 |  0:03:03s\n",
      "epoch 17 | loss: 0.05143 | val_0_mse: 0.03941 |  0:03:14s\n",
      "epoch 18 | loss: 0.0444  | val_0_mse: 0.03446 |  0:03:24s\n",
      "epoch 19 | loss: 0.04063 | val_0_mse: 0.04877 |  0:03:35s\n",
      "epoch 20 | loss: 0.03905 | val_0_mse: 0.02755 |  0:03:46s\n",
      "epoch 21 | loss: 0.03501 | val_0_mse: 0.06439 |  0:03:57s\n",
      "epoch 22 | loss: 0.045   | val_0_mse: 0.03118 |  0:04:07s\n",
      "epoch 23 | loss: 0.03417 | val_0_mse: 0.01856 |  0:04:18s\n",
      "epoch 24 | loss: 0.03175 | val_0_mse: 0.03457 |  0:04:28s\n",
      "epoch 25 | loss: 0.02717 | val_0_mse: 0.02778 |  0:04:38s\n",
      "epoch 26 | loss: 0.02209 | val_0_mse: 0.01321 |  0:04:49s\n",
      "epoch 27 | loss: 0.01787 | val_0_mse: 0.02259 |  0:04:59s\n",
      "epoch 28 | loss: 0.01921 | val_0_mse: 0.0115  |  0:05:10s\n",
      "epoch 29 | loss: 0.02379 | val_0_mse: 0.01516 |  0:05:21s\n",
      "epoch 30 | loss: 0.0195  | val_0_mse: 0.02816 |  0:05:32s\n",
      "epoch 31 | loss: 0.01611 | val_0_mse: 0.0223  |  0:05:42s\n",
      "epoch 32 | loss: 0.01538 | val_0_mse: 0.00995 |  0:05:53s\n",
      "epoch 33 | loss: 0.02043 | val_0_mse: 0.01692 |  0:06:04s\n",
      "epoch 34 | loss: 0.01701 | val_0_mse: 0.00964 |  0:06:15s\n",
      "epoch 35 | loss: 0.01475 | val_0_mse: 0.01265 |  0:06:25s\n",
      "epoch 36 | loss: 0.01937 | val_0_mse: 0.01923 |  0:06:36s\n",
      "epoch 37 | loss: 0.01951 | val_0_mse: 0.02748 |  0:06:47s\n",
      "epoch 38 | loss: 0.02589 | val_0_mse: 0.05201 |  0:06:58s\n",
      "epoch 39 | loss: 0.018   | val_0_mse: 0.01581 |  0:07:08s\n",
      "epoch 40 | loss: 0.01498 | val_0_mse: 0.01262 |  0:07:19s\n",
      "epoch 41 | loss: 0.0135  | val_0_mse: 0.01365 |  0:07:30s\n",
      "epoch 42 | loss: 0.01559 | val_0_mse: 0.03516 |  0:07:41s\n",
      "epoch 43 | loss: 0.02064 | val_0_mse: 0.01009 |  0:07:52s\n",
      "epoch 44 | loss: 0.01355 | val_0_mse: 0.00795 |  0:08:02s\n",
      "epoch 45 | loss: 0.01005 | val_0_mse: 0.01898 |  0:08:13s\n",
      "epoch 46 | loss: 0.01206 | val_0_mse: 0.0109  |  0:08:24s\n",
      "epoch 47 | loss: 0.01218 | val_0_mse: 0.00866 |  0:08:35s\n",
      "epoch 48 | loss: 0.01394 | val_0_mse: 0.0083  |  0:08:45s\n",
      "epoch 49 | loss: 0.01225 | val_0_mse: 0.01544 |  0:08:56s\n",
      "epoch 50 | loss: 0.01104 | val_0_mse: 0.01074 |  0:09:07s\n",
      "epoch 51 | loss: 0.01255 | val_0_mse: 0.00829 |  0:09:18s\n",
      "epoch 52 | loss: 0.01398 | val_0_mse: 0.01005 |  0:09:28s\n",
      "epoch 53 | loss: 0.00928 | val_0_mse: 0.01414 |  0:09:39s\n",
      "epoch 54 | loss: 0.01175 | val_0_mse: 0.01566 |  0:09:50s\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_mse = 0.00795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008701 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.960747 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 31/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.8619  | val_0_mse: 0.14786 |  0:00:28s\n",
      "epoch 1  | loss: 0.1474  | val_0_mse: 0.10509 |  0:00:56s\n",
      "epoch 2  | loss: 0.12169 | val_0_mse: 0.07887 |  0:01:24s\n",
      "epoch 3  | loss: 0.1211  | val_0_mse: 0.11436 |  0:01:53s\n",
      "epoch 4  | loss: 0.09927 | val_0_mse: 0.10127 |  0:02:21s\n",
      "epoch 5  | loss: 0.07925 | val_0_mse: 0.04609 |  0:02:50s\n",
      "epoch 6  | loss: 0.07346 | val_0_mse: 0.10298 |  0:03:17s\n",
      "epoch 7  | loss: 0.09114 | val_0_mse: 0.07706 |  0:03:45s\n",
      "epoch 8  | loss: 0.07777 | val_0_mse: 0.09167 |  0:04:14s\n",
      "epoch 9  | loss: 0.07618 | val_0_mse: 0.05073 |  0:04:42s\n",
      "epoch 10 | loss: 0.07345 | val_0_mse: 0.07059 |  0:05:10s\n",
      "epoch 11 | loss: 0.06758 | val_0_mse: 0.04795 |  0:05:38s\n",
      "epoch 12 | loss: 0.06498 | val_0_mse: 0.04326 |  0:06:06s\n",
      "epoch 13 | loss: 0.05579 | val_0_mse: 0.03515 |  0:06:34s\n",
      "epoch 14 | loss: 0.04279 | val_0_mse: 0.02524 |  0:07:02s\n",
      "epoch 15 | loss: 0.03349 | val_0_mse: 0.04216 |  0:07:30s\n",
      "epoch 16 | loss: 0.03135 | val_0_mse: 0.03244 |  0:07:59s\n",
      "epoch 17 | loss: 0.02697 | val_0_mse: 0.04294 |  0:08:27s\n",
      "epoch 18 | loss: 0.02615 | val_0_mse: 0.01964 |  0:08:55s\n",
      "epoch 19 | loss: 0.02271 | val_0_mse: 0.01062 |  0:09:23s\n",
      "epoch 20 | loss: 0.02584 | val_0_mse: 0.01597 |  0:09:51s\n",
      "epoch 21 | loss: 0.02401 | val_0_mse: 0.00951 |  0:10:19s\n",
      "epoch 22 | loss: 0.02287 | val_0_mse: 0.01717 |  0:10:48s\n",
      "epoch 23 | loss: 0.02322 | val_0_mse: 0.03777 |  0:11:16s\n",
      "epoch 24 | loss: 0.02308 | val_0_mse: 0.01659 |  0:11:44s\n",
      "epoch 25 | loss: 0.02043 | val_0_mse: 0.02016 |  0:12:12s\n",
      "epoch 26 | loss: 0.0218  | val_0_mse: 0.01898 |  0:12:40s\n",
      "epoch 27 | loss: 0.01953 | val_0_mse: 0.01311 |  0:13:08s\n",
      "epoch 28 | loss: 0.02121 | val_0_mse: 0.01606 |  0:13:36s\n",
      "epoch 29 | loss: 0.02114 | val_0_mse: 0.01599 |  0:14:05s\n",
      "epoch 30 | loss: 0.02127 | val_0_mse: 0.02919 |  0:14:33s\n",
      "epoch 31 | loss: 0.02097 | val_0_mse: 0.0204  |  0:15:01s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mse = 0.00951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008436 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.961943 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 32/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.11408 | val_0_mse: 0.59787 |  0:00:17s\n",
      "epoch 1  | loss: 0.18668 | val_0_mse: 0.13425 |  0:00:35s\n",
      "epoch 2  | loss: 0.12096 | val_0_mse: 0.10364 |  0:00:53s\n",
      "epoch 3  | loss: 0.09836 | val_0_mse: 0.06804 |  0:01:11s\n",
      "epoch 4  | loss: 0.09214 | val_0_mse: 0.07321 |  0:01:28s\n",
      "epoch 5  | loss: 0.09594 | val_0_mse: 0.06043 |  0:01:46s\n",
      "epoch 6  | loss: 0.06745 | val_0_mse: 0.06559 |  0:02:04s\n",
      "epoch 7  | loss: 0.06928 | val_0_mse: 0.11222 |  0:02:22s\n",
      "epoch 8  | loss: 0.06272 | val_0_mse: 0.04059 |  0:02:40s\n",
      "epoch 9  | loss: 0.05561 | val_0_mse: 0.04576 |  0:02:57s\n",
      "epoch 10 | loss: 0.05892 | val_0_mse: 0.04026 |  0:03:15s\n",
      "epoch 11 | loss: 0.04797 | val_0_mse: 0.0389  |  0:03:33s\n",
      "epoch 12 | loss: 0.04532 | val_0_mse: 0.03059 |  0:03:51s\n",
      "epoch 13 | loss: 0.03962 | val_0_mse: 0.03494 |  0:04:08s\n",
      "epoch 14 | loss: 0.03892 | val_0_mse: 0.03446 |  0:04:26s\n",
      "epoch 15 | loss: 0.03736 | val_0_mse: 0.05804 |  0:04:44s\n",
      "epoch 16 | loss: 0.03257 | val_0_mse: 0.10248 |  0:05:02s\n",
      "epoch 17 | loss: 0.02707 | val_0_mse: 0.02619 |  0:05:20s\n",
      "epoch 18 | loss: 0.02388 | val_0_mse: 0.02419 |  0:05:37s\n",
      "epoch 19 | loss: 0.02487 | val_0_mse: 0.05669 |  0:05:55s\n",
      "epoch 20 | loss: 0.02231 | val_0_mse: 0.01383 |  0:06:13s\n",
      "epoch 21 | loss: 0.02832 | val_0_mse: 0.02199 |  0:06:31s\n",
      "epoch 22 | loss: 0.02104 | val_0_mse: 0.0127  |  0:06:49s\n",
      "epoch 23 | loss: 0.01892 | val_0_mse: 0.02664 |  0:07:06s\n",
      "epoch 24 | loss: 0.0231  | val_0_mse: 0.02372 |  0:07:24s\n",
      "epoch 25 | loss: 0.01835 | val_0_mse: 0.02657 |  0:07:42s\n",
      "epoch 26 | loss: 0.01955 | val_0_mse: 0.01111 |  0:08:00s\n",
      "epoch 27 | loss: 0.01676 | val_0_mse: 0.00956 |  0:08:18s\n",
      "epoch 28 | loss: 0.01924 | val_0_mse: 0.0182  |  0:08:36s\n",
      "epoch 29 | loss: 0.02139 | val_0_mse: 0.01018 |  0:08:54s\n",
      "epoch 30 | loss: 0.02197 | val_0_mse: 0.01907 |  0:09:16s\n",
      "epoch 31 | loss: 0.0182  | val_0_mse: 0.01802 |  0:09:34s\n",
      "epoch 32 | loss: 0.02129 | val_0_mse: 0.04967 |  0:09:52s\n",
      "epoch 33 | loss: 0.01913 | val_0_mse: 0.01242 |  0:10:10s\n",
      "epoch 34 | loss: 0.01767 | val_0_mse: 0.04355 |  0:10:27s\n",
      "epoch 35 | loss: 0.018   | val_0_mse: 0.01559 |  0:10:45s\n",
      "epoch 36 | loss: 0.01702 | val_0_mse: 0.08589 |  0:11:03s\n",
      "epoch 37 | loss: 0.02243 | val_0_mse: 0.01526 |  0:11:21s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_mse = 0.00956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009064 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.959110 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 33/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.93943 | val_0_mse: 1.1461  |  0:00:10s\n",
      "epoch 1  | loss: 0.24361 | val_0_mse: 0.35156 |  0:00:20s\n",
      "epoch 2  | loss: 0.1147  | val_0_mse: 0.20798 |  0:00:31s\n",
      "epoch 3  | loss: 0.08919 | val_0_mse: 0.19677 |  0:00:41s\n",
      "epoch 4  | loss: 0.09031 | val_0_mse: 0.0688  |  0:00:52s\n",
      "epoch 5  | loss: 0.0794  | val_0_mse: 0.0883  |  0:01:03s\n",
      "epoch 6  | loss: 0.07741 | val_0_mse: 0.07474 |  0:01:13s\n",
      "epoch 7  | loss: 0.07443 | val_0_mse: 0.0648  |  0:01:24s\n",
      "epoch 8  | loss: 0.07678 | val_0_mse: 0.06582 |  0:01:35s\n",
      "epoch 9  | loss: 0.0644  | val_0_mse: 0.13192 |  0:01:46s\n",
      "epoch 10 | loss: 0.08111 | val_0_mse: 0.06954 |  0:01:56s\n",
      "epoch 11 | loss: 0.06513 | val_0_mse: 0.05569 |  0:02:07s\n",
      "epoch 12 | loss: 0.05803 | val_0_mse: 0.06276 |  0:02:18s\n",
      "epoch 13 | loss: 0.05538 | val_0_mse: 0.04772 |  0:02:28s\n",
      "epoch 14 | loss: 0.05606 | val_0_mse: 0.04851 |  0:02:39s\n",
      "epoch 15 | loss: 0.05104 | val_0_mse: 0.06161 |  0:02:50s\n",
      "epoch 16 | loss: 0.04977 | val_0_mse: 0.04593 |  0:03:01s\n",
      "epoch 17 | loss: 0.04768 | val_0_mse: 0.04519 |  0:03:12s\n",
      "epoch 18 | loss: 0.04431 | val_0_mse: 0.04031 |  0:03:22s\n",
      "epoch 19 | loss: 0.04642 | val_0_mse: 0.04333 |  0:03:33s\n",
      "epoch 20 | loss: 0.0413  | val_0_mse: 0.03815 |  0:03:44s\n",
      "epoch 21 | loss: 0.04688 | val_0_mse: 0.04346 |  0:03:55s\n",
      "epoch 22 | loss: 0.04487 | val_0_mse: 0.04056 |  0:04:05s\n",
      "epoch 23 | loss: 0.04253 | val_0_mse: 0.04387 |  0:04:16s\n",
      "epoch 24 | loss: 0.03615 | val_0_mse: 0.04069 |  0:04:27s\n",
      "epoch 25 | loss: 0.04461 | val_0_mse: 0.0545  |  0:04:38s\n",
      "epoch 26 | loss: 0.04177 | val_0_mse: 0.03221 |  0:04:48s\n",
      "epoch 27 | loss: 0.03896 | val_0_mse: 0.0314  |  0:04:59s\n",
      "epoch 28 | loss: 0.03651 | val_0_mse: 0.05252 |  0:05:10s\n",
      "epoch 29 | loss: 0.0343  | val_0_mse: 0.03498 |  0:05:21s\n",
      "epoch 30 | loss: 0.0307  | val_0_mse: 0.03505 |  0:05:32s\n",
      "epoch 31 | loss: 0.03027 | val_0_mse: 0.02105 |  0:05:42s\n",
      "epoch 32 | loss: 0.0332  | val_0_mse: 0.04223 |  0:05:53s\n",
      "epoch 33 | loss: 0.02817 | val_0_mse: 0.02587 |  0:06:04s\n",
      "epoch 34 | loss: 0.02428 | val_0_mse: 0.02193 |  0:06:15s\n",
      "epoch 35 | loss: 0.02386 | val_0_mse: 0.01934 |  0:06:25s\n",
      "epoch 36 | loss: 0.02352 | val_0_mse: 0.06566 |  0:06:36s\n",
      "epoch 37 | loss: 0.02292 | val_0_mse: 0.01952 |  0:06:47s\n",
      "epoch 38 | loss: 0.02219 | val_0_mse: 0.03098 |  0:06:58s\n",
      "epoch 39 | loss: 0.01983 | val_0_mse: 0.01409 |  0:07:09s\n",
      "epoch 40 | loss: 0.0252  | val_0_mse: 0.03757 |  0:07:20s\n",
      "epoch 41 | loss: 0.02183 | val_0_mse: 0.03456 |  0:07:30s\n",
      "epoch 42 | loss: 0.01834 | val_0_mse: 0.01886 |  0:07:41s\n",
      "epoch 43 | loss: 0.01803 | val_0_mse: 0.01839 |  0:07:52s\n",
      "epoch 44 | loss: 0.01639 | val_0_mse: 0.01113 |  0:08:02s\n",
      "epoch 45 | loss: 0.01314 | val_0_mse: 0.01147 |  0:08:13s\n",
      "epoch 46 | loss: 0.01523 | val_0_mse: 0.00905 |  0:08:24s\n",
      "epoch 47 | loss: 0.01307 | val_0_mse: 0.01185 |  0:08:34s\n",
      "epoch 48 | loss: 0.01336 | val_0_mse: 0.01346 |  0:08:45s\n",
      "epoch 49 | loss: 0.01272 | val_0_mse: 0.01736 |  0:08:56s\n",
      "epoch 50 | loss: 0.0147  | val_0_mse: 0.00964 |  0:09:06s\n",
      "epoch 51 | loss: 0.01268 | val_0_mse: 0.03351 |  0:09:17s\n",
      "epoch 52 | loss: 0.01888 | val_0_mse: 0.01004 |  0:09:28s\n",
      "epoch 53 | loss: 0.01647 | val_0_mse: 0.02    |  0:09:38s\n",
      "epoch 54 | loss: 0.01434 | val_0_mse: 0.01084 |  0:09:49s\n",
      "epoch 55 | loss: 0.0145  | val_0_mse: 0.01721 |  0:10:00s\n",
      "epoch 56 | loss: 0.01396 | val_0_mse: 0.00831 |  0:10:11s\n",
      "epoch 57 | loss: 0.01277 | val_0_mse: 0.00946 |  0:10:22s\n",
      "epoch 58 | loss: 0.01365 | val_0_mse: 0.00751 |  0:10:32s\n",
      "epoch 59 | loss: 0.01456 | val_0_mse: 0.01027 |  0:10:43s\n",
      "epoch 60 | loss: 0.01241 | val_0_mse: 0.00854 |  0:10:54s\n",
      "epoch 61 | loss: 0.01514 | val_0_mse: 0.00688 |  0:11:05s\n",
      "epoch 62 | loss: 0.01102 | val_0_mse: 0.00975 |  0:11:15s\n",
      "epoch 63 | loss: 0.01072 | val_0_mse: 0.00965 |  0:11:26s\n",
      "epoch 64 | loss: 0.01233 | val_0_mse: 0.00899 |  0:11:37s\n",
      "epoch 65 | loss: 0.01431 | val_0_mse: 0.01063 |  0:11:48s\n",
      "epoch 66 | loss: 0.0121  | val_0_mse: 0.01418 |  0:11:58s\n",
      "epoch 67 | loss: 0.00991 | val_0_mse: 0.01363 |  0:12:09s\n",
      "epoch 68 | loss: 0.01091 | val_0_mse: 0.00566 |  0:12:20s\n",
      "epoch 69 | loss: 0.01278 | val_0_mse: 0.00792 |  0:12:31s\n",
      "epoch 70 | loss: 0.01258 | val_0_mse: 0.04508 |  0:12:41s\n",
      "epoch 71 | loss: 0.01483 | val_0_mse: 0.01096 |  0:12:52s\n",
      "epoch 72 | loss: 0.01052 | val_0_mse: 0.00595 |  0:13:03s\n",
      "epoch 73 | loss: 0.00844 | val_0_mse: 0.01253 |  0:13:14s\n",
      "epoch 74 | loss: 0.0091  | val_0_mse: 0.01056 |  0:13:25s\n",
      "epoch 75 | loss: 0.00922 | val_0_mse: 0.00662 |  0:13:35s\n",
      "epoch 76 | loss: 0.01073 | val_0_mse: 0.01144 |  0:13:46s\n",
      "epoch 77 | loss: 0.01039 | val_0_mse: 0.17088 |  0:13:57s\n",
      "epoch 78 | loss: 0.00919 | val_0_mse: 0.00932 |  0:14:08s\n",
      "\n",
      "Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_mse = 0.00566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.005920 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.973292 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 34/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.82267 | val_0_mse: 0.13859 |  0:00:30s\n",
      "epoch 1  | loss: 0.13653 | val_0_mse: 0.11405 |  0:01:02s\n",
      "epoch 2  | loss: 0.1479  | val_0_mse: 0.08296 |  0:01:32s\n",
      "epoch 3  | loss: 0.08361 | val_0_mse: 0.09567 |  0:02:03s\n",
      "epoch 4  | loss: 0.07207 | val_0_mse: 0.0424  |  0:02:34s\n",
      "epoch 5  | loss: 0.05901 | val_0_mse: 0.08033 |  0:03:05s\n",
      "epoch 6  | loss: 0.04871 | val_0_mse: 0.04303 |  0:03:36s\n",
      "epoch 7  | loss: 0.03869 | val_0_mse: 0.02539 |  0:04:07s\n",
      "epoch 8  | loss: 0.03383 | val_0_mse: 0.0274  |  0:04:38s\n",
      "epoch 9  | loss: 0.03411 | val_0_mse: 0.02808 |  0:05:08s\n",
      "epoch 10 | loss: 0.02994 | val_0_mse: 0.06057 |  0:05:39s\n",
      "epoch 11 | loss: 0.02819 | val_0_mse: 0.03753 |  0:06:10s\n",
      "epoch 12 | loss: 0.02715 | val_0_mse: 0.02456 |  0:06:41s\n",
      "epoch 13 | loss: 0.03106 | val_0_mse: 0.04793 |  0:07:12s\n",
      "epoch 14 | loss: 0.02425 | val_0_mse: 0.00977 |  0:07:43s\n",
      "epoch 15 | loss: 0.0272  | val_0_mse: 0.02858 |  0:08:14s\n",
      "epoch 16 | loss: 0.02555 | val_0_mse: 0.01618 |  0:08:44s\n",
      "epoch 17 | loss: 0.02516 | val_0_mse: 0.01483 |  0:09:15s\n",
      "epoch 18 | loss: 0.02311 | val_0_mse: 0.03716 |  0:09:46s\n",
      "epoch 19 | loss: 0.02358 | val_0_mse: 0.03241 |  0:10:17s\n",
      "epoch 20 | loss: 0.0254  | val_0_mse: 0.04234 |  0:10:47s\n",
      "epoch 21 | loss: 0.02072 | val_0_mse: 0.01674 |  0:11:18s\n",
      "epoch 22 | loss: 0.01984 | val_0_mse: 0.01968 |  0:11:49s\n",
      "epoch 23 | loss: 0.02304 | val_0_mse: 0.00667 |  0:12:20s\n",
      "epoch 24 | loss: 0.02896 | val_0_mse: 0.01148 |  0:12:51s\n",
      "epoch 25 | loss: 0.01762 | val_0_mse: 0.03122 |  0:13:22s\n",
      "epoch 26 | loss: 0.02543 | val_0_mse: 0.02614 |  0:13:52s\n",
      "epoch 27 | loss: 0.02099 | val_0_mse: 0.00844 |  0:14:23s\n",
      "epoch 28 | loss: 0.01849 | val_0_mse: 0.02387 |  0:14:54s\n",
      "epoch 29 | loss: 0.02308 | val_0_mse: 0.01694 |  0:15:25s\n",
      "epoch 30 | loss: 0.02101 | val_0_mse: 0.00832 |  0:15:56s\n",
      "epoch 31 | loss: 0.02635 | val_0_mse: 0.12831 |  0:16:27s\n",
      "epoch 32 | loss: 0.02159 | val_0_mse: 0.01942 |  0:16:58s\n",
      "epoch 33 | loss: 0.02305 | val_0_mse: 0.01362 |  0:17:29s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_mse = 0.00667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006307 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.971549 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 35/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.29272 | val_0_mse: 0.44348 |  0:00:20s\n",
      "epoch 1  | loss: 0.1801  | val_0_mse: 0.33466 |  0:00:40s\n",
      "epoch 2  | loss: 0.14008 | val_0_mse: 0.10862 |  0:01:00s\n",
      "epoch 3  | loss: 0.1266  | val_0_mse: 0.10812 |  0:01:20s\n",
      "epoch 4  | loss: 0.09105 | val_0_mse: 0.08644 |  0:01:40s\n",
      "epoch 5  | loss: 0.06752 | val_0_mse: 0.09369 |  0:01:59s\n",
      "epoch 6  | loss: 0.06107 | val_0_mse: 0.05141 |  0:02:19s\n",
      "epoch 7  | loss: 0.04443 | val_0_mse: 0.09273 |  0:02:39s\n",
      "epoch 8  | loss: 0.04078 | val_0_mse: 0.03542 |  0:02:59s\n",
      "epoch 9  | loss: 0.04208 | val_0_mse: 0.04325 |  0:03:19s\n",
      "epoch 10 | loss: 0.03673 | val_0_mse: 0.02381 |  0:03:39s\n",
      "epoch 11 | loss: 0.03249 | val_0_mse: 0.01927 |  0:03:59s\n",
      "epoch 12 | loss: 0.02662 | val_0_mse: 0.05278 |  0:04:18s\n",
      "epoch 13 | loss: 0.02342 | val_0_mse: 0.0257  |  0:04:38s\n",
      "epoch 14 | loss: 0.02006 | val_0_mse: 0.01882 |  0:04:58s\n",
      "epoch 15 | loss: 0.02118 | val_0_mse: 0.04182 |  0:05:18s\n",
      "epoch 16 | loss: 0.01907 | val_0_mse: 0.02947 |  0:05:38s\n",
      "epoch 17 | loss: 0.02066 | val_0_mse: 0.02102 |  0:05:58s\n",
      "epoch 18 | loss: 0.02246 | val_0_mse: 0.0475  |  0:06:18s\n",
      "epoch 19 | loss: 0.02201 | val_0_mse: 0.03181 |  0:06:38s\n",
      "epoch 20 | loss: 0.01801 | val_0_mse: 0.01111 |  0:06:58s\n",
      "epoch 21 | loss: 0.0201  | val_0_mse: 0.0393  |  0:07:18s\n",
      "epoch 22 | loss: 0.02072 | val_0_mse: 0.06502 |  0:07:38s\n",
      "epoch 23 | loss: 0.02899 | val_0_mse: 0.03146 |  0:07:58s\n",
      "epoch 24 | loss: 0.02548 | val_0_mse: 0.03464 |  0:08:18s\n",
      "epoch 25 | loss: 0.01984 | val_0_mse: 0.00858 |  0:08:37s\n",
      "epoch 26 | loss: 0.01829 | val_0_mse: 0.01996 |  0:08:58s\n",
      "epoch 27 | loss: 0.02013 | val_0_mse: 0.02334 |  0:09:18s\n",
      "epoch 28 | loss: 0.02029 | val_0_mse: 0.03728 |  0:09:38s\n",
      "epoch 29 | loss: 0.01718 | val_0_mse: 0.01427 |  0:09:57s\n",
      "epoch 30 | loss: 0.01797 | val_0_mse: 0.01933 |  0:10:17s\n",
      "epoch 31 | loss: 0.02153 | val_0_mse: 0.01595 |  0:10:37s\n",
      "epoch 32 | loss: 0.01822 | val_0_mse: 0.01713 |  0:10:57s\n",
      "epoch 33 | loss: 0.01819 | val_0_mse: 0.04673 |  0:11:17s\n",
      "epoch 34 | loss: 0.01327 | val_0_mse: 0.01546 |  0:11:37s\n",
      "epoch 35 | loss: 0.01616 | val_0_mse: 0.01942 |  0:11:57s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mse = 0.00858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009359 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.957779 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 36/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.19016 | val_0_mse: 0.84064 |  0:00:11s\n",
      "epoch 1  | loss: 0.28198 | val_0_mse: 0.47903 |  0:00:23s\n",
      "epoch 2  | loss: 0.14544 | val_0_mse: 0.12322 |  0:00:35s\n",
      "epoch 3  | loss: 0.10678 | val_0_mse: 0.10851 |  0:00:46s\n",
      "epoch 4  | loss: 0.11916 | val_0_mse: 0.08177 |  0:00:58s\n",
      "epoch 5  | loss: 0.0832  | val_0_mse: 0.07251 |  0:01:10s\n",
      "epoch 6  | loss: 0.0751  | val_0_mse: 0.09711 |  0:01:21s\n",
      "epoch 7  | loss: 0.06497 | val_0_mse: 0.06367 |  0:01:34s\n",
      "epoch 8  | loss: 0.05508 | val_0_mse: 0.15773 |  0:01:45s\n",
      "epoch 9  | loss: 0.05233 | val_0_mse: 0.03591 |  0:01:57s\n",
      "epoch 10 | loss: 0.04949 | val_0_mse: 0.05001 |  0:02:09s\n",
      "epoch 11 | loss: 0.0476  | val_0_mse: 0.03578 |  0:02:20s\n",
      "epoch 12 | loss: 0.03818 | val_0_mse: 0.0297  |  0:02:32s\n",
      "epoch 13 | loss: 0.03866 | val_0_mse: 0.03402 |  0:02:44s\n",
      "epoch 14 | loss: 0.05383 | val_0_mse: 0.03903 |  0:02:56s\n",
      "epoch 15 | loss: 0.03601 | val_0_mse: 0.06718 |  0:03:07s\n",
      "epoch 16 | loss: 0.03825 | val_0_mse: 0.02739 |  0:03:19s\n",
      "epoch 17 | loss: 0.03357 | val_0_mse: 0.03611 |  0:03:31s\n",
      "epoch 18 | loss: 0.02563 | val_0_mse: 0.03186 |  0:03:42s\n",
      "epoch 19 | loss: 0.02914 | val_0_mse: 0.01538 |  0:03:54s\n",
      "epoch 20 | loss: 0.0218  | val_0_mse: 0.01529 |  0:04:06s\n",
      "epoch 21 | loss: 0.02195 | val_0_mse: 0.01217 |  0:04:17s\n",
      "epoch 22 | loss: 0.01786 | val_0_mse: 0.05119 |  0:04:28s\n",
      "epoch 23 | loss: 0.02677 | val_0_mse: 0.00969 |  0:04:40s\n",
      "epoch 24 | loss: 0.01871 | val_0_mse: 0.02616 |  0:04:51s\n",
      "epoch 25 | loss: 0.02127 | val_0_mse: 0.03843 |  0:05:02s\n",
      "epoch 26 | loss: 0.01564 | val_0_mse: 0.0316  |  0:05:13s\n",
      "epoch 27 | loss: 0.01373 | val_0_mse: 0.05052 |  0:05:25s\n",
      "epoch 28 | loss: 0.02257 | val_0_mse: 0.0096  |  0:05:36s\n",
      "epoch 29 | loss: 0.02053 | val_0_mse: 0.00808 |  0:05:47s\n",
      "epoch 30 | loss: 0.01674 | val_0_mse: 0.0103  |  0:05:58s\n",
      "epoch 31 | loss: 0.01378 | val_0_mse: 0.02178 |  0:06:10s\n",
      "epoch 32 | loss: 0.01756 | val_0_mse: 0.00733 |  0:06:21s\n",
      "epoch 33 | loss: 0.01253 | val_0_mse: 0.01751 |  0:06:32s\n",
      "epoch 34 | loss: 0.01417 | val_0_mse: 0.01458 |  0:06:43s\n",
      "epoch 35 | loss: 0.01601 | val_0_mse: 0.01897 |  0:06:54s\n",
      "epoch 36 | loss: 0.01653 | val_0_mse: 0.01265 |  0:07:05s\n",
      "epoch 37 | loss: 0.01631 | val_0_mse: 0.01509 |  0:07:17s\n",
      "epoch 38 | loss: 0.01414 | val_0_mse: 0.01014 |  0:07:28s\n",
      "epoch 39 | loss: 0.01142 | val_0_mse: 0.02615 |  0:07:39s\n",
      "epoch 40 | loss: 0.01407 | val_0_mse: 0.01101 |  0:07:50s\n",
      "epoch 41 | loss: 0.01293 | val_0_mse: 0.0094  |  0:08:01s\n",
      "epoch 42 | loss: 0.02135 | val_0_mse: 0.01107 |  0:08:12s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 0.00733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007224 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.967409 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 37/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.15295 | val_0_mse: 0.13369 |  0:00:30s\n",
      "epoch 1  | loss: 0.12247 | val_0_mse: 0.10354 |  0:01:01s\n",
      "epoch 2  | loss: 0.08914 | val_0_mse: 0.1369  |  0:01:31s\n",
      "epoch 3  | loss: 0.09119 | val_0_mse: 0.09202 |  0:02:01s\n",
      "epoch 4  | loss: 0.09944 | val_0_mse: 0.06157 |  0:02:31s\n",
      "epoch 5  | loss: 0.07124 | val_0_mse: 0.07267 |  0:03:01s\n",
      "epoch 6  | loss: 0.06569 | val_0_mse: 0.05261 |  0:03:31s\n",
      "epoch 7  | loss: 0.05896 | val_0_mse: 0.03887 |  0:04:02s\n",
      "epoch 8  | loss: 0.05169 | val_0_mse: 0.04737 |  0:04:32s\n",
      "epoch 9  | loss: 0.04457 | val_0_mse: 0.02918 |  0:05:02s\n",
      "epoch 10 | loss: 0.04575 | val_0_mse: 0.0634  |  0:05:32s\n",
      "epoch 11 | loss: 0.05388 | val_0_mse: 0.04098 |  0:06:03s\n",
      "epoch 12 | loss: 0.04073 | val_0_mse: 0.02571 |  0:06:33s\n",
      "epoch 13 | loss: 0.04483 | val_0_mse: 0.02676 |  0:07:03s\n",
      "epoch 14 | loss: 0.03022 | val_0_mse: 0.0287  |  0:07:33s\n",
      "epoch 15 | loss: 0.02707 | val_0_mse: 0.0919  |  0:08:04s\n",
      "epoch 16 | loss: 0.03266 | val_0_mse: 0.0275  |  0:08:34s\n",
      "epoch 17 | loss: 0.03096 | val_0_mse: 0.01835 |  0:09:04s\n",
      "epoch 18 | loss: 0.02752 | val_0_mse: 0.05506 |  0:09:35s\n",
      "epoch 19 | loss: 0.02502 | val_0_mse: 0.02341 |  0:10:08s\n",
      "epoch 20 | loss: 0.02564 | val_0_mse: 0.06914 |  0:10:38s\n",
      "epoch 21 | loss: 0.02416 | val_0_mse: 0.05162 |  0:11:09s\n",
      "epoch 22 | loss: 0.02377 | val_0_mse: 0.01476 |  0:11:39s\n",
      "epoch 23 | loss: 0.02374 | val_0_mse: 0.01752 |  0:12:09s\n",
      "epoch 24 | loss: 0.02368 | val_0_mse: 0.00933 |  0:12:39s\n",
      "epoch 25 | loss: 0.02493 | val_0_mse: 0.03674 |  0:13:10s\n",
      "epoch 26 | loss: 0.02574 | val_0_mse: 0.02686 |  0:13:40s\n",
      "epoch 27 | loss: 0.0267  | val_0_mse: 0.04793 |  0:14:10s\n",
      "epoch 28 | loss: 0.02899 | val_0_mse: 0.01331 |  0:14:40s\n",
      "epoch 29 | loss: 0.0241  | val_0_mse: 0.01791 |  0:15:11s\n",
      "epoch 30 | loss: 0.02492 | val_0_mse: 0.01638 |  0:15:41s\n",
      "epoch 31 | loss: 0.02259 | val_0_mse: 0.01128 |  0:16:11s\n",
      "epoch 32 | loss: 0.02193 | val_0_mse: 0.02062 |  0:16:41s\n",
      "epoch 33 | loss: 0.02573 | val_0_mse: 0.01905 |  0:17:11s\n",
      "epoch 34 | loss: 0.02343 | val_0_mse: 0.05646 |  0:17:42s\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_mse = 0.00933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009659 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.956427 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 38/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.75098 | val_0_mse: 0.40001 |  0:00:19s\n",
      "epoch 1  | loss: 0.17063 | val_0_mse: 0.08413 |  0:00:38s\n",
      "epoch 2  | loss: 0.09399 | val_0_mse: 0.06804 |  0:00:57s\n",
      "epoch 3  | loss: 0.08729 | val_0_mse: 0.09445 |  0:01:16s\n",
      "epoch 4  | loss: 0.09268 | val_0_mse: 0.07446 |  0:01:35s\n",
      "epoch 5  | loss: 0.07823 | val_0_mse: 0.07205 |  0:01:54s\n",
      "epoch 6  | loss: 0.07169 | val_0_mse: 0.05754 |  0:02:13s\n",
      "epoch 7  | loss: 0.06966 | val_0_mse: 0.05272 |  0:02:32s\n",
      "epoch 8  | loss: 0.06099 | val_0_mse: 0.08621 |  0:02:51s\n",
      "epoch 9  | loss: 0.04567 | val_0_mse: 0.04102 |  0:03:10s\n",
      "epoch 10 | loss: 0.04583 | val_0_mse: 0.05549 |  0:03:30s\n",
      "epoch 11 | loss: 0.04837 | val_0_mse: 0.03691 |  0:03:49s\n",
      "epoch 12 | loss: 0.03393 | val_0_mse: 0.05921 |  0:04:08s\n",
      "epoch 13 | loss: 0.03754 | val_0_mse: 0.03279 |  0:04:27s\n",
      "epoch 14 | loss: 0.02991 | val_0_mse: 0.02881 |  0:04:46s\n",
      "epoch 15 | loss: 0.02774 | val_0_mse: 0.02554 |  0:05:06s\n",
      "epoch 16 | loss: 0.03174 | val_0_mse: 0.02181 |  0:05:25s\n",
      "epoch 17 | loss: 0.0348  | val_0_mse: 0.0236  |  0:05:44s\n",
      "epoch 18 | loss: 0.02528 | val_0_mse: 0.02942 |  0:06:03s\n",
      "epoch 19 | loss: 0.02451 | val_0_mse: 0.03677 |  0:06:22s\n",
      "epoch 20 | loss: 0.02584 | val_0_mse: 0.01901 |  0:06:41s\n",
      "epoch 21 | loss: 0.02504 | val_0_mse: 0.07363 |  0:07:00s\n",
      "epoch 22 | loss: 0.02324 | val_0_mse: 0.01037 |  0:07:19s\n",
      "epoch 23 | loss: 0.02606 | val_0_mse: 0.02196 |  0:07:39s\n",
      "epoch 24 | loss: 0.01948 | val_0_mse: 0.011   |  0:07:58s\n",
      "epoch 25 | loss: 0.02589 | val_0_mse: 0.06092 |  0:08:17s\n",
      "epoch 26 | loss: 0.02973 | val_0_mse: 0.01984 |  0:08:36s\n",
      "epoch 27 | loss: 0.02941 | val_0_mse: 0.02305 |  0:08:55s\n",
      "epoch 28 | loss: 0.02248 | val_0_mse: 0.02381 |  0:09:15s\n",
      "epoch 29 | loss: 0.01923 | val_0_mse: 0.00997 |  0:09:34s\n",
      "epoch 30 | loss: 0.01543 | val_0_mse: 0.00915 |  0:09:53s\n",
      "epoch 31 | loss: 0.0182  | val_0_mse: 0.03029 |  0:10:12s\n",
      "epoch 32 | loss: 0.02168 | val_0_mse: 0.04588 |  0:10:31s\n",
      "epoch 33 | loss: 0.02006 | val_0_mse: 0.01344 |  0:10:51s\n",
      "epoch 34 | loss: 0.01956 | val_0_mse: 0.02724 |  0:11:10s\n",
      "epoch 35 | loss: 0.01937 | val_0_mse: 0.01663 |  0:11:29s\n",
      "epoch 36 | loss: 0.0188  | val_0_mse: 0.01105 |  0:11:49s\n",
      "epoch 37 | loss: 0.01537 | val_0_mse: 0.01012 |  0:12:08s\n",
      "epoch 38 | loss: 0.01782 | val_0_mse: 0.00848 |  0:12:28s\n",
      "epoch 39 | loss: 0.01536 | val_0_mse: 0.01019 |  0:12:47s\n",
      "epoch 40 | loss: 0.01708 | val_0_mse: 0.03396 |  0:13:06s\n",
      "epoch 41 | loss: 0.01453 | val_0_mse: 0.01844 |  0:13:25s\n",
      "epoch 42 | loss: 0.01874 | val_0_mse: 0.00977 |  0:13:45s\n",
      "epoch 43 | loss: 0.01228 | val_0_mse: 0.01234 |  0:14:04s\n",
      "epoch 44 | loss: 0.01265 | val_0_mse: 0.01269 |  0:14:23s\n",
      "epoch 45 | loss: 0.0145  | val_0_mse: 0.00756 |  0:14:43s\n",
      "epoch 46 | loss: 0.01261 | val_0_mse: 0.01954 |  0:15:02s\n",
      "epoch 47 | loss: 0.01656 | val_0_mse: 0.01444 |  0:15:21s\n",
      "epoch 48 | loss: 0.01237 | val_0_mse: 0.012   |  0:15:40s\n",
      "epoch 49 | loss: 0.01955 | val_0_mse: 0.02026 |  0:16:00s\n",
      "epoch 50 | loss: 0.01399 | val_0_mse: 0.01329 |  0:16:19s\n",
      "epoch 51 | loss: 0.01405 | val_0_mse: 0.01328 |  0:16:38s\n",
      "epoch 52 | loss: 0.02003 | val_0_mse: 0.04267 |  0:16:57s\n",
      "epoch 53 | loss: 0.01424 | val_0_mse: 0.02436 |  0:17:16s\n",
      "epoch 54 | loss: 0.01731 | val_0_mse: 0.01085 |  0:17:35s\n",
      "epoch 55 | loss: 0.01504 | val_0_mse: 0.01179 |  0:17:54s\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_mse = 0.00756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007135 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.967810 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 39/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.01985 | val_0_mse: 0.23005 |  0:00:11s\n",
      "epoch 1  | loss: 0.7015  | val_0_mse: 0.14935 |  0:00:22s\n",
      "epoch 2  | loss: 0.18605 | val_0_mse: 0.40244 |  0:00:33s\n",
      "epoch 3  | loss: 0.12515 | val_0_mse: 0.10359 |  0:00:45s\n",
      "epoch 4  | loss: 0.12046 | val_0_mse: 0.09442 |  0:00:56s\n",
      "epoch 5  | loss: 0.08966 | val_0_mse: 0.07089 |  0:01:07s\n",
      "epoch 6  | loss: 0.06861 | val_0_mse: 0.079   |  0:01:18s\n",
      "epoch 7  | loss: 0.07674 | val_0_mse: 0.04828 |  0:01:29s\n",
      "epoch 8  | loss: 0.05685 | val_0_mse: 0.04888 |  0:01:40s\n",
      "epoch 9  | loss: 0.04902 | val_0_mse: 0.053   |  0:01:51s\n",
      "epoch 10 | loss: 0.06032 | val_0_mse: 0.0466  |  0:02:02s\n",
      "epoch 11 | loss: 0.05844 | val_0_mse: 0.0419  |  0:02:14s\n",
      "epoch 12 | loss: 0.04772 | val_0_mse: 0.04264 |  0:02:25s\n",
      "epoch 13 | loss: 0.04622 | val_0_mse: 0.04883 |  0:02:36s\n",
      "epoch 14 | loss: 0.0484  | val_0_mse: 0.05711 |  0:02:47s\n",
      "epoch 15 | loss: 0.04593 | val_0_mse: 0.03165 |  0:02:58s\n",
      "epoch 16 | loss: 0.03752 | val_0_mse: 0.02848 |  0:03:09s\n",
      "epoch 17 | loss: 0.03758 | val_0_mse: 0.02422 |  0:03:21s\n",
      "epoch 18 | loss: 0.03102 | val_0_mse: 0.05955 |  0:03:32s\n",
      "epoch 19 | loss: 0.02936 | val_0_mse: 0.02588 |  0:03:43s\n",
      "epoch 20 | loss: 0.02697 | val_0_mse: 0.02423 |  0:03:54s\n",
      "epoch 21 | loss: 0.02688 | val_0_mse: 0.03903 |  0:04:05s\n",
      "epoch 22 | loss: 0.02929 | val_0_mse: 0.02101 |  0:04:16s\n",
      "epoch 23 | loss: 0.02318 | val_0_mse: 0.01635 |  0:04:27s\n",
      "epoch 24 | loss: 0.02097 | val_0_mse: 0.02918 |  0:04:38s\n",
      "epoch 25 | loss: 0.02104 | val_0_mse: 0.0155  |  0:04:49s\n",
      "epoch 26 | loss: 0.02415 | val_0_mse: 0.01849 |  0:05:01s\n",
      "epoch 27 | loss: 0.02195 | val_0_mse: 0.02367 |  0:05:12s\n",
      "epoch 28 | loss: 0.02117 | val_0_mse: 0.0311  |  0:05:23s\n",
      "epoch 29 | loss: 0.02964 | val_0_mse: 0.03083 |  0:05:34s\n",
      "epoch 30 | loss: 0.01919 | val_0_mse: 0.01322 |  0:05:45s\n",
      "epoch 31 | loss: 0.01804 | val_0_mse: 0.01316 |  0:05:56s\n",
      "epoch 32 | loss: 0.01632 | val_0_mse: 0.01241 |  0:06:07s\n",
      "epoch 33 | loss: 0.02113 | val_0_mse: 0.01268 |  0:06:18s\n",
      "epoch 34 | loss: 0.01326 | val_0_mse: 0.00975 |  0:06:29s\n",
      "epoch 35 | loss: 0.0121  | val_0_mse: 0.01677 |  0:06:40s\n",
      "epoch 36 | loss: 0.01517 | val_0_mse: 0.00833 |  0:06:52s\n",
      "epoch 37 | loss: 0.0127  | val_0_mse: 0.01012 |  0:07:03s\n",
      "epoch 38 | loss: 0.01323 | val_0_mse: 0.01101 |  0:07:14s\n",
      "epoch 39 | loss: 0.01322 | val_0_mse: 0.00878 |  0:07:25s\n",
      "epoch 40 | loss: 0.01273 | val_0_mse: 0.01323 |  0:07:36s\n",
      "epoch 41 | loss: 0.01287 | val_0_mse: 0.01327 |  0:07:48s\n",
      "epoch 42 | loss: 0.01137 | val_0_mse: 0.01143 |  0:07:59s\n",
      "epoch 43 | loss: 0.00917 | val_0_mse: 0.01264 |  0:08:10s\n",
      "epoch 44 | loss: 0.01433 | val_0_mse: 0.00945 |  0:08:21s\n",
      "epoch 45 | loss: 0.01515 | val_0_mse: 0.02829 |  0:08:32s\n",
      "epoch 46 | loss: 0.01637 | val_0_mse: 0.0123  |  0:08:44s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_mse = 0.00833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008053 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.963671 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 40/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.00967 | val_0_mse: 0.22041 |  0:00:32s\n",
      "epoch 1  | loss: 0.18324 | val_0_mse: 0.11488 |  0:01:05s\n",
      "epoch 2  | loss: 0.13087 | val_0_mse: 0.09863 |  0:01:37s\n",
      "epoch 3  | loss: 0.10936 | val_0_mse: 0.07127 |  0:02:10s\n",
      "epoch 4  | loss: 0.08289 | val_0_mse: 0.09482 |  0:02:42s\n",
      "epoch 5  | loss: 0.06669 | val_0_mse: 0.04702 |  0:03:15s\n",
      "epoch 6  | loss: 0.04274 | val_0_mse: 0.06516 |  0:03:47s\n",
      "epoch 7  | loss: 0.03446 | val_0_mse: 0.04357 |  0:04:20s\n",
      "epoch 8  | loss: 0.03787 | val_0_mse: 0.01641 |  0:04:52s\n",
      "epoch 9  | loss: 0.03086 | val_0_mse: 0.02027 |  0:05:25s\n",
      "epoch 10 | loss: 0.02871 | val_0_mse: 0.02097 |  0:05:57s\n",
      "epoch 11 | loss: 0.02977 | val_0_mse: 0.0211  |  0:06:30s\n",
      "epoch 12 | loss: 0.02581 | val_0_mse: 0.02497 |  0:07:02s\n",
      "epoch 13 | loss: 0.02591 | val_0_mse: 0.01493 |  0:07:34s\n",
      "epoch 14 | loss: 0.02838 | val_0_mse: 0.01482 |  0:08:07s\n",
      "epoch 15 | loss: 0.02666 | val_0_mse: 0.01174 |  0:08:39s\n",
      "epoch 16 | loss: 0.02764 | val_0_mse: 0.02143 |  0:09:12s\n",
      "epoch 17 | loss: 0.02977 | val_0_mse: 0.014   |  0:09:44s\n",
      "epoch 18 | loss: 0.02394 | val_0_mse: 0.04564 |  0:10:17s\n",
      "epoch 19 | loss: 0.02575 | val_0_mse: 0.01047 |  0:10:50s\n",
      "epoch 20 | loss: 0.02155 | val_0_mse: 0.01333 |  0:11:22s\n",
      "epoch 21 | loss: 0.01902 | val_0_mse: 0.01472 |  0:11:54s\n",
      "epoch 22 | loss: 0.02429 | val_0_mse: 0.01345 |  0:12:27s\n",
      "epoch 23 | loss: 0.02283 | val_0_mse: 0.03312 |  0:12:59s\n",
      "epoch 24 | loss: 0.02312 | val_0_mse: 0.03065 |  0:13:32s\n",
      "epoch 25 | loss: 0.02248 | val_0_mse: 0.02906 |  0:14:04s\n",
      "epoch 26 | loss: 0.02226 | val_0_mse: 0.03354 |  0:14:37s\n",
      "epoch 27 | loss: 0.02087 | val_0_mse: 0.17292 |  0:15:09s\n",
      "epoch 28 | loss: 0.02143 | val_0_mse: 0.02588 |  0:15:41s\n",
      "epoch 29 | loss: 0.0215  | val_0_mse: 0.00828 |  0:16:14s\n",
      "epoch 30 | loss: 0.0265  | val_0_mse: 0.04249 |  0:16:46s\n",
      "epoch 31 | loss: 0.02351 | val_0_mse: 0.06073 |  0:17:19s\n",
      "epoch 32 | loss: 0.02202 | val_0_mse: 0.03741 |  0:17:51s\n",
      "epoch 33 | loss: 0.02264 | val_0_mse: 0.59647 |  0:18:24s\n",
      "epoch 34 | loss: 0.02487 | val_0_mse: 0.01169 |  0:18:56s\n",
      "epoch 35 | loss: 0.02019 | val_0_mse: 0.01549 |  0:19:28s\n",
      "epoch 36 | loss: 0.02064 | val_0_mse: 0.02102 |  0:20:01s\n",
      "epoch 37 | loss: 0.02034 | val_0_mse: 0.01287 |  0:20:34s\n",
      "epoch 38 | loss: 0.02117 | val_0_mse: 0.01202 |  0:21:06s\n",
      "epoch 39 | loss: 0.01986 | val_0_mse: 0.01847 |  0:21:39s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_mse = 0.00828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.025449 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.885192 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 41/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.68362 | val_0_mse: 0.737   |  0:00:20s\n",
      "epoch 1  | loss: 0.17964 | val_0_mse: 0.1964  |  0:00:40s\n",
      "epoch 2  | loss: 0.10166 | val_0_mse: 0.07088 |  0:01:01s\n",
      "epoch 3  | loss: 0.07939 | val_0_mse: 0.07579 |  0:01:22s\n",
      "epoch 4  | loss: 0.07954 | val_0_mse: 0.09904 |  0:01:43s\n",
      "epoch 5  | loss: 0.06582 | val_0_mse: 0.04663 |  0:02:03s\n",
      "epoch 6  | loss: 0.06466 | val_0_mse: 0.05219 |  0:02:23s\n",
      "epoch 7  | loss: 0.05246 | val_0_mse: 0.06013 |  0:02:43s\n",
      "epoch 8  | loss: 0.05023 | val_0_mse: 0.06346 |  0:03:04s\n",
      "epoch 9  | loss: 0.04492 | val_0_mse: 0.04652 |  0:03:24s\n",
      "epoch 10 | loss: 0.03964 | val_0_mse: 0.02867 |  0:03:44s\n",
      "epoch 11 | loss: 0.04127 | val_0_mse: 0.03196 |  0:04:04s\n",
      "epoch 12 | loss: 0.03299 | val_0_mse: 0.02977 |  0:04:25s\n",
      "epoch 13 | loss: 0.03577 | val_0_mse: 0.03265 |  0:04:45s\n",
      "epoch 14 | loss: 0.03035 | val_0_mse: 0.01954 |  0:05:05s\n",
      "epoch 15 | loss: 0.02989 | val_0_mse: 0.04847 |  0:05:25s\n",
      "epoch 16 | loss: 0.03765 | val_0_mse: 0.03508 |  0:05:46s\n",
      "epoch 17 | loss: 0.03549 | val_0_mse: 0.04601 |  0:06:06s\n",
      "epoch 18 | loss: 0.03493 | val_0_mse: 0.02408 |  0:06:27s\n",
      "epoch 19 | loss: 0.03104 | val_0_mse: 0.01558 |  0:06:47s\n",
      "epoch 20 | loss: 0.0204  | val_0_mse: 0.0221  |  0:07:07s\n",
      "epoch 21 | loss: 0.02442 | val_0_mse: 0.01548 |  0:07:27s\n",
      "epoch 22 | loss: 0.02019 | val_0_mse: 0.01419 |  0:07:48s\n",
      "epoch 23 | loss: 0.01813 | val_0_mse: 0.02494 |  0:08:08s\n",
      "epoch 24 | loss: 0.01911 | val_0_mse: 0.01938 |  0:08:28s\n",
      "epoch 25 | loss: 0.0165  | val_0_mse: 0.01568 |  0:08:48s\n",
      "epoch 26 | loss: 0.01692 | val_0_mse: 0.02499 |  0:09:08s\n",
      "epoch 27 | loss: 0.01826 | val_0_mse: 0.00944 |  0:09:28s\n",
      "epoch 28 | loss: 0.01619 | val_0_mse: 0.00915 |  0:09:49s\n",
      "epoch 29 | loss: 0.01496 | val_0_mse: 0.00785 |  0:10:09s\n",
      "epoch 30 | loss: 0.01542 | val_0_mse: 0.00933 |  0:10:29s\n",
      "epoch 31 | loss: 0.01406 | val_0_mse: 0.0156  |  0:10:49s\n",
      "epoch 32 | loss: 0.01477 | val_0_mse: 0.01504 |  0:11:10s\n",
      "epoch 33 | loss: 0.01555 | val_0_mse: 0.03638 |  0:11:30s\n",
      "epoch 34 | loss: 0.01636 | val_0_mse: 0.01115 |  0:11:50s\n",
      "epoch 35 | loss: 0.01315 | val_0_mse: 0.00618 |  0:12:10s\n",
      "epoch 36 | loss: 0.01356 | val_0_mse: 0.00565 |  0:12:30s\n",
      "epoch 37 | loss: 0.01771 | val_0_mse: 0.01286 |  0:12:50s\n",
      "epoch 38 | loss: 0.01478 | val_0_mse: 0.00854 |  0:13:10s\n",
      "epoch 39 | loss: 0.01641 | val_0_mse: 0.00815 |  0:13:31s\n",
      "epoch 40 | loss: 0.01123 | val_0_mse: 0.02456 |  0:13:51s\n",
      "epoch 41 | loss: 0.01287 | val_0_mse: 0.03595 |  0:14:11s\n",
      "epoch 42 | loss: 0.0132  | val_0_mse: 0.00947 |  0:14:31s\n",
      "epoch 43 | loss: 0.01653 | val_0_mse: 0.00744 |  0:14:52s\n",
      "epoch 44 | loss: 0.01183 | val_0_mse: 0.01527 |  0:15:12s\n",
      "epoch 45 | loss: 0.013   | val_0_mse: 0.01524 |  0:15:32s\n",
      "epoch 46 | loss: 0.01393 | val_0_mse: 0.01266 |  0:15:52s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_mse = 0.00565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006010 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.972886 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 42/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.66555 | val_0_mse: 0.77233 |  0:00:12s\n",
      "epoch 1  | loss: 0.39575 | val_0_mse: 0.20523 |  0:00:24s\n",
      "epoch 2  | loss: 0.19748 | val_0_mse: 0.16293 |  0:00:36s\n",
      "epoch 3  | loss: 0.14796 | val_0_mse: 0.0859  |  0:00:48s\n",
      "epoch 4  | loss: 0.10047 | val_0_mse: 0.14517 |  0:01:00s\n",
      "epoch 5  | loss: 0.08479 | val_0_mse: 0.06616 |  0:01:12s\n",
      "epoch 6  | loss: 0.07374 | val_0_mse: 0.06174 |  0:01:24s\n",
      "epoch 7  | loss: 0.07291 | val_0_mse: 0.11176 |  0:01:36s\n",
      "epoch 8  | loss: 0.07257 | val_0_mse: 0.08206 |  0:01:48s\n",
      "epoch 9  | loss: 0.07093 | val_0_mse: 0.07107 |  0:02:00s\n",
      "epoch 10 | loss: 0.05874 | val_0_mse: 0.07777 |  0:02:12s\n",
      "epoch 11 | loss: 0.07028 | val_0_mse: 0.05625 |  0:02:24s\n",
      "epoch 12 | loss: 0.0566  | val_0_mse: 0.04846 |  0:02:36s\n",
      "epoch 13 | loss: 0.05412 | val_0_mse: 0.05808 |  0:02:48s\n",
      "epoch 14 | loss: 0.0619  | val_0_mse: 0.03826 |  0:03:00s\n",
      "epoch 15 | loss: 0.05048 | val_0_mse: 0.05477 |  0:03:12s\n",
      "epoch 16 | loss: 0.04889 | val_0_mse: 0.03233 |  0:03:24s\n",
      "epoch 17 | loss: 0.04251 | val_0_mse: 0.03718 |  0:03:36s\n",
      "epoch 18 | loss: 0.04311 | val_0_mse: 0.03229 |  0:03:49s\n",
      "epoch 19 | loss: 0.04145 | val_0_mse: 0.02921 |  0:04:01s\n",
      "epoch 20 | loss: 0.03938 | val_0_mse: 0.03217 |  0:04:13s\n",
      "epoch 21 | loss: 0.03802 | val_0_mse: 0.03448 |  0:04:26s\n",
      "epoch 22 | loss: 0.03713 | val_0_mse: 0.0259  |  0:04:39s\n",
      "epoch 23 | loss: 0.04502 | val_0_mse: 0.0413  |  0:04:51s\n",
      "epoch 24 | loss: 0.04094 | val_0_mse: 0.04225 |  0:05:03s\n",
      "epoch 25 | loss: 0.0412  | val_0_mse: 0.02528 |  0:05:15s\n",
      "epoch 26 | loss: 0.03955 | val_0_mse: 0.05429 |  0:05:27s\n",
      "epoch 27 | loss: 0.03779 | val_0_mse: 0.02426 |  0:05:39s\n",
      "epoch 28 | loss: 0.03473 | val_0_mse: 0.02706 |  0:05:52s\n",
      "epoch 29 | loss: 0.03454 | val_0_mse: 0.02231 |  0:06:04s\n",
      "epoch 30 | loss: 0.02964 | val_0_mse: 0.02027 |  0:06:16s\n",
      "epoch 31 | loss: 0.03016 | val_0_mse: 0.02568 |  0:06:28s\n",
      "epoch 32 | loss: 0.03483 | val_0_mse: 0.02808 |  0:06:40s\n",
      "epoch 33 | loss: 0.03321 | val_0_mse: 0.02408 |  0:06:52s\n",
      "epoch 34 | loss: 0.02744 | val_0_mse: 0.02642 |  0:07:05s\n",
      "epoch 35 | loss: 0.02521 | val_0_mse: 0.01969 |  0:07:17s\n",
      "epoch 36 | loss: 0.02815 | val_0_mse: 0.02018 |  0:07:29s\n",
      "epoch 37 | loss: 0.02892 | val_0_mse: 0.04604 |  0:07:41s\n",
      "epoch 38 | loss: 0.0349  | val_0_mse: 0.03217 |  0:07:53s\n",
      "epoch 39 | loss: 0.03047 | val_0_mse: 0.0382  |  0:08:06s\n",
      "epoch 40 | loss: 0.02839 | val_0_mse: 0.03763 |  0:08:18s\n",
      "epoch 41 | loss: 0.02566 | val_0_mse: 0.02196 |  0:08:30s\n",
      "epoch 42 | loss: 0.02686 | val_0_mse: 0.02176 |  0:08:42s\n",
      "epoch 43 | loss: 0.02282 | val_0_mse: 0.01546 |  0:08:54s\n",
      "epoch 44 | loss: 0.01858 | val_0_mse: 0.01917 |  0:09:07s\n",
      "epoch 45 | loss: 0.02306 | val_0_mse: 0.02823 |  0:09:19s\n",
      "epoch 46 | loss: 0.02906 | val_0_mse: 0.02187 |  0:09:31s\n",
      "epoch 47 | loss: 0.02407 | val_0_mse: 0.02254 |  0:09:43s\n",
      "epoch 48 | loss: 0.02516 | val_0_mse: 0.06528 |  0:09:55s\n",
      "epoch 49 | loss: 0.02399 | val_0_mse: 0.02096 |  0:10:07s\n",
      "epoch 50 | loss: 0.02567 | val_0_mse: 0.01351 |  0:10:19s\n",
      "epoch 51 | loss: 0.01905 | val_0_mse: 0.02347 |  0:10:31s\n",
      "epoch 52 | loss: 0.01606 | val_0_mse: 0.01027 |  0:10:44s\n",
      "epoch 53 | loss: 0.01717 | val_0_mse: 0.01527 |  0:10:56s\n",
      "epoch 54 | loss: 0.0168  | val_0_mse: 0.02101 |  0:11:08s\n",
      "epoch 55 | loss: 0.01349 | val_0_mse: 0.00896 |  0:11:20s\n",
      "epoch 56 | loss: 0.02297 | val_0_mse: 0.05358 |  0:11:33s\n",
      "epoch 57 | loss: 0.01544 | val_0_mse: 0.01562 |  0:11:45s\n",
      "epoch 58 | loss: 0.01415 | val_0_mse: 0.00977 |  0:11:57s\n",
      "epoch 59 | loss: 0.01523 | val_0_mse: 0.00853 |  0:12:09s\n",
      "epoch 60 | loss: 0.01332 | val_0_mse: 0.00711 |  0:12:21s\n",
      "epoch 61 | loss: 0.01106 | val_0_mse: 0.00857 |  0:12:33s\n",
      "epoch 62 | loss: 0.01607 | val_0_mse: 0.01069 |  0:12:45s\n",
      "epoch 63 | loss: 0.01343 | val_0_mse: 0.01098 |  0:12:57s\n",
      "epoch 64 | loss: 0.01432 | val_0_mse: 0.02625 |  0:13:09s\n",
      "epoch 65 | loss: 0.01229 | val_0_mse: 0.02423 |  0:13:22s\n",
      "epoch 66 | loss: 0.01637 | val_0_mse: 0.02318 |  0:13:34s\n",
      "epoch 67 | loss: 0.01224 | val_0_mse: 0.01147 |  0:13:46s\n",
      "epoch 68 | loss: 0.01352 | val_0_mse: 0.01124 |  0:13:58s\n",
      "epoch 69 | loss: 0.0131  | val_0_mse: 0.01557 |  0:14:10s\n",
      "epoch 70 | loss: 0.01234 | val_0_mse: 0.00696 |  0:14:22s\n",
      "epoch 71 | loss: 0.01615 | val_0_mse: 0.08219 |  0:14:35s\n",
      "epoch 72 | loss: 0.01445 | val_0_mse: 0.02979 |  0:14:47s\n",
      "epoch 73 | loss: 0.01894 | val_0_mse: 0.01189 |  0:14:59s\n",
      "epoch 74 | loss: 0.01642 | val_0_mse: 0.00972 |  0:15:11s\n",
      "epoch 75 | loss: 0.0123  | val_0_mse: 0.01031 |  0:15:24s\n",
      "epoch 76 | loss: 0.01649 | val_0_mse: 0.07675 |  0:15:36s\n",
      "epoch 77 | loss: 0.02253 | val_0_mse: 0.01637 |  0:15:48s\n",
      "epoch 78 | loss: 0.01614 | val_0_mse: 0.01438 |  0:16:00s\n",
      "epoch 79 | loss: 0.01086 | val_0_mse: 0.00829 |  0:16:12s\n",
      "epoch 80 | loss: 0.01149 | val_0_mse: 0.00786 |  0:16:25s\n",
      "\n",
      "Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 0.00696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006680 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.969863 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 43/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.68362 | val_0_mse: 0.59699 |  0:00:32s\n",
      "epoch 1  | loss: 0.16598 | val_0_mse: 0.09284 |  0:01:05s\n",
      "epoch 2  | loss: 0.11531 | val_0_mse: 0.07064 |  0:01:38s\n",
      "epoch 3  | loss: 0.0921  | val_0_mse: 0.06948 |  0:02:10s\n",
      "epoch 4  | loss: 0.07301 | val_0_mse: 0.0753  |  0:02:43s\n",
      "epoch 5  | loss: 0.07233 | val_0_mse: 0.05353 |  0:03:15s\n",
      "epoch 6  | loss: 0.06543 | val_0_mse: 0.03751 |  0:03:48s\n",
      "epoch 7  | loss: 0.05134 | val_0_mse: 0.0372  |  0:04:20s\n",
      "epoch 8  | loss: 0.04976 | val_0_mse: 0.03871 |  0:04:53s\n",
      "epoch 9  | loss: 0.03892 | val_0_mse: 0.02173 |  0:05:26s\n",
      "epoch 10 | loss: 0.03117 | val_0_mse: 0.04208 |  0:05:58s\n",
      "epoch 11 | loss: 0.0328  | val_0_mse: 0.09165 |  0:06:31s\n",
      "epoch 12 | loss: 0.0413  | val_0_mse: 0.04861 |  0:07:04s\n",
      "epoch 13 | loss: 0.03009 | val_0_mse: 0.0224  |  0:07:36s\n",
      "epoch 14 | loss: 0.02849 | val_0_mse: 0.04058 |  0:08:09s\n",
      "epoch 15 | loss: 0.02737 | val_0_mse: 0.02924 |  0:08:41s\n",
      "epoch 16 | loss: 0.02835 | val_0_mse: 0.07217 |  0:09:14s\n",
      "epoch 17 | loss: 0.03667 | val_0_mse: 0.03963 |  0:09:46s\n",
      "epoch 18 | loss: 0.02719 | val_0_mse: 0.13219 |  0:10:19s\n",
      "epoch 19 | loss: 0.0286  | val_0_mse: 0.01559 |  0:10:52s\n",
      "epoch 20 | loss: 0.0276  | val_0_mse: 0.02128 |  0:11:24s\n",
      "epoch 21 | loss: 0.02865 | val_0_mse: 0.36012 |  0:11:57s\n",
      "epoch 22 | loss: 0.024   | val_0_mse: 0.05362 |  0:12:29s\n",
      "epoch 23 | loss: 0.02908 | val_0_mse: 0.01534 |  0:13:02s\n",
      "epoch 24 | loss: 0.02422 | val_0_mse: 0.01286 |  0:13:35s\n",
      "epoch 25 | loss: 0.02157 | val_0_mse: 0.02284 |  0:14:07s\n",
      "epoch 26 | loss: 0.02554 | val_0_mse: 0.01562 |  0:14:40s\n",
      "epoch 27 | loss: 0.02147 | val_0_mse: 0.00984 |  0:15:12s\n",
      "epoch 28 | loss: 0.02128 | val_0_mse: 0.01678 |  0:15:45s\n",
      "epoch 29 | loss: 0.02426 | val_0_mse: 0.03096 |  0:16:18s\n",
      "epoch 30 | loss: 0.02254 | val_0_mse: 0.05189 |  0:16:51s\n",
      "epoch 31 | loss: 0.01996 | val_0_mse: 0.01442 |  0:17:23s\n",
      "epoch 32 | loss: 0.02021 | val_0_mse: 0.02399 |  0:17:56s\n",
      "epoch 33 | loss: 0.01849 | val_0_mse: 0.04693 |  0:18:29s\n",
      "epoch 34 | loss: 0.01841 | val_0_mse: 0.01222 |  0:19:02s\n",
      "epoch 35 | loss: 0.01774 | val_0_mse: 0.00998 |  0:19:34s\n",
      "epoch 36 | loss: 0.02038 | val_0_mse: 0.01712 |  0:20:07s\n",
      "epoch 37 | loss: 0.01514 | val_0_mse: 0.00972 |  0:20:40s\n",
      "epoch 38 | loss: 0.02203 | val_0_mse: 0.01047 |  0:21:12s\n",
      "epoch 39 | loss: 0.01595 | val_0_mse: 0.01447 |  0:21:45s\n",
      "epoch 40 | loss: 0.01641 | val_0_mse: 0.23591 |  0:22:17s\n",
      "epoch 41 | loss: 0.01942 | val_0_mse: 0.05183 |  0:22:50s\n",
      "epoch 42 | loss: 0.01776 | val_0_mse: 0.04496 |  0:23:25s\n",
      "epoch 43 | loss: 0.01839 | val_0_mse: 0.01916 |  0:23:58s\n",
      "epoch 44 | loss: 0.0217  | val_0_mse: 0.01754 |  0:24:30s\n",
      "epoch 45 | loss: 0.01776 | val_0_mse: 0.01727 |  0:25:03s\n",
      "epoch 46 | loss: 0.01667 | val_0_mse: 0.0206  |  0:25:35s\n",
      "epoch 47 | loss: 0.01511 | val_0_mse: 0.00861 |  0:26:09s\n",
      "epoch 48 | loss: 0.0159  | val_0_mse: 0.02802 |  0:26:41s\n",
      "epoch 49 | loss: 0.01672 | val_0_mse: 0.0242  |  0:27:14s\n",
      "epoch 50 | loss: 0.01787 | val_0_mse: 0.01037 |  0:27:46s\n",
      "epoch 51 | loss: 0.01397 | val_0_mse: 0.01592 |  0:28:19s\n",
      "epoch 52 | loss: 0.01458 | val_0_mse: 0.01914 |  0:28:52s\n",
      "epoch 53 | loss: 0.01549 | val_0_mse: 0.01538 |  0:29:24s\n",
      "epoch 54 | loss: 0.01416 | val_0_mse: 0.04242 |  0:29:57s\n",
      "epoch 55 | loss: 0.01432 | val_0_mse: 0.015   |  0:30:30s\n",
      "epoch 56 | loss: 0.01523 | val_0_mse: 0.02597 |  0:31:02s\n",
      "epoch 57 | loss: 0.01514 | val_0_mse: 0.01516 |  0:31:35s\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_mse = 0.00861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009060 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.959128 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 44/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.12358 | val_0_mse: 0.55232 |  0:00:20s\n",
      "epoch 1  | loss: 0.2223  | val_0_mse: 0.13427 |  0:00:41s\n",
      "epoch 2  | loss: 0.10714 | val_0_mse: 0.13255 |  0:01:01s\n",
      "epoch 3  | loss: 0.09454 | val_0_mse: 0.07004 |  0:01:22s\n",
      "epoch 4  | loss: 0.07368 | val_0_mse: 0.1077  |  0:01:43s\n",
      "epoch 5  | loss: 0.06682 | val_0_mse: 0.04196 |  0:02:03s\n",
      "epoch 6  | loss: 0.05104 | val_0_mse: 0.04247 |  0:02:24s\n",
      "epoch 7  | loss: 0.05131 | val_0_mse: 0.03239 |  0:02:44s\n",
      "epoch 8  | loss: 0.04724 | val_0_mse: 0.0534  |  0:03:05s\n",
      "epoch 9  | loss: 0.03932 | val_0_mse: 0.04547 |  0:03:26s\n",
      "epoch 10 | loss: 0.03221 | val_0_mse: 0.02184 |  0:03:46s\n",
      "epoch 11 | loss: 0.03118 | val_0_mse: 0.01656 |  0:04:07s\n",
      "epoch 12 | loss: 0.03251 | val_0_mse: 0.03973 |  0:04:27s\n",
      "epoch 13 | loss: 0.02663 | val_0_mse: 0.02053 |  0:04:48s\n",
      "epoch 14 | loss: 0.02935 | val_0_mse: 0.03337 |  0:05:09s\n",
      "epoch 15 | loss: 0.02868 | val_0_mse: 0.02239 |  0:05:29s\n",
      "epoch 16 | loss: 0.02296 | val_0_mse: 0.043   |  0:05:50s\n",
      "epoch 17 | loss: 0.01992 | val_0_mse: 0.01135 |  0:06:11s\n",
      "epoch 18 | loss: 0.01715 | val_0_mse: 0.02007 |  0:06:32s\n",
      "epoch 19 | loss: 0.02021 | val_0_mse: 0.01606 |  0:06:52s\n",
      "epoch 20 | loss: 0.01973 | val_0_mse: 0.00712 |  0:07:13s\n",
      "epoch 21 | loss: 0.01674 | val_0_mse: 0.04477 |  0:07:34s\n",
      "epoch 22 | loss: 0.01972 | val_0_mse: 0.05637 |  0:07:54s\n",
      "epoch 23 | loss: 0.02006 | val_0_mse: 0.01322 |  0:08:15s\n",
      "epoch 24 | loss: 0.01604 | val_0_mse: 0.01016 |  0:08:36s\n",
      "epoch 25 | loss: 0.02029 | val_0_mse: 0.02921 |  0:08:56s\n",
      "epoch 26 | loss: 0.02065 | val_0_mse: 0.0162  |  0:09:17s\n",
      "epoch 27 | loss: 0.01836 | val_0_mse: 0.02701 |  0:09:38s\n",
      "epoch 28 | loss: 0.01842 | val_0_mse: 0.01285 |  0:09:58s\n",
      "epoch 29 | loss: 0.0213  | val_0_mse: 0.01676 |  0:10:19s\n",
      "epoch 30 | loss: 0.01769 | val_0_mse: 0.00753 |  0:10:40s\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_mse = 0.00712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006737 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.969606 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 45/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.03951 | val_0_mse: 1.36178 |  0:00:11s\n",
      "epoch 1  | loss: 0.4289  | val_0_mse: 0.19501 |  0:00:23s\n",
      "epoch 2  | loss: 0.14438 | val_0_mse: 0.11709 |  0:00:35s\n",
      "epoch 3  | loss: 0.10237 | val_0_mse: 0.08424 |  0:00:47s\n",
      "epoch 4  | loss: 0.07358 | val_0_mse: 0.06453 |  0:00:59s\n",
      "epoch 5  | loss: 0.07341 | val_0_mse: 0.06729 |  0:01:11s\n",
      "epoch 6  | loss: 0.06433 | val_0_mse: 0.05268 |  0:01:22s\n",
      "epoch 7  | loss: 0.05916 | val_0_mse: 0.04668 |  0:01:34s\n",
      "epoch 8  | loss: 0.05629 | val_0_mse: 0.04388 |  0:01:46s\n",
      "epoch 9  | loss: 0.0516  | val_0_mse: 0.07033 |  0:01:58s\n",
      "epoch 10 | loss: 0.04553 | val_0_mse: 0.06329 |  0:02:10s\n",
      "epoch 11 | loss: 0.04227 | val_0_mse: 0.02904 |  0:02:22s\n",
      "epoch 12 | loss: 0.0438  | val_0_mse: 0.02524 |  0:02:34s\n",
      "epoch 13 | loss: 0.04618 | val_0_mse: 0.02918 |  0:02:46s\n",
      "epoch 14 | loss: 0.03396 | val_0_mse: 0.03587 |  0:02:58s\n",
      "epoch 15 | loss: 0.03067 | val_0_mse: 0.02723 |  0:03:10s\n",
      "epoch 16 | loss: 0.03092 | val_0_mse: 0.03587 |  0:03:22s\n",
      "epoch 17 | loss: 0.03763 | val_0_mse: 0.02339 |  0:03:33s\n",
      "epoch 18 | loss: 0.02632 | val_0_mse: 0.01909 |  0:03:45s\n",
      "epoch 19 | loss: 0.02746 | val_0_mse: 0.02546 |  0:03:57s\n",
      "epoch 20 | loss: 0.02448 | val_0_mse: 0.02643 |  0:04:09s\n",
      "epoch 21 | loss: 0.03504 | val_0_mse: 0.03635 |  0:04:21s\n",
      "epoch 22 | loss: 0.02608 | val_0_mse: 0.01681 |  0:04:33s\n",
      "epoch 23 | loss: 0.02179 | val_0_mse: 0.01944 |  0:04:45s\n",
      "epoch 24 | loss: 0.01851 | val_0_mse: 0.01834 |  0:04:57s\n",
      "epoch 25 | loss: 0.02491 | val_0_mse: 0.0175  |  0:05:09s\n",
      "epoch 26 | loss: 0.02057 | val_0_mse: 0.01512 |  0:05:21s\n",
      "epoch 27 | loss: 0.01756 | val_0_mse: 0.01371 |  0:05:33s\n",
      "epoch 28 | loss: 0.01434 | val_0_mse: 0.01119 |  0:05:45s\n",
      "epoch 29 | loss: 0.01833 | val_0_mse: 0.02053 |  0:05:57s\n",
      "epoch 30 | loss: 0.01625 | val_0_mse: 0.01097 |  0:06:09s\n",
      "epoch 31 | loss: 0.02082 | val_0_mse: 0.04435 |  0:06:21s\n",
      "epoch 32 | loss: 0.02976 | val_0_mse: 0.02075 |  0:06:33s\n",
      "epoch 33 | loss: 0.01793 | val_0_mse: 0.02739 |  0:06:45s\n",
      "epoch 34 | loss: 0.01396 | val_0_mse: 0.01053 |  0:06:57s\n",
      "epoch 35 | loss: 0.01511 | val_0_mse: 0.01195 |  0:07:09s\n",
      "epoch 36 | loss: 0.01737 | val_0_mse: 0.02837 |  0:07:21s\n",
      "epoch 37 | loss: 0.01859 | val_0_mse: 0.01809 |  0:07:33s\n",
      "epoch 38 | loss: 0.01444 | val_0_mse: 0.02438 |  0:07:45s\n",
      "epoch 39 | loss: 0.01678 | val_0_mse: 0.01605 |  0:07:57s\n",
      "epoch 40 | loss: 0.01474 | val_0_mse: 0.0089  |  0:08:09s\n",
      "epoch 41 | loss: 0.01714 | val_0_mse: 0.00916 |  0:08:20s\n",
      "epoch 42 | loss: 0.01731 | val_0_mse: 0.00963 |  0:08:32s\n",
      "epoch 43 | loss: 0.01352 | val_0_mse: 0.0073  |  0:08:44s\n",
      "epoch 44 | loss: 0.01608 | val_0_mse: 0.00877 |  0:08:56s\n",
      "epoch 45 | loss: 0.01489 | val_0_mse: 0.01821 |  0:09:09s\n",
      "epoch 46 | loss: 0.00963 | val_0_mse: 0.00876 |  0:09:21s\n",
      "epoch 47 | loss: 0.01495 | val_0_mse: 0.00779 |  0:09:33s\n",
      "epoch 48 | loss: 0.01046 | val_0_mse: 0.00566 |  0:09:45s\n",
      "epoch 49 | loss: 0.01089 | val_0_mse: 0.01746 |  0:09:57s\n",
      "epoch 50 | loss: 0.01079 | val_0_mse: 0.01274 |  0:10:09s\n",
      "epoch 51 | loss: 0.0119  | val_0_mse: 0.00982 |  0:10:21s\n",
      "epoch 52 | loss: 0.01318 | val_0_mse: 0.00974 |  0:10:33s\n",
      "epoch 53 | loss: 0.01313 | val_0_mse: 0.01271 |  0:10:45s\n",
      "epoch 54 | loss: 0.01159 | val_0_mse: 0.00593 |  0:10:57s\n",
      "epoch 55 | loss: 0.00966 | val_0_mse: 0.00676 |  0:11:08s\n",
      "epoch 56 | loss: 0.01034 | val_0_mse: 0.00826 |  0:11:20s\n",
      "epoch 57 | loss: 0.01136 | val_0_mse: 0.0131  |  0:11:32s\n",
      "epoch 58 | loss: 0.00807 | val_0_mse: 0.00651 |  0:11:44s\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_mse = 0.00566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.005931 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.973244 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 46/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.24676 | val_0_mse: 0.18346 |  0:00:34s\n",
      "epoch 1  | loss: 0.19045 | val_0_mse: 0.16576 |  0:01:08s\n",
      "epoch 2  | loss: 0.16076 | val_0_mse: 0.16796 |  0:01:42s\n",
      "epoch 3  | loss: 0.14978 | val_0_mse: 0.13614 |  0:02:16s\n",
      "epoch 4  | loss: 0.1419  | val_0_mse: 0.09909 |  0:02:51s\n",
      "epoch 5  | loss: 0.11517 | val_0_mse: 0.09517 |  0:03:25s\n",
      "epoch 6  | loss: 0.10858 | val_0_mse: 0.09934 |  0:03:59s\n",
      "epoch 7  | loss: 0.09941 | val_0_mse: 0.08392 |  0:04:33s\n",
      "epoch 8  | loss: 0.07869 | val_0_mse: 0.05895 |  0:05:08s\n",
      "epoch 9  | loss: 0.05853 | val_0_mse: 0.04537 |  0:05:42s\n",
      "epoch 10 | loss: 0.04579 | val_0_mse: 0.04131 |  0:06:16s\n",
      "epoch 11 | loss: 0.0368  | val_0_mse: 0.0417  |  0:06:50s\n",
      "epoch 12 | loss: 0.03003 | val_0_mse: 0.03079 |  0:07:24s\n",
      "epoch 13 | loss: 0.02737 | val_0_mse: 0.03051 |  0:07:58s\n",
      "epoch 14 | loss: 0.03067 | val_0_mse: 0.05065 |  0:08:33s\n",
      "epoch 15 | loss: 0.02971 | val_0_mse: 0.01508 |  0:09:07s\n",
      "epoch 16 | loss: 0.02601 | val_0_mse: 0.00894 |  0:09:41s\n",
      "epoch 17 | loss: 0.02345 | val_0_mse: 0.01642 |  0:10:15s\n",
      "epoch 18 | loss: 0.0242  | val_0_mse: 0.02804 |  0:10:50s\n",
      "epoch 19 | loss: 0.02371 | val_0_mse: 0.01016 |  0:11:24s\n",
      "epoch 20 | loss: 0.02749 | val_0_mse: 0.04282 |  0:11:59s\n",
      "epoch 21 | loss: 0.02247 | val_0_mse: 0.01958 |  0:12:33s\n",
      "epoch 22 | loss: 0.02616 | val_0_mse: 0.02005 |  0:13:07s\n",
      "epoch 23 | loss: 0.02297 | val_0_mse: 0.00672 |  0:13:42s\n",
      "epoch 24 | loss: 0.02263 | val_0_mse: 0.02802 |  0:14:16s\n",
      "epoch 25 | loss: 0.02365 | val_0_mse: 0.00736 |  0:14:50s\n",
      "epoch 26 | loss: 0.02309 | val_0_mse: 0.01528 |  0:15:24s\n",
      "epoch 27 | loss: 0.02076 | val_0_mse: 0.01472 |  0:15:58s\n",
      "epoch 28 | loss: 0.02201 | val_0_mse: 0.00966 |  0:16:32s\n",
      "epoch 29 | loss: 0.02073 | val_0_mse: 0.01247 |  0:17:07s\n",
      "epoch 30 | loss: 0.02081 | val_0_mse: 0.01863 |  0:17:41s\n",
      "epoch 31 | loss: 0.02451 | val_0_mse: 0.0171  |  0:18:15s\n",
      "epoch 32 | loss: 0.02662 | val_0_mse: 0.02184 |  0:18:50s\n",
      "epoch 33 | loss: 0.02026 | val_0_mse: 0.0276  |  0:19:24s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_mse = 0.00672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007826 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.964694 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 47/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.58563 | val_0_mse: 0.64097 |  0:00:22s\n",
      "epoch 1  | loss: 0.17908 | val_0_mse: 0.13233 |  0:00:44s\n",
      "epoch 2  | loss: 0.13652 | val_0_mse: 0.11435 |  0:01:06s\n",
      "epoch 3  | loss: 0.11128 | val_0_mse: 0.09611 |  0:01:28s\n",
      "epoch 4  | loss: 0.09399 | val_0_mse: 0.09747 |  0:01:51s\n",
      "epoch 5  | loss: 0.08038 | val_0_mse: 0.05105 |  0:02:13s\n",
      "epoch 6  | loss: 0.06689 | val_0_mse: 0.05665 |  0:02:35s\n",
      "epoch 7  | loss: 0.05969 | val_0_mse: 0.04104 |  0:02:58s\n",
      "epoch 8  | loss: 0.04518 | val_0_mse: 0.0293  |  0:03:20s\n",
      "epoch 9  | loss: 0.05349 | val_0_mse: 0.03004 |  0:03:43s\n",
      "epoch 10 | loss: 0.03189 | val_0_mse: 0.01763 |  0:04:05s\n",
      "epoch 11 | loss: 0.03308 | val_0_mse: 0.02055 |  0:04:28s\n",
      "epoch 12 | loss: 0.02657 | val_0_mse: 0.01944 |  0:04:50s\n",
      "epoch 13 | loss: 0.02954 | val_0_mse: 0.02273 |  0:05:12s\n",
      "epoch 14 | loss: 0.03115 | val_0_mse: 0.07323 |  0:05:34s\n",
      "epoch 15 | loss: 0.04941 | val_0_mse: 0.03467 |  0:05:57s\n",
      "epoch 16 | loss: 0.03203 | val_0_mse: 0.08105 |  0:06:19s\n",
      "epoch 17 | loss: 0.03214 | val_0_mse: 0.0521  |  0:06:42s\n",
      "epoch 18 | loss: 0.02678 | val_0_mse: 0.02187 |  0:07:04s\n",
      "epoch 19 | loss: 0.02203 | val_0_mse: 0.01824 |  0:07:26s\n",
      "epoch 20 | loss: 0.02499 | val_0_mse: 0.01249 |  0:07:48s\n",
      "epoch 21 | loss: 0.02104 | val_0_mse: 0.02023 |  0:08:10s\n",
      "epoch 22 | loss: 0.02344 | val_0_mse: 0.03115 |  0:08:33s\n",
      "epoch 23 | loss: 0.02157 | val_0_mse: 0.04351 |  0:08:55s\n",
      "epoch 24 | loss: 0.0195  | val_0_mse: 0.00976 |  0:09:18s\n",
      "epoch 25 | loss: 0.02095 | val_0_mse: 0.01424 |  0:09:40s\n",
      "epoch 26 | loss: 0.01968 | val_0_mse: 0.00754 |  0:10:02s\n",
      "epoch 27 | loss: 0.01891 | val_0_mse: 0.01133 |  0:10:24s\n",
      "epoch 28 | loss: 0.01771 | val_0_mse: 0.01716 |  0:10:47s\n",
      "epoch 29 | loss: 0.01897 | val_0_mse: 0.01649 |  0:11:09s\n",
      "epoch 30 | loss: 0.01622 | val_0_mse: 0.01341 |  0:11:31s\n",
      "epoch 31 | loss: 0.01914 | val_0_mse: 0.01094 |  0:11:53s\n",
      "epoch 32 | loss: 0.01858 | val_0_mse: 0.01584 |  0:12:18s\n",
      "epoch 33 | loss: 0.01634 | val_0_mse: 0.01292 |  0:12:40s\n",
      "epoch 34 | loss: 0.01349 | val_0_mse: 0.01431 |  0:13:02s\n",
      "epoch 35 | loss: 0.01571 | val_0_mse: 0.01827 |  0:13:25s\n",
      "epoch 36 | loss: 0.01722 | val_0_mse: 0.0091  |  0:13:47s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_mse = 0.00754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007721 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.965169 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 48/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.16812 | val_0_mse: 0.47568 |  0:00:12s\n",
      "epoch 1  | loss: 0.42462 | val_0_mse: 0.16866 |  0:00:25s\n",
      "epoch 2  | loss: 0.20216 | val_0_mse: 0.21907 |  0:00:38s\n",
      "epoch 3  | loss: 0.14838 | val_0_mse: 0.15785 |  0:00:51s\n",
      "epoch 4  | loss: 0.1199  | val_0_mse: 0.19266 |  0:01:04s\n",
      "epoch 5  | loss: 0.11388 | val_0_mse: 0.11422 |  0:01:17s\n",
      "epoch 6  | loss: 0.0953  | val_0_mse: 0.08699 |  0:01:30s\n",
      "epoch 7  | loss: 0.08253 | val_0_mse: 0.11162 |  0:01:43s\n",
      "epoch 8  | loss: 0.08327 | val_0_mse: 0.07278 |  0:01:56s\n",
      "epoch 9  | loss: 0.07601 | val_0_mse: 0.06115 |  0:02:09s\n",
      "epoch 10 | loss: 0.06295 | val_0_mse: 0.05096 |  0:02:21s\n",
      "epoch 11 | loss: 0.06466 | val_0_mse: 0.08955 |  0:02:34s\n",
      "epoch 12 | loss: 0.05041 | val_0_mse: 0.06569 |  0:02:47s\n",
      "epoch 13 | loss: 0.05389 | val_0_mse: 0.0588  |  0:03:00s\n",
      "epoch 14 | loss: 0.04546 | val_0_mse: 0.04093 |  0:03:13s\n",
      "epoch 15 | loss: 0.04242 | val_0_mse: 0.03081 |  0:03:26s\n",
      "epoch 16 | loss: 0.03046 | val_0_mse: 0.02351 |  0:03:39s\n",
      "epoch 17 | loss: 0.0481  | val_0_mse: 0.02524 |  0:03:52s\n",
      "epoch 18 | loss: 0.03192 | val_0_mse: 0.02769 |  0:04:05s\n",
      "epoch 19 | loss: 0.03548 | val_0_mse: 0.10331 |  0:04:18s\n",
      "epoch 20 | loss: 0.04861 | val_0_mse: 0.06457 |  0:04:31s\n",
      "epoch 21 | loss: 0.03782 | val_0_mse: 0.03354 |  0:04:44s\n",
      "epoch 22 | loss: 0.02719 | val_0_mse: 0.02432 |  0:04:57s\n",
      "epoch 23 | loss: 0.02705 | val_0_mse: 0.01611 |  0:05:10s\n",
      "epoch 24 | loss: 0.01989 | val_0_mse: 0.02088 |  0:05:23s\n",
      "epoch 25 | loss: 0.02919 | val_0_mse: 0.01316 |  0:05:35s\n",
      "epoch 26 | loss: 0.01861 | val_0_mse: 0.01252 |  0:05:48s\n",
      "epoch 27 | loss: 0.01922 | val_0_mse: 0.02762 |  0:06:01s\n",
      "epoch 28 | loss: 0.01448 | val_0_mse: 0.0181  |  0:06:14s\n",
      "epoch 29 | loss: 0.01908 | val_0_mse: 0.00772 |  0:06:27s\n",
      "epoch 30 | loss: 0.01273 | val_0_mse: 0.02829 |  0:06:40s\n",
      "epoch 31 | loss: 0.01508 | val_0_mse: 0.01557 |  0:06:53s\n",
      "epoch 32 | loss: 0.01755 | val_0_mse: 0.02015 |  0:07:06s\n",
      "epoch 33 | loss: 0.01344 | val_0_mse: 0.0075  |  0:07:19s\n",
      "epoch 34 | loss: 0.01372 | val_0_mse: 0.01022 |  0:07:32s\n",
      "epoch 35 | loss: 0.01261 | val_0_mse: 0.0167  |  0:07:45s\n",
      "epoch 36 | loss: 0.01041 | val_0_mse: 0.01386 |  0:07:58s\n",
      "epoch 37 | loss: 0.01156 | val_0_mse: 0.00957 |  0:08:11s\n",
      "epoch 38 | loss: 0.01381 | val_0_mse: 0.00623 |  0:08:24s\n",
      "epoch 39 | loss: 0.01319 | val_0_mse: 0.00742 |  0:08:37s\n",
      "epoch 40 | loss: 0.01275 | val_0_mse: 0.02212 |  0:08:50s\n",
      "epoch 41 | loss: 0.01185 | val_0_mse: 0.00927 |  0:09:03s\n",
      "epoch 42 | loss: 0.01188 | val_0_mse: 0.00758 |  0:09:16s\n",
      "epoch 43 | loss: 0.01224 | val_0_mse: 0.00709 |  0:09:29s\n",
      "epoch 44 | loss: 0.01193 | val_0_mse: 0.00747 |  0:09:42s\n",
      "epoch 45 | loss: 0.01267 | val_0_mse: 0.00942 |  0:09:54s\n",
      "epoch 46 | loss: 0.01558 | val_0_mse: 0.01328 |  0:10:07s\n",
      "epoch 47 | loss: 0.01139 | val_0_mse: 0.03299 |  0:10:20s\n",
      "epoch 48 | loss: 0.01223 | val_0_mse: 0.01678 |  0:10:33s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_mse = 0.00623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006626 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.970109 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 49/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.85746 | val_0_mse: 0.16002 |  0:00:32s\n",
      "epoch 1  | loss: 0.16732 | val_0_mse: 0.15978 |  0:01:04s\n",
      "epoch 2  | loss: 0.11809 | val_0_mse: 0.08583 |  0:01:36s\n",
      "epoch 3  | loss: 0.0773  | val_0_mse: 0.05987 |  0:02:07s\n",
      "epoch 4  | loss: 0.05471 | val_0_mse: 0.02424 |  0:02:39s\n",
      "epoch 5  | loss: 0.04593 | val_0_mse: 0.03573 |  0:03:11s\n",
      "epoch 6  | loss: 0.03525 | val_0_mse: 0.04037 |  0:03:43s\n",
      "epoch 7  | loss: 0.04115 | val_0_mse: 0.07643 |  0:04:15s\n",
      "epoch 8  | loss: 0.05897 | val_0_mse: 0.06642 |  0:04:47s\n",
      "epoch 9  | loss: 0.03979 | val_0_mse: 0.02048 |  0:05:19s\n",
      "epoch 10 | loss: 0.02556 | val_0_mse: 0.0232  |  0:05:50s\n",
      "epoch 11 | loss: 0.02871 | val_0_mse: 0.02579 |  0:06:22s\n",
      "epoch 12 | loss: 0.02899 | val_0_mse: 0.01727 |  0:06:54s\n",
      "epoch 13 | loss: 0.02654 | val_0_mse: 0.01847 |  0:07:26s\n",
      "epoch 14 | loss: 0.02806 | val_0_mse: 0.01278 |  0:07:58s\n",
      "epoch 15 | loss: 0.0278  | val_0_mse: 0.01256 |  0:08:30s\n",
      "epoch 16 | loss: 0.02638 | val_0_mse: 0.0342  |  0:09:03s\n",
      "epoch 17 | loss: 0.02957 | val_0_mse: 0.07137 |  0:09:36s\n",
      "epoch 18 | loss: 0.02534 | val_0_mse: 0.03938 |  0:10:09s\n",
      "epoch 19 | loss: 0.02172 | val_0_mse: 0.02259 |  0:10:43s\n",
      "epoch 20 | loss: 0.02141 | val_0_mse: 0.01654 |  0:11:16s\n",
      "epoch 21 | loss: 0.02283 | val_0_mse: 0.01096 |  0:11:49s\n",
      "epoch 22 | loss: 0.02252 | val_0_mse: 0.01097 |  0:12:21s\n",
      "epoch 23 | loss: 0.02271 | val_0_mse: 0.01546 |  0:12:53s\n",
      "epoch 24 | loss: 0.02233 | val_0_mse: 0.01377 |  0:13:25s\n",
      "epoch 25 | loss: 0.02402 | val_0_mse: 0.0066  |  0:13:57s\n",
      "epoch 26 | loss: 0.0227  | val_0_mse: 0.02482 |  0:14:30s\n",
      "epoch 27 | loss: 0.02246 | val_0_mse: 0.03867 |  0:15:03s\n",
      "epoch 28 | loss: 0.02546 | val_0_mse: 0.06151 |  0:15:36s\n",
      "epoch 29 | loss: 0.02364 | val_0_mse: 0.02352 |  0:16:09s\n",
      "epoch 30 | loss: 0.022   | val_0_mse: 0.01515 |  0:16:42s\n",
      "epoch 31 | loss: 0.02385 | val_0_mse: 0.0207  |  0:17:15s\n",
      "epoch 32 | loss: 0.02751 | val_0_mse: 0.04316 |  0:17:48s\n",
      "epoch 33 | loss: 0.02373 | val_0_mse: 0.01985 |  0:18:21s\n",
      "epoch 34 | loss: 0.02131 | val_0_mse: 0.01026 |  0:18:53s\n",
      "epoch 35 | loss: 0.02223 | val_0_mse: 0.03058 |  0:19:26s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mse = 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007234 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.967365 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 50/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.51458 | val_0_mse: 0.34597 |  0:00:18s\n",
      "epoch 1  | loss: 0.16711 | val_0_mse: 0.17095 |  0:00:36s\n",
      "epoch 2  | loss: 0.1281  | val_0_mse: 0.09891 |  0:00:55s\n",
      "epoch 3  | loss: 0.09835 | val_0_mse: 0.1697  |  0:01:14s\n",
      "epoch 4  | loss: 0.10913 | val_0_mse: 0.11704 |  0:01:32s\n",
      "epoch 5  | loss: 0.08779 | val_0_mse: 0.05576 |  0:01:51s\n",
      "epoch 6  | loss: 0.05582 | val_0_mse: 0.06456 |  0:02:09s\n",
      "epoch 7  | loss: 0.06181 | val_0_mse: 0.07162 |  0:02:28s\n",
      "epoch 8  | loss: 0.04512 | val_0_mse: 0.03913 |  0:02:46s\n",
      "epoch 9  | loss: 0.05583 | val_0_mse: 0.04565 |  0:03:05s\n",
      "epoch 10 | loss: 0.03524 | val_0_mse: 0.02124 |  0:03:23s\n",
      "epoch 11 | loss: 0.03579 | val_0_mse: 0.04268 |  0:03:41s\n",
      "epoch 12 | loss: 0.02255 | val_0_mse: 0.01419 |  0:04:00s\n",
      "epoch 13 | loss: 0.03076 | val_0_mse: 0.03709 |  0:04:18s\n",
      "epoch 14 | loss: 0.03186 | val_0_mse: 0.03269 |  0:04:37s\n",
      "epoch 15 | loss: 0.02968 | val_0_mse: 0.01077 |  0:04:55s\n",
      "epoch 16 | loss: 0.02085 | val_0_mse: 0.01354 |  0:05:14s\n",
      "epoch 17 | loss: 0.02697 | val_0_mse: 0.01622 |  0:05:32s\n",
      "epoch 18 | loss: 0.01994 | val_0_mse: 0.01492 |  0:05:50s\n",
      "epoch 19 | loss: 0.02091 | val_0_mse: 0.02587 |  0:06:09s\n",
      "epoch 20 | loss: 0.01712 | val_0_mse: 0.03109 |  0:06:27s\n",
      "epoch 21 | loss: 0.01772 | val_0_mse: 0.00711 |  0:06:46s\n",
      "epoch 22 | loss: 0.01802 | val_0_mse: 0.0082  |  0:07:04s\n",
      "epoch 23 | loss: 0.02111 | val_0_mse: 0.01637 |  0:07:23s\n",
      "epoch 24 | loss: 0.01906 | val_0_mse: 0.01713 |  0:07:41s\n",
      "epoch 25 | loss: 0.01635 | val_0_mse: 0.02801 |  0:07:59s\n",
      "epoch 26 | loss: 0.01957 | val_0_mse: 0.02931 |  0:08:18s\n",
      "epoch 27 | loss: 0.01586 | val_0_mse: 0.01216 |  0:08:36s\n",
      "epoch 28 | loss: 0.01609 | val_0_mse: 0.01524 |  0:08:55s\n",
      "epoch 29 | loss: 0.0168  | val_0_mse: 0.01553 |  0:09:13s\n",
      "epoch 30 | loss: 0.01851 | val_0_mse: 0.03067 |  0:09:31s\n",
      "epoch 31 | loss: 0.01709 | val_0_mse: 0.01868 |  0:09:50s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mse = 0.00711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007418 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.966536 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 51/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.97742 | val_0_mse: 0.61192 |  0:00:10s\n",
      "epoch 1  | loss: 0.3884  | val_0_mse: 0.2047  |  0:00:21s\n",
      "epoch 2  | loss: 0.13506 | val_0_mse: 0.11962 |  0:00:31s\n",
      "epoch 3  | loss: 0.09588 | val_0_mse: 0.1094  |  0:00:42s\n",
      "epoch 4  | loss: 0.10005 | val_0_mse: 0.08879 |  0:00:52s\n",
      "epoch 5  | loss: 0.07366 | val_0_mse: 0.07766 |  0:01:03s\n",
      "epoch 6  | loss: 0.06343 | val_0_mse: 0.04659 |  0:01:14s\n",
      "epoch 7  | loss: 0.05511 | val_0_mse: 0.04399 |  0:01:24s\n",
      "epoch 8  | loss: 0.06739 | val_0_mse: 0.07351 |  0:01:35s\n",
      "epoch 9  | loss: 0.05492 | val_0_mse: 0.0435  |  0:01:46s\n",
      "epoch 10 | loss: 0.04803 | val_0_mse: 0.05651 |  0:01:56s\n",
      "epoch 11 | loss: 0.05144 | val_0_mse: 0.05809 |  0:02:07s\n",
      "epoch 12 | loss: 0.05266 | val_0_mse: 0.04698 |  0:02:17s\n",
      "epoch 13 | loss: 0.04728 | val_0_mse: 0.06353 |  0:02:28s\n",
      "epoch 14 | loss: 0.04564 | val_0_mse: 0.03764 |  0:02:39s\n",
      "epoch 15 | loss: 0.04795 | val_0_mse: 0.06586 |  0:02:50s\n",
      "epoch 16 | loss: 0.04013 | val_0_mse: 0.05199 |  0:03:00s\n",
      "epoch 17 | loss: 0.04479 | val_0_mse: 0.04159 |  0:03:11s\n",
      "epoch 18 | loss: 0.03451 | val_0_mse: 0.06362 |  0:03:22s\n",
      "epoch 19 | loss: 0.03008 | val_0_mse: 0.02694 |  0:03:32s\n",
      "epoch 20 | loss: 0.02966 | val_0_mse: 0.02892 |  0:03:43s\n",
      "epoch 21 | loss: 0.02514 | val_0_mse: 0.02642 |  0:03:54s\n",
      "epoch 22 | loss: 0.02962 | val_0_mse: 0.0296  |  0:04:04s\n",
      "epoch 23 | loss: 0.02411 | val_0_mse: 0.03758 |  0:04:15s\n",
      "epoch 24 | loss: 0.02728 | val_0_mse: 0.03602 |  0:04:26s\n",
      "epoch 25 | loss: 0.0251  | val_0_mse: 0.01195 |  0:04:36s\n",
      "epoch 26 | loss: 0.02635 | val_0_mse: 0.02869 |  0:04:47s\n",
      "epoch 27 | loss: 0.02004 | val_0_mse: 0.02154 |  0:04:57s\n",
      "epoch 28 | loss: 0.02043 | val_0_mse: 0.02296 |  0:05:07s\n",
      "epoch 29 | loss: 0.03402 | val_0_mse: 0.01631 |  0:05:18s\n",
      "epoch 30 | loss: 0.01697 | val_0_mse: 0.03181 |  0:05:28s\n",
      "epoch 31 | loss: 0.0171  | val_0_mse: 0.01799 |  0:05:39s\n",
      "epoch 32 | loss: 0.02015 | val_0_mse: 0.00782 |  0:05:49s\n",
      "epoch 33 | loss: 0.01235 | val_0_mse: 0.02971 |  0:06:00s\n",
      "epoch 34 | loss: 0.01773 | val_0_mse: 0.01256 |  0:06:10s\n",
      "epoch 35 | loss: 0.01157 | val_0_mse: 0.0107  |  0:06:21s\n",
      "epoch 36 | loss: 0.01464 | val_0_mse: 0.01317 |  0:06:32s\n",
      "epoch 37 | loss: 0.0171  | val_0_mse: 0.0155  |  0:06:42s\n",
      "epoch 38 | loss: 0.01853 | val_0_mse: 0.00965 |  0:06:53s\n",
      "epoch 39 | loss: 0.01205 | val_0_mse: 0.01326 |  0:07:04s\n",
      "epoch 40 | loss: 0.01158 | val_0_mse: 0.01223 |  0:07:14s\n",
      "epoch 41 | loss: 0.01257 | val_0_mse: 0.01097 |  0:07:25s\n",
      "epoch 42 | loss: 0.00966 | val_0_mse: 0.01718 |  0:07:36s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 0.00782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008319 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.962471 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 52/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.29893 | val_0_mse: 0.20555 |  0:00:35s\n",
      "epoch 1  | loss: 0.16203 | val_0_mse: 0.08227 |  0:01:10s\n",
      "epoch 2  | loss: 0.09957 | val_0_mse: 0.057   |  0:01:46s\n",
      "epoch 3  | loss: 0.08729 | val_0_mse: 0.05739 |  0:02:21s\n",
      "epoch 4  | loss: 0.08069 | val_0_mse: 0.0703  |  0:02:56s\n",
      "epoch 5  | loss: 0.08149 | val_0_mse: 0.06034 |  0:03:32s\n",
      "epoch 6  | loss: 0.07815 | val_0_mse: 0.07979 |  0:04:07s\n",
      "epoch 7  | loss: 0.07755 | val_0_mse: 0.05958 |  0:04:42s\n",
      "epoch 8  | loss: 0.07641 | val_0_mse: 0.05612 |  0:05:17s\n",
      "epoch 9  | loss: 0.06956 | val_0_mse: 0.05517 |  0:05:52s\n",
      "epoch 10 | loss: 0.07146 | val_0_mse: 0.07951 |  0:06:27s\n",
      "epoch 11 | loss: 0.06811 | val_0_mse: 0.0656  |  0:07:03s\n",
      "epoch 12 | loss: 0.06215 | val_0_mse: 0.06315 |  0:07:38s\n",
      "epoch 13 | loss: 0.05603 | val_0_mse: 0.04951 |  0:08:13s\n",
      "epoch 14 | loss: 0.04249 | val_0_mse: 0.02325 |  0:08:49s\n",
      "epoch 15 | loss: 0.03743 | val_0_mse: 0.03435 |  0:09:24s\n",
      "epoch 16 | loss: 0.03638 | val_0_mse: 0.04622 |  0:10:00s\n",
      "epoch 17 | loss: 0.03385 | val_0_mse: 0.01739 |  0:10:35s\n",
      "epoch 18 | loss: 0.0293  | val_0_mse: 0.02153 |  0:11:10s\n",
      "epoch 19 | loss: 0.02767 | val_0_mse: 0.05713 |  0:11:46s\n",
      "epoch 20 | loss: 0.03195 | val_0_mse: 0.04333 |  0:12:21s\n",
      "epoch 21 | loss: 0.02671 | val_0_mse: 0.01923 |  0:12:56s\n",
      "epoch 22 | loss: 0.0268  | val_0_mse: 0.01889 |  0:13:32s\n",
      "epoch 23 | loss: 0.03079 | val_0_mse: 0.01559 |  0:14:12s\n",
      "epoch 24 | loss: 0.02228 | val_0_mse: 0.02297 |  0:14:47s\n",
      "epoch 25 | loss: 0.02423 | val_0_mse: 0.05704 |  0:15:23s\n",
      "epoch 26 | loss: 0.02347 | val_0_mse: 0.03938 |  0:15:58s\n",
      "epoch 27 | loss: 0.02446 | val_0_mse: 0.01416 |  0:16:34s\n",
      "epoch 28 | loss: 0.02721 | val_0_mse: 0.04296 |  0:17:10s\n",
      "epoch 29 | loss: 0.02095 | val_0_mse: 0.02976 |  0:17:45s\n",
      "epoch 30 | loss: 0.02087 | val_0_mse: 0.01818 |  0:18:21s\n",
      "epoch 31 | loss: 0.02209 | val_0_mse: 0.05984 |  0:18:57s\n",
      "epoch 32 | loss: 0.0215  | val_0_mse: 0.00965 |  0:19:32s\n",
      "epoch 33 | loss: 0.02338 | val_0_mse: 0.01796 |  0:20:07s\n",
      "epoch 34 | loss: 0.02379 | val_0_mse: 0.02301 |  0:20:43s\n",
      "epoch 35 | loss: 0.02144 | val_0_mse: 0.04648 |  0:21:18s\n",
      "epoch 36 | loss: 0.01843 | val_0_mse: 0.0094  |  0:21:53s\n",
      "epoch 37 | loss: 0.01777 | val_0_mse: 0.0104  |  0:22:28s\n",
      "epoch 38 | loss: 0.02457 | val_0_mse: 0.0111  |  0:23:03s\n",
      "epoch 39 | loss: 0.02075 | val_0_mse: 0.05112 |  0:23:39s\n",
      "epoch 40 | loss: 0.02319 | val_0_mse: 0.01225 |  0:24:14s\n",
      "epoch 41 | loss: 0.02221 | val_0_mse: 0.03489 |  0:24:49s\n",
      "epoch 42 | loss: 0.02179 | val_0_mse: 0.02812 |  0:25:24s\n",
      "epoch 43 | loss: 0.02271 | val_0_mse: 0.01338 |  0:25:59s\n",
      "epoch 44 | loss: 0.01989 | val_0_mse: 0.01206 |  0:26:34s\n",
      "epoch 45 | loss: 0.02175 | val_0_mse: 0.0159  |  0:27:09s\n",
      "epoch 46 | loss: 0.02015 | val_0_mse: 0.01639 |  0:27:44s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_mse = 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.010134 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.954283 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 53/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.61384 | val_0_mse: 0.6202  |  0:00:20s\n",
      "epoch 1  | loss: 0.19404 | val_0_mse: 0.14939 |  0:00:41s\n",
      "epoch 2  | loss: 0.13376 | val_0_mse: 0.22811 |  0:01:01s\n",
      "epoch 3  | loss: 0.10882 | val_0_mse: 0.08154 |  0:01:22s\n",
      "epoch 4  | loss: 0.0983  | val_0_mse: 0.09835 |  0:01:42s\n",
      "epoch 5  | loss: 0.07406 | val_0_mse: 0.07469 |  0:02:03s\n",
      "epoch 6  | loss: 0.07194 | val_0_mse: 0.04878 |  0:02:24s\n",
      "epoch 7  | loss: 0.06285 | val_0_mse: 0.08645 |  0:02:47s\n",
      "epoch 8  | loss: 0.05628 | val_0_mse: 0.04695 |  0:03:08s\n",
      "epoch 9  | loss: 0.05221 | val_0_mse: 0.0367  |  0:03:28s\n",
      "epoch 10 | loss: 0.04697 | val_0_mse: 0.02481 |  0:03:48s\n",
      "epoch 11 | loss: 0.03395 | val_0_mse: 0.04486 |  0:04:09s\n",
      "epoch 12 | loss: 0.04162 | val_0_mse: 0.02086 |  0:04:29s\n",
      "epoch 13 | loss: 0.03263 | val_0_mse: 0.04592 |  0:04:49s\n",
      "epoch 14 | loss: 0.03996 | val_0_mse: 0.03285 |  0:05:10s\n",
      "epoch 15 | loss: 0.03935 | val_0_mse: 0.04085 |  0:05:30s\n",
      "epoch 16 | loss: 0.03277 | val_0_mse: 0.03734 |  0:05:51s\n",
      "epoch 17 | loss: 0.03272 | val_0_mse: 0.02204 |  0:06:11s\n",
      "epoch 18 | loss: 0.0268  | val_0_mse: 0.02117 |  0:06:32s\n",
      "epoch 19 | loss: 0.02509 | val_0_mse: 0.00991 |  0:06:52s\n",
      "epoch 20 | loss: 0.0208  | val_0_mse: 0.00957 |  0:07:13s\n",
      "epoch 21 | loss: 0.01946 | val_0_mse: 0.02978 |  0:07:33s\n",
      "epoch 22 | loss: 0.02094 | val_0_mse: 0.01136 |  0:07:54s\n",
      "epoch 23 | loss: 0.02045 | val_0_mse: 0.01902 |  0:08:14s\n",
      "epoch 24 | loss: 0.01751 | val_0_mse: 0.00913 |  0:08:35s\n",
      "epoch 25 | loss: 0.01537 | val_0_mse: 0.01156 |  0:08:55s\n",
      "epoch 26 | loss: 0.01737 | val_0_mse: 0.01879 |  0:09:16s\n",
      "epoch 27 | loss: 0.01746 | val_0_mse: 0.00732 |  0:09:36s\n",
      "epoch 28 | loss: 0.01516 | val_0_mse: 0.03532 |  0:09:57s\n",
      "epoch 29 | loss: 0.01919 | val_0_mse: 0.01894 |  0:10:17s\n",
      "epoch 30 | loss: 0.01899 | val_0_mse: 0.01036 |  0:10:38s\n",
      "epoch 31 | loss: 0.01776 | val_0_mse: 0.01552 |  0:10:58s\n",
      "epoch 32 | loss: 0.02557 | val_0_mse: 0.02415 |  0:11:19s\n",
      "epoch 33 | loss: 0.01673 | val_0_mse: 0.02735 |  0:11:39s\n",
      "epoch 34 | loss: 0.02194 | val_0_mse: 0.1138  |  0:11:59s\n",
      "epoch 35 | loss: 0.02243 | val_0_mse: 0.011   |  0:12:20s\n",
      "epoch 36 | loss: 0.01675 | val_0_mse: 0.01893 |  0:12:41s\n",
      "epoch 37 | loss: 0.01359 | val_0_mse: 0.01292 |  0:13:01s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_mse = 0.00732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007532 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.966023 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 54/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.1864  | val_0_mse: 1.00536 |  0:00:11s\n",
      "epoch 1  | loss: 0.51794 | val_0_mse: 0.46997 |  0:00:22s\n",
      "epoch 2  | loss: 0.15011 | val_0_mse: 0.17174 |  0:00:34s\n",
      "epoch 3  | loss: 0.11627 | val_0_mse: 0.12361 |  0:00:46s\n",
      "epoch 4  | loss: 0.09006 | val_0_mse: 0.07286 |  0:00:57s\n",
      "epoch 5  | loss: 0.08923 | val_0_mse: 0.06782 |  0:01:09s\n",
      "epoch 6  | loss: 0.08152 | val_0_mse: 0.05852 |  0:01:20s\n",
      "epoch 7  | loss: 0.06201 | val_0_mse: 0.04838 |  0:01:32s\n",
      "epoch 8  | loss: 0.05441 | val_0_mse: 0.04527 |  0:01:44s\n",
      "epoch 9  | loss: 0.04959 | val_0_mse: 0.04455 |  0:01:55s\n",
      "epoch 10 | loss: 0.05673 | val_0_mse: 0.05272 |  0:02:07s\n",
      "epoch 11 | loss: 0.0423  | val_0_mse: 0.06014 |  0:02:19s\n",
      "epoch 12 | loss: 0.04131 | val_0_mse: 0.0282  |  0:02:30s\n",
      "epoch 13 | loss: 0.03663 | val_0_mse: 0.0395  |  0:02:42s\n",
      "epoch 14 | loss: 0.0395  | val_0_mse: 0.04395 |  0:02:53s\n",
      "epoch 15 | loss: 0.04795 | val_0_mse: 0.0437  |  0:03:05s\n",
      "epoch 16 | loss: 0.03722 | val_0_mse: 0.02761 |  0:03:17s\n",
      "epoch 17 | loss: 0.0353  | val_0_mse: 0.02114 |  0:03:28s\n",
      "epoch 18 | loss: 0.02566 | val_0_mse: 0.02404 |  0:03:40s\n",
      "epoch 19 | loss: 0.03134 | val_0_mse: 0.02788 |  0:03:52s\n",
      "epoch 20 | loss: 0.02228 | val_0_mse: 0.02396 |  0:04:03s\n",
      "epoch 21 | loss: 0.02364 | val_0_mse: 0.02487 |  0:04:15s\n",
      "epoch 22 | loss: 0.01643 | val_0_mse: 0.0142  |  0:04:27s\n",
      "epoch 23 | loss: 0.01779 | val_0_mse: 0.01331 |  0:04:38s\n",
      "epoch 24 | loss: 0.01728 | val_0_mse: 0.01166 |  0:04:50s\n",
      "epoch 25 | loss: 0.01561 | val_0_mse: 0.0115  |  0:05:01s\n",
      "epoch 26 | loss: 0.01754 | val_0_mse: 0.04713 |  0:05:13s\n",
      "epoch 27 | loss: 0.01853 | val_0_mse: 0.02122 |  0:05:25s\n",
      "epoch 28 | loss: 0.01871 | val_0_mse: 0.01294 |  0:05:36s\n",
      "epoch 29 | loss: 0.01924 | val_0_mse: 0.04287 |  0:05:48s\n",
      "epoch 30 | loss: 0.0184  | val_0_mse: 0.02556 |  0:05:59s\n",
      "epoch 31 | loss: 0.01638 | val_0_mse: 0.00985 |  0:06:11s\n",
      "epoch 32 | loss: 0.01834 | val_0_mse: 0.01962 |  0:06:22s\n",
      "epoch 33 | loss: 0.01382 | val_0_mse: 0.0087  |  0:06:34s\n",
      "epoch 34 | loss: 0.02237 | val_0_mse: 0.01667 |  0:06:46s\n",
      "epoch 35 | loss: 0.01484 | val_0_mse: 0.01035 |  0:06:57s\n",
      "epoch 36 | loss: 0.01181 | val_0_mse: 0.00866 |  0:07:09s\n",
      "epoch 37 | loss: 0.01856 | val_0_mse: 0.01009 |  0:07:21s\n",
      "epoch 38 | loss: 0.0119  | val_0_mse: 0.01087 |  0:07:32s\n",
      "epoch 39 | loss: 0.01147 | val_0_mse: 0.00719 |  0:07:44s\n",
      "epoch 40 | loss: 0.01346 | val_0_mse: 0.00884 |  0:07:55s\n",
      "epoch 41 | loss: 0.01061 | val_0_mse: 0.00664 |  0:08:07s\n",
      "epoch 42 | loss: 0.0115  | val_0_mse: 0.0085  |  0:08:19s\n",
      "epoch 43 | loss: 0.01052 | val_0_mse: 0.00686 |  0:08:30s\n",
      "epoch 44 | loss: 0.01018 | val_0_mse: 0.01156 |  0:08:42s\n",
      "epoch 45 | loss: 0.01196 | val_0_mse: 0.01446 |  0:08:53s\n",
      "epoch 46 | loss: 0.01495 | val_0_mse: 0.01562 |  0:09:05s\n",
      "epoch 47 | loss: 0.02159 | val_0_mse: 0.01009 |  0:09:17s\n",
      "epoch 48 | loss: 0.01521 | val_0_mse: 0.00856 |  0:09:28s\n",
      "epoch 49 | loss: 0.00979 | val_0_mse: 0.00695 |  0:09:40s\n",
      "epoch 50 | loss: 0.01319 | val_0_mse: 0.01227 |  0:09:51s\n",
      "epoch 51 | loss: 0.01041 | val_0_mse: 0.01017 |  0:10:03s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_mse = 0.00664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006923 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.968766 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 55/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.39678 | val_0_mse: 0.25417 |  0:00:35s\n",
      "epoch 1  | loss: 0.15564 | val_0_mse: 0.10086 |  0:01:11s\n",
      "epoch 2  | loss: 0.11082 | val_0_mse: 0.08766 |  0:01:47s\n",
      "epoch 3  | loss: 0.09323 | val_0_mse: 0.07026 |  0:02:23s\n",
      "epoch 4  | loss: 0.07608 | val_0_mse: 0.11076 |  0:02:58s\n",
      "epoch 5  | loss: 0.07337 | val_0_mse: 0.05346 |  0:03:34s\n",
      "epoch 6  | loss: 0.05226 | val_0_mse: 0.04813 |  0:04:10s\n",
      "epoch 7  | loss: 0.03947 | val_0_mse: 0.06076 |  0:04:45s\n",
      "epoch 8  | loss: 0.03739 | val_0_mse: 0.02161 |  0:05:21s\n",
      "epoch 9  | loss: 0.03557 | val_0_mse: 0.02356 |  0:05:57s\n",
      "epoch 10 | loss: 0.03464 | val_0_mse: 0.01443 |  0:06:33s\n",
      "epoch 11 | loss: 0.02909 | val_0_mse: 0.01866 |  0:07:08s\n",
      "epoch 12 | loss: 0.03521 | val_0_mse: 0.01036 |  0:07:44s\n",
      "epoch 13 | loss: 0.02804 | val_0_mse: 0.04988 |  0:08:20s\n",
      "epoch 14 | loss: 0.02883 | val_0_mse: 0.01958 |  0:08:56s\n",
      "epoch 15 | loss: 0.02955 | val_0_mse: 0.04648 |  0:09:32s\n",
      "epoch 16 | loss: 0.03264 | val_0_mse: 0.02113 |  0:10:08s\n",
      "epoch 17 | loss: 0.02566 | val_0_mse: 0.03381 |  0:10:43s\n",
      "epoch 18 | loss: 0.02571 | val_0_mse: 0.03058 |  0:11:19s\n",
      "epoch 19 | loss: 0.02584 | val_0_mse: 0.02108 |  0:11:55s\n",
      "epoch 20 | loss: 0.02594 | val_0_mse: 0.01005 |  0:12:30s\n",
      "epoch 21 | loss: 0.02802 | val_0_mse: 0.01785 |  0:13:06s\n",
      "epoch 22 | loss: 0.02733 | val_0_mse: 0.03765 |  0:13:41s\n",
      "epoch 23 | loss: 0.02665 | val_0_mse: 0.03793 |  0:14:17s\n",
      "epoch 24 | loss: 0.02965 | val_0_mse: 0.01694 |  0:14:53s\n",
      "epoch 25 | loss: 0.01903 | val_0_mse: 0.00907 |  0:15:29s\n",
      "epoch 26 | loss: 0.02281 | val_0_mse: 0.08954 |  0:16:04s\n",
      "epoch 27 | loss: 0.02365 | val_0_mse: 0.01967 |  0:16:40s\n",
      "epoch 28 | loss: 0.02267 | val_0_mse: 0.0329  |  0:17:18s\n",
      "epoch 29 | loss: 0.02194 | val_0_mse: 0.10508 |  0:17:54s\n",
      "epoch 30 | loss: 0.02267 | val_0_mse: 0.01577 |  0:18:30s\n",
      "epoch 31 | loss: 0.02089 | val_0_mse: 0.02072 |  0:19:06s\n",
      "epoch 32 | loss: 0.02285 | val_0_mse: 0.01782 |  0:19:42s\n",
      "epoch 33 | loss: 0.0231  | val_0_mse: 0.01172 |  0:20:18s\n",
      "epoch 34 | loss: 0.02097 | val_0_mse: 0.01834 |  0:20:53s\n",
      "epoch 35 | loss: 0.02069 | val_0_mse: 0.05057 |  0:21:29s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mse = 0.00907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.010279 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.953630 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 56/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.74387 | val_0_mse: 0.46287 |  0:00:19s\n",
      "epoch 1  | loss: 0.19179 | val_0_mse: 0.18331 |  0:00:40s\n",
      "epoch 2  | loss: 0.12211 | val_0_mse: 0.07625 |  0:00:59s\n",
      "epoch 3  | loss: 0.08453 | val_0_mse: 0.0829  |  0:01:19s\n",
      "epoch 4  | loss: 0.0756  | val_0_mse: 0.07284 |  0:01:39s\n",
      "epoch 5  | loss: 0.06493 | val_0_mse: 0.05438 |  0:01:58s\n",
      "epoch 6  | loss: 0.05653 | val_0_mse: 0.04676 |  0:02:18s\n",
      "epoch 7  | loss: 0.05097 | val_0_mse: 0.04004 |  0:02:38s\n",
      "epoch 8  | loss: 0.04958 | val_0_mse: 0.05621 |  0:02:57s\n",
      "epoch 9  | loss: 0.03683 | val_0_mse: 0.01965 |  0:03:17s\n",
      "epoch 10 | loss: 0.03892 | val_0_mse: 0.03551 |  0:03:37s\n",
      "epoch 11 | loss: 0.03637 | val_0_mse: 0.03049 |  0:03:56s\n",
      "epoch 12 | loss: 0.02969 | val_0_mse: 0.01816 |  0:04:16s\n",
      "epoch 13 | loss: 0.02366 | val_0_mse: 0.05102 |  0:04:36s\n",
      "epoch 14 | loss: 0.02221 | val_0_mse: 0.01019 |  0:04:56s\n",
      "epoch 15 | loss: 0.02558 | val_0_mse: 0.02819 |  0:05:15s\n",
      "epoch 16 | loss: 0.02205 | val_0_mse: 0.02207 |  0:05:35s\n",
      "epoch 17 | loss: 0.01608 | val_0_mse: 0.03768 |  0:05:55s\n",
      "epoch 18 | loss: 0.01873 | val_0_mse: 0.0112  |  0:06:14s\n",
      "epoch 19 | loss: 0.01887 | val_0_mse: 0.01435 |  0:06:34s\n",
      "epoch 20 | loss: 0.02425 | val_0_mse: 0.05023 |  0:06:54s\n",
      "epoch 21 | loss: 0.02269 | val_0_mse: 0.06893 |  0:07:13s\n",
      "epoch 22 | loss: 0.02221 | val_0_mse: 0.02363 |  0:07:33s\n",
      "epoch 23 | loss: 0.02444 | val_0_mse: 0.16957 |  0:07:53s\n",
      "epoch 24 | loss: 0.02634 | val_0_mse: 0.00913 |  0:08:12s\n",
      "epoch 25 | loss: 0.01915 | val_0_mse: 0.0164  |  0:08:32s\n",
      "epoch 26 | loss: 0.02104 | val_0_mse: 0.01583 |  0:08:52s\n",
      "epoch 27 | loss: 0.02085 | val_0_mse: 0.03949 |  0:09:11s\n",
      "epoch 28 | loss: 0.01602 | val_0_mse: 0.0146  |  0:09:31s\n",
      "epoch 29 | loss: 0.01661 | val_0_mse: 0.02062 |  0:09:51s\n",
      "epoch 30 | loss: 0.01827 | val_0_mse: 0.01099 |  0:10:10s\n",
      "epoch 31 | loss: 0.01602 | val_0_mse: 0.02075 |  0:10:30s\n",
      "epoch 32 | loss: 0.0157  | val_0_mse: 0.01483 |  0:10:50s\n",
      "epoch 33 | loss: 0.01534 | val_0_mse: 0.01554 |  0:11:10s\n",
      "epoch 34 | loss: 0.01797 | val_0_mse: 0.03293 |  0:11:29s\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_mse = 0.00913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008701 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.960749 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 57/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.50414 | val_0_mse: 0.7902  |  0:00:11s\n",
      "epoch 1  | loss: 0.32148 | val_0_mse: 0.17836 |  0:00:23s\n",
      "epoch 2  | loss: 0.20216 | val_0_mse: 0.20049 |  0:00:34s\n",
      "epoch 3  | loss: 0.1406  | val_0_mse: 0.16017 |  0:00:46s\n",
      "epoch 4  | loss: 0.10276 | val_0_mse: 0.09266 |  0:00:57s\n",
      "epoch 5  | loss: 0.08022 | val_0_mse: 0.06607 |  0:01:09s\n",
      "epoch 6  | loss: 0.08237 | val_0_mse: 0.04866 |  0:01:20s\n",
      "epoch 7  | loss: 0.07959 | val_0_mse: 0.06565 |  0:01:32s\n",
      "epoch 8  | loss: 0.06983 | val_0_mse: 0.04972 |  0:01:43s\n",
      "epoch 9  | loss: 0.06537 | val_0_mse: 0.05905 |  0:01:55s\n",
      "epoch 10 | loss: 0.06792 | val_0_mse: 0.05737 |  0:02:06s\n",
      "epoch 11 | loss: 0.05192 | val_0_mse: 0.0442  |  0:02:18s\n",
      "epoch 12 | loss: 0.05304 | val_0_mse: 0.04054 |  0:02:30s\n",
      "epoch 13 | loss: 0.04405 | val_0_mse: 0.03601 |  0:02:41s\n",
      "epoch 14 | loss: 0.03752 | val_0_mse: 0.04671 |  0:02:53s\n",
      "epoch 15 | loss: 0.0394  | val_0_mse: 0.03025 |  0:03:04s\n",
      "epoch 16 | loss: 0.03318 | val_0_mse: 0.02973 |  0:03:16s\n",
      "epoch 17 | loss: 0.027   | val_0_mse: 0.0358  |  0:03:27s\n",
      "epoch 18 | loss: 0.03314 | val_0_mse: 0.02448 |  0:03:39s\n",
      "epoch 19 | loss: 0.03143 | val_0_mse: 0.02361 |  0:03:51s\n",
      "epoch 20 | loss: 0.02954 | val_0_mse: 0.02691 |  0:04:02s\n",
      "epoch 21 | loss: 0.02612 | val_0_mse: 0.07381 |  0:04:14s\n",
      "epoch 22 | loss: 0.02509 | val_0_mse: 0.03182 |  0:04:25s\n",
      "epoch 23 | loss: 0.0265  | val_0_mse: 0.01922 |  0:04:36s\n",
      "epoch 24 | loss: 0.02254 | val_0_mse: 0.01627 |  0:04:48s\n",
      "epoch 25 | loss: 0.01833 | val_0_mse: 0.01705 |  0:05:00s\n",
      "epoch 26 | loss: 0.01862 | val_0_mse: 0.02543 |  0:05:11s\n",
      "epoch 27 | loss: 0.02585 | val_0_mse: 0.01556 |  0:05:22s\n",
      "epoch 28 | loss: 0.0137  | val_0_mse: 0.02652 |  0:05:34s\n",
      "epoch 29 | loss: 0.02051 | val_0_mse: 0.01324 |  0:05:45s\n",
      "epoch 30 | loss: 0.01654 | val_0_mse: 0.02618 |  0:05:57s\n",
      "epoch 31 | loss: 0.01491 | val_0_mse: 0.00669 |  0:06:08s\n",
      "epoch 32 | loss: 0.0135  | val_0_mse: 0.03956 |  0:06:20s\n",
      "epoch 33 | loss: 0.01473 | val_0_mse: 0.01004 |  0:06:31s\n",
      "epoch 34 | loss: 0.01374 | val_0_mse: 0.00781 |  0:06:42s\n",
      "epoch 35 | loss: 0.01113 | val_0_mse: 0.01076 |  0:06:53s\n",
      "epoch 36 | loss: 0.01652 | val_0_mse: 0.07544 |  0:07:04s\n",
      "epoch 37 | loss: 0.01931 | val_0_mse: 0.00822 |  0:07:15s\n",
      "epoch 38 | loss: 0.01094 | val_0_mse: 0.0106  |  0:07:27s\n",
      "epoch 39 | loss: 0.01288 | val_0_mse: 0.00813 |  0:07:38s\n",
      "epoch 40 | loss: 0.01042 | val_0_mse: 0.01007 |  0:07:49s\n",
      "epoch 41 | loss: 0.02304 | val_0_mse: 0.03399 |  0:08:00s\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_mse = 0.00669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006776 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.969434 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 58/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.07294 | val_0_mse: 0.13942 |  0:00:40s\n",
      "epoch 1  | loss: 0.18004 | val_0_mse: 0.12171 |  0:01:20s\n",
      "epoch 2  | loss: 0.12097 | val_0_mse: 0.11171 |  0:02:00s\n",
      "epoch 3  | loss: 0.11679 | val_0_mse: 0.05597 |  0:02:40s\n",
      "epoch 4  | loss: 0.07561 | val_0_mse: 0.0561  |  0:03:20s\n",
      "epoch 5  | loss: 0.06867 | val_0_mse: 0.05754 |  0:04:01s\n",
      "epoch 6  | loss: 0.04712 | val_0_mse: 0.03778 |  0:04:41s\n",
      "epoch 7  | loss: 0.04636 | val_0_mse: 0.05331 |  0:05:20s\n",
      "epoch 8  | loss: 0.04333 | val_0_mse: 0.11386 |  0:05:59s\n",
      "epoch 9  | loss: 0.03984 | val_0_mse: 0.02112 |  0:06:38s\n",
      "epoch 10 | loss: 0.03113 | val_0_mse: 0.0304  |  0:07:19s\n",
      "epoch 11 | loss: 0.03283 | val_0_mse: 0.01262 |  0:07:59s\n",
      "epoch 12 | loss: 0.0279  | val_0_mse: 0.02035 |  0:08:39s\n",
      "epoch 13 | loss: 0.02852 | val_0_mse: 0.02013 |  0:09:19s\n",
      "epoch 14 | loss: 0.02562 | val_0_mse: 0.01388 |  0:10:00s\n",
      "epoch 15 | loss: 0.02546 | val_0_mse: 0.0215  |  0:10:40s\n",
      "epoch 16 | loss: 0.03278 | val_0_mse: 0.0434  |  0:11:21s\n",
      "epoch 17 | loss: 0.02216 | val_0_mse: 0.02948 |  0:12:01s\n",
      "epoch 18 | loss: 0.02416 | val_0_mse: 0.01436 |  0:12:41s\n",
      "epoch 19 | loss: 0.02409 | val_0_mse: 0.03834 |  0:13:21s\n",
      "epoch 20 | loss: 0.02154 | val_0_mse: 0.01747 |  0:14:02s\n",
      "epoch 21 | loss: 0.02311 | val_0_mse: 0.01433 |  0:14:42s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_mse = 0.01262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.011387 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.948630 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 59/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.59439 | val_0_mse: 0.2719  |  0:00:22s\n",
      "epoch 1  | loss: 0.195   | val_0_mse: 0.23079 |  0:00:45s\n",
      "epoch 2  | loss: 0.14795 | val_0_mse: 0.12669 |  0:01:08s\n",
      "epoch 3  | loss: 0.1441  | val_0_mse: 0.14623 |  0:01:30s\n",
      "epoch 4  | loss: 0.10367 | val_0_mse: 0.10745 |  0:01:53s\n",
      "epoch 5  | loss: 0.1065  | val_0_mse: 0.08802 |  0:02:15s\n",
      "epoch 6  | loss: 0.10335 | val_0_mse: 0.07791 |  0:02:37s\n",
      "epoch 7  | loss: 0.08528 | val_0_mse: 0.07497 |  0:03:00s\n",
      "epoch 8  | loss: 0.09359 | val_0_mse: 0.09272 |  0:03:22s\n",
      "epoch 9  | loss: 0.09105 | val_0_mse: 0.11134 |  0:03:45s\n",
      "epoch 10 | loss: 0.07591 | val_0_mse: 0.05189 |  0:04:07s\n",
      "epoch 11 | loss: 0.07112 | val_0_mse: 0.0513  |  0:04:29s\n",
      "epoch 12 | loss: 0.04996 | val_0_mse: 0.03005 |  0:04:52s\n",
      "epoch 13 | loss: 0.03805 | val_0_mse: 0.03663 |  0:05:14s\n",
      "epoch 14 | loss: 0.03489 | val_0_mse: 0.01853 |  0:05:36s\n",
      "epoch 15 | loss: 0.03125 | val_0_mse: 0.0236  |  0:05:58s\n",
      "epoch 16 | loss: 0.02513 | val_0_mse: 0.01346 |  0:06:20s\n",
      "epoch 17 | loss: 0.02276 | val_0_mse: 0.02048 |  0:06:42s\n",
      "epoch 18 | loss: 0.01863 | val_0_mse: 0.01776 |  0:07:05s\n",
      "epoch 19 | loss: 0.02014 | val_0_mse: 0.03056 |  0:07:27s\n",
      "epoch 20 | loss: 0.02085 | val_0_mse: 0.03297 |  0:07:49s\n",
      "epoch 21 | loss: 0.02002 | val_0_mse: 0.01001 |  0:08:11s\n",
      "epoch 22 | loss: 0.01566 | val_0_mse: 0.00919 |  0:08:33s\n",
      "epoch 23 | loss: 0.0162  | val_0_mse: 0.00907 |  0:08:55s\n",
      "epoch 24 | loss: 0.01914 | val_0_mse: 0.01751 |  0:09:18s\n",
      "epoch 25 | loss: 0.0147  | val_0_mse: 0.02269 |  0:09:40s\n",
      "epoch 26 | loss: 0.01615 | val_0_mse: 0.01124 |  0:10:02s\n",
      "epoch 27 | loss: 0.01773 | val_0_mse: 0.0317  |  0:10:25s\n",
      "epoch 28 | loss: 0.01829 | val_0_mse: 0.01327 |  0:10:47s\n",
      "epoch 29 | loss: 0.01732 | val_0_mse: 0.01039 |  0:11:10s\n",
      "epoch 30 | loss: 0.01558 | val_0_mse: 0.02983 |  0:11:32s\n",
      "epoch 31 | loss: 0.01349 | val_0_mse: 0.01034 |  0:11:54s\n",
      "epoch 32 | loss: 0.02077 | val_0_mse: 0.00765 |  0:12:20s\n",
      "epoch 33 | loss: 0.01435 | val_0_mse: 0.01164 |  0:12:44s\n",
      "epoch 34 | loss: 0.01415 | val_0_mse: 0.02668 |  0:13:09s\n",
      "epoch 35 | loss: 0.01662 | val_0_mse: 0.02845 |  0:13:33s\n",
      "epoch 36 | loss: 0.01484 | val_0_mse: 0.01286 |  0:13:57s\n",
      "epoch 37 | loss: 0.01461 | val_0_mse: 0.01105 |  0:14:21s\n",
      "epoch 38 | loss: 0.01415 | val_0_mse: 0.01084 |  0:14:45s\n",
      "epoch 39 | loss: 0.01397 | val_0_mse: 0.01776 |  0:15:09s\n",
      "epoch 40 | loss: 0.01143 | val_0_mse: 0.00874 |  0:15:33s\n",
      "epoch 41 | loss: 0.01233 | val_0_mse: 0.01193 |  0:15:58s\n",
      "epoch 42 | loss: 0.01405 | val_0_mse: 0.01055 |  0:16:22s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 0.00765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007541 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.965982 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 60/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.1322  | val_0_mse: 1.13127 |  0:00:13s\n",
      "epoch 1  | loss: 0.33277 | val_0_mse: 0.18001 |  0:00:26s\n",
      "epoch 2  | loss: 0.13331 | val_0_mse: 0.12124 |  0:00:40s\n",
      "epoch 3  | loss: 0.09147 | val_0_mse: 0.07759 |  0:00:55s\n",
      "epoch 4  | loss: 0.09055 | val_0_mse: 0.0794  |  0:01:08s\n",
      "epoch 5  | loss: 0.06959 | val_0_mse: 0.06796 |  0:01:21s\n",
      "epoch 6  | loss: 0.08426 | val_0_mse: 0.08473 |  0:01:34s\n",
      "epoch 7  | loss: 0.06675 | val_0_mse: 0.04478 |  0:01:47s\n",
      "epoch 8  | loss: 0.06593 | val_0_mse: 0.03978 |  0:01:59s\n",
      "epoch 9  | loss: 0.04592 | val_0_mse: 0.03603 |  0:02:12s\n",
      "epoch 10 | loss: 0.04024 | val_0_mse: 0.02951 |  0:02:25s\n",
      "epoch 11 | loss: 0.03446 | val_0_mse: 0.02387 |  0:02:38s\n",
      "epoch 12 | loss: 0.03312 | val_0_mse: 0.02838 |  0:02:51s\n",
      "epoch 13 | loss: 0.03077 | val_0_mse: 0.03053 |  0:03:03s\n",
      "epoch 14 | loss: 0.02344 | val_0_mse: 0.01743 |  0:03:16s\n",
      "epoch 15 | loss: 0.0201  | val_0_mse: 0.02181 |  0:03:29s\n",
      "epoch 16 | loss: 0.02567 | val_0_mse: 0.0201  |  0:03:42s\n",
      "epoch 17 | loss: 0.02899 | val_0_mse: 0.02    |  0:03:55s\n",
      "epoch 18 | loss: 0.01965 | val_0_mse: 0.03835 |  0:04:08s\n",
      "epoch 19 | loss: 0.01943 | val_0_mse: 0.01066 |  0:04:21s\n",
      "epoch 20 | loss: 0.02032 | val_0_mse: 0.00998 |  0:04:33s\n",
      "epoch 21 | loss: 0.0179  | val_0_mse: 0.00849 |  0:04:46s\n",
      "epoch 22 | loss: 0.01643 | val_0_mse: 0.02423 |  0:04:59s\n",
      "epoch 23 | loss: 0.02285 | val_0_mse: 0.00957 |  0:05:12s\n",
      "epoch 24 | loss: 0.0185  | val_0_mse: 0.02337 |  0:05:24s\n",
      "epoch 25 | loss: 0.0164  | val_0_mse: 0.00919 |  0:05:37s\n",
      "epoch 26 | loss: 0.01849 | val_0_mse: 0.01411 |  0:05:50s\n",
      "epoch 27 | loss: 0.01573 | val_0_mse: 0.05192 |  0:06:03s\n",
      "epoch 28 | loss: 0.01778 | val_0_mse: 0.01171 |  0:06:15s\n",
      "epoch 29 | loss: 0.01568 | val_0_mse: 0.05121 |  0:06:29s\n",
      "epoch 30 | loss: 0.0159  | val_0_mse: 0.02206 |  0:06:41s\n",
      "epoch 31 | loss: 0.01562 | val_0_mse: 0.0101  |  0:06:54s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mse = 0.00849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008551 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.961424 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 61/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.103   | val_0_mse: 0.1597  |  0:00:40s\n",
      "epoch 1  | loss: 0.17662 | val_0_mse: 0.10236 |  0:01:20s\n",
      "epoch 2  | loss: 0.11748 | val_0_mse: 0.10673 |  0:02:00s\n",
      "epoch 3  | loss: 0.10928 | val_0_mse: 0.11156 |  0:02:39s\n",
      "epoch 4  | loss: 0.10472 | val_0_mse: 0.08559 |  0:03:19s\n",
      "epoch 5  | loss: 0.08344 | val_0_mse: 0.06586 |  0:03:59s\n",
      "epoch 6  | loss: 0.06434 | val_0_mse: 0.03686 |  0:04:38s\n",
      "epoch 7  | loss: 0.04327 | val_0_mse: 0.07173 |  0:05:17s\n",
      "epoch 8  | loss: 0.03663 | val_0_mse: 0.03127 |  0:05:57s\n",
      "epoch 9  | loss: 0.03552 | val_0_mse: 0.02713 |  0:06:40s\n",
      "epoch 10 | loss: 0.03192 | val_0_mse: 0.02549 |  0:07:19s\n",
      "epoch 11 | loss: 0.02973 | val_0_mse: 0.02381 |  0:08:00s\n",
      "epoch 12 | loss: 0.03161 | val_0_mse: 0.03215 |  0:08:38s\n",
      "epoch 13 | loss: 0.02706 | val_0_mse: 0.02898 |  0:09:17s\n",
      "epoch 14 | loss: 0.03576 | val_0_mse: 0.02846 |  0:09:56s\n",
      "epoch 15 | loss: 0.03308 | val_0_mse: 0.01915 |  0:10:36s\n",
      "epoch 16 | loss: 0.02653 | val_0_mse: 0.02409 |  0:11:15s\n",
      "epoch 17 | loss: 0.02643 | val_0_mse: 0.03038 |  0:11:55s\n",
      "epoch 18 | loss: 0.02372 | val_0_mse: 0.01588 |  0:12:34s\n",
      "epoch 19 | loss: 0.02435 | val_0_mse: 0.01408 |  0:13:14s\n",
      "epoch 20 | loss: 0.02788 | val_0_mse: 0.01941 |  0:13:54s\n",
      "epoch 21 | loss: 0.02497 | val_0_mse: 0.03158 |  0:14:33s\n",
      "epoch 22 | loss: 0.02087 | val_0_mse: 0.01558 |  0:15:13s\n",
      "epoch 23 | loss: 0.02976 | val_0_mse: 0.01858 |  0:15:52s\n",
      "epoch 24 | loss: 0.0252  | val_0_mse: 0.01753 |  0:16:32s\n",
      "epoch 25 | loss: 0.02813 | val_0_mse: 0.01664 |  0:17:11s\n",
      "epoch 26 | loss: 0.02211 | val_0_mse: 0.01828 |  0:17:51s\n",
      "epoch 27 | loss: 0.02609 | val_0_mse: 0.01609 |  0:18:30s\n",
      "epoch 28 | loss: 0.02174 | val_0_mse: 0.01193 |  0:19:10s\n",
      "epoch 29 | loss: 0.02223 | val_0_mse: 0.01161 |  0:19:47s\n",
      "epoch 30 | loss: 0.02484 | val_0_mse: 0.01112 |  0:20:25s\n",
      "epoch 31 | loss: 0.02263 | val_0_mse: 0.02024 |  0:21:06s\n",
      "epoch 32 | loss: 0.02272 | val_0_mse: 0.00863 |  0:21:46s\n",
      "epoch 33 | loss: 0.02059 | val_0_mse: 0.05015 |  0:22:25s\n",
      "epoch 34 | loss: 0.02391 | val_0_mse: 0.01944 |  0:23:04s\n",
      "epoch 35 | loss: 0.01752 | val_0_mse: 0.02501 |  0:23:43s\n",
      "epoch 36 | loss: 0.0169  | val_0_mse: 0.03515 |  0:24:21s\n",
      "epoch 37 | loss: 0.02164 | val_0_mse: 0.0313  |  0:25:00s\n",
      "epoch 38 | loss: 0.0204  | val_0_mse: 0.01922 |  0:25:39s\n",
      "epoch 39 | loss: 0.01879 | val_0_mse: 0.04724 |  0:26:18s\n",
      "epoch 40 | loss: 0.01796 | val_0_mse: 0.02704 |  0:26:57s\n",
      "epoch 41 | loss: 0.02104 | val_0_mse: 0.0235  |  0:27:36s\n",
      "epoch 42 | loss: 0.01863 | val_0_mse: 0.01559 |  0:28:15s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 0.00863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009653 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.956452 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 62/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.91614 | val_0_mse: 0.55414 |  0:00:21s\n",
      "epoch 1  | loss: 0.22969 | val_0_mse: 0.21108 |  0:00:43s\n",
      "epoch 2  | loss: 0.14898 | val_0_mse: 0.10924 |  0:01:04s\n",
      "epoch 3  | loss: 0.13908 | val_0_mse: 0.1193  |  0:01:26s\n",
      "epoch 4  | loss: 0.11439 | val_0_mse: 0.0775  |  0:01:48s\n",
      "epoch 5  | loss: 0.09007 | val_0_mse: 0.104   |  0:02:09s\n",
      "epoch 6  | loss: 0.07947 | val_0_mse: 0.07089 |  0:02:32s\n",
      "epoch 7  | loss: 0.07529 | val_0_mse: 0.07567 |  0:02:53s\n",
      "epoch 8  | loss: 0.06678 | val_0_mse: 0.05419 |  0:03:15s\n",
      "epoch 9  | loss: 0.06906 | val_0_mse: 0.06265 |  0:03:36s\n",
      "epoch 10 | loss: 0.06977 | val_0_mse: 0.06641 |  0:03:57s\n",
      "epoch 11 | loss: 0.05661 | val_0_mse: 0.04269 |  0:04:18s\n",
      "epoch 12 | loss: 0.05211 | val_0_mse: 0.04682 |  0:04:39s\n",
      "epoch 13 | loss: 0.04565 | val_0_mse: 0.03192 |  0:05:00s\n",
      "epoch 14 | loss: 0.03756 | val_0_mse: 0.06639 |  0:05:22s\n",
      "epoch 15 | loss: 0.02986 | val_0_mse: 0.03344 |  0:05:43s\n",
      "epoch 16 | loss: 0.02819 | val_0_mse: 0.0245  |  0:06:06s\n",
      "epoch 17 | loss: 0.03041 | val_0_mse: 0.03137 |  0:06:27s\n",
      "epoch 18 | loss: 0.02222 | val_0_mse: 0.03873 |  0:06:48s\n",
      "epoch 19 | loss: 0.02177 | val_0_mse: 0.03331 |  0:07:10s\n",
      "epoch 20 | loss: 0.02114 | val_0_mse: 0.00904 |  0:07:31s\n",
      "epoch 21 | loss: 0.02394 | val_0_mse: 0.03929 |  0:07:52s\n",
      "epoch 22 | loss: 0.03787 | val_0_mse: 0.02433 |  0:08:13s\n",
      "epoch 23 | loss: 0.03452 | val_0_mse: 0.11917 |  0:08:34s\n",
      "epoch 24 | loss: 0.03671 | val_0_mse: 0.04943 |  0:08:54s\n",
      "epoch 25 | loss: 0.02854 | val_0_mse: 0.04249 |  0:09:15s\n",
      "epoch 26 | loss: 0.02325 | val_0_mse: 0.02478 |  0:09:36s\n",
      "epoch 27 | loss: 0.02864 | val_0_mse: 0.1045  |  0:09:57s\n",
      "epoch 28 | loss: 0.01893 | val_0_mse: 0.01378 |  0:10:18s\n",
      "epoch 29 | loss: 0.02135 | val_0_mse: 0.0168  |  0:10:39s\n",
      "epoch 30 | loss: 0.0197  | val_0_mse: 0.04854 |  0:10:59s\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_mse = 0.00904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008729 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.960619 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 63/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.79959 | val_0_mse: 1.44364 |  0:00:11s\n",
      "epoch 1  | loss: 0.73125 | val_0_mse: 0.30791 |  0:00:23s\n",
      "epoch 2  | loss: 0.23626 | val_0_mse: 0.3487  |  0:00:35s\n",
      "epoch 3  | loss: 0.13129 | val_0_mse: 0.17736 |  0:00:47s\n",
      "epoch 4  | loss: 0.10056 | val_0_mse: 0.07856 |  0:00:58s\n",
      "epoch 5  | loss: 0.08087 | val_0_mse: 0.14809 |  0:01:09s\n",
      "epoch 6  | loss: 0.08267 | val_0_mse: 0.0772  |  0:01:21s\n",
      "epoch 7  | loss: 0.07431 | val_0_mse: 0.05763 |  0:01:32s\n",
      "epoch 8  | loss: 0.07249 | val_0_mse: 0.06688 |  0:01:43s\n",
      "epoch 9  | loss: 0.06985 | val_0_mse: 0.07159 |  0:01:55s\n",
      "epoch 10 | loss: 0.06632 | val_0_mse: 0.05995 |  0:02:06s\n",
      "epoch 11 | loss: 0.0582  | val_0_mse: 0.054   |  0:02:17s\n",
      "epoch 12 | loss: 0.05891 | val_0_mse: 0.04819 |  0:02:28s\n",
      "epoch 13 | loss: 0.05971 | val_0_mse: 0.04442 |  0:02:40s\n",
      "epoch 14 | loss: 0.05868 | val_0_mse: 0.06631 |  0:02:51s\n",
      "epoch 15 | loss: 0.04645 | val_0_mse: 0.04593 |  0:03:02s\n",
      "epoch 16 | loss: 0.04802 | val_0_mse: 0.03977 |  0:03:13s\n",
      "epoch 17 | loss: 0.04479 | val_0_mse: 0.04136 |  0:03:24s\n",
      "epoch 18 | loss: 0.04085 | val_0_mse: 0.03257 |  0:03:35s\n",
      "epoch 19 | loss: 0.0408  | val_0_mse: 0.03132 |  0:03:47s\n",
      "epoch 20 | loss: 0.03445 | val_0_mse: 0.031   |  0:03:58s\n",
      "epoch 21 | loss: 0.03631 | val_0_mse: 0.0595  |  0:04:09s\n",
      "epoch 22 | loss: 0.03525 | val_0_mse: 0.02741 |  0:04:20s\n",
      "epoch 23 | loss: 0.02822 | val_0_mse: 0.0213  |  0:04:31s\n",
      "epoch 24 | loss: 0.02489 | val_0_mse: 0.02268 |  0:04:42s\n",
      "epoch 25 | loss: 0.0238  | val_0_mse: 0.02556 |  0:04:54s\n",
      "epoch 26 | loss: 0.02297 | val_0_mse: 0.01657 |  0:05:05s\n",
      "epoch 27 | loss: 0.022   | val_0_mse: 0.01667 |  0:05:15s\n",
      "epoch 28 | loss: 0.02973 | val_0_mse: 0.01315 |  0:05:27s\n",
      "epoch 29 | loss: 0.01889 | val_0_mse: 0.01576 |  0:05:38s\n",
      "epoch 30 | loss: 0.02317 | val_0_mse: 0.02581 |  0:05:49s\n",
      "epoch 31 | loss: 0.02419 | val_0_mse: 0.01123 |  0:06:00s\n",
      "epoch 32 | loss: 0.02084 | val_0_mse: 0.01349 |  0:06:11s\n",
      "epoch 33 | loss: 0.01684 | val_0_mse: 0.01405 |  0:06:22s\n",
      "epoch 34 | loss: 0.01801 | val_0_mse: 0.01834 |  0:06:33s\n",
      "epoch 35 | loss: 0.021   | val_0_mse: 0.01664 |  0:06:45s\n",
      "epoch 36 | loss: 0.01822 | val_0_mse: 0.0139  |  0:06:56s\n",
      "epoch 37 | loss: 0.01616 | val_0_mse: 0.00974 |  0:07:07s\n",
      "epoch 38 | loss: 0.01706 | val_0_mse: 0.0102  |  0:07:18s\n",
      "epoch 39 | loss: 0.01633 | val_0_mse: 0.01948 |  0:07:30s\n",
      "epoch 40 | loss: 0.01701 | val_0_mse: 0.0188  |  0:07:41s\n",
      "epoch 41 | loss: 0.01554 | val_0_mse: 0.01009 |  0:07:52s\n",
      "epoch 42 | loss: 0.01847 | val_0_mse: 0.00996 |  0:08:04s\n",
      "epoch 43 | loss: 0.01484 | val_0_mse: 0.00971 |  0:08:15s\n",
      "epoch 44 | loss: 0.01383 | val_0_mse: 0.02739 |  0:08:26s\n",
      "epoch 45 | loss: 0.01734 | val_0_mse: 0.02727 |  0:08:37s\n",
      "epoch 46 | loss: 0.01888 | val_0_mse: 0.0104  |  0:08:48s\n",
      "epoch 47 | loss: 0.01635 | val_0_mse: 0.00792 |  0:08:59s\n",
      "epoch 48 | loss: 0.01179 | val_0_mse: 0.00769 |  0:09:11s\n",
      "epoch 49 | loss: 0.01096 | val_0_mse: 0.00722 |  0:09:22s\n",
      "epoch 50 | loss: 0.01241 | val_0_mse: 0.01073 |  0:09:33s\n",
      "epoch 51 | loss: 0.01175 | val_0_mse: 0.00837 |  0:09:44s\n",
      "epoch 52 | loss: 0.01089 | val_0_mse: 0.01146 |  0:09:55s\n",
      "epoch 53 | loss: 0.01199 | val_0_mse: 0.0163  |  0:10:06s\n",
      "epoch 54 | loss: 0.01696 | val_0_mse: 0.00917 |  0:10:17s\n",
      "epoch 55 | loss: 0.0146  | val_0_mse: 0.00868 |  0:10:28s\n",
      "epoch 56 | loss: 0.01444 | val_0_mse: 0.03439 |  0:10:40s\n",
      "epoch 57 | loss: 0.0135  | val_0_mse: 0.01105 |  0:10:51s\n",
      "epoch 58 | loss: 0.01445 | val_0_mse: 0.00813 |  0:11:02s\n",
      "epoch 59 | loss: 0.01532 | val_0_mse: 0.00765 |  0:11:13s\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_mse = 0.00722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007367 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.966767 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 64/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.90741 | val_0_mse: 0.32806 |  0:00:43s\n",
      "epoch 1  | loss: 0.19172 | val_0_mse: 0.17942 |  0:01:26s\n",
      "epoch 2  | loss: 0.13118 | val_0_mse: 0.11941 |  0:02:09s\n",
      "epoch 3  | loss: 0.11021 | val_0_mse: 0.07407 |  0:02:52s\n",
      "epoch 4  | loss: 0.0761  | val_0_mse: 0.05515 |  0:03:35s\n",
      "epoch 5  | loss: 0.06057 | val_0_mse: 0.03752 |  0:04:18s\n",
      "epoch 6  | loss: 0.05483 | val_0_mse: 0.04774 |  0:05:01s\n",
      "epoch 7  | loss: 0.04688 | val_0_mse: 0.02502 |  0:05:43s\n",
      "epoch 8  | loss: 0.03868 | val_0_mse: 0.03208 |  0:06:29s\n",
      "epoch 9  | loss: 0.03924 | val_0_mse: 0.0149  |  0:07:12s\n",
      "epoch 10 | loss: 0.03332 | val_0_mse: 0.05211 |  0:07:54s\n",
      "epoch 11 | loss: 0.02937 | val_0_mse: 0.02647 |  0:08:37s\n",
      "epoch 12 | loss: 0.0305  | val_0_mse: 0.04426 |  0:09:20s\n",
      "epoch 13 | loss: 0.02459 | val_0_mse: 0.02038 |  0:10:03s\n",
      "epoch 14 | loss: 0.02549 | val_0_mse: 0.01442 |  0:10:46s\n",
      "epoch 15 | loss: 0.02841 | val_0_mse: 0.09618 |  0:11:29s\n",
      "epoch 16 | loss: 0.02855 | val_0_mse: 0.03851 |  0:12:13s\n",
      "epoch 17 | loss: 0.02226 | val_0_mse: 0.01723 |  0:12:56s\n",
      "epoch 18 | loss: 0.02307 | val_0_mse: 0.02673 |  0:13:39s\n",
      "epoch 19 | loss: 0.0241  | val_0_mse: 0.00884 |  0:14:21s\n",
      "epoch 20 | loss: 0.02092 | val_0_mse: 0.01515 |  0:15:01s\n",
      "epoch 21 | loss: 0.02966 | val_0_mse: 0.0468  |  0:15:41s\n",
      "epoch 22 | loss: 0.02496 | val_0_mse: 0.05407 |  0:16:21s\n",
      "epoch 23 | loss: 0.0335  | val_0_mse: 0.01169 |  0:17:01s\n",
      "epoch 24 | loss: 0.02341 | val_0_mse: 0.02733 |  0:17:41s\n",
      "epoch 25 | loss: 0.02037 | val_0_mse: 0.01188 |  0:18:21s\n",
      "epoch 26 | loss: 0.02159 | val_0_mse: 0.02373 |  0:19:02s\n",
      "epoch 27 | loss: 0.02133 | val_0_mse: 0.04171 |  0:19:42s\n",
      "epoch 28 | loss: 0.02089 | val_0_mse: 0.01134 |  0:20:22s\n",
      "epoch 29 | loss: 0.02581 | val_0_mse: 0.01699 |  0:21:02s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_mse = 0.00884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.013239 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.940277 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 65/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.8127  | val_0_mse: 0.2526  |  0:00:23s\n",
      "epoch 1  | loss: 0.27351 | val_0_mse: 0.15066 |  0:00:46s\n",
      "epoch 2  | loss: 0.13884 | val_0_mse: 0.08256 |  0:01:09s\n",
      "epoch 3  | loss: 0.11017 | val_0_mse: 0.11061 |  0:01:32s\n",
      "epoch 4  | loss: 0.09134 | val_0_mse: 0.05358 |  0:01:55s\n",
      "epoch 5  | loss: 0.06826 | val_0_mse: 0.04356 |  0:02:18s\n",
      "epoch 6  | loss: 0.05092 | val_0_mse: 0.03268 |  0:02:41s\n",
      "epoch 7  | loss: 0.05028 | val_0_mse: 0.03741 |  0:03:05s\n",
      "epoch 8  | loss: 0.03618 | val_0_mse: 0.01886 |  0:03:28s\n",
      "epoch 9  | loss: 0.03881 | val_0_mse: 0.025   |  0:03:52s\n",
      "epoch 10 | loss: 0.02986 | val_0_mse: 0.03529 |  0:04:15s\n",
      "epoch 11 | loss: 0.02601 | val_0_mse: 0.06261 |  0:04:39s\n",
      "epoch 12 | loss: 0.02875 | val_0_mse: 0.01304 |  0:05:02s\n",
      "epoch 13 | loss: 0.02049 | val_0_mse: 0.02996 |  0:05:25s\n",
      "epoch 14 | loss: 0.0205  | val_0_mse: 0.01099 |  0:05:49s\n",
      "epoch 15 | loss: 0.01996 | val_0_mse: 0.01426 |  0:06:12s\n",
      "epoch 16 | loss: 0.01944 | val_0_mse: 0.01462 |  0:06:35s\n",
      "epoch 17 | loss: 0.01724 | val_0_mse: 0.01446 |  0:06:59s\n",
      "epoch 18 | loss: 0.02559 | val_0_mse: 0.05002 |  0:07:22s\n",
      "epoch 19 | loss: 0.02201 | val_0_mse: 0.03714 |  0:07:45s\n",
      "epoch 20 | loss: 0.01668 | val_0_mse: 0.01022 |  0:08:09s\n",
      "epoch 21 | loss: 0.01619 | val_0_mse: 0.01076 |  0:08:32s\n",
      "epoch 22 | loss: 0.01886 | val_0_mse: 0.02086 |  0:08:56s\n",
      "epoch 23 | loss: 0.02264 | val_0_mse: 0.00693 |  0:09:19s\n",
      "epoch 24 | loss: 0.01838 | val_0_mse: 0.00736 |  0:09:42s\n",
      "epoch 25 | loss: 0.01608 | val_0_mse: 0.01296 |  0:10:06s\n",
      "epoch 26 | loss: 0.01776 | val_0_mse: 0.01064 |  0:10:29s\n",
      "epoch 27 | loss: 0.01391 | val_0_mse: 0.00686 |  0:10:52s\n",
      "epoch 28 | loss: 0.01366 | val_0_mse: 0.01826 |  0:11:16s\n",
      "epoch 29 | loss: 0.01634 | val_0_mse: 0.02877 |  0:11:39s\n",
      "epoch 30 | loss: 0.01717 | val_0_mse: 0.01024 |  0:12:02s\n",
      "epoch 31 | loss: 0.01453 | val_0_mse: 0.01003 |  0:12:26s\n",
      "epoch 32 | loss: 0.02089 | val_0_mse: 0.01855 |  0:12:49s\n",
      "epoch 33 | loss: 0.01753 | val_0_mse: 0.00848 |  0:13:12s\n",
      "epoch 34 | loss: 0.01796 | val_0_mse: 0.02299 |  0:13:36s\n",
      "epoch 35 | loss: 0.02515 | val_0_mse: 0.1775  |  0:13:59s\n",
      "epoch 36 | loss: 0.01826 | val_0_mse: 0.00781 |  0:14:23s\n",
      "epoch 37 | loss: 0.01526 | val_0_mse: 0.01268 |  0:14:46s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_mse = 0.00686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006618 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.970146 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 66/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.44692 | val_0_mse: 1.35661 |  0:00:13s\n",
      "epoch 1  | loss: 0.67191 | val_0_mse: 0.2572  |  0:00:27s\n",
      "epoch 2  | loss: 0.21685 | val_0_mse: 0.32083 |  0:00:40s\n",
      "epoch 3  | loss: 0.15023 | val_0_mse: 0.12313 |  0:00:54s\n",
      "epoch 4  | loss: 0.12676 | val_0_mse: 0.09913 |  0:01:07s\n",
      "epoch 5  | loss: 0.10917 | val_0_mse: 0.09515 |  0:01:21s\n",
      "epoch 6  | loss: 0.0995  | val_0_mse: 0.08059 |  0:01:34s\n",
      "epoch 7  | loss: 0.08851 | val_0_mse: 0.07461 |  0:01:47s\n",
      "epoch 8  | loss: 0.09305 | val_0_mse: 0.07781 |  0:02:01s\n",
      "epoch 9  | loss: 0.08255 | val_0_mse: 0.04983 |  0:02:14s\n",
      "epoch 10 | loss: 0.05672 | val_0_mse: 0.0567  |  0:02:27s\n",
      "epoch 11 | loss: 0.05361 | val_0_mse: 0.05868 |  0:02:40s\n",
      "epoch 12 | loss: 0.0387  | val_0_mse: 0.0362  |  0:02:54s\n",
      "epoch 13 | loss: 0.03975 | val_0_mse: 0.02437 |  0:03:07s\n",
      "epoch 14 | loss: 0.03599 | val_0_mse: 0.03584 |  0:03:20s\n",
      "epoch 15 | loss: 0.03211 | val_0_mse: 0.03838 |  0:03:34s\n",
      "epoch 16 | loss: 0.02919 | val_0_mse: 0.02208 |  0:03:47s\n",
      "epoch 17 | loss: 0.02712 | val_0_mse: 0.02882 |  0:04:00s\n",
      "epoch 18 | loss: 0.03225 | val_0_mse: 0.02284 |  0:04:14s\n",
      "epoch 19 | loss: 0.03121 | val_0_mse: 0.0332  |  0:04:27s\n",
      "epoch 20 | loss: 0.02751 | val_0_mse: 0.01895 |  0:04:40s\n",
      "epoch 21 | loss: 0.02747 | val_0_mse: 0.02994 |  0:04:53s\n",
      "epoch 22 | loss: 0.02112 | val_0_mse: 0.01228 |  0:05:07s\n",
      "epoch 23 | loss: 0.04193 | val_0_mse: 0.01509 |  0:05:20s\n",
      "epoch 24 | loss: 0.02174 | val_0_mse: 0.02933 |  0:05:33s\n",
      "epoch 25 | loss: 0.02322 | val_0_mse: 0.01478 |  0:05:47s\n",
      "epoch 26 | loss: 0.02154 | val_0_mse: 0.03826 |  0:06:01s\n",
      "epoch 27 | loss: 0.02508 | val_0_mse: 0.01354 |  0:06:14s\n",
      "epoch 28 | loss: 0.01755 | val_0_mse: 0.01265 |  0:06:27s\n",
      "epoch 29 | loss: 0.01708 | val_0_mse: 0.02139 |  0:06:41s\n",
      "epoch 30 | loss: 0.02435 | val_0_mse: 0.04066 |  0:06:54s\n",
      "epoch 31 | loss: 0.02247 | val_0_mse: 0.02188 |  0:07:07s\n",
      "epoch 32 | loss: 0.01997 | val_0_mse: 0.01069 |  0:07:21s\n",
      "epoch 33 | loss: 0.01548 | val_0_mse: 0.02947 |  0:07:35s\n",
      "epoch 34 | loss: 0.0162  | val_0_mse: 0.01425 |  0:07:48s\n",
      "epoch 35 | loss: 0.0167  | val_0_mse: 0.03834 |  0:08:02s\n",
      "epoch 36 | loss: 0.01339 | val_0_mse: 0.03856 |  0:08:15s\n",
      "epoch 37 | loss: 0.01461 | val_0_mse: 0.00832 |  0:08:28s\n",
      "epoch 38 | loss: 0.02013 | val_0_mse: 0.02181 |  0:08:42s\n",
      "epoch 39 | loss: 0.0146  | val_0_mse: 0.01184 |  0:08:55s\n",
      "epoch 40 | loss: 0.01135 | val_0_mse: 0.01134 |  0:09:09s\n",
      "epoch 41 | loss: 0.01111 | val_0_mse: 0.02602 |  0:09:22s\n",
      "epoch 42 | loss: 0.01918 | val_0_mse: 0.00774 |  0:09:35s\n",
      "epoch 43 | loss: 0.01851 | val_0_mse: 0.06111 |  0:09:48s\n",
      "epoch 44 | loss: 0.02303 | val_0_mse: 0.07372 |  0:10:02s\n",
      "epoch 45 | loss: 0.02323 | val_0_mse: 0.03107 |  0:10:15s\n",
      "epoch 46 | loss: 0.01612 | val_0_mse: 0.01357 |  0:10:28s\n",
      "epoch 47 | loss: 0.01531 | val_0_mse: 0.02359 |  0:10:41s\n",
      "epoch 48 | loss: 0.01616 | val_0_mse: 0.01185 |  0:10:55s\n",
      "epoch 49 | loss: 0.01284 | val_0_mse: 0.01378 |  0:11:08s\n",
      "epoch 50 | loss: 0.01429 | val_0_mse: 0.01038 |  0:11:20s\n",
      "epoch 51 | loss: 0.0141  | val_0_mse: 0.01397 |  0:11:33s\n",
      "epoch 52 | loss: 0.01178 | val_0_mse: 0.01262 |  0:11:46s\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_mse = 0.00774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007567 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.965861 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 67/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.77298 | val_0_mse: 0.25754 |  0:00:40s\n",
      "epoch 1  | loss: 0.18401 | val_0_mse: 0.20764 |  0:01:22s\n",
      "epoch 2  | loss: 0.15567 | val_0_mse: 0.27223 |  0:02:03s\n",
      "epoch 3  | loss: 0.11847 | val_0_mse: 0.10983 |  0:02:44s\n",
      "epoch 4  | loss: 0.09079 | val_0_mse: 0.05802 |  0:03:25s\n",
      "epoch 5  | loss: 0.0654  | val_0_mse: 0.09599 |  0:04:07s\n",
      "epoch 6  | loss: 0.05294 | val_0_mse: 0.05448 |  0:04:50s\n",
      "epoch 7  | loss: 0.0475  | val_0_mse: 0.02778 |  0:05:32s\n",
      "epoch 8  | loss: 0.047   | val_0_mse: 0.03586 |  0:06:14s\n",
      "epoch 9  | loss: 0.03586 | val_0_mse: 0.01958 |  0:06:55s\n",
      "epoch 10 | loss: 0.03156 | val_0_mse: 0.01257 |  0:07:37s\n",
      "epoch 11 | loss: 0.03058 | val_0_mse: 0.03572 |  0:08:18s\n",
      "epoch 12 | loss: 0.02756 | val_0_mse: 0.01045 |  0:09:00s\n",
      "epoch 13 | loss: 0.0309  | val_0_mse: 0.0251  |  0:09:42s\n",
      "epoch 14 | loss: 0.02555 | val_0_mse: 0.01317 |  0:10:24s\n",
      "epoch 15 | loss: 0.03091 | val_0_mse: 0.02358 |  0:11:06s\n",
      "epoch 16 | loss: 0.03019 | val_0_mse: 0.03766 |  0:11:49s\n",
      "epoch 17 | loss: 0.03222 | val_0_mse: 0.07113 |  0:12:31s\n",
      "epoch 18 | loss: 0.03023 | val_0_mse: 0.49313 |  0:13:14s\n",
      "epoch 19 | loss: 0.02717 | val_0_mse: 0.05911 |  0:13:57s\n",
      "epoch 20 | loss: 0.02591 | val_0_mse: 0.02139 |  0:14:39s\n",
      "epoch 21 | loss: 0.02441 | val_0_mse: 0.18291 |  0:15:22s\n",
      "epoch 22 | loss: 0.02452 | val_0_mse: 0.02564 |  0:16:04s\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_mse = 0.01045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.010964 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.950536 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 68/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.58453 | val_0_mse: 0.59958 |  0:00:22s\n",
      "epoch 1  | loss: 0.16917 | val_0_mse: 0.15474 |  0:00:46s\n",
      "epoch 2  | loss: 0.12632 | val_0_mse: 0.13614 |  0:01:08s\n",
      "epoch 3  | loss: 0.09224 | val_0_mse: 0.13348 |  0:01:32s\n",
      "epoch 4  | loss: 0.09113 | val_0_mse: 0.07403 |  0:01:55s\n",
      "epoch 5  | loss: 0.07179 | val_0_mse: 0.08847 |  0:02:17s\n",
      "epoch 6  | loss: 0.07016 | val_0_mse: 0.04936 |  0:02:44s\n",
      "epoch 7  | loss: 0.06486 | val_0_mse: 0.05335 |  0:03:07s\n",
      "epoch 8  | loss: 0.07001 | val_0_mse: 0.05112 |  0:03:30s\n",
      "epoch 9  | loss: 0.05504 | val_0_mse: 0.06151 |  0:03:53s\n",
      "epoch 10 | loss: 0.047   | val_0_mse: 0.03101 |  0:04:16s\n",
      "epoch 11 | loss: 0.04135 | val_0_mse: 0.02473 |  0:04:39s\n",
      "epoch 12 | loss: 0.03135 | val_0_mse: 0.02129 |  0:05:02s\n",
      "epoch 13 | loss: 0.0274  | val_0_mse: 0.01995 |  0:05:25s\n",
      "epoch 14 | loss: 0.02587 | val_0_mse: 0.01352 |  0:05:48s\n",
      "epoch 15 | loss: 0.02296 | val_0_mse: 0.02289 |  0:06:11s\n",
      "epoch 16 | loss: 0.02625 | val_0_mse: 0.03502 |  0:06:34s\n",
      "epoch 17 | loss: 0.01991 | val_0_mse: 0.01433 |  0:06:57s\n",
      "epoch 18 | loss: 0.01833 | val_0_mse: 0.02087 |  0:07:20s\n",
      "epoch 19 | loss: 0.01781 | val_0_mse: 0.0085  |  0:07:43s\n",
      "epoch 20 | loss: 0.02103 | val_0_mse: 0.01974 |  0:08:06s\n",
      "epoch 21 | loss: 0.01895 | val_0_mse: 0.0142  |  0:08:29s\n",
      "epoch 22 | loss: 0.02145 | val_0_mse: 0.01169 |  0:08:52s\n",
      "epoch 23 | loss: 0.01655 | val_0_mse: 0.00635 |  0:09:14s\n",
      "epoch 24 | loss: 0.01507 | val_0_mse: 0.02393 |  0:09:37s\n",
      "epoch 25 | loss: 0.01513 | val_0_mse: 0.01375 |  0:10:00s\n",
      "epoch 26 | loss: 0.01597 | val_0_mse: 0.00891 |  0:10:23s\n",
      "epoch 27 | loss: 0.01601 | val_0_mse: 0.01776 |  0:10:46s\n",
      "epoch 28 | loss: 0.01758 | val_0_mse: 0.01203 |  0:11:09s\n",
      "epoch 29 | loss: 0.01815 | val_0_mse: 0.00925 |  0:11:32s\n",
      "epoch 30 | loss: 0.01462 | val_0_mse: 0.01644 |  0:11:55s\n",
      "epoch 31 | loss: 0.01916 | val_0_mse: 0.02883 |  0:12:18s\n",
      "epoch 32 | loss: 0.02191 | val_0_mse: 0.01689 |  0:12:41s\n",
      "epoch 33 | loss: 0.0164  | val_0_mse: 0.01371 |  0:13:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_mse = 0.00635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007879 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.964456 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 69/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.01875 | val_0_mse: 0.88124 |  0:00:13s\n",
      "epoch 1  | loss: 0.91435 | val_0_mse: 0.13829 |  0:00:27s\n",
      "epoch 2  | loss: 0.16375 | val_0_mse: 0.13032 |  0:00:40s\n",
      "epoch 3  | loss: 0.11057 | val_0_mse: 0.09849 |  0:00:53s\n",
      "epoch 4  | loss: 0.09527 | val_0_mse: 0.08185 |  0:01:07s\n",
      "epoch 5  | loss: 0.09095 | val_0_mse: 0.07349 |  0:01:20s\n",
      "epoch 6  | loss: 0.08016 | val_0_mse: 0.08759 |  0:01:33s\n",
      "epoch 7  | loss: 0.07573 | val_0_mse: 0.06502 |  0:01:46s\n",
      "epoch 8  | loss: 0.06923 | val_0_mse: 0.07716 |  0:02:00s\n",
      "epoch 9  | loss: 0.06095 | val_0_mse: 0.06539 |  0:02:13s\n",
      "epoch 10 | loss: 0.05394 | val_0_mse: 0.04541 |  0:02:26s\n",
      "epoch 11 | loss: 0.05343 | val_0_mse: 0.03268 |  0:02:39s\n",
      "epoch 12 | loss: 0.04206 | val_0_mse: 0.03155 |  0:02:53s\n",
      "epoch 13 | loss: 0.03893 | val_0_mse: 0.04635 |  0:03:06s\n",
      "epoch 14 | loss: 0.04483 | val_0_mse: 0.02595 |  0:03:19s\n",
      "epoch 15 | loss: 0.03992 | val_0_mse: 0.02334 |  0:03:32s\n",
      "epoch 16 | loss: 0.02951 | val_0_mse: 0.03394 |  0:03:45s\n",
      "epoch 17 | loss: 0.02915 | val_0_mse: 0.02087 |  0:03:58s\n",
      "epoch 18 | loss: 0.02559 | val_0_mse: 0.04971 |  0:04:12s\n",
      "epoch 19 | loss: 0.02375 | val_0_mse: 0.01534 |  0:04:25s\n",
      "epoch 20 | loss: 0.025   | val_0_mse: 0.01947 |  0:04:38s\n",
      "epoch 21 | loss: 0.02479 | val_0_mse: 0.01843 |  0:04:51s\n",
      "epoch 22 | loss: 0.02115 | val_0_mse: 0.01182 |  0:05:04s\n",
      "epoch 23 | loss: 0.01843 | val_0_mse: 0.02144 |  0:05:18s\n",
      "epoch 24 | loss: 0.019   | val_0_mse: 0.0324  |  0:05:31s\n",
      "epoch 25 | loss: 0.01565 | val_0_mse: 0.01536 |  0:05:44s\n",
      "epoch 26 | loss: 0.01627 | val_0_mse: 0.01076 |  0:05:57s\n",
      "epoch 27 | loss: 0.01899 | val_0_mse: 0.00899 |  0:06:10s\n",
      "epoch 28 | loss: 0.01342 | val_0_mse: 0.03231 |  0:06:23s\n",
      "epoch 29 | loss: 0.01271 | val_0_mse: 0.01259 |  0:06:36s\n",
      "epoch 30 | loss: 0.01714 | val_0_mse: 0.02266 |  0:06:50s\n",
      "epoch 31 | loss: 0.014   | val_0_mse: 0.02253 |  0:07:03s\n",
      "epoch 32 | loss: 0.01381 | val_0_mse: 0.01097 |  0:07:16s\n",
      "epoch 33 | loss: 0.01745 | val_0_mse: 0.01119 |  0:07:29s\n",
      "epoch 34 | loss: 0.01315 | val_0_mse: 0.0154  |  0:07:42s\n",
      "epoch 35 | loss: 0.01484 | val_0_mse: 0.03895 |  0:07:55s\n",
      "epoch 36 | loss: 0.01331 | val_0_mse: 0.01038 |  0:08:08s\n",
      "epoch 37 | loss: 0.01343 | val_0_mse: 0.01015 |  0:08:21s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_mse = 0.00899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008705 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.960729 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 70/72 - Hyperparameters:  batch_sizes=32, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.41139 | val_0_mse: 0.18628 |  0:00:45s\n",
      "epoch 1  | loss: 0.15042 | val_0_mse: 0.10377 |  0:01:31s\n",
      "epoch 2  | loss: 0.11671 | val_0_mse: 0.17041 |  0:02:16s\n",
      "epoch 3  | loss: 0.10865 | val_0_mse: 0.06206 |  0:03:01s\n",
      "epoch 4  | loss: 0.09275 | val_0_mse: 0.06914 |  0:03:47s\n",
      "epoch 5  | loss: 0.07292 | val_0_mse: 0.05704 |  0:04:32s\n",
      "epoch 6  | loss: 0.05495 | val_0_mse: 0.04392 |  0:05:17s\n",
      "epoch 7  | loss: 0.05066 | val_0_mse: 0.09106 |  0:06:03s\n",
      "epoch 8  | loss: 0.04626 | val_0_mse: 0.02738 |  0:06:48s\n",
      "epoch 9  | loss: 0.03795 | val_0_mse: 0.02074 |  0:07:33s\n",
      "epoch 10 | loss: 0.03728 | val_0_mse: 0.01402 |  0:08:18s\n",
      "epoch 11 | loss: 0.03581 | val_0_mse: 0.03932 |  0:09:04s\n",
      "epoch 12 | loss: 0.03779 | val_0_mse: 0.02185 |  0:09:49s\n",
      "epoch 13 | loss: 0.03278 | val_0_mse: 0.02843 |  0:10:34s\n",
      "epoch 14 | loss: 0.03609 | val_0_mse: 0.01787 |  0:11:20s\n",
      "epoch 15 | loss: 0.03028 | val_0_mse: 0.03195 |  0:12:05s\n",
      "epoch 16 | loss: 0.0279  | val_0_mse: 0.03352 |  0:12:50s\n",
      "epoch 17 | loss: 0.03117 | val_0_mse: 0.04679 |  0:13:36s\n",
      "epoch 18 | loss: 0.02586 | val_0_mse: 0.02137 |  0:14:21s\n",
      "epoch 19 | loss: 0.02735 | val_0_mse: 0.17089 |  0:15:06s\n",
      "epoch 20 | loss: 0.02712 | val_0_mse: 0.0342  |  0:15:52s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_mse = 0.01402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.016069 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.927507 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 71/72 - Hyperparameters:  batch_sizes=64, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.62147 | val_0_mse: 0.62152 |  0:00:25s\n",
      "epoch 1  | loss: 0.23757 | val_0_mse: 0.27748 |  0:00:50s\n",
      "epoch 2  | loss: 0.14248 | val_0_mse: 0.10218 |  0:01:16s\n",
      "epoch 3  | loss: 0.10953 | val_0_mse: 0.07428 |  0:01:41s\n",
      "epoch 4  | loss: 0.10053 | val_0_mse: 0.08191 |  0:02:06s\n",
      "epoch 5  | loss: 0.0892  | val_0_mse: 0.10308 |  0:02:32s\n",
      "epoch 6  | loss: 0.08836 | val_0_mse: 0.06032 |  0:02:57s\n",
      "epoch 7  | loss: 0.06831 | val_0_mse: 0.05497 |  0:03:22s\n",
      "epoch 8  | loss: 0.06431 | val_0_mse: 0.05722 |  0:03:48s\n",
      "epoch 9  | loss: 0.05141 | val_0_mse: 0.04076 |  0:04:13s\n",
      "epoch 10 | loss: 0.04509 | val_0_mse: 0.04708 |  0:04:38s\n",
      "epoch 11 | loss: 0.03767 | val_0_mse: 0.02658 |  0:05:04s\n",
      "epoch 12 | loss: 0.03649 | val_0_mse: 0.02386 |  0:05:29s\n",
      "epoch 13 | loss: 0.02751 | val_0_mse: 0.04496 |  0:05:54s\n",
      "epoch 14 | loss: 0.0258  | val_0_mse: 0.03175 |  0:06:19s\n",
      "epoch 15 | loss: 0.02653 | val_0_mse: 0.05977 |  0:06:45s\n",
      "epoch 16 | loss: 0.02551 | val_0_mse: 0.01895 |  0:07:10s\n",
      "epoch 17 | loss: 0.0278  | val_0_mse: 0.01573 |  0:07:35s\n",
      "epoch 18 | loss: 0.02395 | val_0_mse: 0.01635 |  0:08:00s\n",
      "epoch 19 | loss: 0.02799 | val_0_mse: 0.01732 |  0:08:25s\n",
      "epoch 20 | loss: 0.02424 | val_0_mse: 0.02381 |  0:08:51s\n",
      "epoch 21 | loss: 0.0202  | val_0_mse: 0.03333 |  0:09:16s\n",
      "epoch 22 | loss: 0.0203  | val_0_mse: 0.01573 |  0:09:41s\n",
      "epoch 23 | loss: 0.02277 | val_0_mse: 0.02157 |  0:10:06s\n",
      "epoch 24 | loss: 0.01949 | val_0_mse: 0.02252 |  0:10:31s\n",
      "epoch 25 | loss: 0.01888 | val_0_mse: 0.03948 |  0:10:56s\n",
      "epoch 26 | loss: 0.01967 | val_0_mse: 0.0205  |  0:11:22s\n",
      "epoch 27 | loss: 0.0215  | val_0_mse: 0.09509 |  0:11:47s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_mse = 0.01573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.016955 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.923510 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 72/72 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.22196 | val_0_mse: 1.27889 |  0:00:14s\n",
      "epoch 1  | loss: 0.45572 | val_0_mse: 0.39651 |  0:00:28s\n",
      "epoch 2  | loss: 0.17542 | val_0_mse: 0.15741 |  0:00:42s\n",
      "epoch 3  | loss: 0.11764 | val_0_mse: 0.11767 |  0:00:57s\n",
      "epoch 4  | loss: 0.10186 | val_0_mse: 0.16902 |  0:01:11s\n",
      "epoch 5  | loss: 0.08264 | val_0_mse: 0.09103 |  0:01:25s\n",
      "epoch 6  | loss: 0.07563 | val_0_mse: 0.05528 |  0:01:39s\n",
      "epoch 7  | loss: 0.06591 | val_0_mse: 0.04954 |  0:01:53s\n",
      "epoch 8  | loss: 0.05665 | val_0_mse: 0.06215 |  0:02:08s\n",
      "epoch 9  | loss: 0.05399 | val_0_mse: 0.0459  |  0:02:22s\n",
      "epoch 10 | loss: 0.05521 | val_0_mse: 0.04569 |  0:02:36s\n",
      "epoch 11 | loss: 0.04153 | val_0_mse: 0.03786 |  0:02:51s\n",
      "epoch 12 | loss: 0.04352 | val_0_mse: 0.04191 |  0:03:05s\n",
      "epoch 13 | loss: 0.03467 | val_0_mse: 0.06188 |  0:03:19s\n",
      "epoch 14 | loss: 0.04315 | val_0_mse: 0.02599 |  0:03:33s\n",
      "epoch 15 | loss: 0.03463 | val_0_mse: 0.02886 |  0:03:47s\n",
      "epoch 16 | loss: 0.02681 | val_0_mse: 0.0516  |  0:04:02s\n",
      "epoch 17 | loss: 0.02902 | val_0_mse: 0.02057 |  0:04:16s\n",
      "epoch 18 | loss: 0.02567 | val_0_mse: 0.0168  |  0:04:30s\n",
      "epoch 19 | loss: 0.02475 | val_0_mse: 0.01405 |  0:04:44s\n",
      "epoch 20 | loss: 0.02724 | val_0_mse: 0.0386  |  0:04:58s\n",
      "epoch 21 | loss: 0.02963 | val_0_mse: 0.01878 |  0:05:12s\n",
      "epoch 22 | loss: 0.0186  | val_0_mse: 0.01275 |  0:05:27s\n",
      "epoch 23 | loss: 0.02128 | val_0_mse: 0.01298 |  0:05:41s\n",
      "epoch 24 | loss: 0.01707 | val_0_mse: 0.01878 |  0:05:55s\n",
      "epoch 25 | loss: 0.02454 | val_0_mse: 0.01145 |  0:06:09s\n",
      "epoch 26 | loss: 0.01371 | val_0_mse: 0.03514 |  0:06:24s\n",
      "epoch 27 | loss: 0.0288  | val_0_mse: 0.02014 |  0:06:38s\n",
      "epoch 28 | loss: 0.02007 | val_0_mse: 0.01876 |  0:06:52s\n",
      "epoch 29 | loss: 0.01722 | val_0_mse: 0.01131 |  0:07:06s\n",
      "epoch 30 | loss: 0.01711 | val_0_mse: 0.02285 |  0:07:20s\n",
      "epoch 31 | loss: 0.01774 | val_0_mse: 0.01615 |  0:07:36s\n",
      "epoch 32 | loss: 0.0182  | val_0_mse: 0.06094 |  0:07:50s\n",
      "epoch 33 | loss: 0.02387 | val_0_mse: 0.02006 |  0:08:04s\n",
      "epoch 34 | loss: 0.01691 | val_0_mse: 0.06865 |  0:08:18s\n",
      "epoch 35 | loss: 0.01855 | val_0_mse: 0.01599 |  0:08:32s\n",
      "epoch 36 | loss: 0.01843 | val_0_mse: 0.01045 |  0:08:46s\n",
      "epoch 37 | loss: 0.02302 | val_0_mse: 0.01329 |  0:09:00s\n",
      "epoch 38 | loss: 0.01566 | val_0_mse: 0.00993 |  0:09:14s\n",
      "epoch 39 | loss: 0.01451 | val_0_mse: 0.01162 |  0:09:27s\n",
      "epoch 40 | loss: 0.01237 | val_0_mse: 0.00747 |  0:09:41s\n",
      "epoch 41 | loss: 0.01192 | val_0_mse: 0.00727 |  0:09:55s\n",
      "epoch 42 | loss: 0.01347 | val_0_mse: 0.00869 |  0:10:08s\n",
      "epoch 43 | loss: 0.01421 | val_0_mse: 0.01025 |  0:10:22s\n",
      "epoch 44 | loss: 0.01617 | val_0_mse: 0.01989 |  0:10:36s\n",
      "epoch 45 | loss: 0.01227 | val_0_mse: 0.00747 |  0:10:50s\n",
      "epoch 46 | loss: 0.01418 | val_0_mse: 0.0294  |  0:11:03s\n",
      "epoch 47 | loss: 0.02006 | val_0_mse: 0.01885 |  0:11:17s\n",
      "epoch 48 | loss: 0.01916 | val_0_mse: 0.073   |  0:11:31s\n",
      "epoch 49 | loss: 0.02033 | val_0_mse: 0.23052 |  0:11:45s\n",
      "epoch 50 | loss: 0.02229 | val_0_mse: 0.02492 |  0:11:58s\n",
      "epoch 51 | loss: 0.01395 | val_0_mse: 0.01652 |  0:12:12s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_mse = 0.00727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007998 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.963917 - Best R2 Score: 0.976475\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('tabularML/training'):\n",
    "    os.system('rm -r tabularML/training')\n",
    "else:\n",
    "    os.makedirs('tabularML/training')\n",
    "\n",
    "current_iter = 0\n",
    "\n",
    "best_mse = float('inf')\n",
    "best_model = None\n",
    "best_n_d = None\n",
    "best_n_a = None\n",
    "best_n_step = None\n",
    "best_n_indipendent = None\n",
    "best_n_shared = None\n",
    "best_gamma = None\n",
    "best_batch_size = None\n",
    "\n",
    "for n_d_a, n_step,n_indipendent,n_shared, gamma, epsilon,nums_epochs, batch_sizes in hyperparameters:\n",
    "    current_iter += 1\n",
    "\n",
    "    print(\"\\nIterations {}/{} - Hyperparameters:  batch_sizes={}, nums_epochs={}, n_d={}, n_a={}, n_step={}, n_indipendent={}, n_shared={}, gamma={}, epsilon={}\".format(\n",
    "        current_iter, n_comb, batch_sizes, nums_epochs, n_d_a, n_d_a, n_step, n_indipendent, n_shared, gamma, epsilon ))\n",
    "\n",
    "    model = get_model(n_d_a, n_step, n_indipendent, n_shared, gamma, epsilon)\n",
    "    \n",
    "    log_name = \"batch_size:\"+str(batch_sizes)+\"n_d:\"+str(n_d_a)+\"n_a:\"+str(n_d_a)+\"n_step:\"+str(n_step)+\"n_indipendent:\"+str(n_indipendent)+\"n_shared:\"+str(n_shared)+\"gamma:\"+str(gamma)+\"epsilon:\"+str(epsilon)\n",
    "    \n",
    "    # start tensorboard\n",
    "    writer = SummaryWriter('tabularML/training/'+log_name)\n",
    "    \n",
    "    # train\n",
    "    model.fit(\n",
    "                X_train=X_train,\n",
    "                y_train=Y_train,\n",
    "                eval_set=[(X_val, Y_val)],\n",
    "                eval_metric=['mse'],\n",
    "                # patience: the number of epochs to wait without improvement in validation loss before early stopping (default 10)\n",
    "                patience=10,\n",
    "                # batch_size: the number of samples per batch (default 1024)\n",
    "                batch_size=batch_sizes,\n",
    "                # virtual_batch_size: the number of samples per virtual batch (default 128)\n",
    "                virtual_batch_size=128,\n",
    "                # num_workers: the number of worker processes to use for data loading (default 0)\n",
    "                num_workers=0,\n",
    "                # drop_last: whether to drop the last incomplete batch if the dataset size is not divisible by the batch size (default False)\n",
    "                drop_last=False,\n",
    "                # max_epochs: the maximum number of epochs to train for (default 100)\n",
    "                max_epochs=nums_epochs,\n",
    "            )\n",
    "    \n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, preds)\n",
    "    \n",
    "    writer.add_hparams({'n_d':n_d_a, 'n_a':n_d_a, 'n_step':n_step, 'n_indipendent':n_indipendent, 'n_shared':n_shared, 'gamma':gamma, 'epsilon':epsilon, 'batch_sizes':batch_sizes, 'nums_epochs':nums_epochs }, {'hparam/mse': mse})\n",
    "\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_n_d = n_d_a\n",
    "        best_n_a = n_d_a\n",
    "        best_n_step = n_step\n",
    "        best_n_indipendent = n_indipendent\n",
    "        best_n_shared = n_shared\n",
    "        best_gamma = gamma\n",
    "        best_batch_size = batch_sizes\n",
    "        best_model = copy.deepcopy(model) \n",
    "        \n",
    "    writer.flush()            \n",
    "            \n",
    "    print(\"Model MSE: {:.6f} - Best MSE: {:.6f}\".format(mse, best_mse))\n",
    "    print(\"Model R2 Score: {:.6f} - Best R2 Score: {:.6f}\".format(r2_score(Y_test, preds), r2_score(Y_test, best_model.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = best_model.history\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['loss'], label='train')\n",
    "plt.plot(history['val_0_mse'], label='validation')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid')\n",
    "sns.set_context('talk')\n",
    "sns.set_palette('colorblind')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(Y_test, preds, s=1)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('True Values vs Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training and validation losses\n",
    "train_losses = history['loss']\n",
    "valid_losses = history['val_0_mse']\n",
    "\n",
    "train_array = np.array(train_losses)\n",
    "valid_array = np.array(valid_losses)\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame({'training loss': train_array, 'validation loss': valid_array})\n",
    "\n",
    "df.to_csv('tabularML/training/loss.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
