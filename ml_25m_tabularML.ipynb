{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import copy\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def fix_random(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower\n",
    "\n",
    "fix_random(42)\n",
    "\n",
    "# check if tabular ML folder exists\n",
    "if not os.path.exists('tabularML'):\n",
    "    os.makedirs('tabularML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# PyTorch Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 9946\n",
      "Number of validation samples: 1106\n",
      "Number of testing samples: 2764\n",
      "\n",
      "Number of features: 1128\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('rating', axis=1)\n",
    "Y = df['rating']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "Y_train = Y_train.to_numpy()\n",
    "Y_val = Y_val.to_numpy()\n",
    "Y_test = Y_test.to_numpy()\n",
    "\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_val = Y_val.reshape(-1, 1)\n",
    "\n",
    "print(f'Number of training samples: {X_train.shape[0]}')\n",
    "print(f'Number of validation samples: {X_val.shape[0]}')\n",
    "print(f'Number of testing samples: {X_test.shape[0]}')\n",
    "print(f'\\nNumber of features: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hyperparameter combinations: 64\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "nums_epochs = [200]\n",
    "batch_sizes = [128, 256]\n",
    "patience = [10]\n",
    "n_d_a = [8,16,32,64]\n",
    "n_shared = [2,3]\n",
    "n_indipendent = [2,3]\n",
    "n_step = [6,7]\n",
    "gamma = [1.3]\n",
    "epsilon = [1e-8]\n",
    "\n",
    "hyperparameters = itertools.product(n_d_a, n_step,n_indipendent,n_shared, gamma, epsilon,nums_epochs, batch_sizes)\n",
    "n_comb = len(n_d_a)*len(n_step)*len(n_indipendent)*len(n_shared)*len(gamma)*len(epsilon)*len(nums_epochs)*len(batch_sizes)\n",
    "print (f'Number of hyperparameter combinations: {n_comb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_d_a, n_step,n_indipendent,n_shared, gamma, epsilon):\n",
    "    model = TabNetRegressor(\n",
    "        # n_d: the dimensionality of the output space of the feature transformer network (default 64)\n",
    "        n_d=n_d_a,\n",
    "        # n_a: the dimensionality of the output space of the attention network (default 64)\n",
    "        n_a=n_d_a,\n",
    "        # n_steps: the number of sequential steps in the attention mechanism (default 3)\n",
    "        n_steps=n_step,\n",
    "        # gamma: the scaling factor for the feature transformer network (default 1.3)\n",
    "        gamma=gamma,\n",
    "        # optimizerm name of optimizer to use (default Adam)\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        # n_independent: the number of independent feature transformer networks to use (default 2)\n",
    "        n_independent=n_indipendent,\n",
    "        # n_shared: the number of shared feature transformer networks to use (default 2)\n",
    "        n_shared=n_shared,\n",
    "        # epsilon: a small value to add to the denominator of the feature importance calculation to avoid division by zero (default 1e-15)\n",
    "        epsilon=epsilon,\n",
    "        # seed: the random seed to use for reproducibility (default None)\n",
    "        seed=42    \n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iterations 1/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=8, n_a=8, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: tabularM/training: No such file or directory\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.00698 | val_0_mse: 0.42433 |  0:00:09s\n",
      "epoch 1  | loss: 0.23017 | val_0_mse: 0.15601 |  0:00:18s\n",
      "epoch 2  | loss: 0.13447 | val_0_mse: 0.15482 |  0:00:26s\n",
      "epoch 3  | loss: 0.10059 | val_0_mse: 0.09609 |  0:00:34s\n",
      "epoch 4  | loss: 0.07389 | val_0_mse: 0.08525 |  0:00:42s\n",
      "epoch 5  | loss: 0.06187 | val_0_mse: 0.05699 |  0:00:49s\n",
      "epoch 6  | loss: 0.05964 | val_0_mse: 0.066   |  0:00:57s\n",
      "epoch 7  | loss: 0.05049 | val_0_mse: 0.03176 |  0:01:04s\n",
      "epoch 8  | loss: 0.04626 | val_0_mse: 0.0316  |  0:01:12s\n",
      "epoch 9  | loss: 0.03179 | val_0_mse: 0.0258  |  0:01:19s\n",
      "epoch 10 | loss: 0.02765 | val_0_mse: 0.02775 |  0:01:27s\n",
      "epoch 11 | loss: 0.02889 | val_0_mse: 0.02961 |  0:01:34s\n",
      "epoch 12 | loss: 0.02511 | val_0_mse: 0.01693 |  0:01:41s\n",
      "epoch 13 | loss: 0.02276 | val_0_mse: 0.02126 |  0:01:47s\n",
      "epoch 14 | loss: 0.02234 | val_0_mse: 0.02003 |  0:01:55s\n",
      "epoch 15 | loss: 0.01925 | val_0_mse: 0.01966 |  0:02:02s\n",
      "epoch 16 | loss: 0.02477 | val_0_mse: 0.01279 |  0:02:09s\n",
      "epoch 17 | loss: 0.01883 | val_0_mse: 0.0118  |  0:02:16s\n",
      "epoch 18 | loss: 0.01479 | val_0_mse: 0.01991 |  0:02:23s\n",
      "epoch 19 | loss: 0.01554 | val_0_mse: 0.01613 |  0:02:29s\n",
      "epoch 20 | loss: 0.01688 | val_0_mse: 0.01079 |  0:02:36s\n",
      "epoch 21 | loss: 0.01616 | val_0_mse: 0.01709 |  0:02:43s\n",
      "epoch 22 | loss: 0.01567 | val_0_mse: 0.00862 |  0:02:50s\n",
      "epoch 23 | loss: 0.01384 | val_0_mse: 0.01338 |  0:02:57s\n",
      "epoch 24 | loss: 0.01827 | val_0_mse: 0.02831 |  0:03:03s\n",
      "epoch 25 | loss: 0.01528 | val_0_mse: 0.01754 |  0:03:10s\n",
      "epoch 26 | loss: 0.01262 | val_0_mse: 0.00844 |  0:03:17s\n",
      "epoch 27 | loss: 0.01318 | val_0_mse: 0.00895 |  0:03:24s\n",
      "epoch 28 | loss: 0.01074 | val_0_mse: 0.00738 |  0:03:31s\n",
      "epoch 29 | loss: 0.01316 | val_0_mse: 0.00886 |  0:03:37s\n",
      "epoch 30 | loss: 0.01149 | val_0_mse: 0.0085  |  0:03:44s\n",
      "epoch 31 | loss: 0.01086 | val_0_mse: 0.01998 |  0:03:51s\n",
      "epoch 32 | loss: 0.01032 | val_0_mse: 0.00973 |  0:03:57s\n",
      "epoch 33 | loss: 0.01132 | val_0_mse: 0.00693 |  0:04:04s\n",
      "epoch 34 | loss: 0.01294 | val_0_mse: 0.01132 |  0:04:11s\n",
      "epoch 35 | loss: 0.01091 | val_0_mse: 0.0082  |  0:04:18s\n",
      "epoch 36 | loss: 0.01004 | val_0_mse: 0.00635 |  0:04:24s\n",
      "epoch 37 | loss: 0.01335 | val_0_mse: 0.01212 |  0:04:32s\n",
      "epoch 38 | loss: 0.01383 | val_0_mse: 0.00673 |  0:04:39s\n",
      "epoch 39 | loss: 0.01189 | val_0_mse: 0.00716 |  0:04:46s\n",
      "epoch 40 | loss: 0.01492 | val_0_mse: 0.01188 |  0:04:53s\n",
      "epoch 41 | loss: 0.01239 | val_0_mse: 0.00661 |  0:04:59s\n",
      "epoch 42 | loss: 0.01321 | val_0_mse: 0.00933 |  0:05:06s\n",
      "epoch 43 | loss: 0.0148  | val_0_mse: 0.01275 |  0:05:14s\n",
      "epoch 44 | loss: 0.01013 | val_0_mse: 0.00628 |  0:05:20s\n",
      "epoch 45 | loss: 0.0107  | val_0_mse: 0.02202 |  0:05:27s\n",
      "epoch 46 | loss: 0.01014 | val_0_mse: 0.01779 |  0:05:34s\n",
      "epoch 47 | loss: 0.01138 | val_0_mse: 0.0067  |  0:05:41s\n",
      "epoch 48 | loss: 0.00866 | val_0_mse: 0.00628 |  0:05:48s\n",
      "epoch 49 | loss: 0.01078 | val_0_mse: 0.04217 |  0:05:55s\n",
      "epoch 50 | loss: 0.01138 | val_0_mse: 0.00742 |  0:06:02s\n",
      "epoch 51 | loss: 0.01867 | val_0_mse: 0.01885 |  0:06:09s\n",
      "epoch 52 | loss: 0.01142 | val_0_mse: 0.01305 |  0:06:16s\n",
      "epoch 53 | loss: 0.00976 | val_0_mse: 0.02882 |  0:06:23s\n",
      "epoch 54 | loss: 0.01138 | val_0_mse: 0.01576 |  0:06:29s\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_mse = 0.00628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.005838 - Best MSE: 0.005838\n",
      "Model R2 Score: 0.973664 - Best R2 Score: 0.973664\n",
      "\n",
      "Iterations 2/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=8, n_a=8, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.29919 | val_0_mse: 0.58486 |  0:00:05s\n",
      "epoch 1  | loss: 0.33347 | val_0_mse: 0.20111 |  0:00:10s\n",
      "epoch 2  | loss: 0.17596 | val_0_mse: 0.36465 |  0:00:16s\n",
      "epoch 3  | loss: 0.12307 | val_0_mse: 0.17212 |  0:00:21s\n",
      "epoch 4  | loss: 0.09091 | val_0_mse: 0.14869 |  0:00:26s\n",
      "epoch 5  | loss: 0.10562 | val_0_mse: 0.10495 |  0:00:32s\n",
      "epoch 6  | loss: 0.09257 | val_0_mse: 0.1167  |  0:00:37s\n",
      "epoch 7  | loss: 0.07138 | val_0_mse: 0.09543 |  0:00:42s\n",
      "epoch 8  | loss: 0.0675  | val_0_mse: 0.07485 |  0:00:47s\n",
      "epoch 9  | loss: 0.06001 | val_0_mse: 0.06219 |  0:00:52s\n",
      "epoch 10 | loss: 0.06157 | val_0_mse: 0.07212 |  0:00:57s\n",
      "epoch 11 | loss: 0.05544 | val_0_mse: 0.05087 |  0:01:02s\n",
      "epoch 12 | loss: 0.06271 | val_0_mse: 0.05632 |  0:01:08s\n",
      "epoch 13 | loss: 0.05611 | val_0_mse: 0.05051 |  0:01:13s\n",
      "epoch 14 | loss: 0.06232 | val_0_mse: 0.06344 |  0:01:18s\n",
      "epoch 15 | loss: 0.0552  | val_0_mse: 0.05197 |  0:01:23s\n",
      "epoch 16 | loss: 0.05556 | val_0_mse: 0.04166 |  0:01:28s\n",
      "epoch 17 | loss: 0.05056 | val_0_mse: 0.04463 |  0:01:33s\n",
      "epoch 18 | loss: 0.04999 | val_0_mse: 0.03783 |  0:01:38s\n",
      "epoch 19 | loss: 0.05166 | val_0_mse: 0.05434 |  0:01:44s\n",
      "epoch 20 | loss: 0.05012 | val_0_mse: 0.04016 |  0:01:49s\n",
      "epoch 21 | loss: 0.04564 | val_0_mse: 0.04224 |  0:01:54s\n",
      "epoch 22 | loss: 0.04204 | val_0_mse: 0.03953 |  0:01:59s\n",
      "epoch 23 | loss: 0.04112 | val_0_mse: 0.04332 |  0:02:05s\n",
      "epoch 24 | loss: 0.04611 | val_0_mse: 0.05293 |  0:02:10s\n",
      "epoch 25 | loss: 0.03904 | val_0_mse: 0.03059 |  0:02:15s\n",
      "epoch 26 | loss: 0.03602 | val_0_mse: 0.03442 |  0:02:20s\n",
      "epoch 27 | loss: 0.04179 | val_0_mse: 0.03709 |  0:02:26s\n",
      "epoch 28 | loss: 0.03484 | val_0_mse: 0.04105 |  0:02:31s\n",
      "epoch 29 | loss: 0.03255 | val_0_mse: 0.03087 |  0:02:36s\n",
      "epoch 30 | loss: 0.03182 | val_0_mse: 0.02422 |  0:02:41s\n",
      "epoch 31 | loss: 0.03069 | val_0_mse: 0.02851 |  0:02:46s\n",
      "epoch 32 | loss: 0.02574 | val_0_mse: 0.02205 |  0:02:52s\n",
      "epoch 33 | loss: 0.02493 | val_0_mse: 0.02473 |  0:02:57s\n",
      "epoch 34 | loss: 0.025   | val_0_mse: 0.02494 |  0:03:02s\n",
      "epoch 35 | loss: 0.02846 | val_0_mse: 0.01888 |  0:03:08s\n",
      "epoch 36 | loss: 0.02376 | val_0_mse: 0.01825 |  0:03:13s\n",
      "epoch 37 | loss: 0.02372 | val_0_mse: 0.02041 |  0:03:18s\n",
      "epoch 38 | loss: 0.0268  | val_0_mse: 0.02303 |  0:03:23s\n",
      "epoch 39 | loss: 0.02687 | val_0_mse: 0.01955 |  0:03:28s\n",
      "epoch 40 | loss: 0.02189 | val_0_mse: 0.01844 |  0:03:33s\n",
      "epoch 41 | loss: 0.0231  | val_0_mse: 0.02465 |  0:03:38s\n",
      "epoch 42 | loss: 0.01939 | val_0_mse: 0.01835 |  0:03:43s\n",
      "epoch 43 | loss: 0.01856 | val_0_mse: 0.01648 |  0:03:48s\n",
      "epoch 44 | loss: 0.0197  | val_0_mse: 0.02121 |  0:03:53s\n",
      "epoch 45 | loss: 0.02386 | val_0_mse: 0.01681 |  0:03:58s\n",
      "epoch 46 | loss: 0.02466 | val_0_mse: 0.01693 |  0:04:03s\n",
      "epoch 47 | loss: 0.02109 | val_0_mse: 0.01905 |  0:04:08s\n",
      "epoch 48 | loss: 0.01775 | val_0_mse: 0.0159  |  0:04:13s\n",
      "epoch 49 | loss: 0.02151 | val_0_mse: 0.01366 |  0:04:18s\n",
      "epoch 50 | loss: 0.01858 | val_0_mse: 0.02105 |  0:04:23s\n",
      "epoch 51 | loss: 0.02169 | val_0_mse: 0.0162  |  0:04:28s\n",
      "epoch 52 | loss: 0.01578 | val_0_mse: 0.02358 |  0:04:33s\n",
      "epoch 53 | loss: 0.01776 | val_0_mse: 0.01235 |  0:04:38s\n",
      "epoch 54 | loss: 0.01972 | val_0_mse: 0.01229 |  0:04:43s\n",
      "epoch 55 | loss: 0.0178  | val_0_mse: 0.01108 |  0:04:49s\n",
      "epoch 56 | loss: 0.0147  | val_0_mse: 0.01041 |  0:04:54s\n",
      "epoch 57 | loss: 0.01393 | val_0_mse: 0.01044 |  0:04:59s\n",
      "epoch 58 | loss: 0.01844 | val_0_mse: 0.01388 |  0:05:04s\n",
      "epoch 59 | loss: 0.01417 | val_0_mse: 0.01016 |  0:05:09s\n",
      "epoch 60 | loss: 0.01521 | val_0_mse: 0.01042 |  0:05:14s\n",
      "epoch 61 | loss: 0.01201 | val_0_mse: 0.00964 |  0:05:19s\n",
      "epoch 62 | loss: 0.01276 | val_0_mse: 0.01098 |  0:05:24s\n",
      "epoch 63 | loss: 0.01204 | val_0_mse: 0.01447 |  0:05:29s\n",
      "epoch 64 | loss: 0.01344 | val_0_mse: 0.01272 |  0:05:34s\n",
      "epoch 65 | loss: 0.01254 | val_0_mse: 0.01405 |  0:05:39s\n",
      "epoch 66 | loss: 0.01158 | val_0_mse: 0.00731 |  0:05:45s\n",
      "epoch 67 | loss: 0.01145 | val_0_mse: 0.00964 |  0:05:50s\n",
      "epoch 68 | loss: 0.01314 | val_0_mse: 0.011   |  0:05:55s\n",
      "epoch 69 | loss: 0.0112  | val_0_mse: 0.00788 |  0:06:00s\n",
      "epoch 70 | loss: 0.01227 | val_0_mse: 0.01214 |  0:06:05s\n",
      "epoch 71 | loss: 0.01292 | val_0_mse: 0.00649 |  0:06:10s\n",
      "epoch 72 | loss: 0.01126 | val_0_mse: 0.00726 |  0:06:15s\n",
      "epoch 73 | loss: 0.01378 | val_0_mse: 0.01405 |  0:06:20s\n",
      "epoch 74 | loss: 0.01435 | val_0_mse: 0.01336 |  0:06:25s\n",
      "epoch 75 | loss: 0.01892 | val_0_mse: 0.01553 |  0:06:30s\n",
      "epoch 76 | loss: 0.01829 | val_0_mse: 0.01066 |  0:06:35s\n",
      "epoch 77 | loss: 0.01251 | val_0_mse: 0.01298 |  0:06:40s\n",
      "epoch 78 | loss: 0.0127  | val_0_mse: 0.016   |  0:06:45s\n",
      "epoch 79 | loss: 0.02118 | val_0_mse: 0.06247 |  0:06:50s\n",
      "epoch 80 | loss: 0.02244 | val_0_mse: 0.01468 |  0:06:55s\n",
      "epoch 81 | loss: 0.01724 | val_0_mse: 0.02439 |  0:07:01s\n",
      "\n",
      "Early stopping occurred at epoch 81 with best_epoch = 71 and best_val_0_mse = 0.00649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006841 - Best MSE: 0.005838\n",
      "Model R2 Score: 0.969138 - Best R2 Score: 0.973664\n",
      "\n",
      "Iterations 3/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=8, n_a=8, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.88132 | val_0_mse: 0.40434 |  0:00:07s\n",
      "epoch 1  | loss: 0.22519 | val_0_mse: 0.18634 |  0:00:15s\n",
      "epoch 2  | loss: 0.14325 | val_0_mse: 0.12477 |  0:00:22s\n",
      "epoch 3  | loss: 0.12365 | val_0_mse: 0.09982 |  0:00:30s\n",
      "epoch 4  | loss: 0.08992 | val_0_mse: 0.09223 |  0:00:37s\n",
      "epoch 5  | loss: 0.08151 | val_0_mse: 0.06657 |  0:00:45s\n",
      "epoch 6  | loss: 0.08828 | val_0_mse: 0.07717 |  0:00:52s\n",
      "epoch 7  | loss: 0.07977 | val_0_mse: 0.06671 |  0:01:00s\n",
      "epoch 8  | loss: 0.08178 | val_0_mse: 0.08461 |  0:01:07s\n",
      "epoch 9  | loss: 0.07703 | val_0_mse: 0.06647 |  0:01:15s\n",
      "epoch 10 | loss: 0.07394 | val_0_mse: 0.07016 |  0:01:23s\n",
      "epoch 11 | loss: 0.06069 | val_0_mse: 0.0537  |  0:01:30s\n",
      "epoch 12 | loss: 0.05873 | val_0_mse: 0.0493  |  0:01:37s\n",
      "epoch 13 | loss: 0.0522  | val_0_mse: 0.0431  |  0:01:45s\n",
      "epoch 14 | loss: 0.04223 | val_0_mse: 0.02937 |  0:01:53s\n",
      "epoch 15 | loss: 0.04612 | val_0_mse: 0.04099 |  0:02:00s\n",
      "epoch 16 | loss: 0.04439 | val_0_mse: 0.05142 |  0:02:08s\n",
      "epoch 17 | loss: 0.03524 | val_0_mse: 0.0264  |  0:02:15s\n",
      "epoch 18 | loss: 0.03227 | val_0_mse: 0.03198 |  0:02:23s\n",
      "epoch 19 | loss: 0.03428 | val_0_mse: 0.05881 |  0:02:31s\n",
      "epoch 20 | loss: 0.03495 | val_0_mse: 0.0264  |  0:02:38s\n",
      "epoch 21 | loss: 0.02932 | val_0_mse: 0.02213 |  0:02:46s\n",
      "epoch 22 | loss: 0.02497 | val_0_mse: 0.0202  |  0:02:54s\n",
      "epoch 23 | loss: 0.02494 | val_0_mse: 0.01633 |  0:03:01s\n",
      "epoch 24 | loss: 0.02605 | val_0_mse: 0.02747 |  0:03:09s\n",
      "epoch 25 | loss: 0.02138 | val_0_mse: 0.02594 |  0:03:16s\n",
      "epoch 26 | loss: 0.01881 | val_0_mse: 0.04279 |  0:03:24s\n",
      "epoch 27 | loss: 0.01963 | val_0_mse: 0.01551 |  0:03:31s\n",
      "epoch 28 | loss: 0.0201  | val_0_mse: 0.02102 |  0:03:39s\n",
      "epoch 29 | loss: 0.0158  | val_0_mse: 0.0114  |  0:03:47s\n",
      "epoch 30 | loss: 0.02104 | val_0_mse: 0.03061 |  0:03:54s\n",
      "epoch 31 | loss: 0.01875 | val_0_mse: 0.00967 |  0:04:02s\n",
      "epoch 32 | loss: 0.01614 | val_0_mse: 0.00932 |  0:04:09s\n",
      "epoch 33 | loss: 0.01609 | val_0_mse: 0.00923 |  0:04:17s\n",
      "epoch 34 | loss: 0.02384 | val_0_mse: 0.05296 |  0:04:25s\n",
      "epoch 35 | loss: 0.01655 | val_0_mse: 0.01181 |  0:04:32s\n",
      "epoch 36 | loss: 0.01652 | val_0_mse: 0.01289 |  0:04:40s\n",
      "epoch 37 | loss: 0.01914 | val_0_mse: 0.01318 |  0:04:47s\n",
      "epoch 38 | loss: 0.01802 | val_0_mse: 0.0193  |  0:04:55s\n",
      "epoch 39 | loss: 0.01488 | val_0_mse: 0.00858 |  0:05:03s\n",
      "epoch 40 | loss: 0.02301 | val_0_mse: 0.01158 |  0:05:10s\n",
      "epoch 41 | loss: 0.01719 | val_0_mse: 0.00852 |  0:05:18s\n",
      "epoch 42 | loss: 0.01544 | val_0_mse: 0.01301 |  0:05:26s\n",
      "epoch 43 | loss: 0.01299 | val_0_mse: 0.02843 |  0:05:33s\n",
      "epoch 44 | loss: 0.01605 | val_0_mse: 0.00787 |  0:05:41s\n",
      "epoch 45 | loss: 0.01955 | val_0_mse: 0.01294 |  0:05:48s\n",
      "epoch 46 | loss: 0.01885 | val_0_mse: 0.03261 |  0:05:56s\n",
      "epoch 47 | loss: 0.01335 | val_0_mse: 0.02699 |  0:06:04s\n",
      "epoch 48 | loss: 0.03294 | val_0_mse: 0.24871 |  0:06:12s\n",
      "epoch 49 | loss: 0.02468 | val_0_mse: 0.0165  |  0:06:19s\n",
      "epoch 50 | loss: 0.01649 | val_0_mse: 0.02397 |  0:06:27s\n",
      "epoch 51 | loss: 0.01267 | val_0_mse: 0.00896 |  0:06:34s\n",
      "epoch 52 | loss: 0.01169 | val_0_mse: 0.01581 |  0:06:42s\n",
      "epoch 53 | loss: 0.01339 | val_0_mse: 0.00726 |  0:06:49s\n",
      "epoch 54 | loss: 0.01108 | val_0_mse: 0.00701 |  0:06:57s\n",
      "epoch 55 | loss: 0.01101 | val_0_mse: 0.13009 |  0:07:05s\n",
      "epoch 56 | loss: 0.01323 | val_0_mse: 0.01347 |  0:07:12s\n",
      "epoch 57 | loss: 0.01029 | val_0_mse: 0.01721 |  0:07:20s\n",
      "epoch 58 | loss: 0.01618 | val_0_mse: 0.01145 |  0:07:27s\n",
      "epoch 59 | loss: 0.00961 | val_0_mse: 0.01125 |  0:07:35s\n",
      "epoch 60 | loss: 0.01392 | val_0_mse: 0.0117  |  0:07:43s\n",
      "epoch 61 | loss: 0.02445 | val_0_mse: 0.01083 |  0:07:50s\n",
      "epoch 62 | loss: 0.01399 | val_0_mse: 0.00967 |  0:07:58s\n",
      "epoch 63 | loss: 0.01196 | val_0_mse: 0.0095  |  0:08:05s\n",
      "epoch 64 | loss: 0.01127 | val_0_mse: 0.03741 |  0:08:13s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_mse = 0.00701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007418 - Best MSE: 0.005838\n",
      "Model R2 Score: 0.966534 - Best R2 Score: 0.973664\n",
      "\n",
      "Iterations 4/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=8, n_a=8, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.57949 | val_0_mse: 0.45557 |  0:00:05s\n",
      "epoch 1  | loss: 0.30423 | val_0_mse: 0.20838 |  0:00:11s\n",
      "epoch 2  | loss: 0.17251 | val_0_mse: 0.26376 |  0:00:16s\n",
      "epoch 3  | loss: 0.14784 | val_0_mse: 0.18954 |  0:00:22s\n",
      "epoch 4  | loss: 0.11782 | val_0_mse: 0.18048 |  0:00:27s\n",
      "epoch 5  | loss: 0.10351 | val_0_mse: 0.13896 |  0:00:32s\n",
      "epoch 6  | loss: 0.09457 | val_0_mse: 0.12107 |  0:00:38s\n",
      "epoch 7  | loss: 0.1101  | val_0_mse: 0.16134 |  0:00:44s\n",
      "epoch 8  | loss: 0.07695 | val_0_mse: 0.11398 |  0:00:49s\n",
      "epoch 9  | loss: 0.07477 | val_0_mse: 0.08455 |  0:00:54s\n",
      "epoch 10 | loss: 0.06827 | val_0_mse: 0.07709 |  0:01:00s\n",
      "epoch 11 | loss: 0.06647 | val_0_mse: 0.06345 |  0:01:05s\n",
      "epoch 12 | loss: 0.06274 | val_0_mse: 0.06627 |  0:01:11s\n",
      "epoch 13 | loss: 0.06753 | val_0_mse: 0.05625 |  0:01:16s\n",
      "epoch 14 | loss: 0.05999 | val_0_mse: 0.05149 |  0:01:22s\n",
      "epoch 15 | loss: 0.0647  | val_0_mse: 0.10296 |  0:01:27s\n",
      "epoch 16 | loss: 0.06195 | val_0_mse: 0.07111 |  0:01:33s\n",
      "epoch 17 | loss: 0.05498 | val_0_mse: 0.04459 |  0:01:38s\n",
      "epoch 18 | loss: 0.05944 | val_0_mse: 0.06422 |  0:01:44s\n",
      "epoch 19 | loss: 0.06115 | val_0_mse: 0.05463 |  0:01:49s\n",
      "epoch 20 | loss: 0.05627 | val_0_mse: 0.05463 |  0:01:54s\n",
      "epoch 21 | loss: 0.05766 | val_0_mse: 0.05363 |  0:02:00s\n",
      "epoch 22 | loss: 0.04993 | val_0_mse: 0.0429  |  0:02:05s\n",
      "epoch 23 | loss: 0.0481  | val_0_mse: 0.04057 |  0:02:11s\n",
      "epoch 24 | loss: 0.05689 | val_0_mse: 0.04699 |  0:02:16s\n",
      "epoch 25 | loss: 0.05288 | val_0_mse: 0.0408  |  0:02:22s\n",
      "epoch 26 | loss: 0.04578 | val_0_mse: 0.05486 |  0:02:28s\n",
      "epoch 27 | loss: 0.04864 | val_0_mse: 0.04392 |  0:02:35s\n",
      "epoch 28 | loss: 0.04476 | val_0_mse: 0.05622 |  0:02:41s\n",
      "epoch 29 | loss: 0.04484 | val_0_mse: 0.03939 |  0:02:46s\n",
      "epoch 30 | loss: 0.04192 | val_0_mse: 0.03659 |  0:02:52s\n",
      "epoch 31 | loss: 0.0448  | val_0_mse: 0.03518 |  0:02:57s\n",
      "epoch 32 | loss: 0.03966 | val_0_mse: 0.04469 |  0:03:03s\n",
      "epoch 33 | loss: 0.04179 | val_0_mse: 0.04249 |  0:03:08s\n",
      "epoch 34 | loss: 0.03834 | val_0_mse: 0.0316  |  0:03:14s\n",
      "epoch 35 | loss: 0.03638 | val_0_mse: 0.03156 |  0:03:20s\n",
      "epoch 36 | loss: 0.03877 | val_0_mse: 0.02832 |  0:03:25s\n",
      "epoch 37 | loss: 0.03337 | val_0_mse: 0.03618 |  0:03:31s\n",
      "epoch 38 | loss: 0.03443 | val_0_mse: 0.02369 |  0:03:36s\n",
      "epoch 39 | loss: 0.03258 | val_0_mse: 0.02298 |  0:03:42s\n",
      "epoch 40 | loss: 0.02983 | val_0_mse: 0.02129 |  0:03:47s\n",
      "epoch 41 | loss: 0.02803 | val_0_mse: 0.02315 |  0:03:53s\n",
      "epoch 42 | loss: 0.0278  | val_0_mse: 0.02188 |  0:03:59s\n",
      "epoch 43 | loss: 0.02499 | val_0_mse: 0.02055 |  0:04:04s\n",
      "epoch 44 | loss: 0.02466 | val_0_mse: 0.02519 |  0:04:09s\n",
      "epoch 45 | loss: 0.02733 | val_0_mse: 0.0169  |  0:04:15s\n",
      "epoch 46 | loss: 0.02812 | val_0_mse: 0.03194 |  0:04:20s\n",
      "epoch 47 | loss: 0.02574 | val_0_mse: 0.01432 |  0:04:26s\n",
      "epoch 48 | loss: 0.02039 | val_0_mse: 0.0147  |  0:04:31s\n",
      "epoch 49 | loss: 0.01963 | val_0_mse: 0.01389 |  0:04:37s\n",
      "epoch 50 | loss: 0.01952 | val_0_mse: 0.01405 |  0:04:42s\n",
      "epoch 51 | loss: 0.01824 | val_0_mse: 0.01378 |  0:04:48s\n",
      "epoch 52 | loss: 0.01855 | val_0_mse: 0.01662 |  0:04:53s\n",
      "epoch 53 | loss: 0.01831 | val_0_mse: 0.01222 |  0:04:58s\n",
      "epoch 54 | loss: 0.02015 | val_0_mse: 0.02384 |  0:05:04s\n",
      "epoch 55 | loss: 0.01814 | val_0_mse: 0.02323 |  0:05:10s\n",
      "epoch 56 | loss: 0.01988 | val_0_mse: 0.01836 |  0:05:15s\n",
      "epoch 57 | loss: 0.01968 | val_0_mse: 0.01276 |  0:05:20s\n",
      "epoch 58 | loss: 0.02172 | val_0_mse: 0.01461 |  0:05:25s\n",
      "epoch 59 | loss: 0.01408 | val_0_mse: 0.01288 |  0:05:31s\n",
      "epoch 60 | loss: 0.01571 | val_0_mse: 0.01112 |  0:05:36s\n",
      "epoch 61 | loss: 0.01553 | val_0_mse: 0.01212 |  0:05:42s\n",
      "epoch 62 | loss: 0.0148  | val_0_mse: 0.01155 |  0:05:47s\n",
      "epoch 63 | loss: 0.01731 | val_0_mse: 0.01232 |  0:05:53s\n",
      "epoch 64 | loss: 0.01418 | val_0_mse: 0.01385 |  0:05:58s\n",
      "epoch 65 | loss: 0.01412 | val_0_mse: 0.01184 |  0:06:03s\n",
      "epoch 66 | loss: 0.01655 | val_0_mse: 0.01333 |  0:06:09s\n",
      "epoch 67 | loss: 0.01412 | val_0_mse: 0.01059 |  0:06:14s\n",
      "epoch 68 | loss: 0.0119  | val_0_mse: 0.0102  |  0:06:19s\n",
      "epoch 69 | loss: 0.01608 | val_0_mse: 0.01158 |  0:06:25s\n",
      "epoch 70 | loss: 0.01197 | val_0_mse: 0.00943 |  0:06:31s\n",
      "epoch 71 | loss: 0.01249 | val_0_mse: 0.00925 |  0:06:37s\n",
      "epoch 72 | loss: 0.01458 | val_0_mse: 0.0094  |  0:06:45s\n",
      "epoch 73 | loss: 0.01151 | val_0_mse: 0.00751 |  0:06:51s\n",
      "epoch 74 | loss: 0.01366 | val_0_mse: 0.01775 |  0:06:57s\n",
      "epoch 75 | loss: 0.01405 | val_0_mse: 0.01354 |  0:07:04s\n",
      "epoch 76 | loss: 0.01142 | val_0_mse: 0.01034 |  0:07:09s\n",
      "epoch 77 | loss: 0.01113 | val_0_mse: 0.00935 |  0:07:15s\n",
      "epoch 78 | loss: 0.00952 | val_0_mse: 0.00946 |  0:07:21s\n",
      "epoch 79 | loss: 0.01172 | val_0_mse: 0.00713 |  0:07:28s\n",
      "epoch 80 | loss: 0.00983 | val_0_mse: 0.00795 |  0:07:36s\n",
      "epoch 81 | loss: 0.00968 | val_0_mse: 0.01021 |  0:07:42s\n",
      "epoch 82 | loss: 0.01018 | val_0_mse: 0.01133 |  0:07:47s\n",
      "epoch 83 | loss: 0.00921 | val_0_mse: 0.00732 |  0:07:53s\n",
      "epoch 84 | loss: 0.01116 | val_0_mse: 0.00781 |  0:07:58s\n",
      "epoch 85 | loss: 0.0093  | val_0_mse: 0.01115 |  0:08:04s\n",
      "epoch 86 | loss: 0.01404 | val_0_mse: 0.00624 |  0:08:10s\n",
      "epoch 87 | loss: 0.00974 | val_0_mse: 0.01728 |  0:08:15s\n",
      "epoch 88 | loss: 0.01238 | val_0_mse: 0.00973 |  0:08:21s\n",
      "epoch 89 | loss: 0.01012 | val_0_mse: 0.00652 |  0:08:28s\n",
      "epoch 90 | loss: 0.01493 | val_0_mse: 0.00598 |  0:08:34s\n",
      "epoch 91 | loss: 0.01262 | val_0_mse: 0.01561 |  0:08:40s\n",
      "epoch 92 | loss: 0.01192 | val_0_mse: 0.00717 |  0:08:45s\n",
      "epoch 93 | loss: 0.00987 | val_0_mse: 0.01167 |  0:08:51s\n",
      "epoch 94 | loss: 0.00984 | val_0_mse: 0.00696 |  0:08:56s\n",
      "epoch 95 | loss: 0.00909 | val_0_mse: 0.00704 |  0:09:02s\n",
      "epoch 96 | loss: 0.00939 | val_0_mse: 0.00908 |  0:09:08s\n",
      "epoch 97 | loss: 0.01098 | val_0_mse: 0.00616 |  0:09:14s\n",
      "epoch 98 | loss: 0.01022 | val_0_mse: 0.01567 |  0:09:19s\n",
      "epoch 99 | loss: 0.01039 | val_0_mse: 0.00701 |  0:09:25s\n",
      "epoch 100| loss: 0.01034 | val_0_mse: 0.01073 |  0:09:30s\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 90 and best_val_0_mse = 0.00598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.005770 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.973969 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 5/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=8, n_a=8, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.46678 | val_0_mse: 0.77861 |  0:00:09s\n",
      "epoch 1  | loss: 0.27659 | val_0_mse: 0.22076 |  0:00:18s\n",
      "epoch 2  | loss: 0.15774 | val_0_mse: 0.17799 |  0:00:28s\n",
      "epoch 3  | loss: 0.10047 | val_0_mse: 0.10706 |  0:00:37s\n",
      "epoch 4  | loss: 0.09226 | val_0_mse: 0.10415 |  0:00:47s\n",
      "epoch 5  | loss: 0.07691 | val_0_mse: 0.08849 |  0:00:57s\n",
      "epoch 6  | loss: 0.07903 | val_0_mse: 0.06655 |  0:01:06s\n",
      "epoch 7  | loss: 0.06519 | val_0_mse: 0.0539  |  0:01:16s\n",
      "epoch 8  | loss: 0.06121 | val_0_mse: 0.06193 |  0:01:26s\n",
      "epoch 9  | loss: 0.05608 | val_0_mse: 0.05139 |  0:01:35s\n",
      "epoch 10 | loss: 0.05519 | val_0_mse: 0.05016 |  0:01:44s\n",
      "epoch 11 | loss: 0.05365 | val_0_mse: 0.04511 |  0:01:53s\n",
      "epoch 12 | loss: 0.05236 | val_0_mse: 0.04502 |  0:02:01s\n",
      "epoch 13 | loss: 0.0508  | val_0_mse: 0.04995 |  0:02:10s\n",
      "epoch 14 | loss: 0.05294 | val_0_mse: 0.04789 |  0:02:19s\n",
      "epoch 15 | loss: 0.04955 | val_0_mse: 0.04512 |  0:02:27s\n",
      "epoch 16 | loss: 0.04954 | val_0_mse: 0.04134 |  0:02:36s\n",
      "epoch 17 | loss: 0.04653 | val_0_mse: 0.0419  |  0:02:44s\n",
      "epoch 18 | loss: 0.04303 | val_0_mse: 0.04363 |  0:02:53s\n",
      "epoch 19 | loss: 0.03844 | val_0_mse: 0.03168 |  0:03:02s\n",
      "epoch 20 | loss: 0.03274 | val_0_mse: 0.02392 |  0:03:10s\n",
      "epoch 21 | loss: 0.03131 | val_0_mse: 0.03651 |  0:03:19s\n",
      "epoch 22 | loss: 0.02757 | val_0_mse: 0.02196 |  0:03:28s\n",
      "epoch 23 | loss: 0.02369 | val_0_mse: 0.02294 |  0:03:37s\n",
      "epoch 24 | loss: 0.02275 | val_0_mse: 0.01677 |  0:03:46s\n",
      "epoch 25 | loss: 0.02155 | val_0_mse: 0.01789 |  0:03:56s\n",
      "epoch 26 | loss: 0.02308 | val_0_mse: 0.02545 |  0:04:05s\n",
      "epoch 27 | loss: 0.02926 | val_0_mse: 0.02569 |  0:04:13s\n",
      "epoch 28 | loss: 0.02217 | val_0_mse: 0.02374 |  0:04:21s\n",
      "epoch 29 | loss: 0.02258 | val_0_mse: 0.03692 |  0:04:29s\n",
      "epoch 30 | loss: 0.02089 | val_0_mse: 0.02074 |  0:04:36s\n",
      "epoch 31 | loss: 0.01652 | val_0_mse: 0.0184  |  0:04:44s\n",
      "epoch 32 | loss: 0.0168  | val_0_mse: 0.01798 |  0:04:52s\n",
      "epoch 33 | loss: 0.01746 | val_0_mse: 0.01355 |  0:05:00s\n",
      "epoch 34 | loss: 0.02111 | val_0_mse: 0.03187 |  0:05:08s\n",
      "epoch 35 | loss: 0.01925 | val_0_mse: 0.01499 |  0:05:16s\n",
      "epoch 36 | loss: 0.01747 | val_0_mse: 0.02204 |  0:05:24s\n",
      "epoch 37 | loss: 0.01539 | val_0_mse: 0.01693 |  0:05:33s\n",
      "epoch 38 | loss: 0.01553 | val_0_mse: 0.01011 |  0:05:41s\n",
      "epoch 39 | loss: 0.01426 | val_0_mse: 0.0253  |  0:05:49s\n",
      "epoch 40 | loss: 0.01432 | val_0_mse: 0.02114 |  0:05:57s\n",
      "epoch 41 | loss: 0.01406 | val_0_mse: 0.27572 |  0:06:05s\n",
      "epoch 42 | loss: 0.01746 | val_0_mse: 0.02022 |  0:06:13s\n",
      "epoch 43 | loss: 0.01768 | val_0_mse: 0.0105  |  0:06:22s\n",
      "epoch 44 | loss: 0.01447 | val_0_mse: 0.00979 |  0:06:29s\n",
      "epoch 45 | loss: 0.01124 | val_0_mse: 0.00984 |  0:06:38s\n",
      "epoch 46 | loss: 0.01126 | val_0_mse: 0.01563 |  0:06:46s\n",
      "epoch 47 | loss: 0.01701 | val_0_mse: 0.01158 |  0:06:54s\n",
      "epoch 48 | loss: 0.01224 | val_0_mse: 0.00766 |  0:07:02s\n",
      "epoch 49 | loss: 0.01113 | val_0_mse: 0.01271 |  0:07:10s\n",
      "epoch 50 | loss: 0.0137  | val_0_mse: 0.01409 |  0:07:18s\n",
      "epoch 51 | loss: 0.01172 | val_0_mse: 0.00897 |  0:07:26s\n",
      "epoch 52 | loss: 0.01323 | val_0_mse: 0.00675 |  0:07:34s\n",
      "epoch 53 | loss: 0.01021 | val_0_mse: 0.01001 |  0:07:42s\n",
      "epoch 54 | loss: 0.01084 | val_0_mse: 0.01143 |  0:07:50s\n",
      "epoch 55 | loss: 0.01524 | val_0_mse: 0.0166  |  0:07:58s\n",
      "epoch 56 | loss: 0.00968 | val_0_mse: 0.00818 |  0:08:07s\n",
      "epoch 57 | loss: 0.01144 | val_0_mse: 0.01131 |  0:08:15s\n",
      "epoch 58 | loss: 0.0107  | val_0_mse: 0.0082  |  0:08:23s\n",
      "epoch 59 | loss: 0.0115  | val_0_mse: 0.00678 |  0:08:31s\n",
      "epoch 60 | loss: 0.01029 | val_0_mse: 0.00623 |  0:08:39s\n",
      "epoch 61 | loss: 0.01066 | val_0_mse: 0.00677 |  0:08:47s\n",
      "epoch 62 | loss: 0.01031 | val_0_mse: 0.01588 |  0:08:55s\n",
      "epoch 63 | loss: 0.01105 | val_0_mse: 0.02095 |  0:09:03s\n",
      "epoch 64 | loss: 0.01358 | val_0_mse: 0.01595 |  0:09:11s\n",
      "epoch 65 | loss: 0.01086 | val_0_mse: 0.00671 |  0:09:20s\n",
      "epoch 66 | loss: 0.01624 | val_0_mse: 0.01319 |  0:09:28s\n",
      "epoch 67 | loss: 0.01142 | val_0_mse: 0.01164 |  0:09:36s\n",
      "epoch 68 | loss: 0.00956 | val_0_mse: 0.00767 |  0:09:44s\n",
      "epoch 69 | loss: 0.01118 | val_0_mse: 0.01207 |  0:09:52s\n",
      "epoch 70 | loss: 0.01095 | val_0_mse: 0.01584 |  0:10:00s\n",
      "\n",
      "Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_mse = 0.00623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.005783 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.973912 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 6/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=8, n_a=8, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.4917  | val_0_mse: 0.44106 |  0:00:06s\n",
      "epoch 1  | loss: 0.29315 | val_0_mse: 0.73345 |  0:00:13s\n",
      "epoch 2  | loss: 0.21669 | val_0_mse: 0.16075 |  0:00:20s\n",
      "epoch 3  | loss: 0.15471 | val_0_mse: 0.15562 |  0:00:26s\n",
      "epoch 4  | loss: 0.11877 | val_0_mse: 0.15783 |  0:00:33s\n",
      "epoch 5  | loss: 0.10988 | val_0_mse: 0.15873 |  0:00:39s\n",
      "epoch 6  | loss: 0.1019  | val_0_mse: 0.14407 |  0:00:45s\n",
      "epoch 7  | loss: 0.11371 | val_0_mse: 0.13453 |  0:00:52s\n",
      "epoch 8  | loss: 0.0959  | val_0_mse: 0.10594 |  0:00:58s\n",
      "epoch 9  | loss: 0.08496 | val_0_mse: 0.11047 |  0:01:05s\n",
      "epoch 10 | loss: 0.08091 | val_0_mse: 0.09177 |  0:01:12s\n",
      "epoch 11 | loss: 0.07655 | val_0_mse: 0.07422 |  0:01:18s\n",
      "epoch 12 | loss: 0.06487 | val_0_mse: 0.06082 |  0:01:25s\n",
      "epoch 13 | loss: 0.05781 | val_0_mse: 0.05854 |  0:01:31s\n",
      "epoch 14 | loss: 0.05963 | val_0_mse: 0.05453 |  0:01:38s\n",
      "epoch 15 | loss: 0.05738 | val_0_mse: 0.05373 |  0:01:44s\n",
      "epoch 16 | loss: 0.06319 | val_0_mse: 0.05302 |  0:01:51s\n",
      "epoch 17 | loss: 0.05566 | val_0_mse: 0.05145 |  0:01:57s\n",
      "epoch 18 | loss: 0.05321 | val_0_mse: 0.05272 |  0:02:04s\n",
      "epoch 19 | loss: 0.05871 | val_0_mse: 0.05477 |  0:02:10s\n",
      "epoch 20 | loss: 0.05514 | val_0_mse: 0.0516  |  0:02:17s\n",
      "epoch 21 | loss: 0.05721 | val_0_mse: 0.05224 |  0:02:24s\n",
      "epoch 22 | loss: 0.05285 | val_0_mse: 0.04854 |  0:02:30s\n",
      "epoch 23 | loss: 0.05197 | val_0_mse: 0.04696 |  0:02:37s\n",
      "epoch 24 | loss: 0.05146 | val_0_mse: 0.04544 |  0:02:43s\n",
      "epoch 25 | loss: 0.04833 | val_0_mse: 0.05026 |  0:02:50s\n",
      "epoch 26 | loss: 0.05219 | val_0_mse: 0.05668 |  0:02:56s\n",
      "epoch 27 | loss: 0.05307 | val_0_mse: 0.04369 |  0:03:03s\n",
      "epoch 28 | loss: 0.05055 | val_0_mse: 0.055   |  0:03:10s\n",
      "epoch 29 | loss: 0.05272 | val_0_mse: 0.04732 |  0:03:16s\n",
      "epoch 30 | loss: 0.04942 | val_0_mse: 0.0447  |  0:03:23s\n",
      "epoch 31 | loss: 0.04666 | val_0_mse: 0.04506 |  0:03:29s\n",
      "epoch 32 | loss: 0.04503 | val_0_mse: 0.04042 |  0:03:36s\n",
      "epoch 33 | loss: 0.04394 | val_0_mse: 0.03849 |  0:03:42s\n",
      "epoch 34 | loss: 0.04424 | val_0_mse: 0.04059 |  0:03:49s\n",
      "epoch 35 | loss: 0.04575 | val_0_mse: 0.03917 |  0:03:55s\n",
      "epoch 36 | loss: 0.04669 | val_0_mse: 0.03802 |  0:04:01s\n",
      "epoch 37 | loss: 0.04319 | val_0_mse: 0.03594 |  0:04:08s\n",
      "epoch 38 | loss: 0.04805 | val_0_mse: 0.03749 |  0:04:14s\n",
      "epoch 39 | loss: 0.0418  | val_0_mse: 0.04374 |  0:04:21s\n",
      "epoch 40 | loss: 0.03911 | val_0_mse: 0.03331 |  0:04:27s\n",
      "epoch 41 | loss: 0.03733 | val_0_mse: 0.03482 |  0:04:34s\n",
      "epoch 42 | loss: 0.03713 | val_0_mse: 0.03324 |  0:04:40s\n",
      "epoch 43 | loss: 0.03444 | val_0_mse: 0.03133 |  0:04:47s\n",
      "epoch 44 | loss: 0.03424 | val_0_mse: 0.03141 |  0:04:54s\n",
      "epoch 45 | loss: 0.03322 | val_0_mse: 0.03256 |  0:05:00s\n",
      "epoch 46 | loss: 0.03228 | val_0_mse: 0.03095 |  0:05:07s\n",
      "epoch 47 | loss: 0.03314 | val_0_mse: 0.02899 |  0:05:13s\n",
      "epoch 48 | loss: 0.03127 | val_0_mse: 0.03282 |  0:05:20s\n",
      "epoch 49 | loss: 0.02972 | val_0_mse: 0.03292 |  0:05:26s\n",
      "epoch 50 | loss: 0.03111 | val_0_mse: 0.02982 |  0:05:33s\n",
      "epoch 51 | loss: 0.03514 | val_0_mse: 0.02763 |  0:05:39s\n",
      "epoch 52 | loss: 0.02825 | val_0_mse: 0.02719 |  0:05:46s\n",
      "epoch 53 | loss: 0.02791 | val_0_mse: 0.02729 |  0:05:52s\n",
      "epoch 54 | loss: 0.02646 | val_0_mse: 0.02833 |  0:05:59s\n",
      "epoch 55 | loss: 0.02704 | val_0_mse: 0.02125 |  0:06:05s\n",
      "epoch 56 | loss: 0.02248 | val_0_mse: 0.02137 |  0:06:11s\n",
      "epoch 57 | loss: 0.02381 | val_0_mse: 0.01997 |  0:06:18s\n",
      "epoch 58 | loss: 0.0212  | val_0_mse: 0.02253 |  0:06:25s\n",
      "epoch 59 | loss: 0.01974 | val_0_mse: 0.01541 |  0:06:32s\n",
      "epoch 60 | loss: 0.019   | val_0_mse: 0.03181 |  0:06:38s\n",
      "epoch 61 | loss: 0.02227 | val_0_mse: 0.0157  |  0:06:44s\n",
      "epoch 62 | loss: 0.02197 | val_0_mse: 0.0149  |  0:06:51s\n",
      "epoch 63 | loss: 0.01973 | val_0_mse: 0.01573 |  0:06:57s\n",
      "epoch 64 | loss: 0.01585 | val_0_mse: 0.01243 |  0:07:03s\n",
      "epoch 65 | loss: 0.0174  | val_0_mse: 0.01408 |  0:07:09s\n",
      "epoch 66 | loss: 0.0174  | val_0_mse: 0.01627 |  0:07:16s\n",
      "epoch 67 | loss: 0.01356 | val_0_mse: 0.01234 |  0:07:22s\n",
      "epoch 68 | loss: 0.01598 | val_0_mse: 0.01264 |  0:07:29s\n",
      "epoch 69 | loss: 0.02068 | val_0_mse: 0.01249 |  0:07:35s\n",
      "epoch 70 | loss: 0.01535 | val_0_mse: 0.01312 |  0:07:41s\n",
      "epoch 71 | loss: 0.01515 | val_0_mse: 0.01008 |  0:07:48s\n",
      "epoch 72 | loss: 0.01368 | val_0_mse: 0.01875 |  0:07:54s\n",
      "epoch 73 | loss: 0.01696 | val_0_mse: 0.01004 |  0:08:00s\n",
      "epoch 74 | loss: 0.01569 | val_0_mse: 0.01067 |  0:08:07s\n",
      "epoch 75 | loss: 0.01465 | val_0_mse: 0.01037 |  0:08:13s\n",
      "epoch 76 | loss: 0.01201 | val_0_mse: 0.01086 |  0:08:20s\n",
      "epoch 77 | loss: 0.01132 | val_0_mse: 0.00839 |  0:08:26s\n",
      "epoch 78 | loss: 0.0137  | val_0_mse: 0.01564 |  0:08:32s\n",
      "epoch 79 | loss: 0.01591 | val_0_mse: 0.00957 |  0:08:39s\n",
      "epoch 80 | loss: 0.0139  | val_0_mse: 0.01294 |  0:08:45s\n",
      "epoch 81 | loss: 0.01359 | val_0_mse: 0.00873 |  0:08:51s\n",
      "epoch 82 | loss: 0.01139 | val_0_mse: 0.0083  |  0:08:58s\n",
      "epoch 83 | loss: 0.01219 | val_0_mse: 0.0082  |  0:09:04s\n",
      "epoch 84 | loss: 0.01088 | val_0_mse: 0.00788 |  0:09:11s\n",
      "epoch 85 | loss: 0.01027 | val_0_mse: 0.00811 |  0:09:17s\n",
      "epoch 86 | loss: 0.01229 | val_0_mse: 0.01532 |  0:09:24s\n",
      "epoch 87 | loss: 0.01546 | val_0_mse: 0.00702 |  0:09:30s\n",
      "epoch 88 | loss: 0.01266 | val_0_mse: 0.00733 |  0:09:37s\n",
      "epoch 89 | loss: 0.01007 | val_0_mse: 0.00722 |  0:09:43s\n",
      "epoch 90 | loss: 0.01009 | val_0_mse: 0.00833 |  0:09:50s\n",
      "epoch 91 | loss: 0.01446 | val_0_mse: 0.01437 |  0:09:56s\n",
      "epoch 92 | loss: 0.01966 | val_0_mse: 0.0122  |  0:10:03s\n",
      "epoch 93 | loss: 0.01232 | val_0_mse: 0.00913 |  0:10:09s\n",
      "epoch 94 | loss: 0.01237 | val_0_mse: 0.01419 |  0:10:16s\n",
      "epoch 95 | loss: 0.01017 | val_0_mse: 0.00665 |  0:10:22s\n",
      "epoch 96 | loss: 0.01137 | val_0_mse: 0.00699 |  0:10:29s\n",
      "epoch 97 | loss: 0.01472 | val_0_mse: 0.01763 |  0:10:35s\n",
      "epoch 98 | loss: 0.01116 | val_0_mse: 0.0092  |  0:10:41s\n",
      "epoch 99 | loss: 0.01068 | val_0_mse: 0.00971 |  0:10:48s\n",
      "epoch 100| loss: 0.00855 | val_0_mse: 0.00779 |  0:10:54s\n",
      "epoch 101| loss: 0.01023 | val_0_mse: 0.00799 |  0:11:01s\n",
      "epoch 102| loss: 0.01087 | val_0_mse: 0.00682 |  0:11:07s\n",
      "epoch 103| loss: 0.01    | val_0_mse: 0.00933 |  0:11:13s\n",
      "epoch 104| loss: 0.00986 | val_0_mse: 0.00602 |  0:11:20s\n",
      "epoch 105| loss: 0.01059 | val_0_mse: 0.01054 |  0:11:26s\n",
      "epoch 106| loss: 0.01222 | val_0_mse: 0.00726 |  0:11:33s\n",
      "epoch 107| loss: 0.01282 | val_0_mse: 0.01354 |  0:11:39s\n",
      "epoch 108| loss: 0.0118  | val_0_mse: 0.00712 |  0:11:46s\n",
      "epoch 109| loss: 0.01084 | val_0_mse: 0.01094 |  0:11:52s\n",
      "epoch 110| loss: 0.00949 | val_0_mse: 0.00717 |  0:11:59s\n",
      "epoch 111| loss: 0.00854 | val_0_mse: 0.00862 |  0:12:05s\n",
      "epoch 112| loss: 0.00986 | val_0_mse: 0.0063  |  0:12:12s\n",
      "epoch 113| loss: 0.00867 | val_0_mse: 0.00777 |  0:12:18s\n",
      "epoch 114| loss: 0.01126 | val_0_mse: 0.00618 |  0:12:25s\n",
      "\n",
      "Early stopping occurred at epoch 114 with best_epoch = 104 and best_val_0_mse = 0.00602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006256 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.971777 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 7/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=8, n_a=8, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.92396 | val_0_mse: 0.73891 |  0:00:09s\n",
      "epoch 1  | loss: 0.19623 | val_0_mse: 0.41795 |  0:00:19s\n",
      "epoch 2  | loss: 0.14545 | val_0_mse: 0.16439 |  0:00:29s\n",
      "epoch 3  | loss: 0.11865 | val_0_mse: 0.18012 |  0:00:40s\n",
      "epoch 4  | loss: 0.10901 | val_0_mse: 0.21808 |  0:00:50s\n",
      "epoch 5  | loss: 0.09602 | val_0_mse: 0.0849  |  0:01:00s\n",
      "epoch 6  | loss: 0.08609 | val_0_mse: 0.07631 |  0:01:10s\n",
      "epoch 7  | loss: 0.07463 | val_0_mse: 0.06899 |  0:01:20s\n",
      "epoch 8  | loss: 0.06195 | val_0_mse: 0.04087 |  0:01:30s\n",
      "epoch 9  | loss: 0.05108 | val_0_mse: 0.05241 |  0:01:39s\n",
      "epoch 10 | loss: 0.03908 | val_0_mse: 0.06567 |  0:01:49s\n",
      "epoch 11 | loss: 0.03703 | val_0_mse: 0.03758 |  0:01:59s\n",
      "epoch 12 | loss: 0.03131 | val_0_mse: 0.02691 |  0:02:09s\n",
      "epoch 13 | loss: 0.03263 | val_0_mse: 0.0224  |  0:02:19s\n",
      "epoch 14 | loss: 0.02788 | val_0_mse: 0.02248 |  0:02:29s\n",
      "epoch 15 | loss: 0.03211 | val_0_mse: 0.01755 |  0:02:38s\n",
      "epoch 16 | loss: 0.02403 | val_0_mse: 0.01615 |  0:02:48s\n",
      "epoch 17 | loss: 0.02229 | val_0_mse: 0.01355 |  0:02:58s\n",
      "epoch 18 | loss: 0.0185  | val_0_mse: 0.02275 |  0:03:08s\n",
      "epoch 19 | loss: 0.01951 | val_0_mse: 0.0115  |  0:03:18s\n",
      "epoch 20 | loss: 0.01948 | val_0_mse: 0.01744 |  0:03:27s\n",
      "epoch 21 | loss: 0.01617 | val_0_mse: 0.02105 |  0:03:37s\n",
      "epoch 22 | loss: 0.02502 | val_0_mse: 0.0301  |  0:03:47s\n",
      "epoch 23 | loss: 0.01953 | val_0_mse: 0.01774 |  0:03:57s\n",
      "epoch 24 | loss: 0.01701 | val_0_mse: 0.011   |  0:04:08s\n",
      "epoch 25 | loss: 0.0144  | val_0_mse: 0.03005 |  0:04:18s\n",
      "epoch 26 | loss: 0.01282 | val_0_mse: 0.00964 |  0:04:28s\n",
      "epoch 27 | loss: 0.01195 | val_0_mse: 0.01425 |  0:04:39s\n",
      "epoch 28 | loss: 0.01343 | val_0_mse: 0.01585 |  0:04:47s\n",
      "epoch 29 | loss: 0.01339 | val_0_mse: 0.01062 |  0:04:56s\n",
      "epoch 30 | loss: 0.01405 | val_0_mse: 0.0186  |  0:05:05s\n",
      "epoch 31 | loss: 0.01069 | val_0_mse: 0.01359 |  0:05:14s\n",
      "epoch 32 | loss: 0.01212 | val_0_mse: 0.02675 |  0:05:23s\n",
      "epoch 33 | loss: 0.01369 | val_0_mse: 0.04684 |  0:05:31s\n",
      "epoch 34 | loss: 0.01352 | val_0_mse: 0.00988 |  0:05:40s\n",
      "epoch 35 | loss: 0.01455 | val_0_mse: 0.01998 |  0:05:48s\n",
      "epoch 36 | loss: 0.01175 | val_0_mse: 0.02758 |  0:05:57s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_mse = 0.00964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009038 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.959229 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 8/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=8, n_a=8, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.48214 | val_0_mse: 0.39674 |  0:00:07s\n",
      "epoch 1  | loss: 0.31995 | val_0_mse: 0.29996 |  0:00:14s\n",
      "epoch 2  | loss: 0.16912 | val_0_mse: 0.20333 |  0:00:21s\n",
      "epoch 3  | loss: 0.1341  | val_0_mse: 0.1887  |  0:00:28s\n",
      "epoch 4  | loss: 0.1014  | val_0_mse: 0.12784 |  0:00:35s\n",
      "epoch 5  | loss: 0.08997 | val_0_mse: 0.13016 |  0:00:42s\n",
      "epoch 6  | loss: 0.06518 | val_0_mse: 0.11472 |  0:00:49s\n",
      "epoch 7  | loss: 0.05949 | val_0_mse: 0.11091 |  0:00:56s\n",
      "epoch 8  | loss: 0.05733 | val_0_mse: 0.11022 |  0:01:03s\n",
      "epoch 9  | loss: 0.05861 | val_0_mse: 0.08109 |  0:01:10s\n",
      "epoch 10 | loss: 0.0497  | val_0_mse: 0.06532 |  0:01:17s\n",
      "epoch 11 | loss: 0.05449 | val_0_mse: 0.05014 |  0:01:24s\n",
      "epoch 12 | loss: 0.06265 | val_0_mse: 0.05654 |  0:01:31s\n",
      "epoch 13 | loss: 0.05804 | val_0_mse: 0.0479  |  0:01:38s\n",
      "epoch 14 | loss: 0.0545  | val_0_mse: 0.04369 |  0:01:45s\n",
      "epoch 15 | loss: 0.05169 | val_0_mse: 0.06391 |  0:01:52s\n",
      "epoch 16 | loss: 0.04793 | val_0_mse: 0.0351  |  0:01:59s\n",
      "epoch 17 | loss: 0.0424  | val_0_mse: 0.04234 |  0:02:06s\n",
      "epoch 18 | loss: 0.04456 | val_0_mse: 0.0414  |  0:02:13s\n",
      "epoch 19 | loss: 0.04152 | val_0_mse: 0.03256 |  0:02:19s\n",
      "epoch 20 | loss: 0.04201 | val_0_mse: 0.02922 |  0:02:26s\n",
      "epoch 21 | loss: 0.03404 | val_0_mse: 0.02758 |  0:02:33s\n",
      "epoch 22 | loss: 0.03226 | val_0_mse: 0.02556 |  0:02:40s\n",
      "epoch 23 | loss: 0.02834 | val_0_mse: 0.022   |  0:02:46s\n",
      "epoch 24 | loss: 0.03643 | val_0_mse: 0.0259  |  0:02:53s\n",
      "epoch 25 | loss: 0.03393 | val_0_mse: 0.04273 |  0:03:00s\n",
      "epoch 26 | loss: 0.03003 | val_0_mse: 0.01846 |  0:03:07s\n",
      "epoch 27 | loss: 0.02437 | val_0_mse: 0.01791 |  0:03:14s\n",
      "epoch 28 | loss: 0.0229  | val_0_mse: 0.01604 |  0:03:21s\n",
      "epoch 29 | loss: 0.02196 | val_0_mse: 0.01606 |  0:03:28s\n",
      "epoch 30 | loss: 0.0225  | val_0_mse: 0.0137  |  0:03:35s\n",
      "epoch 31 | loss: 0.01841 | val_0_mse: 0.02508 |  0:03:42s\n",
      "epoch 32 | loss: 0.02687 | val_0_mse: 0.01218 |  0:03:49s\n",
      "epoch 33 | loss: 0.01719 | val_0_mse: 0.0116  |  0:03:56s\n",
      "epoch 34 | loss: 0.01617 | val_0_mse: 0.01105 |  0:04:03s\n",
      "epoch 35 | loss: 0.01701 | val_0_mse: 0.01199 |  0:04:10s\n",
      "epoch 36 | loss: 0.01661 | val_0_mse: 0.01012 |  0:04:17s\n",
      "epoch 37 | loss: 0.02091 | val_0_mse: 0.04556 |  0:04:24s\n",
      "epoch 38 | loss: 0.01901 | val_0_mse: 0.01619 |  0:04:31s\n",
      "epoch 39 | loss: 0.0182  | val_0_mse: 0.0148  |  0:04:38s\n",
      "epoch 40 | loss: 0.0166  | val_0_mse: 0.01569 |  0:04:45s\n",
      "epoch 41 | loss: 0.0235  | val_0_mse: 0.01548 |  0:04:52s\n",
      "epoch 42 | loss: 0.02362 | val_0_mse: 0.02823 |  0:04:59s\n",
      "epoch 43 | loss: 0.01929 | val_0_mse: 0.0109  |  0:05:06s\n",
      "epoch 44 | loss: 0.01525 | val_0_mse: 0.00966 |  0:05:13s\n",
      "epoch 45 | loss: 0.01686 | val_0_mse: 0.01748 |  0:05:20s\n",
      "epoch 46 | loss: 0.01517 | val_0_mse: 0.01087 |  0:05:27s\n",
      "epoch 47 | loss: 0.01388 | val_0_mse: 0.01475 |  0:05:34s\n",
      "epoch 48 | loss: 0.01317 | val_0_mse: 0.01111 |  0:05:41s\n",
      "epoch 49 | loss: 0.0124  | val_0_mse: 0.01015 |  0:05:48s\n",
      "epoch 50 | loss: 0.0124  | val_0_mse: 0.01007 |  0:05:55s\n",
      "epoch 51 | loss: 0.01268 | val_0_mse: 0.00905 |  0:06:02s\n",
      "epoch 52 | loss: 0.01228 | val_0_mse: 0.00697 |  0:06:09s\n",
      "epoch 53 | loss: 0.0117  | val_0_mse: 0.0075  |  0:06:16s\n",
      "epoch 54 | loss: 0.01278 | val_0_mse: 0.01455 |  0:06:23s\n",
      "epoch 55 | loss: 0.01036 | val_0_mse: 0.01726 |  0:06:30s\n",
      "epoch 56 | loss: 0.01133 | val_0_mse: 0.00849 |  0:06:37s\n",
      "epoch 57 | loss: 0.0136  | val_0_mse: 0.0077  |  0:06:44s\n",
      "epoch 58 | loss: 0.0108  | val_0_mse: 0.00778 |  0:06:51s\n",
      "epoch 59 | loss: 0.00994 | val_0_mse: 0.0107  |  0:06:58s\n",
      "epoch 60 | loss: 0.01129 | val_0_mse: 0.0067  |  0:07:05s\n",
      "epoch 61 | loss: 0.01205 | val_0_mse: 0.01153 |  0:07:12s\n",
      "epoch 62 | loss: 0.01375 | val_0_mse: 0.01077 |  0:07:19s\n",
      "epoch 63 | loss: 0.01044 | val_0_mse: 0.01267 |  0:07:26s\n",
      "epoch 64 | loss: 0.0131  | val_0_mse: 0.0115  |  0:07:33s\n",
      "epoch 65 | loss: 0.01235 | val_0_mse: 0.00685 |  0:07:40s\n",
      "epoch 66 | loss: 0.01135 | val_0_mse: 0.00789 |  0:07:47s\n",
      "epoch 67 | loss: 0.0117  | val_0_mse: 0.01207 |  0:07:54s\n",
      "epoch 68 | loss: 0.01157 | val_0_mse: 0.0097  |  0:08:01s\n",
      "epoch 69 | loss: 0.01077 | val_0_mse: 0.00687 |  0:08:08s\n",
      "epoch 70 | loss: 0.0119  | val_0_mse: 0.01068 |  0:08:15s\n",
      "\n",
      "Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_mse = 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006413 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.971067 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 9/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=8, n_a=8, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.71037 | val_0_mse: 0.37258 |  0:00:11s\n",
      "epoch 1  | loss: 0.31865 | val_0_mse: 0.1774  |  0:00:20s\n",
      "epoch 2  | loss: 0.16281 | val_0_mse: 0.16241 |  0:00:29s\n",
      "epoch 3  | loss: 0.12551 | val_0_mse: 0.10818 |  0:00:39s\n",
      "epoch 4  | loss: 0.10098 | val_0_mse: 0.07629 |  0:00:48s\n",
      "epoch 5  | loss: 0.09212 | val_0_mse: 0.10025 |  0:00:58s\n",
      "epoch 6  | loss: 0.08516 | val_0_mse: 0.08217 |  0:01:08s\n",
      "epoch 7  | loss: 0.10052 | val_0_mse: 0.0826  |  0:01:18s\n",
      "epoch 8  | loss: 0.07561 | val_0_mse: 0.06777 |  0:01:27s\n",
      "epoch 9  | loss: 0.06375 | val_0_mse: 0.0683  |  0:01:37s\n",
      "epoch 10 | loss: 0.05256 | val_0_mse: 0.06131 |  0:01:46s\n",
      "epoch 11 | loss: 0.04476 | val_0_mse: 0.03905 |  0:01:56s\n",
      "epoch 12 | loss: 0.04683 | val_0_mse: 0.06246 |  0:02:05s\n",
      "epoch 13 | loss: 0.04339 | val_0_mse: 0.04472 |  0:02:14s\n",
      "epoch 14 | loss: 0.0372  | val_0_mse: 0.03312 |  0:02:25s\n",
      "epoch 15 | loss: 0.03244 | val_0_mse: 0.0405  |  0:02:34s\n",
      "epoch 16 | loss: 0.0317  | val_0_mse: 0.04289 |  0:02:42s\n",
      "epoch 17 | loss: 0.03671 | val_0_mse: 0.04372 |  0:02:52s\n",
      "epoch 18 | loss: 0.0274  | val_0_mse: 0.06858 |  0:03:02s\n",
      "epoch 19 | loss: 0.02628 | val_0_mse: 0.02547 |  0:03:11s\n",
      "epoch 20 | loss: 0.02353 | val_0_mse: 0.03673 |  0:03:20s\n",
      "epoch 21 | loss: 0.02995 | val_0_mse: 0.04402 |  0:03:28s\n",
      "epoch 22 | loss: 0.03279 | val_0_mse: 0.02484 |  0:03:37s\n",
      "epoch 23 | loss: 0.02772 | val_0_mse: 0.02365 |  0:03:46s\n",
      "epoch 24 | loss: 0.02474 | val_0_mse: 0.02355 |  0:03:55s\n",
      "epoch 25 | loss: 0.0216  | val_0_mse: 0.01879 |  0:04:04s\n",
      "epoch 26 | loss: 0.02171 | val_0_mse: 0.01784 |  0:04:12s\n",
      "epoch 27 | loss: 0.02417 | val_0_mse: 0.04826 |  0:04:21s\n",
      "epoch 28 | loss: 0.02438 | val_0_mse: 0.01516 |  0:04:30s\n",
      "epoch 29 | loss: 0.01784 | val_0_mse: 0.00992 |  0:04:39s\n",
      "epoch 30 | loss: 0.02288 | val_0_mse: 0.01509 |  0:04:48s\n",
      "epoch 31 | loss: 0.02023 | val_0_mse: 0.01867 |  0:04:58s\n",
      "epoch 32 | loss: 0.01534 | val_0_mse: 0.02922 |  0:05:06s\n",
      "epoch 33 | loss: 0.02038 | val_0_mse: 0.02375 |  0:05:15s\n",
      "epoch 34 | loss: 0.02825 | val_0_mse: 0.01954 |  0:05:24s\n",
      "epoch 35 | loss: 0.01987 | val_0_mse: 0.01324 |  0:05:33s\n",
      "epoch 36 | loss: 0.01669 | val_0_mse: 0.01307 |  0:05:42s\n",
      "epoch 37 | loss: 0.01568 | val_0_mse: 0.00856 |  0:05:51s\n",
      "epoch 38 | loss: 0.0185  | val_0_mse: 0.01517 |  0:06:00s\n",
      "epoch 39 | loss: 0.02054 | val_0_mse: 0.02657 |  0:06:08s\n",
      "epoch 40 | loss: 0.01425 | val_0_mse: 0.01076 |  0:06:17s\n",
      "epoch 41 | loss: 0.01932 | val_0_mse: 0.03457 |  0:06:26s\n",
      "epoch 42 | loss: 0.02387 | val_0_mse: 0.01721 |  0:06:34s\n",
      "epoch 43 | loss: 0.01919 | val_0_mse: 0.02119 |  0:06:43s\n",
      "epoch 44 | loss: 0.01378 | val_0_mse: 0.07089 |  0:06:52s\n",
      "epoch 45 | loss: 0.02135 | val_0_mse: 0.01718 |  0:07:01s\n",
      "epoch 46 | loss: 0.01498 | val_0_mse: 0.00929 |  0:07:09s\n",
      "epoch 47 | loss: 0.01165 | val_0_mse: 0.01009 |  0:07:18s\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_mse = 0.00856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008624 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.961095 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 10/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=8, n_a=8, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.3312  | val_0_mse: 1.01002 |  0:00:07s\n",
      "epoch 1  | loss: 0.31113 | val_0_mse: 0.2601  |  0:00:15s\n",
      "epoch 2  | loss: 0.30194 | val_0_mse: 0.16121 |  0:00:22s\n",
      "epoch 3  | loss: 0.1411  | val_0_mse: 0.18273 |  0:00:29s\n",
      "epoch 4  | loss: 0.12709 | val_0_mse: 0.16318 |  0:00:36s\n",
      "epoch 5  | loss: 0.09461 | val_0_mse: 0.15327 |  0:00:43s\n",
      "epoch 6  | loss: 0.07974 | val_0_mse: 0.14108 |  0:00:50s\n",
      "epoch 7  | loss: 0.07398 | val_0_mse: 0.09531 |  0:00:57s\n",
      "epoch 8  | loss: 0.0916  | val_0_mse: 0.08794 |  0:01:04s\n",
      "epoch 9  | loss: 0.07438 | val_0_mse: 0.06902 |  0:01:11s\n",
      "epoch 10 | loss: 0.07647 | val_0_mse: 0.08688 |  0:01:18s\n",
      "epoch 11 | loss: 0.06998 | val_0_mse: 0.07048 |  0:01:25s\n",
      "epoch 12 | loss: 0.06653 | val_0_mse: 0.06822 |  0:01:33s\n",
      "epoch 13 | loss: 0.07046 | val_0_mse: 0.06524 |  0:01:40s\n",
      "epoch 14 | loss: 0.10085 | val_0_mse: 0.07853 |  0:01:46s\n",
      "epoch 15 | loss: 0.08826 | val_0_mse: 0.05935 |  0:01:53s\n",
      "epoch 16 | loss: 0.0646  | val_0_mse: 0.05991 |  0:01:59s\n",
      "epoch 17 | loss: 0.06672 | val_0_mse: 0.06955 |  0:02:04s\n",
      "epoch 18 | loss: 0.06742 | val_0_mse: 0.05839 |  0:02:11s\n",
      "epoch 19 | loss: 0.0616  | val_0_mse: 0.05505 |  0:02:17s\n",
      "epoch 20 | loss: 0.05349 | val_0_mse: 0.04892 |  0:02:22s\n",
      "epoch 21 | loss: 0.05301 | val_0_mse: 0.04473 |  0:02:30s\n",
      "epoch 22 | loss: 0.05312 | val_0_mse: 0.05886 |  0:02:36s\n",
      "epoch 23 | loss: 0.0584  | val_0_mse: 0.05226 |  0:02:42s\n",
      "epoch 24 | loss: 0.05336 | val_0_mse: 0.04648 |  0:02:50s\n",
      "epoch 25 | loss: 0.04879 | val_0_mse: 0.04222 |  0:02:56s\n",
      "epoch 26 | loss: 0.04511 | val_0_mse: 0.05505 |  0:03:02s\n",
      "epoch 27 | loss: 0.0431  | val_0_mse: 0.04389 |  0:03:08s\n",
      "epoch 28 | loss: 0.04515 | val_0_mse: 0.05832 |  0:03:14s\n",
      "epoch 29 | loss: 0.05274 | val_0_mse: 0.03652 |  0:03:21s\n",
      "epoch 30 | loss: 0.04146 | val_0_mse: 0.03178 |  0:03:27s\n",
      "epoch 31 | loss: 0.04029 | val_0_mse: 0.03459 |  0:03:34s\n",
      "epoch 32 | loss: 0.03972 | val_0_mse: 0.03337 |  0:03:40s\n",
      "epoch 33 | loss: 0.04043 | val_0_mse: 0.04405 |  0:03:46s\n",
      "epoch 34 | loss: 0.03867 | val_0_mse: 0.0404  |  0:03:53s\n",
      "epoch 35 | loss: 0.03396 | val_0_mse: 0.02803 |  0:04:00s\n",
      "epoch 36 | loss: 0.0331  | val_0_mse: 0.0263  |  0:04:06s\n",
      "epoch 37 | loss: 0.03552 | val_0_mse: 0.03187 |  0:04:12s\n",
      "epoch 38 | loss: 0.03232 | val_0_mse: 0.03259 |  0:04:19s\n",
      "epoch 39 | loss: 0.03116 | val_0_mse: 0.03281 |  0:04:25s\n",
      "epoch 40 | loss: 0.03165 | val_0_mse: 0.02609 |  0:04:32s\n",
      "epoch 41 | loss: 0.02758 | val_0_mse: 0.02464 |  0:04:38s\n",
      "epoch 42 | loss: 0.02645 | val_0_mse: 0.02118 |  0:04:45s\n",
      "epoch 43 | loss: 0.02918 | val_0_mse: 0.02942 |  0:04:51s\n",
      "epoch 44 | loss: 0.02744 | val_0_mse: 0.03567 |  0:04:58s\n",
      "epoch 45 | loss: 0.03879 | val_0_mse: 0.08395 |  0:05:04s\n",
      "epoch 46 | loss: 0.03387 | val_0_mse: 0.01862 |  0:05:10s\n",
      "epoch 47 | loss: 0.02379 | val_0_mse: 0.0352  |  0:05:17s\n",
      "epoch 48 | loss: 0.02809 | val_0_mse: 0.02461 |  0:05:23s\n",
      "epoch 49 | loss: 0.03562 | val_0_mse: 0.02023 |  0:05:29s\n",
      "epoch 50 | loss: 0.02424 | val_0_mse: 0.02039 |  0:05:35s\n",
      "epoch 51 | loss: 0.02308 | val_0_mse: 0.02593 |  0:05:42s\n",
      "epoch 52 | loss: 0.02483 | val_0_mse: 0.01782 |  0:05:48s\n",
      "epoch 53 | loss: 0.02204 | val_0_mse: 0.01609 |  0:05:54s\n",
      "epoch 54 | loss: 0.02173 | val_0_mse: 0.01492 |  0:06:01s\n",
      "epoch 55 | loss: 0.02108 | val_0_mse: 0.03046 |  0:06:07s\n",
      "epoch 56 | loss: 0.01978 | val_0_mse: 0.01825 |  0:06:13s\n",
      "epoch 57 | loss: 0.01834 | val_0_mse: 0.02057 |  0:06:20s\n",
      "epoch 58 | loss: 0.02101 | val_0_mse: 0.01498 |  0:06:26s\n",
      "epoch 59 | loss: 0.01549 | val_0_mse: 0.01446 |  0:06:32s\n",
      "epoch 60 | loss: 0.01669 | val_0_mse: 0.01181 |  0:06:39s\n",
      "epoch 61 | loss: 0.01481 | val_0_mse: 0.01666 |  0:06:45s\n",
      "epoch 62 | loss: 0.01928 | val_0_mse: 0.01331 |  0:06:51s\n",
      "epoch 63 | loss: 0.0162  | val_0_mse: 0.01084 |  0:06:58s\n",
      "epoch 64 | loss: 0.01473 | val_0_mse: 0.0145  |  0:07:04s\n",
      "epoch 65 | loss: 0.01472 | val_0_mse: 0.014   |  0:07:10s\n",
      "epoch 66 | loss: 0.01396 | val_0_mse: 0.0113  |  0:07:17s\n",
      "epoch 67 | loss: 0.01385 | val_0_mse: 0.01951 |  0:07:23s\n",
      "epoch 68 | loss: 0.01821 | val_0_mse: 0.00963 |  0:07:30s\n",
      "epoch 69 | loss: 0.01228 | val_0_mse: 0.01065 |  0:07:36s\n",
      "epoch 70 | loss: 0.01367 | val_0_mse: 0.01137 |  0:07:42s\n",
      "epoch 71 | loss: 0.01414 | val_0_mse: 0.01208 |  0:07:49s\n",
      "epoch 72 | loss: 0.01354 | val_0_mse: 0.03225 |  0:07:55s\n",
      "epoch 73 | loss: 0.02657 | val_0_mse: 0.03971 |  0:08:01s\n",
      "epoch 74 | loss: 0.02559 | val_0_mse: 0.02015 |  0:08:08s\n",
      "epoch 75 | loss: 0.01963 | val_0_mse: 0.01335 |  0:08:14s\n",
      "epoch 76 | loss: 0.01776 | val_0_mse: 0.01346 |  0:08:20s\n",
      "epoch 77 | loss: 0.01538 | val_0_mse: 0.01862 |  0:08:27s\n",
      "epoch 78 | loss: 0.01591 | val_0_mse: 0.02409 |  0:08:33s\n",
      "\n",
      "Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_mse = 0.00963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009703 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.956225 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 11/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=8, n_a=8, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.29779 | val_0_mse: 0.50563 |  0:00:10s\n",
      "epoch 1  | loss: 0.42354 | val_0_mse: 0.68005 |  0:00:20s\n",
      "epoch 2  | loss: 0.15318 | val_0_mse: 0.09087 |  0:00:30s\n",
      "epoch 3  | loss: 0.10367 | val_0_mse: 0.11574 |  0:00:40s\n",
      "epoch 4  | loss: 0.08959 | val_0_mse: 0.07137 |  0:00:50s\n",
      "epoch 5  | loss: 0.07481 | val_0_mse: 0.06707 |  0:01:00s\n",
      "epoch 6  | loss: 0.06668 | val_0_mse: 0.05975 |  0:01:13s\n",
      "epoch 7  | loss: 0.0617  | val_0_mse: 0.05297 |  0:01:23s\n",
      "epoch 8  | loss: 0.05341 | val_0_mse: 0.04237 |  0:01:33s\n",
      "epoch 9  | loss: 0.04852 | val_0_mse: 0.0486  |  0:01:42s\n",
      "epoch 10 | loss: 0.05204 | val_0_mse: 0.04638 |  0:01:51s\n",
      "epoch 11 | loss: 0.04186 | val_0_mse: 0.04272 |  0:02:00s\n",
      "epoch 12 | loss: 0.04508 | val_0_mse: 0.10752 |  0:02:09s\n",
      "epoch 13 | loss: 0.04096 | val_0_mse: 0.03637 |  0:02:18s\n",
      "epoch 14 | loss: 0.03677 | val_0_mse: 0.03594 |  0:02:27s\n",
      "epoch 15 | loss: 0.03694 | val_0_mse: 0.0328  |  0:02:37s\n",
      "epoch 16 | loss: 0.03209 | val_0_mse: 0.02585 |  0:02:46s\n",
      "epoch 17 | loss: 0.03154 | val_0_mse: 0.03981 |  0:02:55s\n",
      "epoch 18 | loss: 0.03404 | val_0_mse: 0.02973 |  0:03:04s\n",
      "epoch 19 | loss: 0.03141 | val_0_mse: 0.02205 |  0:03:14s\n",
      "epoch 20 | loss: 0.02677 | val_0_mse: 0.02517 |  0:03:23s\n",
      "epoch 21 | loss: 0.02626 | val_0_mse: 0.01674 |  0:03:33s\n",
      "epoch 22 | loss: 0.02043 | val_0_mse: 0.02971 |  0:03:42s\n",
      "epoch 23 | loss: 0.02261 | val_0_mse: 0.01869 |  0:03:51s\n",
      "epoch 24 | loss: 0.01858 | val_0_mse: 0.01594 |  0:04:00s\n",
      "epoch 25 | loss: 0.01992 | val_0_mse: 0.02718 |  0:04:09s\n",
      "epoch 26 | loss: 0.02789 | val_0_mse: 0.04496 |  0:04:17s\n",
      "epoch 27 | loss: 0.02115 | val_0_mse: 0.02226 |  0:04:27s\n",
      "epoch 28 | loss: 0.01646 | val_0_mse: 0.01316 |  0:04:36s\n",
      "epoch 29 | loss: 0.01623 | val_0_mse: 0.01326 |  0:04:46s\n",
      "epoch 30 | loss: 0.01567 | val_0_mse: 0.01181 |  0:04:55s\n",
      "epoch 31 | loss: 0.01366 | val_0_mse: 0.01705 |  0:05:04s\n",
      "epoch 32 | loss: 0.01434 | val_0_mse: 0.01249 |  0:05:13s\n",
      "epoch 33 | loss: 0.01306 | val_0_mse: 0.02695 |  0:05:22s\n",
      "epoch 34 | loss: 0.01294 | val_0_mse: 0.01179 |  0:05:31s\n",
      "epoch 35 | loss: 0.01146 | val_0_mse: 0.00889 |  0:05:40s\n",
      "epoch 36 | loss: 0.01591 | val_0_mse: 0.05881 |  0:05:49s\n",
      "epoch 37 | loss: 0.01614 | val_0_mse: 0.02501 |  0:05:59s\n",
      "epoch 38 | loss: 0.01763 | val_0_mse: 0.01666 |  0:06:08s\n",
      "epoch 39 | loss: 0.01332 | val_0_mse: 0.01126 |  0:06:17s\n",
      "epoch 40 | loss: 0.0135  | val_0_mse: 0.01618 |  0:06:26s\n",
      "epoch 41 | loss: 0.01354 | val_0_mse: 0.01769 |  0:06:35s\n",
      "epoch 42 | loss: 0.01299 | val_0_mse: 0.00992 |  0:06:44s\n",
      "epoch 43 | loss: 0.01077 | val_0_mse: 0.00941 |  0:06:54s\n",
      "epoch 44 | loss: 0.01141 | val_0_mse: 0.01009 |  0:07:03s\n",
      "epoch 45 | loss: 0.01629 | val_0_mse: 0.00917 |  0:07:13s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_mse = 0.00889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008320 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.962464 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 12/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=8, n_a=8, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.84252 | val_0_mse: 0.49301 |  0:00:07s\n",
      "epoch 1  | loss: 0.40884 | val_0_mse: 0.21456 |  0:00:14s\n",
      "epoch 2  | loss: 0.31873 | val_0_mse: 0.4452  |  0:00:21s\n",
      "epoch 3  | loss: 0.29657 | val_0_mse: 0.13157 |  0:00:28s\n",
      "epoch 4  | loss: 0.15408 | val_0_mse: 0.14604 |  0:00:34s\n",
      "epoch 5  | loss: 0.13143 | val_0_mse: 0.11162 |  0:00:41s\n",
      "epoch 6  | loss: 0.11034 | val_0_mse: 0.12123 |  0:00:47s\n",
      "epoch 7  | loss: 0.12806 | val_0_mse: 0.10083 |  0:00:54s\n",
      "epoch 8  | loss: 0.12294 | val_0_mse: 0.1633  |  0:01:01s\n",
      "epoch 9  | loss: 0.10245 | val_0_mse: 0.08729 |  0:01:07s\n",
      "epoch 10 | loss: 0.08766 | val_0_mse: 0.06998 |  0:01:15s\n",
      "epoch 11 | loss: 0.07465 | val_0_mse: 0.07234 |  0:01:21s\n",
      "epoch 12 | loss: 0.06837 | val_0_mse: 0.07469 |  0:01:28s\n",
      "epoch 13 | loss: 0.07023 | val_0_mse: 0.07299 |  0:01:35s\n",
      "epoch 14 | loss: 0.06397 | val_0_mse: 0.06207 |  0:01:41s\n",
      "epoch 15 | loss: 0.0618  | val_0_mse: 0.05671 |  0:01:49s\n",
      "epoch 16 | loss: 0.06206 | val_0_mse: 0.06261 |  0:01:57s\n",
      "epoch 17 | loss: 0.0672  | val_0_mse: 0.06322 |  0:02:04s\n",
      "epoch 18 | loss: 0.07363 | val_0_mse: 0.05984 |  0:02:11s\n",
      "epoch 19 | loss: 0.06848 | val_0_mse: 0.06088 |  0:02:19s\n",
      "epoch 20 | loss: 0.06274 | val_0_mse: 0.05697 |  0:02:26s\n",
      "epoch 21 | loss: 0.06289 | val_0_mse: 0.05295 |  0:02:33s\n",
      "epoch 22 | loss: 0.0593  | val_0_mse: 0.05389 |  0:02:41s\n",
      "epoch 23 | loss: 0.06001 | val_0_mse: 0.05712 |  0:02:48s\n",
      "epoch 24 | loss: 0.05734 | val_0_mse: 0.05768 |  0:02:55s\n",
      "epoch 25 | loss: 0.05652 | val_0_mse: 0.05511 |  0:03:02s\n",
      "epoch 26 | loss: 0.05625 | val_0_mse: 0.05942 |  0:03:09s\n",
      "epoch 27 | loss: 0.05253 | val_0_mse: 0.05542 |  0:03:16s\n",
      "epoch 28 | loss: 0.05299 | val_0_mse: 0.05289 |  0:03:23s\n",
      "epoch 29 | loss: 0.05425 | val_0_mse: 0.05777 |  0:03:30s\n",
      "epoch 30 | loss: 0.05488 | val_0_mse: 0.04775 |  0:03:38s\n",
      "epoch 31 | loss: 0.05227 | val_0_mse: 0.04662 |  0:03:45s\n",
      "epoch 32 | loss: 0.04987 | val_0_mse: 0.05159 |  0:03:52s\n",
      "epoch 33 | loss: 0.04935 | val_0_mse: 0.04014 |  0:03:59s\n",
      "epoch 34 | loss: 0.04728 | val_0_mse: 0.04123 |  0:04:06s\n",
      "epoch 35 | loss: 0.04262 | val_0_mse: 0.0446  |  0:04:13s\n",
      "epoch 36 | loss: 0.04633 | val_0_mse: 0.03976 |  0:04:20s\n",
      "epoch 37 | loss: 0.04979 | val_0_mse: 0.05319 |  0:04:27s\n",
      "epoch 38 | loss: 0.04471 | val_0_mse: 0.04738 |  0:04:35s\n",
      "epoch 39 | loss: 0.0541  | val_0_mse: 0.04919 |  0:04:42s\n",
      "epoch 40 | loss: 0.05071 | val_0_mse: 0.04884 |  0:04:49s\n",
      "epoch 41 | loss: 0.04747 | val_0_mse: 0.05645 |  0:04:56s\n",
      "epoch 42 | loss: 0.04917 | val_0_mse: 0.03933 |  0:05:03s\n",
      "epoch 43 | loss: 0.04383 | val_0_mse: 0.0447  |  0:05:10s\n",
      "epoch 44 | loss: 0.04363 | val_0_mse: 0.04425 |  0:05:17s\n",
      "epoch 45 | loss: 0.04704 | val_0_mse: 0.03706 |  0:05:24s\n",
      "epoch 46 | loss: 0.03882 | val_0_mse: 0.03522 |  0:05:32s\n",
      "epoch 47 | loss: 0.03625 | val_0_mse: 0.04279 |  0:05:39s\n",
      "epoch 48 | loss: 0.03449 | val_0_mse: 0.03076 |  0:05:46s\n",
      "epoch 49 | loss: 0.03688 | val_0_mse: 0.02775 |  0:05:53s\n",
      "epoch 50 | loss: 0.03203 | val_0_mse: 0.02989 |  0:06:00s\n",
      "epoch 51 | loss: 0.03266 | val_0_mse: 0.02848 |  0:06:08s\n",
      "epoch 52 | loss: 0.03056 | val_0_mse: 0.03778 |  0:06:15s\n",
      "epoch 53 | loss: 0.03021 | val_0_mse: 0.02678 |  0:06:22s\n",
      "epoch 54 | loss: 0.03596 | val_0_mse: 0.04054 |  0:06:29s\n",
      "epoch 55 | loss: 0.02899 | val_0_mse: 0.03152 |  0:06:36s\n",
      "epoch 56 | loss: 0.03189 | val_0_mse: 0.02399 |  0:06:44s\n",
      "epoch 57 | loss: 0.03023 | val_0_mse: 0.03385 |  0:06:51s\n",
      "epoch 58 | loss: 0.02626 | val_0_mse: 0.02184 |  0:06:58s\n",
      "epoch 59 | loss: 0.02268 | val_0_mse: 0.01915 |  0:07:05s\n",
      "epoch 60 | loss: 0.02238 | val_0_mse: 0.02375 |  0:07:12s\n",
      "epoch 61 | loss: 0.021   | val_0_mse: 0.01964 |  0:07:19s\n",
      "epoch 62 | loss: 0.02042 | val_0_mse: 0.01606 |  0:07:26s\n",
      "epoch 63 | loss: 0.02097 | val_0_mse: 0.01719 |  0:07:34s\n",
      "epoch 64 | loss: 0.0209  | val_0_mse: 0.0218  |  0:07:41s\n",
      "epoch 65 | loss: 0.02375 | val_0_mse: 0.02147 |  0:07:48s\n",
      "epoch 66 | loss: 0.01909 | val_0_mse: 0.01672 |  0:07:55s\n",
      "epoch 67 | loss: 0.02231 | val_0_mse: 0.02161 |  0:08:02s\n",
      "epoch 68 | loss: 0.01886 | val_0_mse: 0.01623 |  0:08:10s\n",
      "epoch 69 | loss: 0.01692 | val_0_mse: 0.0186  |  0:08:18s\n",
      "epoch 70 | loss: 0.02179 | val_0_mse: 0.0122  |  0:08:25s\n",
      "epoch 71 | loss: 0.01511 | val_0_mse: 0.01384 |  0:08:32s\n",
      "epoch 72 | loss: 0.01977 | val_0_mse: 0.03127 |  0:08:39s\n",
      "epoch 73 | loss: 0.023   | val_0_mse: 0.02824 |  0:08:47s\n",
      "epoch 74 | loss: 0.02096 | val_0_mse: 0.01734 |  0:08:54s\n",
      "epoch 75 | loss: 0.0208  | val_0_mse: 0.01448 |  0:09:02s\n",
      "epoch 76 | loss: 0.01728 | val_0_mse: 0.02199 |  0:09:09s\n",
      "epoch 77 | loss: 0.01764 | val_0_mse: 0.01394 |  0:09:17s\n",
      "epoch 78 | loss: 0.01498 | val_0_mse: 0.01376 |  0:09:24s\n",
      "epoch 79 | loss: 0.01491 | val_0_mse: 0.01708 |  0:09:32s\n",
      "epoch 80 | loss: 0.01536 | val_0_mse: 0.01416 |  0:09:40s\n",
      "\n",
      "Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.013612 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.938594 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 13/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=8, n_a=8, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.04324 | val_0_mse: 0.4659  |  0:00:10s\n",
      "epoch 1  | loss: 0.46424 | val_0_mse: 0.2827  |  0:00:20s\n",
      "epoch 2  | loss: 0.18214 | val_0_mse: 0.20053 |  0:00:30s\n",
      "epoch 3  | loss: 0.13377 | val_0_mse: 0.11044 |  0:00:40s\n",
      "epoch 4  | loss: 0.11223 | val_0_mse: 0.15292 |  0:00:49s\n",
      "epoch 5  | loss: 0.11317 | val_0_mse: 0.09636 |  0:01:02s\n",
      "epoch 6  | loss: 0.10401 | val_0_mse: 0.08883 |  0:01:15s\n",
      "epoch 7  | loss: 0.10963 | val_0_mse: 0.09882 |  0:01:24s\n",
      "epoch 8  | loss: 0.09428 | val_0_mse: 0.07879 |  0:01:33s\n",
      "epoch 9  | loss: 0.08989 | val_0_mse: 0.07771 |  0:01:43s\n",
      "epoch 10 | loss: 0.08648 | val_0_mse: 0.0689  |  0:01:52s\n",
      "epoch 11 | loss: 0.06645 | val_0_mse: 0.06327 |  0:02:01s\n",
      "epoch 12 | loss: 0.06083 | val_0_mse: 0.06381 |  0:02:11s\n",
      "epoch 13 | loss: 0.05135 | val_0_mse: 0.03817 |  0:02:22s\n",
      "epoch 14 | loss: 0.05214 | val_0_mse: 0.04761 |  0:02:31s\n",
      "epoch 15 | loss: 0.0436  | val_0_mse: 0.04277 |  0:02:40s\n",
      "epoch 16 | loss: 0.04154 | val_0_mse: 0.03418 |  0:02:49s\n",
      "epoch 17 | loss: 0.03914 | val_0_mse: 0.03938 |  0:02:59s\n",
      "epoch 18 | loss: 0.03549 | val_0_mse: 0.03034 |  0:03:08s\n",
      "epoch 19 | loss: 0.03788 | val_0_mse: 0.02147 |  0:03:17s\n",
      "epoch 20 | loss: 0.03159 | val_0_mse: 0.03774 |  0:03:27s\n",
      "epoch 21 | loss: 0.02459 | val_0_mse: 0.0153  |  0:03:36s\n",
      "epoch 22 | loss: 0.02422 | val_0_mse: 0.03856 |  0:03:46s\n",
      "epoch 23 | loss: 0.0252  | val_0_mse: 0.0164  |  0:03:56s\n",
      "epoch 24 | loss: 0.02074 | val_0_mse: 0.01567 |  0:04:05s\n",
      "epoch 25 | loss: 0.01994 | val_0_mse: 0.01402 |  0:04:14s\n",
      "epoch 26 | loss: 0.01626 | val_0_mse: 0.01686 |  0:04:24s\n",
      "epoch 27 | loss: 0.01843 | val_0_mse: 0.05275 |  0:04:33s\n",
      "epoch 28 | loss: 0.03037 | val_0_mse: 0.02414 |  0:04:43s\n",
      "epoch 29 | loss: 0.02353 | val_0_mse: 0.01425 |  0:04:52s\n",
      "epoch 30 | loss: 0.01646 | val_0_mse: 0.02276 |  0:05:02s\n",
      "epoch 31 | loss: 0.01862 | val_0_mse: 0.06123 |  0:05:11s\n",
      "epoch 32 | loss: 0.01808 | val_0_mse: 0.09553 |  0:05:21s\n",
      "epoch 33 | loss: 0.02427 | val_0_mse: 0.06702 |  0:05:31s\n",
      "epoch 34 | loss: 0.02698 | val_0_mse: 0.01667 |  0:05:40s\n",
      "epoch 35 | loss: 0.02078 | val_0_mse: 0.02175 |  0:05:50s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mse = 0.01402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.014079 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.936484 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 14/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=8, n_a=8, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.28459 | val_0_mse: 1.12451 |  0:00:07s\n",
      "epoch 1  | loss: 0.4175  | val_0_mse: 0.36704 |  0:00:15s\n",
      "epoch 2  | loss: 0.21476 | val_0_mse: 0.24936 |  0:00:22s\n",
      "epoch 3  | loss: 0.21491 | val_0_mse: 0.2036  |  0:00:29s\n",
      "epoch 4  | loss: 0.1747  | val_0_mse: 0.22709 |  0:00:37s\n",
      "epoch 5  | loss: 0.16649 | val_0_mse: 0.17022 |  0:00:44s\n",
      "epoch 6  | loss: 0.14843 | val_0_mse: 0.24479 |  0:00:52s\n",
      "epoch 7  | loss: 0.14411 | val_0_mse: 0.15188 |  0:00:59s\n",
      "epoch 8  | loss: 0.11537 | val_0_mse: 0.1105  |  0:01:07s\n",
      "epoch 9  | loss: 0.11471 | val_0_mse: 0.10763 |  0:01:14s\n",
      "epoch 10 | loss: 0.10365 | val_0_mse: 0.09914 |  0:01:21s\n",
      "epoch 11 | loss: 0.0992  | val_0_mse: 0.09834 |  0:01:29s\n",
      "epoch 12 | loss: 0.096   | val_0_mse: 0.08759 |  0:01:36s\n",
      "epoch 13 | loss: 0.0924  | val_0_mse: 0.07994 |  0:01:43s\n",
      "epoch 14 | loss: 0.0799  | val_0_mse: 0.07669 |  0:01:50s\n",
      "epoch 15 | loss: 0.07454 | val_0_mse: 0.06669 |  0:01:59s\n",
      "epoch 16 | loss: 0.07721 | val_0_mse: 0.06936 |  0:02:06s\n",
      "epoch 17 | loss: 0.06553 | val_0_mse: 0.07154 |  0:02:13s\n",
      "epoch 18 | loss: 0.06808 | val_0_mse: 0.06109 |  0:02:20s\n",
      "epoch 19 | loss: 0.06918 | val_0_mse: 0.05623 |  0:02:27s\n",
      "epoch 20 | loss: 0.06438 | val_0_mse: 0.06177 |  0:02:34s\n",
      "epoch 21 | loss: 0.06278 | val_0_mse: 0.0535  |  0:02:41s\n",
      "epoch 22 | loss: 0.05844 | val_0_mse: 0.05951 |  0:02:49s\n",
      "epoch 23 | loss: 0.05755 | val_0_mse: 0.05507 |  0:02:56s\n",
      "epoch 24 | loss: 0.0573  | val_0_mse: 0.04939 |  0:03:03s\n",
      "epoch 25 | loss: 0.07164 | val_0_mse: 0.05627 |  0:03:10s\n",
      "epoch 26 | loss: 0.05906 | val_0_mse: 0.05179 |  0:03:18s\n",
      "epoch 27 | loss: 0.05963 | val_0_mse: 0.06657 |  0:03:25s\n",
      "epoch 28 | loss: 0.05457 | val_0_mse: 0.05628 |  0:03:32s\n",
      "epoch 29 | loss: 0.05005 | val_0_mse: 0.04661 |  0:03:39s\n",
      "epoch 30 | loss: 0.04893 | val_0_mse: 0.04238 |  0:03:47s\n",
      "epoch 31 | loss: 0.04198 | val_0_mse: 0.05061 |  0:03:54s\n",
      "epoch 32 | loss: 0.04626 | val_0_mse: 0.0423  |  0:04:01s\n",
      "epoch 33 | loss: 0.04258 | val_0_mse: 0.03977 |  0:04:08s\n",
      "epoch 34 | loss: 0.04331 | val_0_mse: 0.04391 |  0:04:15s\n",
      "epoch 35 | loss: 0.04748 | val_0_mse: 0.03696 |  0:04:22s\n",
      "epoch 36 | loss: 0.04568 | val_0_mse: 0.03323 |  0:04:30s\n",
      "epoch 37 | loss: 0.03689 | val_0_mse: 0.03836 |  0:04:37s\n",
      "epoch 38 | loss: 0.03552 | val_0_mse: 0.03342 |  0:04:44s\n",
      "epoch 39 | loss: 0.03547 | val_0_mse: 0.02838 |  0:04:51s\n",
      "epoch 40 | loss: 0.03127 | val_0_mse: 0.03236 |  0:04:58s\n",
      "epoch 41 | loss: 0.03473 | val_0_mse: 0.03346 |  0:05:05s\n",
      "epoch 42 | loss: 0.03164 | val_0_mse: 0.02674 |  0:05:13s\n",
      "epoch 43 | loss: 0.02982 | val_0_mse: 0.02729 |  0:05:20s\n",
      "epoch 44 | loss: 0.02732 | val_0_mse: 0.03027 |  0:05:27s\n",
      "epoch 45 | loss: 0.02958 | val_0_mse: 0.02339 |  0:05:34s\n",
      "epoch 46 | loss: 0.02724 | val_0_mse: 0.02291 |  0:05:41s\n",
      "epoch 47 | loss: 0.02592 | val_0_mse: 0.02011 |  0:05:48s\n",
      "epoch 48 | loss: 0.02321 | val_0_mse: 0.02137 |  0:05:56s\n",
      "epoch 49 | loss: 0.02591 | val_0_mse: 0.02433 |  0:06:03s\n",
      "epoch 50 | loss: 0.02362 | val_0_mse: 0.02529 |  0:06:10s\n",
      "epoch 51 | loss: 0.02824 | val_0_mse: 0.01963 |  0:06:17s\n",
      "epoch 52 | loss: 0.02392 | val_0_mse: 0.02642 |  0:06:24s\n",
      "epoch 53 | loss: 0.02761 | val_0_mse: 0.01972 |  0:06:32s\n",
      "epoch 54 | loss: 0.03286 | val_0_mse: 0.03118 |  0:06:39s\n",
      "epoch 55 | loss: 0.02837 | val_0_mse: 0.02667 |  0:06:46s\n",
      "epoch 56 | loss: 0.0323  | val_0_mse: 0.05575 |  0:06:53s\n",
      "epoch 57 | loss: 0.03292 | val_0_mse: 0.03162 |  0:07:01s\n",
      "epoch 58 | loss: 0.02257 | val_0_mse: 0.02373 |  0:07:08s\n",
      "epoch 59 | loss: 0.02151 | val_0_mse: 0.01602 |  0:07:15s\n",
      "epoch 60 | loss: 0.02447 | val_0_mse: 0.02584 |  0:07:22s\n",
      "epoch 61 | loss: 0.02116 | val_0_mse: 0.01543 |  0:07:30s\n",
      "epoch 62 | loss: 0.01814 | val_0_mse: 0.01973 |  0:07:37s\n",
      "epoch 63 | loss: 0.02109 | val_0_mse: 0.01512 |  0:07:44s\n",
      "epoch 64 | loss: 0.02156 | val_0_mse: 0.01879 |  0:07:52s\n",
      "epoch 65 | loss: 0.01813 | val_0_mse: 0.01644 |  0:07:59s\n",
      "epoch 66 | loss: 0.01744 | val_0_mse: 0.01295 |  0:08:06s\n",
      "epoch 67 | loss: 0.01793 | val_0_mse: 0.01389 |  0:08:13s\n",
      "epoch 68 | loss: 0.01871 | val_0_mse: 0.01537 |  0:08:21s\n",
      "epoch 69 | loss: 0.01962 | val_0_mse: 0.01264 |  0:08:28s\n",
      "epoch 70 | loss: 0.01772 | val_0_mse: 0.00989 |  0:08:35s\n",
      "epoch 71 | loss: 0.01466 | val_0_mse: 0.01132 |  0:08:42s\n",
      "epoch 72 | loss: 0.01652 | val_0_mse: 0.02111 |  0:08:49s\n",
      "epoch 73 | loss: 0.01905 | val_0_mse: 0.02982 |  0:08:57s\n",
      "epoch 74 | loss: 0.018   | val_0_mse: 0.01929 |  0:09:04s\n",
      "epoch 75 | loss: 0.0193  | val_0_mse: 0.02695 |  0:09:11s\n",
      "epoch 76 | loss: 0.0178  | val_0_mse: 0.01362 |  0:09:18s\n",
      "epoch 77 | loss: 0.01775 | val_0_mse: 0.01052 |  0:09:26s\n",
      "epoch 78 | loss: 0.01598 | val_0_mse: 0.01369 |  0:09:33s\n",
      "epoch 79 | loss: 0.01612 | val_0_mse: 0.01619 |  0:09:40s\n",
      "epoch 80 | loss: 0.01962 | val_0_mse: 0.02246 |  0:09:47s\n",
      "\n",
      "Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 0.00989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.010460 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.952810 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 15/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=8, n_a=8, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.97355 | val_0_mse: 0.30703 |  0:00:11s\n",
      "epoch 1  | loss: 0.278   | val_0_mse: 0.21042 |  0:00:22s\n",
      "epoch 2  | loss: 0.1603  | val_0_mse: 0.11069 |  0:00:34s\n",
      "epoch 3  | loss: 0.09313 | val_0_mse: 0.11514 |  0:00:45s\n",
      "epoch 4  | loss: 0.09322 | val_0_mse: 0.15304 |  0:00:56s\n",
      "epoch 5  | loss: 0.08625 | val_0_mse: 0.07179 |  0:01:07s\n",
      "epoch 6  | loss: 0.08166 | val_0_mse: 0.0957  |  0:01:18s\n",
      "epoch 7  | loss: 0.07536 | val_0_mse: 0.09543 |  0:01:30s\n",
      "epoch 8  | loss: 0.07783 | val_0_mse: 0.08122 |  0:01:41s\n",
      "epoch 9  | loss: 0.07675 | val_0_mse: 0.08626 |  0:01:52s\n",
      "epoch 10 | loss: 0.0835  | val_0_mse: 0.07045 |  0:02:03s\n",
      "epoch 11 | loss: 0.07242 | val_0_mse: 0.05583 |  0:02:14s\n",
      "epoch 12 | loss: 0.06302 | val_0_mse: 0.06871 |  0:02:25s\n",
      "epoch 13 | loss: 0.06518 | val_0_mse: 0.05243 |  0:02:36s\n",
      "epoch 14 | loss: 0.06951 | val_0_mse: 0.05789 |  0:02:47s\n",
      "epoch 15 | loss: 0.06431 | val_0_mse: 0.04826 |  0:02:58s\n",
      "epoch 16 | loss: 0.04925 | val_0_mse: 0.04393 |  0:03:09s\n",
      "epoch 17 | loss: 0.04348 | val_0_mse: 0.03617 |  0:03:20s\n",
      "epoch 18 | loss: 0.03868 | val_0_mse: 0.04227 |  0:03:31s\n",
      "epoch 19 | loss: 0.03107 | val_0_mse: 0.03154 |  0:03:43s\n",
      "epoch 20 | loss: 0.03392 | val_0_mse: 0.08692 |  0:03:54s\n",
      "epoch 21 | loss: 0.03331 | val_0_mse: 0.01841 |  0:04:05s\n",
      "epoch 22 | loss: 0.02643 | val_0_mse: 0.0302  |  0:04:16s\n",
      "epoch 23 | loss: 0.02278 | val_0_mse: 0.02006 |  0:04:27s\n",
      "epoch 24 | loss: 0.0197  | val_0_mse: 0.01425 |  0:04:38s\n",
      "epoch 25 | loss: 0.01899 | val_0_mse: 0.01317 |  0:04:49s\n",
      "epoch 26 | loss: 0.01861 | val_0_mse: 0.02205 |  0:05:00s\n",
      "epoch 27 | loss: 0.01772 | val_0_mse: 0.01022 |  0:05:11s\n",
      "epoch 28 | loss: 0.01988 | val_0_mse: 0.02339 |  0:05:22s\n",
      "epoch 29 | loss: 0.01548 | val_0_mse: 0.01436 |  0:05:33s\n",
      "epoch 30 | loss: 0.02211 | val_0_mse: 0.03536 |  0:05:45s\n",
      "epoch 31 | loss: 0.02342 | val_0_mse: 0.01926 |  0:05:56s\n",
      "epoch 32 | loss: 0.01606 | val_0_mse: 0.01706 |  0:06:07s\n",
      "epoch 33 | loss: 0.0153  | val_0_mse: 0.01323 |  0:06:18s\n",
      "epoch 34 | loss: 0.01461 | val_0_mse: 0.01418 |  0:06:29s\n",
      "epoch 35 | loss: 0.01458 | val_0_mse: 0.02494 |  0:06:40s\n",
      "epoch 36 | loss: 0.02166 | val_0_mse: 0.00995 |  0:06:51s\n",
      "epoch 37 | loss: 0.01757 | val_0_mse: 0.02478 |  0:07:02s\n",
      "epoch 38 | loss: 0.01414 | val_0_mse: 0.01023 |  0:07:13s\n",
      "epoch 39 | loss: 0.01352 | val_0_mse: 0.03735 |  0:07:23s\n",
      "epoch 40 | loss: 0.01757 | val_0_mse: 0.01264 |  0:07:34s\n",
      "epoch 41 | loss: 0.01305 | val_0_mse: 0.00901 |  0:07:45s\n",
      "epoch 42 | loss: 0.01618 | val_0_mse: 0.01327 |  0:07:56s\n",
      "epoch 43 | loss: 0.01481 | val_0_mse: 0.00867 |  0:08:06s\n",
      "epoch 44 | loss: 0.01608 | val_0_mse: 0.01937 |  0:08:17s\n",
      "epoch 45 | loss: 0.01499 | val_0_mse: 0.01571 |  0:08:27s\n",
      "epoch 46 | loss: 0.01517 | val_0_mse: 0.01097 |  0:08:38s\n",
      "epoch 47 | loss: 0.01977 | val_0_mse: 0.01077 |  0:08:48s\n",
      "epoch 48 | loss: 0.01894 | val_0_mse: 0.10984 |  0:08:58s\n",
      "epoch 49 | loss: 0.01861 | val_0_mse: 0.05109 |  0:09:09s\n",
      "epoch 50 | loss: 0.01581 | val_0_mse: 0.01613 |  0:09:19s\n",
      "epoch 51 | loss: 0.01543 | val_0_mse: 0.01263 |  0:09:30s\n",
      "epoch 52 | loss: 0.01424 | val_0_mse: 0.035   |  0:09:40s\n",
      "epoch 53 | loss: 0.018   | val_0_mse: 0.00715 |  0:09:50s\n",
      "epoch 54 | loss: 0.0151  | val_0_mse: 0.00943 |  0:10:01s\n",
      "epoch 55 | loss: 0.01286 | val_0_mse: 0.00875 |  0:10:11s\n",
      "epoch 56 | loss: 0.01275 | val_0_mse: 0.00983 |  0:10:22s\n",
      "epoch 57 | loss: 0.01226 | val_0_mse: 0.02478 |  0:10:32s\n",
      "epoch 58 | loss: 0.01375 | val_0_mse: 0.01295 |  0:10:42s\n",
      "epoch 59 | loss: 0.01357 | val_0_mse: 0.01384 |  0:10:53s\n",
      "epoch 60 | loss: 0.01139 | val_0_mse: 0.00818 |  0:11:03s\n",
      "epoch 61 | loss: 0.0108  | val_0_mse: 0.00777 |  0:11:14s\n",
      "epoch 62 | loss: 0.01251 | val_0_mse: 0.0162  |  0:11:26s\n",
      "epoch 63 | loss: 0.01432 | val_0_mse: 0.00651 |  0:11:40s\n",
      "epoch 64 | loss: 0.01092 | val_0_mse: 0.01421 |  0:11:50s\n",
      "epoch 65 | loss: 0.01718 | val_0_mse: 0.01631 |  0:12:01s\n",
      "epoch 66 | loss: 0.01736 | val_0_mse: 0.02497 |  0:12:11s\n",
      "epoch 67 | loss: 0.01177 | val_0_mse: 0.00935 |  0:12:22s\n",
      "epoch 68 | loss: 0.01144 | val_0_mse: 0.09074 |  0:12:32s\n",
      "epoch 69 | loss: 0.01198 | val_0_mse: 0.01106 |  0:12:42s\n",
      "epoch 70 | loss: 0.01182 | val_0_mse: 0.01191 |  0:12:52s\n",
      "epoch 71 | loss: 0.01552 | val_0_mse: 0.01242 |  0:13:02s\n",
      "epoch 72 | loss: 0.01234 | val_0_mse: 0.00822 |  0:13:12s\n",
      "epoch 73 | loss: 0.00969 | val_0_mse: 0.03022 |  0:13:22s\n",
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 63 and best_val_0_mse = 0.00651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006068 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.972626 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 16/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=8, n_a=8, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.61801 | val_0_mse: 0.49578 |  0:00:07s\n",
      "epoch 1  | loss: 0.40192 | val_0_mse: 0.25176 |  0:00:15s\n",
      "epoch 2  | loss: 0.21631 | val_0_mse: 0.4086  |  0:00:23s\n",
      "epoch 3  | loss: 0.2194  | val_0_mse: 0.16258 |  0:00:31s\n",
      "epoch 4  | loss: 0.17598 | val_0_mse: 0.22261 |  0:00:39s\n",
      "epoch 5  | loss: 0.10795 | val_0_mse: 0.18504 |  0:00:47s\n",
      "epoch 6  | loss: 0.10759 | val_0_mse: 0.11785 |  0:00:55s\n",
      "epoch 7  | loss: 0.09741 | val_0_mse: 0.10301 |  0:01:03s\n",
      "epoch 8  | loss: 0.0978  | val_0_mse: 0.09642 |  0:01:11s\n",
      "epoch 9  | loss: 0.09181 | val_0_mse: 0.08832 |  0:01:20s\n",
      "epoch 10 | loss: 0.09066 | val_0_mse: 0.08772 |  0:01:28s\n",
      "epoch 11 | loss: 0.08689 | val_0_mse: 0.06764 |  0:01:36s\n",
      "epoch 12 | loss: 0.08075 | val_0_mse: 0.08428 |  0:01:44s\n",
      "epoch 13 | loss: 0.08655 | val_0_mse: 0.08004 |  0:01:52s\n",
      "epoch 14 | loss: 0.08756 | val_0_mse: 0.07906 |  0:02:00s\n",
      "epoch 15 | loss: 0.08215 | val_0_mse: 0.07406 |  0:02:08s\n",
      "epoch 16 | loss: 0.08195 | val_0_mse: 0.07286 |  0:02:17s\n",
      "epoch 17 | loss: 0.07524 | val_0_mse: 0.0642  |  0:02:25s\n",
      "epoch 18 | loss: 0.07083 | val_0_mse: 0.06136 |  0:02:33s\n",
      "epoch 19 | loss: 0.06597 | val_0_mse: 0.05689 |  0:02:41s\n",
      "epoch 20 | loss: 0.06178 | val_0_mse: 0.06421 |  0:02:49s\n",
      "epoch 21 | loss: 0.06523 | val_0_mse: 0.05403 |  0:02:57s\n",
      "epoch 22 | loss: 0.05859 | val_0_mse: 0.0523  |  0:03:05s\n",
      "epoch 23 | loss: 0.05368 | val_0_mse: 0.04805 |  0:03:13s\n",
      "epoch 24 | loss: 0.04993 | val_0_mse: 0.05627 |  0:03:21s\n",
      "epoch 25 | loss: 0.05415 | val_0_mse: 0.05222 |  0:03:30s\n",
      "epoch 26 | loss: 0.04729 | val_0_mse: 0.03713 |  0:03:38s\n",
      "epoch 27 | loss: 0.04089 | val_0_mse: 0.03814 |  0:03:46s\n",
      "epoch 28 | loss: 0.04106 | val_0_mse: 0.04122 |  0:03:54s\n",
      "epoch 29 | loss: 0.04285 | val_0_mse: 0.03448 |  0:04:02s\n",
      "epoch 30 | loss: 0.03555 | val_0_mse: 0.02958 |  0:04:10s\n",
      "epoch 31 | loss: 0.03758 | val_0_mse: 0.02684 |  0:04:18s\n",
      "epoch 32 | loss: 0.04103 | val_0_mse: 0.02575 |  0:04:27s\n",
      "epoch 33 | loss: 0.02941 | val_0_mse: 0.03983 |  0:04:35s\n",
      "epoch 34 | loss: 0.03122 | val_0_mse: 0.02305 |  0:04:43s\n",
      "epoch 35 | loss: 0.03009 | val_0_mse: 0.02291 |  0:04:51s\n",
      "epoch 36 | loss: 0.02611 | val_0_mse: 0.03258 |  0:04:59s\n",
      "epoch 37 | loss: 0.02823 | val_0_mse: 0.02909 |  0:05:07s\n",
      "epoch 38 | loss: 0.02642 | val_0_mse: 0.02009 |  0:05:15s\n",
      "epoch 39 | loss: 0.02563 | val_0_mse: 0.02001 |  0:05:24s\n",
      "epoch 40 | loss: 0.02382 | val_0_mse: 0.01825 |  0:05:32s\n",
      "epoch 41 | loss: 0.02074 | val_0_mse: 0.0175  |  0:05:40s\n",
      "epoch 42 | loss: 0.02071 | val_0_mse: 0.01564 |  0:05:48s\n",
      "epoch 43 | loss: 0.02345 | val_0_mse: 0.02024 |  0:05:56s\n",
      "epoch 44 | loss: 0.01885 | val_0_mse: 0.0198  |  0:06:04s\n",
      "epoch 45 | loss: 0.01837 | val_0_mse: 0.01629 |  0:06:13s\n",
      "epoch 46 | loss: 0.0186  | val_0_mse: 0.01465 |  0:06:21s\n",
      "epoch 47 | loss: 0.01699 | val_0_mse: 0.01392 |  0:06:29s\n",
      "epoch 48 | loss: 0.01683 | val_0_mse: 0.01757 |  0:06:37s\n",
      "epoch 49 | loss: 0.01798 | val_0_mse: 0.01143 |  0:06:45s\n",
      "epoch 50 | loss: 0.01412 | val_0_mse: 0.01967 |  0:06:53s\n",
      "epoch 51 | loss: 0.02087 | val_0_mse: 0.02193 |  0:07:02s\n",
      "epoch 52 | loss: 0.01581 | val_0_mse: 0.01288 |  0:07:10s\n",
      "epoch 53 | loss: 0.01612 | val_0_mse: 0.01106 |  0:07:18s\n",
      "epoch 54 | loss: 0.01344 | val_0_mse: 0.01583 |  0:07:26s\n",
      "epoch 55 | loss: 0.01447 | val_0_mse: 0.02017 |  0:07:34s\n",
      "epoch 56 | loss: 0.015   | val_0_mse: 0.02419 |  0:07:42s\n",
      "epoch 57 | loss: 0.01748 | val_0_mse: 0.01271 |  0:07:50s\n",
      "epoch 58 | loss: 0.01362 | val_0_mse: 0.01043 |  0:07:58s\n",
      "epoch 59 | loss: 0.01192 | val_0_mse: 0.00869 |  0:08:07s\n",
      "epoch 60 | loss: 0.01067 | val_0_mse: 0.00912 |  0:08:15s\n",
      "epoch 61 | loss: 0.01131 | val_0_mse: 0.00826 |  0:08:23s\n",
      "epoch 62 | loss: 0.01031 | val_0_mse: 0.0114  |  0:08:31s\n",
      "epoch 63 | loss: 0.01253 | val_0_mse: 0.01019 |  0:08:39s\n",
      "epoch 64 | loss: 0.01098 | val_0_mse: 0.00721 |  0:08:47s\n",
      "epoch 65 | loss: 0.01171 | val_0_mse: 0.01856 |  0:08:56s\n",
      "epoch 66 | loss: 0.01332 | val_0_mse: 0.00876 |  0:09:04s\n",
      "epoch 67 | loss: 0.01352 | val_0_mse: 0.01    |  0:09:12s\n",
      "epoch 68 | loss: 0.01366 | val_0_mse: 0.01579 |  0:09:20s\n",
      "epoch 69 | loss: 0.01188 | val_0_mse: 0.01027 |  0:09:28s\n",
      "epoch 70 | loss: 0.00908 | val_0_mse: 0.0136  |  0:09:36s\n",
      "epoch 71 | loss: 0.01115 | val_0_mse: 0.00729 |  0:09:44s\n",
      "epoch 72 | loss: 0.01095 | val_0_mse: 0.00772 |  0:09:53s\n",
      "epoch 73 | loss: 0.00854 | val_0_mse: 0.01965 |  0:10:01s\n",
      "epoch 74 | loss: 0.01345 | val_0_mse: 0.00789 |  0:10:09s\n",
      "\n",
      "Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 0.00721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006888 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.968927 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 17/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.60696 | val_0_mse: 0.70206 |  0:00:09s\n",
      "epoch 1  | loss: 0.23767 | val_0_mse: 0.41681 |  0:00:18s\n",
      "epoch 2  | loss: 0.15    | val_0_mse: 0.13363 |  0:00:27s\n",
      "epoch 3  | loss: 0.11714 | val_0_mse: 0.12192 |  0:00:36s\n",
      "epoch 4  | loss: 0.1159  | val_0_mse: 0.08962 |  0:00:45s\n",
      "epoch 5  | loss: 0.09512 | val_0_mse: 0.0757  |  0:00:54s\n",
      "epoch 6  | loss: 0.10113 | val_0_mse: 0.08143 |  0:01:03s\n",
      "epoch 7  | loss: 0.09179 | val_0_mse: 0.07778 |  0:01:12s\n",
      "epoch 8  | loss: 0.08172 | val_0_mse: 0.0692  |  0:01:21s\n",
      "epoch 9  | loss: 0.07743 | val_0_mse: 0.06641 |  0:01:29s\n",
      "epoch 10 | loss: 0.07181 | val_0_mse: 0.05605 |  0:01:38s\n",
      "epoch 11 | loss: 0.06347 | val_0_mse: 0.05821 |  0:01:47s\n",
      "epoch 12 | loss: 0.07167 | val_0_mse: 0.06324 |  0:01:55s\n",
      "epoch 13 | loss: 0.05859 | val_0_mse: 0.0554  |  0:02:03s\n",
      "epoch 14 | loss: 0.05291 | val_0_mse: 0.04466 |  0:02:10s\n",
      "epoch 15 | loss: 0.05939 | val_0_mse: 0.04134 |  0:02:18s\n",
      "epoch 16 | loss: 0.06154 | val_0_mse: 0.04655 |  0:02:26s\n",
      "epoch 17 | loss: 0.05499 | val_0_mse: 0.04923 |  0:02:34s\n",
      "epoch 18 | loss: 0.06104 | val_0_mse: 0.0389  |  0:02:42s\n",
      "epoch 19 | loss: 0.04602 | val_0_mse: 0.04498 |  0:02:50s\n",
      "epoch 20 | loss: 0.0479  | val_0_mse: 0.03708 |  0:02:58s\n",
      "epoch 21 | loss: 0.04526 | val_0_mse: 0.0479  |  0:03:06s\n",
      "epoch 22 | loss: 0.04874 | val_0_mse: 0.03994 |  0:03:14s\n",
      "epoch 23 | loss: 0.04977 | val_0_mse: 0.05077 |  0:03:21s\n",
      "epoch 24 | loss: 0.04126 | val_0_mse: 0.03789 |  0:03:29s\n",
      "epoch 25 | loss: 0.04032 | val_0_mse: 0.03815 |  0:03:37s\n",
      "epoch 26 | loss: 0.03652 | val_0_mse: 0.0321  |  0:03:46s\n",
      "epoch 27 | loss: 0.04104 | val_0_mse: 0.02758 |  0:03:54s\n",
      "epoch 28 | loss: 0.03751 | val_0_mse: 0.02331 |  0:04:02s\n",
      "epoch 29 | loss: 0.03026 | val_0_mse: 0.05476 |  0:04:09s\n",
      "epoch 30 | loss: 0.03243 | val_0_mse: 0.02604 |  0:04:17s\n",
      "epoch 31 | loss: 0.02931 | val_0_mse: 0.04413 |  0:04:25s\n",
      "epoch 32 | loss: 0.03064 | val_0_mse: 0.03979 |  0:04:33s\n",
      "epoch 33 | loss: 0.04123 | val_0_mse: 0.0381  |  0:04:41s\n",
      "epoch 34 | loss: 0.03379 | val_0_mse: 0.03218 |  0:04:49s\n",
      "epoch 35 | loss: 0.02378 | val_0_mse: 0.01964 |  0:04:57s\n",
      "epoch 36 | loss: 0.01972 | val_0_mse: 0.01507 |  0:05:05s\n",
      "epoch 37 | loss: 0.01752 | val_0_mse: 0.01231 |  0:05:13s\n",
      "epoch 38 | loss: 0.02098 | val_0_mse: 0.01976 |  0:05:21s\n",
      "epoch 39 | loss: 0.01601 | val_0_mse: 0.01852 |  0:05:29s\n",
      "epoch 40 | loss: 0.01715 | val_0_mse: 0.00939 |  0:05:37s\n",
      "epoch 41 | loss: 0.01798 | val_0_mse: 0.01602 |  0:05:45s\n",
      "epoch 42 | loss: 0.01464 | val_0_mse: 0.0089  |  0:05:53s\n",
      "epoch 43 | loss: 0.01373 | val_0_mse: 0.03395 |  0:06:01s\n",
      "epoch 44 | loss: 0.01218 | val_0_mse: 0.01796 |  0:06:09s\n",
      "epoch 45 | loss: 0.01188 | val_0_mse: 0.0083  |  0:06:17s\n",
      "epoch 46 | loss: 0.01241 | val_0_mse: 0.01612 |  0:06:25s\n",
      "epoch 47 | loss: 0.01227 | val_0_mse: 0.01801 |  0:06:33s\n",
      "epoch 48 | loss: 0.01205 | val_0_mse: 0.01769 |  0:06:41s\n",
      "epoch 49 | loss: 0.01395 | val_0_mse: 0.04819 |  0:06:49s\n",
      "epoch 50 | loss: 0.01329 | val_0_mse: 0.02785 |  0:06:56s\n",
      "epoch 51 | loss: 0.02109 | val_0_mse: 0.04723 |  0:07:04s\n",
      "epoch 52 | loss: 0.02501 | val_0_mse: 0.01948 |  0:07:12s\n",
      "epoch 53 | loss: 0.01988 | val_0_mse: 0.01551 |  0:07:20s\n",
      "epoch 54 | loss: 0.02413 | val_0_mse: 0.02483 |  0:07:28s\n",
      "epoch 55 | loss: 0.01718 | val_0_mse: 0.01111 |  0:07:36s\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_mse = 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008292 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.962594 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 18/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.75404 | val_0_mse: 0.8403  |  0:00:06s\n",
      "epoch 1  | loss: 0.35205 | val_0_mse: 0.21708 |  0:00:13s\n",
      "epoch 2  | loss: 0.17181 | val_0_mse: 0.17749 |  0:00:20s\n",
      "epoch 3  | loss: 0.11916 | val_0_mse: 0.14521 |  0:00:27s\n",
      "epoch 4  | loss: 0.08996 | val_0_mse: 0.12608 |  0:00:34s\n",
      "epoch 5  | loss: 0.07498 | val_0_mse: 0.11809 |  0:00:40s\n",
      "epoch 6  | loss: 0.07222 | val_0_mse: 0.10784 |  0:00:46s\n",
      "epoch 7  | loss: 0.05321 | val_0_mse: 0.08541 |  0:00:53s\n",
      "epoch 8  | loss: 0.05585 | val_0_mse: 0.07579 |  0:00:59s\n",
      "epoch 9  | loss: 0.05283 | val_0_mse: 0.06827 |  0:01:06s\n",
      "epoch 10 | loss: 0.04659 | val_0_mse: 0.05632 |  0:01:13s\n",
      "epoch 11 | loss: 0.04846 | val_0_mse: 0.05865 |  0:01:19s\n",
      "epoch 12 | loss: 0.05047 | val_0_mse: 0.05753 |  0:01:26s\n",
      "epoch 13 | loss: 0.06627 | val_0_mse: 0.07163 |  0:01:33s\n",
      "epoch 14 | loss: 0.05218 | val_0_mse: 0.05121 |  0:01:39s\n",
      "epoch 15 | loss: 0.04968 | val_0_mse: 0.04532 |  0:01:46s\n",
      "epoch 16 | loss: 0.053   | val_0_mse: 0.04732 |  0:01:52s\n",
      "epoch 17 | loss: 0.04787 | val_0_mse: 0.04468 |  0:01:59s\n",
      "epoch 18 | loss: 0.04633 | val_0_mse: 0.04146 |  0:02:06s\n",
      "epoch 19 | loss: 0.04659 | val_0_mse: 0.04323 |  0:02:12s\n",
      "epoch 20 | loss: 0.04634 | val_0_mse: 0.04479 |  0:02:19s\n",
      "epoch 21 | loss: 0.04629 | val_0_mse: 0.04477 |  0:02:25s\n",
      "epoch 22 | loss: 0.04586 | val_0_mse: 0.04213 |  0:02:33s\n",
      "epoch 23 | loss: 0.0462  | val_0_mse: 0.04573 |  0:02:39s\n",
      "epoch 24 | loss: 0.04398 | val_0_mse: 0.04458 |  0:02:46s\n",
      "epoch 25 | loss: 0.04626 | val_0_mse: 0.04039 |  0:02:53s\n",
      "epoch 26 | loss: 0.04166 | val_0_mse: 0.04252 |  0:02:59s\n",
      "epoch 27 | loss: 0.04565 | val_0_mse: 0.03835 |  0:03:06s\n",
      "epoch 28 | loss: 0.04349 | val_0_mse: 0.03846 |  0:03:13s\n",
      "epoch 29 | loss: 0.04095 | val_0_mse: 0.03959 |  0:03:19s\n",
      "epoch 30 | loss: 0.04817 | val_0_mse: 0.03837 |  0:03:26s\n",
      "epoch 31 | loss: 0.04775 | val_0_mse: 0.04671 |  0:03:32s\n",
      "epoch 32 | loss: 0.04004 | val_0_mse: 0.03791 |  0:03:39s\n",
      "epoch 33 | loss: 0.04283 | val_0_mse: 0.03545 |  0:03:45s\n",
      "epoch 34 | loss: 0.04107 | val_0_mse: 0.03673 |  0:03:52s\n",
      "epoch 35 | loss: 0.03939 | val_0_mse: 0.03548 |  0:03:58s\n",
      "epoch 36 | loss: 0.04504 | val_0_mse: 0.03524 |  0:04:05s\n",
      "epoch 37 | loss: 0.03844 | val_0_mse: 0.03289 |  0:04:11s\n",
      "epoch 38 | loss: 0.03524 | val_0_mse: 0.03683 |  0:04:17s\n",
      "epoch 39 | loss: 0.03616 | val_0_mse: 0.03665 |  0:04:24s\n",
      "epoch 40 | loss: 0.03615 | val_0_mse: 0.03248 |  0:04:31s\n",
      "epoch 41 | loss: 0.03649 | val_0_mse: 0.03872 |  0:04:37s\n",
      "epoch 42 | loss: 0.035   | val_0_mse: 0.0299  |  0:04:44s\n",
      "epoch 43 | loss: 0.03711 | val_0_mse: 0.02879 |  0:04:50s\n",
      "epoch 44 | loss: 0.03131 | val_0_mse: 0.03213 |  0:04:57s\n",
      "epoch 45 | loss: 0.0357  | val_0_mse: 0.02756 |  0:05:04s\n",
      "epoch 46 | loss: 0.03229 | val_0_mse: 0.02658 |  0:05:11s\n",
      "epoch 47 | loss: 0.02918 | val_0_mse: 0.02406 |  0:05:17s\n",
      "epoch 48 | loss: 0.0279  | val_0_mse: 0.02222 |  0:05:24s\n",
      "epoch 49 | loss: 0.02506 | val_0_mse: 0.03035 |  0:05:30s\n",
      "epoch 50 | loss: 0.02647 | val_0_mse: 0.02001 |  0:05:37s\n",
      "epoch 51 | loss: 0.02574 | val_0_mse: 0.02085 |  0:05:44s\n",
      "epoch 52 | loss: 0.02591 | val_0_mse: 0.01903 |  0:05:50s\n",
      "epoch 53 | loss: 0.02087 | val_0_mse: 0.0242  |  0:05:57s\n",
      "epoch 54 | loss: 0.02454 | val_0_mse: 0.03403 |  0:06:04s\n",
      "epoch 55 | loss: 0.02248 | val_0_mse: 0.0181  |  0:06:10s\n",
      "epoch 56 | loss: 0.02045 | val_0_mse: 0.03275 |  0:06:17s\n",
      "epoch 57 | loss: 0.01812 | val_0_mse: 0.01366 |  0:06:23s\n",
      "epoch 58 | loss: 0.01743 | val_0_mse: 0.01155 |  0:06:30s\n",
      "epoch 59 | loss: 0.01967 | val_0_mse: 0.01281 |  0:06:36s\n",
      "epoch 60 | loss: 0.01809 | val_0_mse: 0.01232 |  0:06:43s\n",
      "epoch 61 | loss: 0.01675 | val_0_mse: 0.01783 |  0:06:50s\n",
      "epoch 62 | loss: 0.01686 | val_0_mse: 0.01168 |  0:06:56s\n",
      "epoch 63 | loss: 0.01337 | val_0_mse: 0.01503 |  0:07:03s\n",
      "epoch 64 | loss: 0.01529 | val_0_mse: 0.0175  |  0:07:09s\n",
      "epoch 65 | loss: 0.01639 | val_0_mse: 0.00877 |  0:07:16s\n",
      "epoch 66 | loss: 0.01422 | val_0_mse: 0.01226 |  0:07:23s\n",
      "epoch 67 | loss: 0.01355 | val_0_mse: 0.01026 |  0:07:29s\n",
      "epoch 68 | loss: 0.01182 | val_0_mse: 0.02242 |  0:07:35s\n",
      "epoch 69 | loss: 0.01532 | val_0_mse: 0.0123  |  0:07:42s\n",
      "epoch 70 | loss: 0.01268 | val_0_mse: 0.00881 |  0:07:49s\n",
      "epoch 71 | loss: 0.01037 | val_0_mse: 0.00718 |  0:07:55s\n",
      "epoch 72 | loss: 0.01439 | val_0_mse: 0.00834 |  0:08:02s\n",
      "epoch 73 | loss: 0.01083 | val_0_mse: 0.01701 |  0:08:08s\n",
      "epoch 74 | loss: 0.01161 | val_0_mse: 0.00868 |  0:08:15s\n",
      "epoch 75 | loss: 0.01268 | val_0_mse: 0.01532 |  0:08:21s\n",
      "epoch 76 | loss: 0.01147 | val_0_mse: 0.00816 |  0:08:28s\n",
      "epoch 77 | loss: 0.01068 | val_0_mse: 0.00634 |  0:08:34s\n",
      "epoch 78 | loss: 0.01033 | val_0_mse: 0.00803 |  0:08:40s\n",
      "epoch 79 | loss: 0.01038 | val_0_mse: 0.0087  |  0:08:47s\n",
      "epoch 80 | loss: 0.01019 | val_0_mse: 0.01438 |  0:08:53s\n",
      "epoch 81 | loss: 0.01075 | val_0_mse: 0.00799 |  0:09:00s\n",
      "epoch 82 | loss: 0.01313 | val_0_mse: 0.01015 |  0:09:06s\n",
      "epoch 83 | loss: 0.01618 | val_0_mse: 0.01062 |  0:09:13s\n",
      "epoch 84 | loss: 0.0101  | val_0_mse: 0.01205 |  0:09:19s\n",
      "epoch 85 | loss: 0.01178 | val_0_mse: 0.01469 |  0:09:26s\n",
      "epoch 86 | loss: 0.01103 | val_0_mse: 0.00769 |  0:09:32s\n",
      "epoch 87 | loss: 0.00953 | val_0_mse: 0.00791 |  0:09:39s\n",
      "\n",
      "Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_mse = 0.00634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006831 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.969184 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 19/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.91501 | val_0_mse: 0.57152 |  0:00:09s\n",
      "epoch 1  | loss: 0.2539  | val_0_mse: 0.13418 |  0:00:18s\n",
      "epoch 2  | loss: 0.12859 | val_0_mse: 0.10908 |  0:00:27s\n",
      "epoch 3  | loss: 0.08605 | val_0_mse: 0.09569 |  0:00:36s\n",
      "epoch 4  | loss: 0.0788  | val_0_mse: 0.06572 |  0:00:45s\n",
      "epoch 5  | loss: 0.07673 | val_0_mse: 0.07612 |  0:00:54s\n",
      "epoch 6  | loss: 0.06845 | val_0_mse: 0.06675 |  0:01:03s\n",
      "epoch 7  | loss: 0.07048 | val_0_mse: 0.05866 |  0:01:12s\n",
      "epoch 8  | loss: 0.06467 | val_0_mse: 0.05762 |  0:01:21s\n",
      "epoch 9  | loss: 0.05798 | val_0_mse: 0.05584 |  0:01:30s\n",
      "epoch 10 | loss: 0.05276 | val_0_mse: 0.04129 |  0:01:39s\n",
      "epoch 11 | loss: 0.04961 | val_0_mse: 0.03993 |  0:01:48s\n",
      "epoch 12 | loss: 0.04385 | val_0_mse: 0.03242 |  0:01:57s\n",
      "epoch 13 | loss: 0.03967 | val_0_mse: 0.04237 |  0:02:06s\n",
      "epoch 14 | loss: 0.03521 | val_0_mse: 0.02485 |  0:02:15s\n",
      "epoch 15 | loss: 0.03295 | val_0_mse: 0.05112 |  0:02:24s\n",
      "epoch 16 | loss: 0.03206 | val_0_mse: 0.05616 |  0:02:33s\n",
      "epoch 17 | loss: 0.03756 | val_0_mse: 0.09204 |  0:02:42s\n",
      "epoch 18 | loss: 0.03219 | val_0_mse: 0.04809 |  0:02:51s\n",
      "epoch 19 | loss: 0.04205 | val_0_mse: 0.0333  |  0:03:00s\n",
      "epoch 20 | loss: 0.03512 | val_0_mse: 0.0245  |  0:03:09s\n",
      "epoch 21 | loss: 0.02674 | val_0_mse: 0.03153 |  0:03:18s\n",
      "epoch 22 | loss: 0.02641 | val_0_mse: 0.03194 |  0:03:27s\n",
      "epoch 23 | loss: 0.02238 | val_0_mse: 0.01356 |  0:03:36s\n",
      "epoch 24 | loss: 0.02075 | val_0_mse: 0.01844 |  0:03:45s\n",
      "epoch 25 | loss: 0.01826 | val_0_mse: 0.0241  |  0:03:54s\n",
      "epoch 26 | loss: 0.01957 | val_0_mse: 0.03284 |  0:04:03s\n",
      "epoch 27 | loss: 0.01638 | val_0_mse: 0.01472 |  0:04:13s\n",
      "epoch 28 | loss: 0.01537 | val_0_mse: 0.0103  |  0:04:22s\n",
      "epoch 29 | loss: 0.01453 | val_0_mse: 0.01091 |  0:04:31s\n",
      "epoch 30 | loss: 0.01493 | val_0_mse: 0.00885 |  0:04:40s\n",
      "epoch 31 | loss: 0.01548 | val_0_mse: 0.02515 |  0:04:49s\n",
      "epoch 32 | loss: 0.01605 | val_0_mse: 0.01341 |  0:04:58s\n",
      "epoch 33 | loss: 0.01393 | val_0_mse: 0.01235 |  0:05:07s\n",
      "epoch 34 | loss: 0.01251 | val_0_mse: 0.00849 |  0:05:16s\n",
      "epoch 35 | loss: 0.01243 | val_0_mse: 0.01438 |  0:05:25s\n",
      "epoch 36 | loss: 0.01252 | val_0_mse: 0.02539 |  0:05:34s\n",
      "epoch 37 | loss: 0.01113 | val_0_mse: 0.01965 |  0:05:43s\n",
      "epoch 38 | loss: 0.01251 | val_0_mse: 0.00739 |  0:05:52s\n",
      "epoch 39 | loss: 0.01229 | val_0_mse: 0.00737 |  0:06:01s\n",
      "epoch 40 | loss: 0.01127 | val_0_mse: 0.00729 |  0:06:10s\n",
      "epoch 41 | loss: 0.01094 | val_0_mse: 0.00739 |  0:06:19s\n",
      "epoch 42 | loss: 0.0128  | val_0_mse: 0.00741 |  0:06:28s\n",
      "epoch 43 | loss: 0.01222 | val_0_mse: 0.01261 |  0:06:37s\n",
      "epoch 44 | loss: 0.01159 | val_0_mse: 0.00991 |  0:06:45s\n",
      "epoch 45 | loss: 0.01147 | val_0_mse: 0.0118  |  0:06:54s\n",
      "epoch 46 | loss: 0.00953 | val_0_mse: 0.01007 |  0:07:03s\n",
      "epoch 47 | loss: 0.01346 | val_0_mse: 0.01701 |  0:07:12s\n",
      "epoch 48 | loss: 0.01314 | val_0_mse: 0.02405 |  0:07:21s\n",
      "epoch 49 | loss: 0.01489 | val_0_mse: 0.01229 |  0:07:30s\n",
      "epoch 50 | loss: 0.02239 | val_0_mse: 0.02391 |  0:07:39s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_mse = 0.00729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007125 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.967859 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 20/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.24903 | val_0_mse: 0.45794 |  0:00:08s\n",
      "epoch 1  | loss: 0.32404 | val_0_mse: 0.19305 |  0:00:15s\n",
      "epoch 2  | loss: 0.18306 | val_0_mse: 0.1845  |  0:00:23s\n",
      "epoch 3  | loss: 0.13586 | val_0_mse: 0.16761 |  0:00:31s\n",
      "epoch 4  | loss: 0.10712 | val_0_mse: 0.11585 |  0:00:38s\n",
      "epoch 5  | loss: 0.08994 | val_0_mse: 0.10871 |  0:00:46s\n",
      "epoch 6  | loss: 0.09907 | val_0_mse: 0.09604 |  0:00:53s\n",
      "epoch 7  | loss: 0.07152 | val_0_mse: 0.09206 |  0:01:01s\n",
      "epoch 8  | loss: 0.06734 | val_0_mse: 0.07311 |  0:01:10s\n",
      "epoch 9  | loss: 0.07202 | val_0_mse: 0.07003 |  0:01:17s\n",
      "epoch 10 | loss: 0.07277 | val_0_mse: 0.07807 |  0:01:25s\n",
      "epoch 11 | loss: 0.07273 | val_0_mse: 0.06676 |  0:01:32s\n",
      "epoch 12 | loss: 0.0671  | val_0_mse: 0.05926 |  0:01:39s\n",
      "epoch 13 | loss: 0.06387 | val_0_mse: 0.05675 |  0:01:47s\n",
      "epoch 14 | loss: 0.06339 | val_0_mse: 0.06252 |  0:01:54s\n",
      "epoch 15 | loss: 0.0565  | val_0_mse: 0.05211 |  0:02:02s\n",
      "epoch 16 | loss: 0.05446 | val_0_mse: 0.0548  |  0:02:10s\n",
      "epoch 17 | loss: 0.05219 | val_0_mse: 0.06004 |  0:02:19s\n",
      "epoch 18 | loss: 0.05152 | val_0_mse: 0.05173 |  0:02:27s\n",
      "epoch 19 | loss: 0.05008 | val_0_mse: 0.03971 |  0:02:35s\n",
      "epoch 20 | loss: 0.04183 | val_0_mse: 0.06977 |  0:02:42s\n",
      "epoch 21 | loss: 0.04503 | val_0_mse: 0.05484 |  0:02:50s\n",
      "epoch 22 | loss: 0.04142 | val_0_mse: 0.04147 |  0:02:57s\n",
      "epoch 23 | loss: 0.03734 | val_0_mse: 0.0279  |  0:03:05s\n",
      "epoch 24 | loss: 0.03264 | val_0_mse: 0.02615 |  0:03:12s\n",
      "epoch 25 | loss: 0.03114 | val_0_mse: 0.02599 |  0:03:20s\n",
      "epoch 26 | loss: 0.02839 | val_0_mse: 0.02404 |  0:03:27s\n",
      "epoch 27 | loss: 0.02759 | val_0_mse: 0.0212  |  0:03:35s\n",
      "epoch 28 | loss: 0.02429 | val_0_mse: 0.02076 |  0:03:42s\n",
      "epoch 29 | loss: 0.02127 | val_0_mse: 0.01842 |  0:03:50s\n",
      "epoch 30 | loss: 0.02133 | val_0_mse: 0.01715 |  0:03:57s\n",
      "epoch 31 | loss: 0.01873 | val_0_mse: 0.02834 |  0:04:04s\n",
      "epoch 32 | loss: 0.01937 | val_0_mse: 0.02247 |  0:04:12s\n",
      "epoch 33 | loss: 0.02012 | val_0_mse: 0.01479 |  0:04:19s\n",
      "epoch 34 | loss: 0.02091 | val_0_mse: 0.01262 |  0:04:27s\n",
      "epoch 35 | loss: 0.01453 | val_0_mse: 0.0114  |  0:04:34s\n",
      "epoch 36 | loss: 0.01713 | val_0_mse: 0.02505 |  0:04:42s\n",
      "epoch 37 | loss: 0.02191 | val_0_mse: 0.02734 |  0:04:49s\n",
      "epoch 38 | loss: 0.01662 | val_0_mse: 0.01064 |  0:04:56s\n",
      "epoch 39 | loss: 0.01398 | val_0_mse: 0.00981 |  0:05:04s\n",
      "epoch 40 | loss: 0.01558 | val_0_mse: 0.01357 |  0:05:11s\n",
      "epoch 41 | loss: 0.01547 | val_0_mse: 0.01858 |  0:05:18s\n",
      "epoch 42 | loss: 0.01456 | val_0_mse: 0.01124 |  0:05:26s\n",
      "epoch 43 | loss: 0.01216 | val_0_mse: 0.01051 |  0:05:33s\n",
      "epoch 44 | loss: 0.01209 | val_0_mse: 0.01085 |  0:05:40s\n",
      "epoch 45 | loss: 0.01226 | val_0_mse: 0.00844 |  0:05:48s\n",
      "epoch 46 | loss: 0.0116  | val_0_mse: 0.00896 |  0:05:55s\n",
      "epoch 47 | loss: 0.01471 | val_0_mse: 0.02523 |  0:06:02s\n",
      "epoch 48 | loss: 0.01456 | val_0_mse: 0.00828 |  0:06:10s\n",
      "epoch 49 | loss: 0.01615 | val_0_mse: 0.00916 |  0:06:18s\n",
      "epoch 50 | loss: 0.01552 | val_0_mse: 0.01702 |  0:06:25s\n",
      "epoch 51 | loss: 0.01243 | val_0_mse: 0.01119 |  0:06:33s\n",
      "epoch 52 | loss: 0.01346 | val_0_mse: 0.01047 |  0:06:41s\n",
      "epoch 53 | loss: 0.01426 | val_0_mse: 0.01826 |  0:06:48s\n",
      "epoch 54 | loss: 0.01168 | val_0_mse: 0.00813 |  0:06:56s\n",
      "epoch 55 | loss: 0.01101 | val_0_mse: 0.00813 |  0:07:04s\n",
      "epoch 56 | loss: 0.01121 | val_0_mse: 0.00737 |  0:07:11s\n",
      "epoch 57 | loss: 0.01446 | val_0_mse: 0.00759 |  0:07:19s\n",
      "epoch 58 | loss: 0.0102  | val_0_mse: 0.00801 |  0:07:27s\n",
      "epoch 59 | loss: 0.011   | val_0_mse: 0.00661 |  0:07:35s\n",
      "epoch 60 | loss: 0.01004 | val_0_mse: 0.00734 |  0:07:43s\n",
      "epoch 61 | loss: 0.01    | val_0_mse: 0.0069  |  0:07:50s\n",
      "epoch 62 | loss: 0.01011 | val_0_mse: 0.00869 |  0:07:58s\n",
      "epoch 63 | loss: 0.00993 | val_0_mse: 0.00881 |  0:08:06s\n",
      "epoch 64 | loss: 0.01582 | val_0_mse: 0.02721 |  0:08:13s\n",
      "epoch 65 | loss: 0.01105 | val_0_mse: 0.0114  |  0:08:21s\n",
      "epoch 66 | loss: 0.01129 | val_0_mse: 0.01276 |  0:08:28s\n",
      "epoch 67 | loss: 0.01066 | val_0_mse: 0.01192 |  0:08:37s\n",
      "epoch 68 | loss: 0.00822 | val_0_mse: 0.01011 |  0:08:45s\n",
      "epoch 69 | loss: 0.00977 | val_0_mse: 0.01401 |  0:08:52s\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_mse = 0.00661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006372 - Best MSE: 0.005770\n",
      "Model R2 Score: 0.971253 - Best R2 Score: 0.973969\n",
      "\n",
      "Iterations 21/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.57674 | val_0_mse: 0.90057 |  0:00:09s\n",
      "epoch 1  | loss: 0.29655 | val_0_mse: 0.16383 |  0:00:19s\n",
      "epoch 2  | loss: 0.09866 | val_0_mse: 0.15316 |  0:00:29s\n",
      "epoch 3  | loss: 0.07353 | val_0_mse: 0.1626  |  0:00:38s\n",
      "epoch 4  | loss: 0.06237 | val_0_mse: 0.11498 |  0:00:48s\n",
      "epoch 5  | loss: 0.0645  | val_0_mse: 0.08086 |  0:00:58s\n",
      "epoch 6  | loss: 0.06669 | val_0_mse: 0.05456 |  0:01:07s\n",
      "epoch 7  | loss: 0.05303 | val_0_mse: 0.05651 |  0:01:17s\n",
      "epoch 8  | loss: 0.0517  | val_0_mse: 0.03983 |  0:01:27s\n",
      "epoch 9  | loss: 0.0523  | val_0_mse: 0.04055 |  0:01:36s\n",
      "epoch 10 | loss: 0.04953 | val_0_mse: 0.04454 |  0:01:46s\n",
      "epoch 11 | loss: 0.05329 | val_0_mse: 0.04533 |  0:01:55s\n",
      "epoch 12 | loss: 0.0493  | val_0_mse: 0.03455 |  0:02:05s\n",
      "epoch 13 | loss: 0.05018 | val_0_mse: 0.04229 |  0:02:15s\n",
      "epoch 14 | loss: 0.04707 | val_0_mse: 0.03728 |  0:02:24s\n",
      "epoch 15 | loss: 0.05235 | val_0_mse: 0.03635 |  0:02:34s\n",
      "epoch 16 | loss: 0.0452  | val_0_mse: 0.03557 |  0:02:43s\n",
      "epoch 17 | loss: 0.05567 | val_0_mse: 0.05267 |  0:02:53s\n",
      "epoch 18 | loss: 0.05058 | val_0_mse: 0.04266 |  0:03:03s\n",
      "epoch 19 | loss: 0.04394 | val_0_mse: 0.03491 |  0:03:12s\n",
      "epoch 20 | loss: 0.04379 | val_0_mse: 0.04429 |  0:03:22s\n",
      "epoch 21 | loss: 0.0396  | val_0_mse: 0.03468 |  0:03:32s\n",
      "epoch 22 | loss: 0.04493 | val_0_mse: 0.03235 |  0:03:41s\n",
      "epoch 23 | loss: 0.04055 | val_0_mse: 0.04852 |  0:03:51s\n",
      "epoch 24 | loss: 0.03883 | val_0_mse: 0.03572 |  0:04:01s\n",
      "epoch 25 | loss: 0.03846 | val_0_mse: 0.02793 |  0:04:10s\n",
      "epoch 26 | loss: 0.04397 | val_0_mse: 0.02781 |  0:04:20s\n",
      "epoch 27 | loss: 0.03364 | val_0_mse: 0.02743 |  0:04:29s\n",
      "epoch 28 | loss: 0.03286 | val_0_mse: 0.02442 |  0:04:39s\n",
      "epoch 29 | loss: 0.03534 | val_0_mse: 0.05142 |  0:04:49s\n",
      "epoch 30 | loss: 0.02721 | val_0_mse: 0.021   |  0:04:58s\n",
      "epoch 31 | loss: 0.02557 | val_0_mse: 0.02773 |  0:05:08s\n",
      "epoch 32 | loss: 0.02603 | val_0_mse: 0.01574 |  0:05:18s\n",
      "epoch 33 | loss: 0.02191 | val_0_mse: 0.01619 |  0:05:27s\n",
      "epoch 34 | loss: 0.02013 | val_0_mse: 0.01761 |  0:05:37s\n",
      "epoch 35 | loss: 0.01568 | val_0_mse: 0.01566 |  0:05:47s\n",
      "epoch 36 | loss: 0.02196 | val_0_mse: 0.02252 |  0:05:56s\n",
      "epoch 37 | loss: 0.01968 | val_0_mse: 0.01073 |  0:06:06s\n",
      "epoch 38 | loss: 0.01698 | val_0_mse: 0.00923 |  0:06:16s\n",
      "epoch 39 | loss: 0.01478 | val_0_mse: 0.01397 |  0:06:25s\n",
      "epoch 40 | loss: 0.01574 | val_0_mse: 0.00869 |  0:06:35s\n",
      "epoch 41 | loss: 0.01398 | val_0_mse: 0.01043 |  0:06:44s\n",
      "epoch 42 | loss: 0.01363 | val_0_mse: 0.01357 |  0:06:54s\n",
      "epoch 43 | loss: 0.01941 | val_0_mse: 0.02117 |  0:07:04s\n",
      "epoch 44 | loss: 0.01021 | val_0_mse: 0.0071  |  0:07:14s\n",
      "epoch 45 | loss: 0.01143 | val_0_mse: 0.00719 |  0:07:24s\n",
      "epoch 46 | loss: 0.01388 | val_0_mse: 0.02635 |  0:07:34s\n",
      "epoch 47 | loss: 0.01307 | val_0_mse: 0.01666 |  0:07:43s\n",
      "epoch 48 | loss: 0.01171 | val_0_mse: 0.00595 |  0:07:53s\n",
      "epoch 49 | loss: 0.01557 | val_0_mse: 0.01037 |  0:08:03s\n",
      "epoch 50 | loss: 0.01414 | val_0_mse: 0.00847 |  0:08:12s\n",
      "epoch 51 | loss: 0.00975 | val_0_mse: 0.03731 |  0:08:22s\n",
      "epoch 52 | loss: 0.01533 | val_0_mse: 0.00721 |  0:08:31s\n",
      "epoch 53 | loss: 0.01133 | val_0_mse: 0.00506 |  0:08:41s\n",
      "epoch 54 | loss: 0.01048 | val_0_mse: 0.00766 |  0:08:50s\n",
      "epoch 55 | loss: 0.00959 | val_0_mse: 0.00667 |  0:09:00s\n",
      "epoch 56 | loss: 0.01012 | val_0_mse: 0.01365 |  0:09:10s\n",
      "epoch 57 | loss: 0.01199 | val_0_mse: 0.00519 |  0:09:19s\n",
      "epoch 58 | loss: 0.01026 | val_0_mse: 0.00788 |  0:09:29s\n",
      "epoch 59 | loss: 0.00984 | val_0_mse: 0.02385 |  0:09:39s\n",
      "epoch 60 | loss: 0.01108 | val_0_mse: 0.00617 |  0:09:48s\n",
      "epoch 61 | loss: 0.01356 | val_0_mse: 0.00673 |  0:09:58s\n",
      "epoch 62 | loss: 0.00909 | val_0_mse: 0.00528 |  0:10:08s\n",
      "epoch 63 | loss: 0.01111 | val_0_mse: 0.00665 |  0:10:18s\n",
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_mse = 0.00506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.005215 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.976475 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 22/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.16193 | val_0_mse: 0.9597  |  0:00:08s\n",
      "epoch 1  | loss: 0.2707  | val_0_mse: 0.27125 |  0:00:16s\n",
      "epoch 2  | loss: 0.14552 | val_0_mse: 0.19905 |  0:00:24s\n",
      "epoch 3  | loss: 0.16095 | val_0_mse: 0.18414 |  0:00:32s\n",
      "epoch 4  | loss: 0.08616 | val_0_mse: 0.12566 |  0:00:40s\n",
      "epoch 5  | loss: 0.07917 | val_0_mse: 0.10735 |  0:00:48s\n",
      "epoch 6  | loss: 0.0628  | val_0_mse: 0.09979 |  0:00:56s\n",
      "epoch 7  | loss: 0.05187 | val_0_mse: 0.10569 |  0:01:04s\n",
      "epoch 8  | loss: 0.05105 | val_0_mse: 0.09051 |  0:01:12s\n",
      "epoch 9  | loss: 0.05366 | val_0_mse: 0.10236 |  0:01:20s\n",
      "epoch 10 | loss: 0.04961 | val_0_mse: 0.0905  |  0:01:28s\n",
      "epoch 11 | loss: 0.05029 | val_0_mse: 0.0457  |  0:01:36s\n",
      "epoch 12 | loss: 0.05671 | val_0_mse: 0.04234 |  0:01:45s\n",
      "epoch 13 | loss: 0.0628  | val_0_mse: 0.04027 |  0:01:53s\n",
      "epoch 14 | loss: 0.0504  | val_0_mse: 0.0692  |  0:02:01s\n",
      "epoch 15 | loss: 0.04978 | val_0_mse: 0.03647 |  0:02:09s\n",
      "epoch 16 | loss: 0.04849 | val_0_mse: 0.0383  |  0:02:16s\n",
      "epoch 17 | loss: 0.04648 | val_0_mse: 0.03694 |  0:02:24s\n",
      "epoch 18 | loss: 0.04729 | val_0_mse: 0.03849 |  0:02:32s\n",
      "epoch 19 | loss: 0.05168 | val_0_mse: 0.04826 |  0:02:40s\n",
      "epoch 20 | loss: 0.04668 | val_0_mse: 0.06464 |  0:02:47s\n",
      "epoch 21 | loss: 0.06636 | val_0_mse: 0.08509 |  0:02:55s\n",
      "epoch 22 | loss: 0.04632 | val_0_mse: 0.07708 |  0:03:03s\n",
      "epoch 23 | loss: 0.04895 | val_0_mse: 0.04147 |  0:03:11s\n",
      "epoch 24 | loss: 0.04261 | val_0_mse: 0.03684 |  0:03:18s\n",
      "epoch 25 | loss: 0.04452 | val_0_mse: 0.03344 |  0:03:26s\n",
      "epoch 26 | loss: 0.04027 | val_0_mse: 0.03313 |  0:03:34s\n",
      "epoch 27 | loss: 0.04947 | val_0_mse: 0.05291 |  0:03:41s\n",
      "epoch 28 | loss: 0.04973 | val_0_mse: 0.04396 |  0:03:49s\n",
      "epoch 29 | loss: 0.04179 | val_0_mse: 0.03354 |  0:03:57s\n",
      "epoch 30 | loss: 0.04034 | val_0_mse: 0.03838 |  0:04:05s\n",
      "epoch 31 | loss: 0.04459 | val_0_mse: 0.03588 |  0:04:13s\n",
      "epoch 32 | loss: 0.0384  | val_0_mse: 0.03975 |  0:04:21s\n",
      "epoch 33 | loss: 0.0422  | val_0_mse: 0.04256 |  0:04:29s\n",
      "epoch 34 | loss: 0.03806 | val_0_mse: 0.04535 |  0:04:36s\n",
      "epoch 35 | loss: 0.04014 | val_0_mse: 0.03338 |  0:04:44s\n",
      "epoch 36 | loss: 0.04606 | val_0_mse: 0.0335  |  0:04:52s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_mse = 0.03313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.034014 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.846552 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 23/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.70208 | val_0_mse: 0.33373 |  0:00:10s\n",
      "epoch 1  | loss: 0.27153 | val_0_mse: 0.19291 |  0:00:20s\n",
      "epoch 2  | loss: 0.1464  | val_0_mse: 0.12456 |  0:00:30s\n",
      "epoch 3  | loss: 0.12291 | val_0_mse: 0.12573 |  0:00:40s\n",
      "epoch 4  | loss: 0.12575 | val_0_mse: 0.13644 |  0:00:50s\n",
      "epoch 5  | loss: 0.10203 | val_0_mse: 0.07834 |  0:01:01s\n",
      "epoch 6  | loss: 0.08805 | val_0_mse: 0.06289 |  0:01:11s\n",
      "epoch 7  | loss: 0.06833 | val_0_mse: 0.06506 |  0:01:21s\n",
      "epoch 8  | loss: 0.05757 | val_0_mse: 0.04269 |  0:01:32s\n",
      "epoch 9  | loss: 0.04947 | val_0_mse: 0.04623 |  0:01:42s\n",
      "epoch 10 | loss: 0.04715 | val_0_mse: 0.05258 |  0:01:52s\n",
      "epoch 11 | loss: 0.04492 | val_0_mse: 0.04439 |  0:02:02s\n",
      "epoch 12 | loss: 0.03883 | val_0_mse: 0.02361 |  0:02:12s\n",
      "epoch 13 | loss: 0.03618 | val_0_mse: 0.03027 |  0:02:22s\n",
      "epoch 14 | loss: 0.02902 | val_0_mse: 0.0197  |  0:02:33s\n",
      "epoch 15 | loss: 0.03057 | val_0_mse: 0.08094 |  0:02:43s\n",
      "epoch 16 | loss: 0.02436 | val_0_mse: 0.01842 |  0:02:53s\n",
      "epoch 17 | loss: 0.01885 | val_0_mse: 0.0117  |  0:03:03s\n",
      "epoch 18 | loss: 0.01797 | val_0_mse: 0.01177 |  0:03:14s\n",
      "epoch 19 | loss: 0.01752 | val_0_mse: 0.01198 |  0:03:24s\n",
      "epoch 20 | loss: 0.01776 | val_0_mse: 0.01027 |  0:03:34s\n",
      "epoch 21 | loss: 0.01512 | val_0_mse: 0.01108 |  0:03:44s\n",
      "epoch 22 | loss: 0.01723 | val_0_mse: 0.00854 |  0:03:54s\n",
      "epoch 23 | loss: 0.01772 | val_0_mse: 0.01251 |  0:04:04s\n",
      "epoch 24 | loss: 0.01507 | val_0_mse: 0.00959 |  0:04:14s\n",
      "epoch 25 | loss: 0.0142  | val_0_mse: 0.01096 |  0:04:25s\n",
      "epoch 26 | loss: 0.02184 | val_0_mse: 0.01839 |  0:04:35s\n",
      "epoch 27 | loss: 0.01783 | val_0_mse: 0.01244 |  0:04:45s\n",
      "epoch 28 | loss: 0.01414 | val_0_mse: 0.02047 |  0:04:56s\n",
      "epoch 29 | loss: 0.01562 | val_0_mse: 0.02231 |  0:05:06s\n",
      "epoch 30 | loss: 0.01541 | val_0_mse: 0.01843 |  0:05:16s\n",
      "epoch 31 | loss: 0.01411 | val_0_mse: 0.00982 |  0:05:26s\n",
      "epoch 32 | loss: 0.01303 | val_0_mse: 0.01328 |  0:05:37s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_mse = 0.00854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008087 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.963515 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 24/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=16, n_a=16, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.89894 | val_0_mse: 0.67933 |  0:00:08s\n",
      "epoch 1  | loss: 0.33779 | val_0_mse: 0.36072 |  0:00:17s\n",
      "epoch 2  | loss: 0.2284  | val_0_mse: 0.19276 |  0:00:26s\n",
      "epoch 3  | loss: 0.17122 | val_0_mse: 0.17385 |  0:00:35s\n",
      "epoch 4  | loss: 0.11649 | val_0_mse: 0.11546 |  0:00:44s\n",
      "epoch 5  | loss: 0.12219 | val_0_mse: 0.15315 |  0:00:53s\n",
      "epoch 6  | loss: 0.10139 | val_0_mse: 0.10579 |  0:01:02s\n",
      "epoch 7  | loss: 0.07623 | val_0_mse: 0.089   |  0:01:11s\n",
      "epoch 8  | loss: 0.06773 | val_0_mse: 0.1089  |  0:01:19s\n",
      "epoch 9  | loss: 0.06421 | val_0_mse: 0.07605 |  0:01:28s\n",
      "epoch 10 | loss: 0.05597 | val_0_mse: 0.10503 |  0:01:37s\n",
      "epoch 11 | loss: 0.05509 | val_0_mse: 0.0743  |  0:01:46s\n",
      "epoch 12 | loss: 0.05338 | val_0_mse: 0.05355 |  0:01:55s\n",
      "epoch 13 | loss: 0.05137 | val_0_mse: 0.05063 |  0:02:03s\n",
      "epoch 14 | loss: 0.0516  | val_0_mse: 0.0582  |  0:02:12s\n",
      "epoch 15 | loss: 0.05197 | val_0_mse: 0.04366 |  0:02:21s\n",
      "epoch 16 | loss: 0.04809 | val_0_mse: 0.06457 |  0:02:30s\n",
      "epoch 17 | loss: 0.05089 | val_0_mse: 0.04648 |  0:02:38s\n",
      "epoch 18 | loss: 0.05087 | val_0_mse: 0.0589  |  0:02:47s\n",
      "epoch 19 | loss: 0.04783 | val_0_mse: 0.04123 |  0:02:56s\n",
      "epoch 20 | loss: 0.05118 | val_0_mse: 0.04203 |  0:03:05s\n",
      "epoch 21 | loss: 0.04867 | val_0_mse: 0.05032 |  0:03:14s\n",
      "epoch 22 | loss: 0.05172 | val_0_mse: 0.04503 |  0:03:23s\n",
      "epoch 23 | loss: 0.04876 | val_0_mse: 0.04077 |  0:03:31s\n",
      "epoch 24 | loss: 0.05158 | val_0_mse: 0.04043 |  0:03:40s\n",
      "epoch 25 | loss: 0.05241 | val_0_mse: 0.05594 |  0:03:49s\n",
      "epoch 26 | loss: 0.05384 | val_0_mse: 0.04359 |  0:03:58s\n",
      "epoch 27 | loss: 0.04921 | val_0_mse: 0.05595 |  0:04:07s\n",
      "epoch 28 | loss: 0.04635 | val_0_mse: 0.04543 |  0:04:15s\n",
      "epoch 29 | loss: 0.05269 | val_0_mse: 0.04782 |  0:04:24s\n",
      "epoch 30 | loss: 0.04726 | val_0_mse: 0.03636 |  0:04:33s\n",
      "epoch 31 | loss: 0.04494 | val_0_mse: 0.03916 |  0:04:41s\n",
      "epoch 32 | loss: 0.04691 | val_0_mse: 0.05136 |  0:04:50s\n",
      "epoch 33 | loss: 0.04594 | val_0_mse: 0.04303 |  0:04:59s\n",
      "epoch 34 | loss: 0.04369 | val_0_mse: 0.0412  |  0:05:07s\n",
      "epoch 35 | loss: 0.04602 | val_0_mse: 0.04712 |  0:05:16s\n",
      "epoch 36 | loss: 0.04112 | val_0_mse: 0.03368 |  0:05:24s\n",
      "epoch 37 | loss: 0.04204 | val_0_mse: 0.05458 |  0:05:33s\n",
      "epoch 38 | loss: 0.049   | val_0_mse: 0.07593 |  0:05:42s\n",
      "epoch 39 | loss: 0.04068 | val_0_mse: 0.03134 |  0:05:50s\n",
      "epoch 40 | loss: 0.03527 | val_0_mse: 0.02601 |  0:05:59s\n",
      "epoch 41 | loss: 0.03237 | val_0_mse: 0.02718 |  0:06:08s\n",
      "epoch 42 | loss: 0.0326  | val_0_mse: 0.03402 |  0:06:17s\n",
      "epoch 43 | loss: 0.03207 | val_0_mse: 0.0349  |  0:06:25s\n",
      "epoch 44 | loss: 0.04355 | val_0_mse: 0.04297 |  0:06:33s\n",
      "epoch 45 | loss: 0.04042 | val_0_mse: 0.03656 |  0:06:42s\n",
      "epoch 46 | loss: 0.03354 | val_0_mse: 0.02688 |  0:06:50s\n",
      "epoch 47 | loss: 0.03907 | val_0_mse: 0.03224 |  0:06:58s\n",
      "epoch 48 | loss: 0.03376 | val_0_mse: 0.02659 |  0:07:07s\n",
      "epoch 49 | loss: 0.03588 | val_0_mse: 0.02562 |  0:07:15s\n",
      "epoch 50 | loss: 0.02883 | val_0_mse: 0.026   |  0:07:23s\n",
      "epoch 51 | loss: 0.03066 | val_0_mse: 0.02854 |  0:07:32s\n",
      "epoch 52 | loss: 0.03304 | val_0_mse: 0.03097 |  0:07:40s\n",
      "epoch 53 | loss: 0.02862 | val_0_mse: 0.02722 |  0:07:48s\n",
      "epoch 54 | loss: 0.02359 | val_0_mse: 0.01943 |  0:07:57s\n",
      "epoch 55 | loss: 0.0229  | val_0_mse: 0.02066 |  0:08:05s\n",
      "epoch 56 | loss: 0.02412 | val_0_mse: 0.02213 |  0:08:14s\n",
      "epoch 57 | loss: 0.02197 | val_0_mse: 0.02158 |  0:08:22s\n",
      "epoch 58 | loss: 0.023   | val_0_mse: 0.03148 |  0:08:31s\n",
      "epoch 59 | loss: 0.02385 | val_0_mse: 0.02408 |  0:08:39s\n",
      "epoch 60 | loss: 0.02368 | val_0_mse: 0.02214 |  0:08:48s\n",
      "epoch 61 | loss: 0.02409 | val_0_mse: 0.02126 |  0:08:56s\n",
      "epoch 62 | loss: 0.02276 | val_0_mse: 0.02016 |  0:09:05s\n",
      "epoch 63 | loss: 0.02297 | val_0_mse: 0.02001 |  0:09:13s\n",
      "epoch 64 | loss: 0.02376 | val_0_mse: 0.02111 |  0:09:22s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_mse = 0.01943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.020108 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.909288 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 25/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.66981 | val_0_mse: 0.86477 |  0:00:09s\n",
      "epoch 1  | loss: 0.38589 | val_0_mse: 0.25358 |  0:00:20s\n",
      "epoch 2  | loss: 0.1645  | val_0_mse: 0.21094 |  0:00:29s\n",
      "epoch 3  | loss: 0.1114  | val_0_mse: 0.10149 |  0:00:39s\n",
      "epoch 4  | loss: 0.0882  | val_0_mse: 0.11674 |  0:00:49s\n",
      "epoch 5  | loss: 0.0838  | val_0_mse: 0.06493 |  0:00:58s\n",
      "epoch 6  | loss: 0.08127 | val_0_mse: 0.08925 |  0:01:08s\n",
      "epoch 7  | loss: 0.07583 | val_0_mse: 0.05426 |  0:01:18s\n",
      "epoch 8  | loss: 0.06728 | val_0_mse: 0.05249 |  0:01:28s\n",
      "epoch 9  | loss: 0.06524 | val_0_mse: 0.04116 |  0:01:37s\n",
      "epoch 10 | loss: 0.05436 | val_0_mse: 0.04276 |  0:01:49s\n",
      "epoch 11 | loss: 0.05185 | val_0_mse: 0.03525 |  0:01:58s\n",
      "epoch 12 | loss: 0.0446  | val_0_mse: 0.03386 |  0:02:06s\n",
      "epoch 13 | loss: 0.04312 | val_0_mse: 0.03407 |  0:02:15s\n",
      "epoch 14 | loss: 0.04295 | val_0_mse: 0.03411 |  0:02:24s\n",
      "epoch 15 | loss: 0.03221 | val_0_mse: 0.02796 |  0:02:35s\n",
      "epoch 16 | loss: 0.03354 | val_0_mse: 0.0251  |  0:02:45s\n",
      "epoch 17 | loss: 0.03225 | val_0_mse: 0.0268  |  0:02:53s\n",
      "epoch 18 | loss: 0.03712 | val_0_mse: 0.02791 |  0:03:02s\n",
      "epoch 19 | loss: 0.02528 | val_0_mse: 0.02689 |  0:03:11s\n",
      "epoch 20 | loss: 0.03182 | val_0_mse: 0.02795 |  0:03:20s\n",
      "epoch 21 | loss: 0.03336 | val_0_mse: 0.02355 |  0:03:29s\n",
      "epoch 22 | loss: 0.02849 | val_0_mse: 0.03091 |  0:03:38s\n",
      "epoch 23 | loss: 0.02669 | val_0_mse: 0.02031 |  0:03:47s\n",
      "epoch 24 | loss: 0.02486 | val_0_mse: 0.01963 |  0:03:56s\n",
      "epoch 25 | loss: 0.02291 | val_0_mse: 0.0195  |  0:04:05s\n",
      "epoch 26 | loss: 0.02369 | val_0_mse: 0.04365 |  0:04:13s\n",
      "epoch 27 | loss: 0.0203  | val_0_mse: 0.0199  |  0:04:22s\n",
      "epoch 28 | loss: 0.02389 | val_0_mse: 0.01255 |  0:04:31s\n",
      "epoch 29 | loss: 0.01633 | val_0_mse: 0.01143 |  0:04:40s\n",
      "epoch 30 | loss: 0.01703 | val_0_mse: 0.0087  |  0:04:49s\n",
      "epoch 31 | loss: 0.01452 | val_0_mse: 0.02069 |  0:04:58s\n",
      "epoch 32 | loss: 0.01518 | val_0_mse: 0.0141  |  0:05:07s\n",
      "epoch 33 | loss: 0.01351 | val_0_mse: 0.00799 |  0:05:16s\n",
      "epoch 34 | loss: 0.01403 | val_0_mse: 0.00994 |  0:05:25s\n",
      "epoch 35 | loss: 0.01587 | val_0_mse: 0.01029 |  0:05:34s\n",
      "epoch 36 | loss: 0.01889 | val_0_mse: 0.01014 |  0:05:43s\n",
      "epoch 37 | loss: 0.01644 | val_0_mse: 0.01188 |  0:05:52s\n",
      "epoch 38 | loss: 0.0159  | val_0_mse: 0.00898 |  0:06:01s\n",
      "epoch 39 | loss: 0.01605 | val_0_mse: 0.04188 |  0:06:10s\n",
      "epoch 40 | loss: 0.01249 | val_0_mse: 0.01323 |  0:06:19s\n",
      "epoch 41 | loss: 0.01168 | val_0_mse: 0.00664 |  0:06:28s\n",
      "epoch 42 | loss: 0.01435 | val_0_mse: 0.01    |  0:06:36s\n",
      "epoch 43 | loss: 0.01668 | val_0_mse: 0.02372 |  0:06:45s\n",
      "epoch 44 | loss: 0.02699 | val_0_mse: 0.01611 |  0:06:54s\n",
      "epoch 45 | loss: 0.02017 | val_0_mse: 0.02921 |  0:07:03s\n",
      "epoch 46 | loss: 0.01601 | val_0_mse: 0.02336 |  0:07:12s\n",
      "epoch 47 | loss: 0.01455 | val_0_mse: 0.02596 |  0:07:21s\n",
      "epoch 48 | loss: 0.01415 | val_0_mse: 0.00972 |  0:07:30s\n",
      "epoch 49 | loss: 0.01488 | val_0_mse: 0.01634 |  0:07:39s\n",
      "epoch 50 | loss: 0.01546 | val_0_mse: 0.02599 |  0:07:48s\n",
      "epoch 51 | loss: 0.0192  | val_0_mse: 0.03158 |  0:07:57s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_mse = 0.00664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007129 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.967840 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 26/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.48425 | val_0_mse: 0.42467 |  0:00:08s\n",
      "epoch 1  | loss: 0.30259 | val_0_mse: 0.22674 |  0:00:15s\n",
      "epoch 2  | loss: 0.18176 | val_0_mse: 0.19478 |  0:00:23s\n",
      "epoch 3  | loss: 0.15493 | val_0_mse: 0.15864 |  0:00:31s\n",
      "epoch 4  | loss: 0.11208 | val_0_mse: 0.18422 |  0:00:39s\n",
      "epoch 5  | loss: 0.09622 | val_0_mse: 0.12208 |  0:00:46s\n",
      "epoch 6  | loss: 0.10197 | val_0_mse: 0.10867 |  0:00:54s\n",
      "epoch 7  | loss: 0.07046 | val_0_mse: 0.08876 |  0:01:02s\n",
      "epoch 8  | loss: 0.06815 | val_0_mse: 0.08604 |  0:01:10s\n",
      "epoch 9  | loss: 0.0743  | val_0_mse: 0.09844 |  0:01:17s\n",
      "epoch 10 | loss: 0.08927 | val_0_mse: 0.13224 |  0:01:25s\n",
      "epoch 11 | loss: 0.09079 | val_0_mse: 0.07857 |  0:01:33s\n",
      "epoch 12 | loss: 0.07374 | val_0_mse: 0.07111 |  0:01:40s\n",
      "epoch 13 | loss: 0.07023 | val_0_mse: 0.06819 |  0:01:48s\n",
      "epoch 14 | loss: 0.06693 | val_0_mse: 0.06376 |  0:01:56s\n",
      "epoch 15 | loss: 0.06366 | val_0_mse: 0.06923 |  0:02:03s\n",
      "epoch 16 | loss: 0.06967 | val_0_mse: 0.07742 |  0:02:11s\n",
      "epoch 17 | loss: 0.06365 | val_0_mse: 0.05872 |  0:02:19s\n",
      "epoch 18 | loss: 0.06109 | val_0_mse: 0.06248 |  0:02:26s\n",
      "epoch 19 | loss: 0.06032 | val_0_mse: 0.07296 |  0:02:35s\n",
      "epoch 20 | loss: 0.06151 | val_0_mse: 0.08094 |  0:02:43s\n",
      "epoch 21 | loss: 0.05828 | val_0_mse: 0.04877 |  0:02:50s\n",
      "epoch 22 | loss: 0.05814 | val_0_mse: 0.07099 |  0:02:58s\n",
      "epoch 23 | loss: 0.07121 | val_0_mse: 0.0779  |  0:03:05s\n",
      "epoch 24 | loss: 0.06262 | val_0_mse: 0.05253 |  0:03:13s\n",
      "epoch 25 | loss: 0.07185 | val_0_mse: 0.05149 |  0:03:21s\n",
      "epoch 26 | loss: 0.06314 | val_0_mse: 0.0771  |  0:03:28s\n",
      "epoch 27 | loss: 0.06134 | val_0_mse: 0.05681 |  0:03:36s\n",
      "epoch 28 | loss: 0.06468 | val_0_mse: 0.05901 |  0:03:44s\n",
      "epoch 29 | loss: 0.0611  | val_0_mse: 0.052   |  0:03:51s\n",
      "epoch 30 | loss: 0.05982 | val_0_mse: 0.06481 |  0:03:59s\n",
      "epoch 31 | loss: 0.06498 | val_0_mse: 0.05226 |  0:04:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mse = 0.04877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.054098 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.755950 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 27/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.59417 | val_0_mse: 0.50761 |  0:00:10s\n",
      "epoch 1  | loss: 0.69847 | val_0_mse: 0.18381 |  0:00:20s\n",
      "epoch 2  | loss: 0.23715 | val_0_mse: 0.30488 |  0:00:31s\n",
      "epoch 3  | loss: 0.1538  | val_0_mse: 0.13812 |  0:00:40s\n",
      "epoch 4  | loss: 0.12917 | val_0_mse: 0.09532 |  0:00:50s\n",
      "epoch 5  | loss: 0.10993 | val_0_mse: 0.07416 |  0:01:00s\n",
      "epoch 6  | loss: 0.08698 | val_0_mse: 0.08308 |  0:01:12s\n",
      "epoch 7  | loss: 0.07897 | val_0_mse: 0.08261 |  0:01:22s\n",
      "epoch 8  | loss: 0.07809 | val_0_mse: 0.06861 |  0:01:32s\n",
      "epoch 9  | loss: 0.08068 | val_0_mse: 0.07816 |  0:01:43s\n",
      "epoch 10 | loss: 0.06893 | val_0_mse: 0.06391 |  0:01:52s\n",
      "epoch 11 | loss: 0.05964 | val_0_mse: 0.05734 |  0:02:02s\n",
      "epoch 12 | loss: 0.04964 | val_0_mse: 0.04541 |  0:02:12s\n",
      "epoch 13 | loss: 0.04359 | val_0_mse: 0.04066 |  0:02:22s\n",
      "epoch 14 | loss: 0.0428  | val_0_mse: 0.04026 |  0:02:32s\n",
      "epoch 15 | loss: 0.04055 | val_0_mse: 0.03489 |  0:02:42s\n",
      "epoch 16 | loss: 0.03115 | val_0_mse: 0.02912 |  0:02:51s\n",
      "epoch 17 | loss: 0.03013 | val_0_mse: 0.01771 |  0:03:01s\n",
      "epoch 18 | loss: 0.04048 | val_0_mse: 0.02128 |  0:03:11s\n",
      "epoch 19 | loss: 0.02968 | val_0_mse: 0.034   |  0:03:21s\n",
      "epoch 20 | loss: 0.03539 | val_0_mse: 0.02072 |  0:03:31s\n",
      "epoch 21 | loss: 0.02428 | val_0_mse: 0.01497 |  0:03:41s\n",
      "epoch 22 | loss: 0.02195 | val_0_mse: 0.01343 |  0:03:50s\n",
      "epoch 23 | loss: 0.01922 | val_0_mse: 0.01206 |  0:04:00s\n",
      "epoch 24 | loss: 0.01847 | val_0_mse: 0.01325 |  0:04:10s\n",
      "epoch 25 | loss: 0.01948 | val_0_mse: 0.01226 |  0:04:20s\n",
      "epoch 26 | loss: 0.01967 | val_0_mse: 0.01171 |  0:04:30s\n",
      "epoch 27 | loss: 0.01981 | val_0_mse: 0.01171 |  0:04:40s\n",
      "epoch 28 | loss: 0.01625 | val_0_mse: 0.02269 |  0:04:49s\n",
      "epoch 29 | loss: 0.01558 | val_0_mse: 0.01125 |  0:04:59s\n",
      "epoch 30 | loss: 0.01446 | val_0_mse: 0.015   |  0:05:09s\n",
      "epoch 31 | loss: 0.01404 | val_0_mse: 0.02516 |  0:05:19s\n",
      "epoch 32 | loss: 0.01526 | val_0_mse: 0.01108 |  0:05:29s\n",
      "epoch 33 | loss: 0.01326 | val_0_mse: 0.01025 |  0:05:39s\n",
      "epoch 34 | loss: 0.01191 | val_0_mse: 0.0154  |  0:05:52s\n",
      "epoch 35 | loss: 0.01199 | val_0_mse: 0.01619 |  0:06:01s\n",
      "epoch 36 | loss: 0.01295 | val_0_mse: 0.01854 |  0:06:11s\n",
      "epoch 37 | loss: 0.01187 | val_0_mse: 0.00953 |  0:06:20s\n",
      "epoch 38 | loss: 0.01254 | val_0_mse: 0.00954 |  0:06:30s\n",
      "epoch 39 | loss: 0.01319 | val_0_mse: 0.01029 |  0:06:40s\n",
      "epoch 40 | loss: 0.01184 | val_0_mse: 0.02101 |  0:06:49s\n",
      "epoch 41 | loss: 0.01151 | val_0_mse: 0.00738 |  0:06:59s\n",
      "epoch 42 | loss: 0.00994 | val_0_mse: 0.01055 |  0:07:09s\n",
      "epoch 43 | loss: 0.01196 | val_0_mse: 0.00778 |  0:07:18s\n",
      "epoch 44 | loss: 0.01151 | val_0_mse: 0.01902 |  0:07:28s\n",
      "epoch 45 | loss: 0.01246 | val_0_mse: 0.01028 |  0:07:37s\n",
      "epoch 46 | loss: 0.01013 | val_0_mse: 0.01012 |  0:07:47s\n",
      "epoch 47 | loss: 0.01641 | val_0_mse: 0.01177 |  0:07:57s\n",
      "epoch 48 | loss: 0.01049 | val_0_mse: 0.00885 |  0:08:06s\n",
      "epoch 49 | loss: 0.01816 | val_0_mse: 0.07116 |  0:08:16s\n",
      "epoch 50 | loss: 0.01749 | val_0_mse: 0.02199 |  0:08:26s\n",
      "epoch 51 | loss: 0.01541 | val_0_mse: 0.01705 |  0:08:35s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_mse = 0.00738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006488 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.970733 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 28/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.20637 | val_0_mse: 0.87612 |  0:00:08s\n",
      "epoch 1  | loss: 0.46404 | val_0_mse: 0.29606 |  0:00:17s\n",
      "epoch 2  | loss: 0.28943 | val_0_mse: 0.32063 |  0:00:25s\n",
      "epoch 3  | loss: 0.19186 | val_0_mse: 0.16895 |  0:00:34s\n",
      "epoch 4  | loss: 0.14743 | val_0_mse: 0.1525  |  0:00:42s\n",
      "epoch 5  | loss: 0.16221 | val_0_mse: 0.10045 |  0:00:51s\n",
      "epoch 6  | loss: 0.0968  | val_0_mse: 0.10545 |  0:00:59s\n",
      "epoch 7  | loss: 0.0991  | val_0_mse: 0.07172 |  0:01:07s\n",
      "epoch 8  | loss: 0.08132 | val_0_mse: 0.07344 |  0:01:16s\n",
      "epoch 9  | loss: 0.08387 | val_0_mse: 0.07945 |  0:01:24s\n",
      "epoch 10 | loss: 0.07617 | val_0_mse: 0.06983 |  0:01:32s\n",
      "epoch 11 | loss: 0.0748  | val_0_mse: 0.06081 |  0:01:41s\n",
      "epoch 12 | loss: 0.08181 | val_0_mse: 0.06654 |  0:01:49s\n",
      "epoch 13 | loss: 0.07615 | val_0_mse: 0.05543 |  0:01:57s\n",
      "epoch 14 | loss: 0.07465 | val_0_mse: 0.06877 |  0:02:06s\n",
      "epoch 15 | loss: 0.07273 | val_0_mse: 0.05984 |  0:02:14s\n",
      "epoch 16 | loss: 0.06954 | val_0_mse: 0.06095 |  0:02:23s\n",
      "epoch 17 | loss: 0.07954 | val_0_mse: 0.06435 |  0:02:32s\n",
      "epoch 18 | loss: 0.07169 | val_0_mse: 0.09168 |  0:02:41s\n",
      "epoch 19 | loss: 0.06982 | val_0_mse: 0.05576 |  0:02:50s\n",
      "epoch 20 | loss: 0.06007 | val_0_mse: 0.05168 |  0:02:58s\n",
      "epoch 21 | loss: 0.05703 | val_0_mse: 0.05151 |  0:03:06s\n",
      "epoch 22 | loss: 0.05779 | val_0_mse: 0.04901 |  0:03:15s\n",
      "epoch 23 | loss: 0.05419 | val_0_mse: 0.04692 |  0:03:23s\n",
      "epoch 24 | loss: 0.05503 | val_0_mse: 0.05051 |  0:03:32s\n",
      "epoch 25 | loss: 0.0544  | val_0_mse: 0.05553 |  0:03:40s\n",
      "epoch 26 | loss: 0.05419 | val_0_mse: 0.04814 |  0:03:48s\n",
      "epoch 27 | loss: 0.05153 | val_0_mse: 0.04892 |  0:03:57s\n",
      "epoch 28 | loss: 0.05233 | val_0_mse: 0.08004 |  0:04:05s\n",
      "epoch 29 | loss: 0.05443 | val_0_mse: 0.05257 |  0:04:14s\n",
      "epoch 30 | loss: 0.04806 | val_0_mse: 0.04406 |  0:04:22s\n",
      "epoch 31 | loss: 0.05555 | val_0_mse: 0.04783 |  0:04:30s\n",
      "epoch 32 | loss: 0.05002 | val_0_mse: 0.04954 |  0:04:39s\n",
      "epoch 33 | loss: 0.04863 | val_0_mse: 0.04201 |  0:04:47s\n",
      "epoch 34 | loss: 0.04874 | val_0_mse: 0.04723 |  0:04:55s\n",
      "epoch 35 | loss: 0.05361 | val_0_mse: 0.05043 |  0:05:04s\n",
      "epoch 36 | loss: 0.04918 | val_0_mse: 0.03785 |  0:05:12s\n",
      "epoch 37 | loss: 0.04773 | val_0_mse: 0.03801 |  0:05:21s\n",
      "epoch 38 | loss: 0.04388 | val_0_mse: 0.03805 |  0:05:29s\n",
      "epoch 39 | loss: 0.043   | val_0_mse: 0.03627 |  0:05:38s\n",
      "epoch 40 | loss: 0.03715 | val_0_mse: 0.0342  |  0:05:46s\n",
      "epoch 41 | loss: 0.03916 | val_0_mse: 0.04454 |  0:05:54s\n",
      "epoch 42 | loss: 0.04199 | val_0_mse: 0.03972 |  0:06:03s\n",
      "epoch 43 | loss: 0.05096 | val_0_mse: 0.04165 |  0:06:11s\n",
      "epoch 44 | loss: 0.03959 | val_0_mse: 0.03882 |  0:06:20s\n",
      "epoch 45 | loss: 0.03713 | val_0_mse: 0.03368 |  0:06:28s\n",
      "epoch 46 | loss: 0.03651 | val_0_mse: 0.03202 |  0:06:37s\n",
      "epoch 47 | loss: 0.03588 | val_0_mse: 0.03632 |  0:06:46s\n",
      "epoch 48 | loss: 0.03815 | val_0_mse: 0.03439 |  0:06:54s\n",
      "epoch 49 | loss: 0.03832 | val_0_mse: 0.0288  |  0:07:02s\n",
      "epoch 50 | loss: 0.03351 | val_0_mse: 0.0263  |  0:07:10s\n",
      "epoch 51 | loss: 0.03176 | val_0_mse: 0.03258 |  0:07:19s\n",
      "epoch 52 | loss: 0.0307  | val_0_mse: 0.02474 |  0:07:27s\n",
      "epoch 53 | loss: 0.02856 | val_0_mse: 0.02285 |  0:07:35s\n",
      "epoch 54 | loss: 0.02989 | val_0_mse: 0.0225  |  0:07:44s\n",
      "epoch 55 | loss: 0.02573 | val_0_mse: 0.02173 |  0:07:52s\n",
      "epoch 56 | loss: 0.02423 | val_0_mse: 0.02067 |  0:08:01s\n",
      "epoch 57 | loss: 0.02533 | val_0_mse: 0.0185  |  0:08:09s\n",
      "epoch 58 | loss: 0.02466 | val_0_mse: 0.03574 |  0:08:18s\n",
      "epoch 59 | loss: 0.03165 | val_0_mse: 0.0191  |  0:08:26s\n",
      "epoch 60 | loss: 0.0248  | val_0_mse: 0.03182 |  0:08:34s\n",
      "epoch 61 | loss: 0.03362 | val_0_mse: 0.01888 |  0:08:43s\n",
      "epoch 62 | loss: 0.02005 | val_0_mse: 0.01645 |  0:08:51s\n",
      "epoch 63 | loss: 0.01866 | val_0_mse: 0.0151  |  0:09:00s\n",
      "epoch 64 | loss: 0.01634 | val_0_mse: 0.01168 |  0:09:08s\n",
      "epoch 65 | loss: 0.01467 | val_0_mse: 0.01468 |  0:09:16s\n",
      "epoch 66 | loss: 0.01729 | val_0_mse: 0.01462 |  0:09:25s\n",
      "epoch 67 | loss: 0.01392 | val_0_mse: 0.01025 |  0:09:33s\n",
      "epoch 68 | loss: 0.01556 | val_0_mse: 0.01823 |  0:09:42s\n",
      "epoch 69 | loss: 0.01849 | val_0_mse: 0.01945 |  0:09:50s\n",
      "epoch 70 | loss: 0.02276 | val_0_mse: 0.01369 |  0:09:58s\n",
      "epoch 71 | loss: 0.01811 | val_0_mse: 0.01633 |  0:10:07s\n",
      "epoch 72 | loss: 0.0144  | val_0_mse: 0.01709 |  0:10:15s\n",
      "epoch 73 | loss: 0.01534 | val_0_mse: 0.01021 |  0:10:23s\n",
      "epoch 74 | loss: 0.01268 | val_0_mse: 0.00977 |  0:10:32s\n",
      "epoch 75 | loss: 0.01395 | val_0_mse: 0.00914 |  0:10:40s\n",
      "epoch 76 | loss: 0.01382 | val_0_mse: 0.0187  |  0:10:49s\n",
      "epoch 77 | loss: 0.01392 | val_0_mse: 0.00984 |  0:10:57s\n",
      "epoch 78 | loss: 0.01892 | val_0_mse: 0.00984 |  0:11:05s\n",
      "epoch 79 | loss: 0.01119 | val_0_mse: 0.00829 |  0:11:13s\n",
      "epoch 80 | loss: 0.01296 | val_0_mse: 0.01391 |  0:11:22s\n",
      "epoch 81 | loss: 0.01162 | val_0_mse: 0.00791 |  0:11:30s\n",
      "epoch 82 | loss: 0.01067 | val_0_mse: 0.00762 |  0:11:39s\n",
      "epoch 83 | loss: 0.01216 | val_0_mse: 0.00746 |  0:11:48s\n",
      "epoch 84 | loss: 0.01561 | val_0_mse: 0.02733 |  0:11:56s\n",
      "epoch 85 | loss: 0.01538 | val_0_mse: 0.01266 |  0:12:04s\n",
      "epoch 86 | loss: 0.01286 | val_0_mse: 0.01017 |  0:12:12s\n",
      "epoch 87 | loss: 0.01129 | val_0_mse: 0.00876 |  0:12:21s\n",
      "epoch 88 | loss: 0.0126  | val_0_mse: 0.02009 |  0:12:29s\n",
      "epoch 89 | loss: 0.02148 | val_0_mse: 0.01413 |  0:12:37s\n",
      "epoch 90 | loss: 0.01552 | val_0_mse: 0.01809 |  0:12:46s\n",
      "epoch 91 | loss: 0.01334 | val_0_mse: 0.01423 |  0:12:54s\n",
      "epoch 92 | loss: 0.01589 | val_0_mse: 0.00957 |  0:13:02s\n",
      "epoch 93 | loss: 0.01138 | val_0_mse: 0.02075 |  0:13:11s\n",
      "\n",
      "Early stopping occurred at epoch 93 with best_epoch = 83 and best_val_0_mse = 0.00746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007535 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.966008 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 29/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.97965 | val_0_mse: 0.61757 |  0:00:10s\n",
      "epoch 1  | loss: 0.40068 | val_0_mse: 0.28953 |  0:00:21s\n",
      "epoch 2  | loss: 0.18928 | val_0_mse: 0.13878 |  0:00:32s\n",
      "epoch 3  | loss: 0.12585 | val_0_mse: 0.09089 |  0:00:42s\n",
      "epoch 4  | loss: 0.10651 | val_0_mse: 0.08234 |  0:00:52s\n",
      "epoch 5  | loss: 0.08782 | val_0_mse: 0.07783 |  0:01:02s\n",
      "epoch 6  | loss: 0.08568 | val_0_mse: 0.09571 |  0:01:13s\n",
      "epoch 7  | loss: 0.0748  | val_0_mse: 0.08866 |  0:01:23s\n",
      "epoch 8  | loss: 0.07096 | val_0_mse: 0.06154 |  0:01:33s\n",
      "epoch 9  | loss: 0.06496 | val_0_mse: 0.08406 |  0:01:44s\n",
      "epoch 10 | loss: 0.07175 | val_0_mse: 0.06707 |  0:01:53s\n",
      "epoch 11 | loss: 0.0721  | val_0_mse: 0.08411 |  0:02:03s\n",
      "epoch 12 | loss: 0.0828  | val_0_mse: 0.07073 |  0:02:12s\n",
      "epoch 13 | loss: 0.0789  | val_0_mse: 0.06294 |  0:02:22s\n",
      "epoch 14 | loss: 0.06521 | val_0_mse: 0.06292 |  0:02:32s\n",
      "epoch 15 | loss: 0.06366 | val_0_mse: 0.05383 |  0:02:41s\n",
      "epoch 16 | loss: 0.06649 | val_0_mse: 0.05692 |  0:02:51s\n",
      "epoch 17 | loss: 0.06205 | val_0_mse: 0.06822 |  0:03:00s\n",
      "epoch 18 | loss: 0.05988 | val_0_mse: 0.06965 |  0:03:10s\n",
      "epoch 19 | loss: 0.05056 | val_0_mse: 0.05589 |  0:03:20s\n",
      "epoch 20 | loss: 0.05178 | val_0_mse: 0.06793 |  0:03:29s\n",
      "epoch 21 | loss: 0.0542  | val_0_mse: 0.05934 |  0:03:39s\n",
      "epoch 22 | loss: 0.05626 | val_0_mse: 0.05613 |  0:03:48s\n",
      "epoch 23 | loss: 0.05326 | val_0_mse: 0.05323 |  0:03:58s\n",
      "epoch 24 | loss: 0.04953 | val_0_mse: 0.07346 |  0:04:08s\n",
      "epoch 25 | loss: 0.05354 | val_0_mse: 0.07519 |  0:04:17s\n",
      "epoch 26 | loss: 0.06299 | val_0_mse: 0.04449 |  0:04:27s\n",
      "epoch 27 | loss: 0.04706 | val_0_mse: 0.05538 |  0:04:37s\n",
      "epoch 28 | loss: 0.04809 | val_0_mse: 0.04878 |  0:04:46s\n",
      "epoch 29 | loss: 0.05198 | val_0_mse: 0.04912 |  0:04:56s\n",
      "epoch 30 | loss: 0.04935 | val_0_mse: 0.0578  |  0:05:06s\n",
      "epoch 31 | loss: 0.05004 | val_0_mse: 0.04873 |  0:05:16s\n",
      "epoch 32 | loss: 0.05335 | val_0_mse: 0.05695 |  0:05:27s\n",
      "epoch 33 | loss: 0.049   | val_0_mse: 0.04333 |  0:05:37s\n",
      "epoch 34 | loss: 0.04443 | val_0_mse: 0.04683 |  0:05:47s\n",
      "epoch 35 | loss: 0.04209 | val_0_mse: 0.04156 |  0:05:56s\n",
      "epoch 36 | loss: 0.03988 | val_0_mse: 0.05523 |  0:06:06s\n",
      "epoch 37 | loss: 0.04399 | val_0_mse: 0.03575 |  0:06:16s\n",
      "epoch 38 | loss: 0.03988 | val_0_mse: 0.04615 |  0:06:25s\n",
      "epoch 39 | loss: 0.04136 | val_0_mse: 0.03351 |  0:06:35s\n",
      "epoch 40 | loss: 0.03542 | val_0_mse: 0.02735 |  0:06:45s\n",
      "epoch 41 | loss: 0.02838 | val_0_mse: 0.03496 |  0:06:54s\n",
      "epoch 42 | loss: 0.02432 | val_0_mse: 0.02422 |  0:07:04s\n",
      "epoch 43 | loss: 0.02274 | val_0_mse: 0.01774 |  0:07:14s\n",
      "epoch 44 | loss: 0.02757 | val_0_mse: 0.03336 |  0:07:23s\n",
      "epoch 45 | loss: 0.01881 | val_0_mse: 0.01534 |  0:07:33s\n",
      "epoch 46 | loss: 0.02116 | val_0_mse: 0.01444 |  0:07:43s\n",
      "epoch 47 | loss: 0.01713 | val_0_mse: 0.01349 |  0:07:54s\n",
      "epoch 48 | loss: 0.02024 | val_0_mse: 0.01127 |  0:08:04s\n",
      "epoch 49 | loss: 0.01882 | val_0_mse: 0.01474 |  0:08:13s\n",
      "epoch 50 | loss: 0.01681 | val_0_mse: 0.0112  |  0:08:23s\n",
      "epoch 51 | loss: 0.0205  | val_0_mse: 0.0194  |  0:08:32s\n",
      "epoch 52 | loss: 0.01647 | val_0_mse: 0.01171 |  0:08:42s\n",
      "epoch 53 | loss: 0.01342 | val_0_mse: 0.0103  |  0:08:52s\n",
      "epoch 54 | loss: 0.0175  | val_0_mse: 0.00957 |  0:09:01s\n",
      "epoch 55 | loss: 0.02142 | val_0_mse: 0.02459 |  0:09:11s\n",
      "epoch 56 | loss: 0.01394 | val_0_mse: 0.01016 |  0:09:20s\n",
      "epoch 57 | loss: 0.01701 | val_0_mse: 0.01837 |  0:09:30s\n",
      "epoch 58 | loss: 0.01638 | val_0_mse: 0.01085 |  0:09:40s\n",
      "epoch 59 | loss: 0.01255 | val_0_mse: 0.00946 |  0:09:49s\n",
      "epoch 60 | loss: 0.01393 | val_0_mse: 0.01138 |  0:09:59s\n",
      "epoch 61 | loss: 0.01451 | val_0_mse: 0.01054 |  0:10:08s\n",
      "epoch 62 | loss: 0.01233 | val_0_mse: 0.01202 |  0:10:18s\n",
      "epoch 63 | loss: 0.01557 | val_0_mse: 0.02318 |  0:10:28s\n",
      "epoch 64 | loss: 0.01824 | val_0_mse: 0.03541 |  0:10:37s\n",
      "epoch 65 | loss: 0.01514 | val_0_mse: 0.02347 |  0:10:47s\n",
      "epoch 66 | loss: 0.01314 | val_0_mse: 0.01934 |  0:10:56s\n",
      "epoch 67 | loss: 0.01351 | val_0_mse: 0.01197 |  0:11:06s\n",
      "epoch 68 | loss: 0.01636 | val_0_mse: 0.00891 |  0:11:15s\n",
      "epoch 69 | loss: 0.01097 | val_0_mse: 0.00641 |  0:11:25s\n",
      "epoch 70 | loss: 0.01064 | val_0_mse: 0.00989 |  0:11:35s\n",
      "epoch 71 | loss: 0.01209 | val_0_mse: 0.00874 |  0:11:44s\n",
      "epoch 72 | loss: 0.01893 | val_0_mse: 0.02307 |  0:11:54s\n",
      "epoch 73 | loss: 0.01118 | val_0_mse: 0.00856 |  0:12:04s\n",
      "epoch 74 | loss: 0.00974 | val_0_mse: 0.02315 |  0:12:13s\n",
      "epoch 75 | loss: 0.00938 | val_0_mse: 0.01199 |  0:12:23s\n",
      "epoch 76 | loss: 0.01117 | val_0_mse: 0.01136 |  0:12:33s\n",
      "epoch 77 | loss: 0.01012 | val_0_mse: 0.04165 |  0:12:42s\n",
      "epoch 78 | loss: 0.0116  | val_0_mse: 0.00852 |  0:12:52s\n",
      "epoch 79 | loss: 0.00932 | val_0_mse: 0.00705 |  0:13:02s\n",
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_mse = 0.00641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006152 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.972247 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 30/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.299   | val_0_mse: 0.50215 |  0:00:09s\n",
      "epoch 1  | loss: 0.38082 | val_0_mse: 0.20883 |  0:00:17s\n",
      "epoch 2  | loss: 0.29606 | val_0_mse: 0.28415 |  0:00:26s\n",
      "epoch 3  | loss: 0.22809 | val_0_mse: 0.1968  |  0:00:34s\n",
      "epoch 4  | loss: 0.11423 | val_0_mse: 0.1541  |  0:00:43s\n",
      "epoch 5  | loss: 0.14209 | val_0_mse: 0.13681 |  0:00:51s\n",
      "epoch 6  | loss: 0.17368 | val_0_mse: 0.10206 |  0:01:00s\n",
      "epoch 7  | loss: 0.12279 | val_0_mse: 0.11623 |  0:01:08s\n",
      "epoch 8  | loss: 0.0912  | val_0_mse: 0.08685 |  0:01:17s\n",
      "epoch 9  | loss: 0.0916  | val_0_mse: 0.0732  |  0:01:26s\n",
      "epoch 10 | loss: 0.08519 | val_0_mse: 0.0844  |  0:01:34s\n",
      "epoch 11 | loss: 0.07384 | val_0_mse: 0.09895 |  0:01:43s\n",
      "epoch 12 | loss: 0.06972 | val_0_mse: 0.06313 |  0:01:51s\n",
      "epoch 13 | loss: 0.06817 | val_0_mse: 0.05484 |  0:02:00s\n",
      "epoch 14 | loss: 0.06347 | val_0_mse: 0.05383 |  0:02:08s\n",
      "epoch 15 | loss: 0.06123 | val_0_mse: 0.06291 |  0:02:17s\n",
      "epoch 16 | loss: 0.06234 | val_0_mse: 0.06809 |  0:02:25s\n",
      "epoch 17 | loss: 0.05792 | val_0_mse: 0.05428 |  0:02:34s\n",
      "epoch 18 | loss: 0.05985 | val_0_mse: 0.05431 |  0:02:42s\n",
      "epoch 19 | loss: 0.05019 | val_0_mse: 0.04177 |  0:02:51s\n",
      "epoch 20 | loss: 0.04602 | val_0_mse: 0.04111 |  0:02:59s\n",
      "epoch 21 | loss: 0.04627 | val_0_mse: 0.04782 |  0:03:08s\n",
      "epoch 22 | loss: 0.04873 | val_0_mse: 0.04153 |  0:03:16s\n",
      "epoch 23 | loss: 0.05039 | val_0_mse: 0.05279 |  0:03:25s\n",
      "epoch 24 | loss: 0.04699 | val_0_mse: 0.04174 |  0:03:33s\n",
      "epoch 25 | loss: 0.04068 | val_0_mse: 0.03646 |  0:03:41s\n",
      "epoch 26 | loss: 0.04671 | val_0_mse: 0.03265 |  0:03:50s\n",
      "epoch 27 | loss: 0.03805 | val_0_mse: 0.02985 |  0:03:59s\n",
      "epoch 28 | loss: 0.03618 | val_0_mse: 0.02687 |  0:04:07s\n",
      "epoch 29 | loss: 0.03555 | val_0_mse: 0.02552 |  0:04:16s\n",
      "epoch 30 | loss: 0.02697 | val_0_mse: 0.0225  |  0:04:24s\n",
      "epoch 31 | loss: 0.02548 | val_0_mse: 0.02275 |  0:04:33s\n",
      "epoch 32 | loss: 0.02721 | val_0_mse: 0.02036 |  0:04:41s\n",
      "epoch 33 | loss: 0.0227  | val_0_mse: 0.01833 |  0:04:50s\n",
      "epoch 34 | loss: 0.02012 | val_0_mse: 0.01594 |  0:04:59s\n",
      "epoch 35 | loss: 0.02037 | val_0_mse: 0.02102 |  0:05:07s\n",
      "epoch 36 | loss: 0.01933 | val_0_mse: 0.01313 |  0:05:16s\n",
      "epoch 37 | loss: 0.01798 | val_0_mse: 0.01588 |  0:05:24s\n",
      "epoch 38 | loss: 0.01735 | val_0_mse: 0.01538 |  0:05:33s\n",
      "epoch 39 | loss: 0.01766 | val_0_mse: 0.01378 |  0:05:41s\n",
      "epoch 40 | loss: 0.02296 | val_0_mse: 0.02112 |  0:05:50s\n",
      "epoch 41 | loss: 0.02256 | val_0_mse: 0.03047 |  0:05:58s\n",
      "epoch 42 | loss: 0.02141 | val_0_mse: 0.01662 |  0:06:07s\n",
      "epoch 43 | loss: 0.01997 | val_0_mse: 0.01487 |  0:06:15s\n",
      "epoch 44 | loss: 0.01767 | val_0_mse: 0.01382 |  0:06:24s\n",
      "epoch 45 | loss: 0.0187  | val_0_mse: 0.01164 |  0:06:33s\n",
      "epoch 46 | loss: 0.01602 | val_0_mse: 0.01295 |  0:06:41s\n",
      "epoch 47 | loss: 0.01252 | val_0_mse: 0.0093  |  0:06:50s\n",
      "epoch 48 | loss: 0.01295 | val_0_mse: 0.01599 |  0:06:58s\n",
      "epoch 49 | loss: 0.01235 | val_0_mse: 0.01722 |  0:07:07s\n",
      "epoch 50 | loss: 0.01332 | val_0_mse: 0.00839 |  0:07:15s\n",
      "epoch 51 | loss: 0.0136  | val_0_mse: 0.00979 |  0:07:24s\n",
      "epoch 52 | loss: 0.01517 | val_0_mse: 0.01245 |  0:07:33s\n",
      "epoch 53 | loss: 0.01297 | val_0_mse: 0.01468 |  0:07:41s\n",
      "epoch 54 | loss: 0.0132  | val_0_mse: 0.02402 |  0:07:50s\n",
      "epoch 55 | loss: 0.02041 | val_0_mse: 0.01493 |  0:07:58s\n",
      "epoch 56 | loss: 0.01477 | val_0_mse: 0.01767 |  0:08:07s\n",
      "epoch 57 | loss: 0.01454 | val_0_mse: 0.02452 |  0:08:15s\n",
      "epoch 58 | loss: 0.01825 | val_0_mse: 0.01197 |  0:08:24s\n",
      "epoch 59 | loss: 0.01349 | val_0_mse: 0.01304 |  0:08:32s\n",
      "epoch 60 | loss: 0.0151  | val_0_mse: 0.01951 |  0:08:41s\n",
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 0.00839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008692 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.960788 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 31/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.32806 | val_0_mse: 0.42496 |  0:00:11s\n",
      "epoch 1  | loss: 0.45085 | val_0_mse: 0.37315 |  0:00:23s\n",
      "epoch 2  | loss: 0.20061 | val_0_mse: 0.27149 |  0:00:34s\n",
      "epoch 3  | loss: 0.10592 | val_0_mse: 0.12557 |  0:00:46s\n",
      "epoch 4  | loss: 0.11841 | val_0_mse: 0.1208  |  0:00:58s\n",
      "epoch 5  | loss: 0.11519 | val_0_mse: 0.13723 |  0:01:09s\n",
      "epoch 6  | loss: 0.09571 | val_0_mse: 0.07372 |  0:01:21s\n",
      "epoch 7  | loss: 0.08305 | val_0_mse: 0.06721 |  0:01:33s\n",
      "epoch 8  | loss: 0.0833  | val_0_mse: 0.07135 |  0:01:45s\n",
      "epoch 9  | loss: 0.08188 | val_0_mse: 0.0662  |  0:01:56s\n",
      "epoch 10 | loss: 0.08529 | val_0_mse: 0.06557 |  0:02:08s\n",
      "epoch 11 | loss: 0.07724 | val_0_mse: 0.06201 |  0:02:19s\n",
      "epoch 12 | loss: 0.07498 | val_0_mse: 0.05897 |  0:02:31s\n",
      "epoch 13 | loss: 0.06614 | val_0_mse: 0.05879 |  0:02:43s\n",
      "epoch 14 | loss: 0.07632 | val_0_mse: 0.06281 |  0:02:54s\n",
      "epoch 15 | loss: 0.06331 | val_0_mse: 0.05159 |  0:03:06s\n",
      "epoch 16 | loss: 0.06857 | val_0_mse: 0.0656  |  0:03:18s\n",
      "epoch 17 | loss: 0.06104 | val_0_mse: 0.04832 |  0:03:29s\n",
      "epoch 18 | loss: 0.05846 | val_0_mse: 0.11768 |  0:03:41s\n",
      "epoch 19 | loss: 0.05617 | val_0_mse: 0.07543 |  0:03:53s\n",
      "epoch 20 | loss: 0.05651 | val_0_mse: 0.12898 |  0:04:04s\n",
      "epoch 21 | loss: 0.0701  | val_0_mse: 0.0391  |  0:04:16s\n",
      "epoch 22 | loss: 0.05477 | val_0_mse: 0.04682 |  0:04:28s\n",
      "epoch 23 | loss: 0.05054 | val_0_mse: 0.05776 |  0:04:40s\n",
      "epoch 24 | loss: 0.06284 | val_0_mse: 0.05565 |  0:04:51s\n",
      "epoch 25 | loss: 0.05649 | val_0_mse: 0.0839  |  0:05:03s\n",
      "epoch 26 | loss: 0.06049 | val_0_mse: 0.04861 |  0:05:15s\n",
      "epoch 27 | loss: 0.05447 | val_0_mse: 0.04282 |  0:05:26s\n",
      "epoch 28 | loss: 0.04618 | val_0_mse: 0.03837 |  0:05:38s\n",
      "epoch 29 | loss: 0.05039 | val_0_mse: 0.06575 |  0:05:50s\n",
      "epoch 30 | loss: 0.0458  | val_0_mse: 0.03656 |  0:06:02s\n",
      "epoch 31 | loss: 0.04569 | val_0_mse: 0.03353 |  0:06:13s\n",
      "epoch 32 | loss: 0.04107 | val_0_mse: 0.03909 |  0:06:25s\n",
      "epoch 33 | loss: 0.04465 | val_0_mse: 0.029   |  0:06:37s\n",
      "epoch 34 | loss: 0.04002 | val_0_mse: 0.04179 |  0:06:48s\n",
      "epoch 35 | loss: 0.04174 | val_0_mse: 0.05094 |  0:07:00s\n",
      "epoch 36 | loss: 0.04244 | val_0_mse: 0.05155 |  0:07:12s\n",
      "epoch 37 | loss: 0.03675 | val_0_mse: 0.08605 |  0:07:24s\n",
      "epoch 38 | loss: 0.03947 | val_0_mse: 0.0276  |  0:07:36s\n",
      "epoch 39 | loss: 0.03237 | val_0_mse: 0.08304 |  0:07:47s\n",
      "epoch 40 | loss: 0.03197 | val_0_mse: 0.03    |  0:07:59s\n",
      "epoch 41 | loss: 0.03284 | val_0_mse: 0.02582 |  0:08:10s\n",
      "epoch 42 | loss: 0.03055 | val_0_mse: 0.02415 |  0:08:22s\n",
      "epoch 43 | loss: 0.03258 | val_0_mse: 0.07988 |  0:08:34s\n",
      "epoch 44 | loss: 0.03081 | val_0_mse: 0.02054 |  0:08:45s\n",
      "epoch 45 | loss: 0.02722 | val_0_mse: 0.03802 |  0:08:57s\n",
      "epoch 46 | loss: 0.02213 | val_0_mse: 0.01866 |  0:09:08s\n",
      "epoch 47 | loss: 0.02152 | val_0_mse: 0.02285 |  0:09:20s\n",
      "epoch 48 | loss: 0.02258 | val_0_mse: 0.02615 |  0:09:32s\n",
      "epoch 49 | loss: 0.01818 | val_0_mse: 0.01264 |  0:09:43s\n",
      "epoch 50 | loss: 0.01913 | val_0_mse: 0.02189 |  0:09:55s\n",
      "epoch 51 | loss: 0.02167 | val_0_mse: 0.01524 |  0:10:07s\n",
      "epoch 52 | loss: 0.02261 | val_0_mse: 0.02016 |  0:10:18s\n",
      "epoch 53 | loss: 0.0194  | val_0_mse: 0.02244 |  0:10:30s\n",
      "epoch 54 | loss: 0.01697 | val_0_mse: 0.01859 |  0:10:42s\n",
      "epoch 55 | loss: 0.01676 | val_0_mse: 0.08811 |  0:10:54s\n",
      "epoch 56 | loss: 0.01795 | val_0_mse: 0.02583 |  0:11:05s\n",
      "epoch 57 | loss: 0.0182  | val_0_mse: 0.01038 |  0:11:17s\n",
      "epoch 58 | loss: 0.01685 | val_0_mse: 0.00996 |  0:11:29s\n",
      "epoch 59 | loss: 0.01719 | val_0_mse: 0.01011 |  0:11:40s\n",
      "epoch 60 | loss: 0.01714 | val_0_mse: 0.01327 |  0:11:52s\n",
      "epoch 61 | loss: 0.01381 | val_0_mse: 0.00932 |  0:12:04s\n",
      "epoch 62 | loss: 0.01955 | val_0_mse: 0.01474 |  0:12:15s\n",
      "epoch 63 | loss: 0.01516 | val_0_mse: 0.0129  |  0:12:27s\n",
      "epoch 64 | loss: 0.01469 | val_0_mse: 0.01408 |  0:12:39s\n",
      "epoch 65 | loss: 0.01541 | val_0_mse: 0.0322  |  0:12:50s\n",
      "epoch 66 | loss: 0.03026 | val_0_mse: 0.03123 |  0:13:02s\n",
      "epoch 67 | loss: 0.02286 | val_0_mse: 0.01747 |  0:13:14s\n",
      "epoch 68 | loss: 0.01742 | val_0_mse: 0.0194  |  0:13:26s\n",
      "epoch 69 | loss: 0.01548 | val_0_mse: 0.01099 |  0:13:37s\n",
      "epoch 70 | loss: 0.01177 | val_0_mse: 0.01618 |  0:13:49s\n",
      "epoch 71 | loss: 0.01767 | val_0_mse: 0.03    |  0:14:01s\n",
      "\n",
      "Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_mse = 0.00932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009475 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.957256 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 32/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=16, n_a=16, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.98244 | val_0_mse: 0.68369 |  0:00:09s\n",
      "epoch 1  | loss: 0.381   | val_0_mse: 0.359   |  0:00:19s\n",
      "epoch 2  | loss: 0.20428 | val_0_mse: 0.2258  |  0:00:29s\n",
      "epoch 3  | loss: 0.40696 | val_0_mse: 0.12662 |  0:00:39s\n",
      "epoch 4  | loss: 0.13801 | val_0_mse: 0.28012 |  0:00:48s\n",
      "epoch 5  | loss: 0.11327 | val_0_mse: 0.10821 |  0:00:58s\n",
      "epoch 6  | loss: 0.09916 | val_0_mse: 0.1244  |  0:01:08s\n",
      "epoch 7  | loss: 0.09763 | val_0_mse: 0.09308 |  0:01:17s\n",
      "epoch 8  | loss: 0.07852 | val_0_mse: 0.08722 |  0:01:27s\n",
      "epoch 9  | loss: 0.08562 | val_0_mse: 0.12535 |  0:01:36s\n",
      "epoch 10 | loss: 0.08186 | val_0_mse: 0.10453 |  0:01:46s\n",
      "epoch 11 | loss: 0.065   | val_0_mse: 0.07264 |  0:01:55s\n",
      "epoch 12 | loss: 0.06223 | val_0_mse: 0.06865 |  0:02:05s\n",
      "epoch 13 | loss: 0.06926 | val_0_mse: 0.04739 |  0:02:14s\n",
      "epoch 14 | loss: 0.05402 | val_0_mse: 0.05385 |  0:02:24s\n",
      "epoch 15 | loss: 0.05897 | val_0_mse: 0.04339 |  0:02:33s\n",
      "epoch 16 | loss: 0.05842 | val_0_mse: 0.04261 |  0:02:43s\n",
      "epoch 17 | loss: 0.05243 | val_0_mse: 0.04122 |  0:02:52s\n",
      "epoch 18 | loss: 0.0531  | val_0_mse: 0.06421 |  0:03:02s\n",
      "epoch 19 | loss: 0.05603 | val_0_mse: 0.04408 |  0:03:11s\n",
      "epoch 20 | loss: 0.04796 | val_0_mse: 0.07753 |  0:03:20s\n",
      "epoch 21 | loss: 0.05598 | val_0_mse: 0.0626  |  0:03:30s\n",
      "epoch 22 | loss: 0.05002 | val_0_mse: 0.04359 |  0:03:39s\n",
      "epoch 23 | loss: 0.05036 | val_0_mse: 0.0477  |  0:03:48s\n",
      "epoch 24 | loss: 0.05265 | val_0_mse: 0.05884 |  0:03:58s\n",
      "epoch 25 | loss: 0.044   | val_0_mse: 0.03939 |  0:04:07s\n",
      "epoch 26 | loss: 0.04414 | val_0_mse: 0.04236 |  0:04:17s\n",
      "epoch 27 | loss: 0.04639 | val_0_mse: 0.04517 |  0:04:26s\n",
      "epoch 28 | loss: 0.04341 | val_0_mse: 0.03871 |  0:04:36s\n",
      "epoch 29 | loss: 0.04441 | val_0_mse: 0.04381 |  0:04:45s\n",
      "epoch 30 | loss: 0.04066 | val_0_mse: 0.04142 |  0:04:55s\n",
      "epoch 31 | loss: 0.04171 | val_0_mse: 0.05311 |  0:05:04s\n",
      "epoch 32 | loss: 0.04323 | val_0_mse: 0.04008 |  0:05:14s\n",
      "epoch 33 | loss: 0.04157 | val_0_mse: 0.03465 |  0:05:23s\n",
      "epoch 34 | loss: 0.03807 | val_0_mse: 0.03187 |  0:05:33s\n",
      "epoch 35 | loss: 0.0363  | val_0_mse: 0.04496 |  0:05:42s\n",
      "epoch 36 | loss: 0.03717 | val_0_mse: 0.03448 |  0:05:52s\n",
      "epoch 37 | loss: 0.03717 | val_0_mse: 0.06012 |  0:06:01s\n",
      "epoch 38 | loss: 0.04242 | val_0_mse: 0.02947 |  0:06:11s\n",
      "epoch 39 | loss: 0.0345  | val_0_mse: 0.04327 |  0:06:21s\n",
      "epoch 40 | loss: 0.03987 | val_0_mse: 0.03729 |  0:06:30s\n",
      "epoch 41 | loss: 0.03208 | val_0_mse: 0.02983 |  0:06:40s\n",
      "epoch 42 | loss: 0.03155 | val_0_mse: 0.0285  |  0:06:50s\n",
      "epoch 43 | loss: 0.03261 | val_0_mse: 0.02681 |  0:06:59s\n",
      "epoch 44 | loss: 0.03049 | val_0_mse: 0.0243  |  0:07:09s\n",
      "epoch 45 | loss: 0.02971 | val_0_mse: 0.03978 |  0:07:19s\n",
      "epoch 46 | loss: 0.03275 | val_0_mse: 0.02996 |  0:07:28s\n",
      "epoch 47 | loss: 0.02467 | val_0_mse: 0.02126 |  0:07:38s\n",
      "epoch 48 | loss: 0.02859 | val_0_mse: 0.02309 |  0:07:48s\n",
      "epoch 49 | loss: 0.02744 | val_0_mse: 0.02902 |  0:07:58s\n",
      "epoch 50 | loss: 0.02899 | val_0_mse: 0.02414 |  0:08:07s\n",
      "epoch 51 | loss: 0.03533 | val_0_mse: 0.02314 |  0:08:17s\n",
      "epoch 52 | loss: 0.03258 | val_0_mse: 0.03854 |  0:08:27s\n",
      "epoch 53 | loss: 0.03127 | val_0_mse: 0.04264 |  0:08:36s\n",
      "epoch 54 | loss: 0.03539 | val_0_mse: 0.02196 |  0:08:46s\n",
      "epoch 55 | loss: 0.02416 | val_0_mse: 0.0205  |  0:08:56s\n",
      "epoch 56 | loss: 0.03299 | val_0_mse: 0.02071 |  0:09:06s\n",
      "epoch 57 | loss: 0.0228  | val_0_mse: 0.01936 |  0:09:15s\n",
      "epoch 58 | loss: 0.02291 | val_0_mse: 0.03016 |  0:09:25s\n",
      "epoch 59 | loss: 0.02431 | val_0_mse: 0.02037 |  0:09:35s\n",
      "epoch 60 | loss: 0.02063 | val_0_mse: 0.01927 |  0:09:44s\n",
      "epoch 61 | loss: 0.02648 | val_0_mse: 0.02048 |  0:09:54s\n",
      "epoch 62 | loss: 0.02064 | val_0_mse: 0.01693 |  0:10:03s\n",
      "epoch 63 | loss: 0.01964 | val_0_mse: 0.0402  |  0:10:13s\n",
      "epoch 64 | loss: 0.02654 | val_0_mse: 0.01695 |  0:10:22s\n",
      "epoch 65 | loss: 0.02373 | val_0_mse: 0.01646 |  0:10:32s\n",
      "epoch 66 | loss: 0.01913 | val_0_mse: 0.01474 |  0:10:42s\n",
      "epoch 67 | loss: 0.02042 | val_0_mse: 0.01571 |  0:10:51s\n",
      "epoch 68 | loss: 0.028   | val_0_mse: 0.02333 |  0:11:01s\n",
      "epoch 69 | loss: 0.01846 | val_0_mse: 0.01651 |  0:11:10s\n",
      "epoch 70 | loss: 0.01877 | val_0_mse: 0.01501 |  0:11:19s\n",
      "epoch 71 | loss: 0.01745 | val_0_mse: 0.01282 |  0:11:29s\n",
      "epoch 72 | loss: 0.01442 | val_0_mse: 0.01334 |  0:11:38s\n",
      "epoch 73 | loss: 0.01784 | val_0_mse: 0.01163 |  0:11:47s\n",
      "epoch 74 | loss: 0.01736 | val_0_mse: 0.01752 |  0:11:57s\n",
      "epoch 75 | loss: 0.01657 | val_0_mse: 0.01462 |  0:12:07s\n",
      "epoch 76 | loss: 0.01793 | val_0_mse: 0.03527 |  0:12:16s\n",
      "epoch 77 | loss: 0.01431 | val_0_mse: 0.01279 |  0:12:26s\n",
      "epoch 78 | loss: 0.01556 | val_0_mse: 0.01173 |  0:12:39s\n",
      "epoch 79 | loss: 0.01586 | val_0_mse: 0.04583 |  0:12:49s\n",
      "epoch 80 | loss: 0.0184  | val_0_mse: 0.01382 |  0:12:59s\n",
      "epoch 81 | loss: 0.01551 | val_0_mse: 0.01149 |  0:13:09s\n",
      "epoch 82 | loss: 0.01945 | val_0_mse: 0.01501 |  0:13:19s\n",
      "epoch 83 | loss: 0.01595 | val_0_mse: 0.01296 |  0:13:29s\n",
      "epoch 84 | loss: 0.01675 | val_0_mse: 0.01239 |  0:13:39s\n",
      "epoch 85 | loss: 0.01493 | val_0_mse: 0.01086 |  0:13:48s\n",
      "epoch 86 | loss: 0.01327 | val_0_mse: 0.01946 |  0:13:58s\n",
      "epoch 87 | loss: 0.01824 | val_0_mse: 0.01886 |  0:14:07s\n",
      "epoch 88 | loss: 0.0201  | val_0_mse: 0.02651 |  0:14:16s\n",
      "epoch 89 | loss: 0.02173 | val_0_mse: 0.01296 |  0:14:26s\n",
      "epoch 90 | loss: 0.01428 | val_0_mse: 0.02157 |  0:14:35s\n",
      "epoch 91 | loss: 0.02067 | val_0_mse: 0.0148  |  0:14:45s\n",
      "epoch 92 | loss: 0.0165  | val_0_mse: 0.01947 |  0:14:54s\n",
      "epoch 93 | loss: 0.01369 | val_0_mse: 0.01666 |  0:15:03s\n",
      "epoch 94 | loss: 0.01315 | val_0_mse: 0.01284 |  0:15:13s\n",
      "epoch 95 | loss: 0.01362 | val_0_mse: 0.01776 |  0:15:22s\n",
      "\n",
      "Early stopping occurred at epoch 95 with best_epoch = 85 and best_val_0_mse = 0.01086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.010801 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.951274 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 33/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.05534 | val_0_mse: 0.35982 |  0:00:10s\n",
      "epoch 1  | loss: 0.29693 | val_0_mse: 0.33213 |  0:00:20s\n",
      "epoch 2  | loss: 0.10997 | val_0_mse: 0.15132 |  0:00:29s\n",
      "epoch 3  | loss: 0.10132 | val_0_mse: 0.17957 |  0:00:39s\n",
      "epoch 4  | loss: 0.07688 | val_0_mse: 0.14274 |  0:00:49s\n",
      "epoch 5  | loss: 0.07196 | val_0_mse: 0.0974  |  0:00:59s\n",
      "epoch 6  | loss: 0.07988 | val_0_mse: 0.05406 |  0:01:09s\n",
      "epoch 7  | loss: 0.06848 | val_0_mse: 0.05873 |  0:01:19s\n",
      "epoch 8  | loss: 0.06879 | val_0_mse: 0.07751 |  0:01:30s\n",
      "epoch 9  | loss: 0.0748  | val_0_mse: 0.07117 |  0:01:43s\n",
      "epoch 10 | loss: 0.0641  | val_0_mse: 0.04794 |  0:01:53s\n",
      "epoch 11 | loss: 0.05675 | val_0_mse: 0.07138 |  0:02:02s\n",
      "epoch 12 | loss: 0.05591 | val_0_mse: 0.04861 |  0:02:12s\n",
      "epoch 13 | loss: 0.05056 | val_0_mse: 0.04819 |  0:02:22s\n",
      "epoch 14 | loss: 0.05114 | val_0_mse: 0.05789 |  0:02:31s\n",
      "epoch 15 | loss: 0.05035 | val_0_mse: 0.03278 |  0:02:41s\n",
      "epoch 16 | loss: 0.04269 | val_0_mse: 0.03557 |  0:02:51s\n",
      "epoch 17 | loss: 0.04234 | val_0_mse: 0.04633 |  0:03:02s\n",
      "epoch 18 | loss: 0.04066 | val_0_mse: 0.03176 |  0:03:11s\n",
      "epoch 19 | loss: 0.03576 | val_0_mse: 0.03122 |  0:03:21s\n",
      "epoch 20 | loss: 0.03764 | val_0_mse: 0.03671 |  0:03:30s\n",
      "epoch 21 | loss: 0.03583 | val_0_mse: 0.02016 |  0:03:40s\n",
      "epoch 22 | loss: 0.02711 | val_0_mse: 0.02466 |  0:03:50s\n",
      "epoch 23 | loss: 0.02712 | val_0_mse: 0.04128 |  0:03:59s\n",
      "epoch 24 | loss: 0.0292  | val_0_mse: 0.04841 |  0:04:09s\n",
      "epoch 25 | loss: 0.03473 | val_0_mse: 0.0226  |  0:04:18s\n",
      "epoch 26 | loss: 0.02803 | val_0_mse: 0.02224 |  0:04:28s\n",
      "epoch 27 | loss: 0.02079 | val_0_mse: 0.03745 |  0:04:37s\n",
      "epoch 28 | loss: 0.01886 | val_0_mse: 0.0204  |  0:04:47s\n",
      "epoch 29 | loss: 0.02119 | val_0_mse: 0.02149 |  0:04:56s\n",
      "epoch 30 | loss: 0.02213 | val_0_mse: 0.01339 |  0:05:06s\n",
      "epoch 31 | loss: 0.01666 | val_0_mse: 0.01666 |  0:05:15s\n",
      "epoch 32 | loss: 0.0196  | val_0_mse: 0.01161 |  0:05:25s\n",
      "epoch 33 | loss: 0.01703 | val_0_mse: 0.01537 |  0:05:34s\n",
      "epoch 34 | loss: 0.01682 | val_0_mse: 0.00924 |  0:05:44s\n",
      "epoch 35 | loss: 0.01232 | val_0_mse: 0.00957 |  0:05:53s\n",
      "epoch 36 | loss: 0.01353 | val_0_mse: 0.00769 |  0:06:03s\n",
      "epoch 37 | loss: 0.01309 | val_0_mse: 0.02762 |  0:06:12s\n",
      "epoch 38 | loss: 0.0153  | val_0_mse: 0.01429 |  0:06:22s\n",
      "epoch 39 | loss: 0.0215  | val_0_mse: 0.03581 |  0:06:32s\n",
      "epoch 40 | loss: 0.02398 | val_0_mse: 0.02337 |  0:06:42s\n",
      "epoch 41 | loss: 0.01892 | val_0_mse: 0.01102 |  0:06:53s\n",
      "epoch 42 | loss: 0.01511 | val_0_mse: 0.01568 |  0:07:03s\n",
      "epoch 43 | loss: 0.01428 | val_0_mse: 0.00884 |  0:07:12s\n",
      "epoch 44 | loss: 0.02084 | val_0_mse: 0.01678 |  0:07:21s\n",
      "epoch 45 | loss: 0.01294 | val_0_mse: 0.01543 |  0:07:31s\n",
      "epoch 46 | loss: 0.018   | val_0_mse: 0.00927 |  0:07:40s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_mse = 0.00769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007415 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.966547 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 34/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.24131 | val_0_mse: 0.78538 |  0:00:07s\n",
      "epoch 1  | loss: 0.41951 | val_0_mse: 0.29403 |  0:00:14s\n",
      "epoch 2  | loss: 0.23947 | val_0_mse: 0.29645 |  0:00:21s\n",
      "epoch 3  | loss: 0.16358 | val_0_mse: 0.16802 |  0:00:28s\n",
      "epoch 4  | loss: 0.13994 | val_0_mse: 0.24462 |  0:00:36s\n",
      "epoch 5  | loss: 0.16771 | val_0_mse: 0.12653 |  0:00:43s\n",
      "epoch 6  | loss: 0.14121 | val_0_mse: 0.14125 |  0:00:50s\n",
      "epoch 7  | loss: 0.13812 | val_0_mse: 0.09046 |  0:00:57s\n",
      "epoch 8  | loss: 0.10038 | val_0_mse: 0.08339 |  0:01:04s\n",
      "epoch 9  | loss: 0.07607 | val_0_mse: 0.0765  |  0:01:11s\n",
      "epoch 10 | loss: 0.07842 | val_0_mse: 0.08553 |  0:01:18s\n",
      "epoch 11 | loss: 0.07645 | val_0_mse: 0.06983 |  0:01:25s\n",
      "epoch 12 | loss: 0.0668  | val_0_mse: 0.06742 |  0:01:32s\n",
      "epoch 13 | loss: 0.0644  | val_0_mse: 0.06334 |  0:01:39s\n",
      "epoch 14 | loss: 0.0644  | val_0_mse: 0.05784 |  0:01:46s\n",
      "epoch 15 | loss: 0.06812 | val_0_mse: 0.06827 |  0:01:53s\n",
      "epoch 16 | loss: 0.06265 | val_0_mse: 0.06155 |  0:02:01s\n",
      "epoch 17 | loss: 0.05786 | val_0_mse: 0.05131 |  0:02:08s\n",
      "epoch 18 | loss: 0.05804 | val_0_mse: 0.04982 |  0:02:15s\n",
      "epoch 19 | loss: 0.05463 | val_0_mse: 0.04791 |  0:02:22s\n",
      "epoch 20 | loss: 0.04783 | val_0_mse: 0.04212 |  0:02:29s\n",
      "epoch 21 | loss: 0.05392 | val_0_mse: 0.04039 |  0:02:36s\n",
      "epoch 22 | loss: 0.04834 | val_0_mse: 0.03961 |  0:02:43s\n",
      "epoch 23 | loss: 0.042   | val_0_mse: 0.03669 |  0:02:50s\n",
      "epoch 24 | loss: 0.04814 | val_0_mse: 0.05963 |  0:02:57s\n",
      "epoch 25 | loss: 0.04757 | val_0_mse: 0.06575 |  0:03:04s\n",
      "epoch 26 | loss: 0.05534 | val_0_mse: 0.04407 |  0:03:12s\n",
      "epoch 27 | loss: 0.04392 | val_0_mse: 0.04    |  0:03:19s\n",
      "epoch 28 | loss: 0.04397 | val_0_mse: 0.04327 |  0:03:30s\n",
      "epoch 29 | loss: 0.04506 | val_0_mse: 0.03686 |  0:03:44s\n",
      "epoch 30 | loss: 0.04592 | val_0_mse: 0.04721 |  0:03:51s\n",
      "epoch 31 | loss: 0.03309 | val_0_mse: 0.02693 |  0:03:58s\n",
      "epoch 32 | loss: 0.03222 | val_0_mse: 0.02612 |  0:04:05s\n",
      "epoch 33 | loss: 0.02687 | val_0_mse: 0.02091 |  0:04:13s\n",
      "epoch 34 | loss: 0.02789 | val_0_mse: 0.01991 |  0:04:20s\n",
      "epoch 35 | loss: 0.02327 | val_0_mse: 0.01781 |  0:04:27s\n",
      "epoch 36 | loss: 0.02379 | val_0_mse: 0.01782 |  0:04:34s\n",
      "epoch 37 | loss: 0.02315 | val_0_mse: 0.01736 |  0:04:41s\n",
      "epoch 38 | loss: 0.02111 | val_0_mse: 0.02493 |  0:04:48s\n",
      "epoch 39 | loss: 0.02147 | val_0_mse: 0.01905 |  0:04:55s\n",
      "epoch 40 | loss: 0.02348 | val_0_mse: 0.02183 |  0:05:03s\n",
      "epoch 41 | loss: 0.01726 | val_0_mse: 0.01605 |  0:05:11s\n",
      "epoch 42 | loss: 0.01556 | val_0_mse: 0.0229  |  0:05:19s\n",
      "epoch 43 | loss: 0.01812 | val_0_mse: 0.02488 |  0:05:26s\n",
      "epoch 44 | loss: 0.01969 | val_0_mse: 0.02083 |  0:05:34s\n",
      "epoch 45 | loss: 0.0211  | val_0_mse: 0.0203  |  0:05:40s\n",
      "epoch 46 | loss: 0.01565 | val_0_mse: 0.0138  |  0:05:47s\n",
      "epoch 47 | loss: 0.0129  | val_0_mse: 0.01039 |  0:05:53s\n",
      "epoch 48 | loss: 0.0149  | val_0_mse: 0.01882 |  0:06:00s\n",
      "epoch 49 | loss: 0.01452 | val_0_mse: 0.01409 |  0:06:07s\n",
      "epoch 50 | loss: 0.01515 | val_0_mse: 0.01694 |  0:06:13s\n",
      "epoch 51 | loss: 0.01623 | val_0_mse: 0.01254 |  0:06:20s\n",
      "epoch 52 | loss: 0.01508 | val_0_mse: 0.01291 |  0:06:27s\n",
      "epoch 53 | loss: 0.01438 | val_0_mse: 0.00995 |  0:06:41s\n",
      "epoch 54 | loss: 0.01149 | val_0_mse: 0.0121  |  0:06:48s\n",
      "epoch 55 | loss: 0.01298 | val_0_mse: 0.01039 |  0:06:55s\n",
      "epoch 56 | loss: 0.01201 | val_0_mse: 0.0098  |  0:07:02s\n",
      "epoch 57 | loss: 0.01888 | val_0_mse: 0.0243  |  0:07:09s\n",
      "epoch 58 | loss: 0.01894 | val_0_mse: 0.01111 |  0:07:15s\n",
      "epoch 59 | loss: 0.0102  | val_0_mse: 0.00813 |  0:07:22s\n",
      "epoch 60 | loss: 0.01055 | val_0_mse: 0.02823 |  0:07:28s\n",
      "epoch 61 | loss: 0.01639 | val_0_mse: 0.03042 |  0:07:35s\n",
      "epoch 62 | loss: 0.01599 | val_0_mse: 0.02985 |  0:07:42s\n",
      "epoch 63 | loss: 0.01454 | val_0_mse: 0.01383 |  0:07:48s\n",
      "epoch 64 | loss: 0.01172 | val_0_mse: 0.01025 |  0:07:55s\n",
      "epoch 65 | loss: 0.01099 | val_0_mse: 0.01679 |  0:08:02s\n",
      "epoch 66 | loss: 0.01015 | val_0_mse: 0.00758 |  0:08:08s\n",
      "epoch 67 | loss: 0.01171 | val_0_mse: 0.01103 |  0:08:16s\n",
      "epoch 68 | loss: 0.01221 | val_0_mse: 0.01153 |  0:08:22s\n",
      "epoch 69 | loss: 0.01452 | val_0_mse: 0.0065  |  0:08:29s\n",
      "epoch 70 | loss: 0.00847 | val_0_mse: 0.01638 |  0:08:36s\n",
      "epoch 71 | loss: 0.01188 | val_0_mse: 0.00815 |  0:08:43s\n",
      "epoch 72 | loss: 0.01027 | val_0_mse: 0.01514 |  0:08:50s\n",
      "epoch 73 | loss: 0.00819 | val_0_mse: 0.01435 |  0:08:57s\n",
      "epoch 74 | loss: 0.00894 | val_0_mse: 0.01421 |  0:09:03s\n",
      "epoch 75 | loss: 0.00959 | val_0_mse: 0.01219 |  0:09:10s\n",
      "epoch 76 | loss: 0.01066 | val_0_mse: 0.00782 |  0:09:16s\n",
      "epoch 77 | loss: 0.01027 | val_0_mse: 0.01208 |  0:09:23s\n",
      "epoch 78 | loss: 0.00985 | val_0_mse: 0.00674 |  0:09:30s\n",
      "epoch 79 | loss: 0.00866 | val_0_mse: 0.00796 |  0:09:37s\n",
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_mse = 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006651 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.969997 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 35/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.29938 | val_0_mse: 0.63859 |  0:00:11s\n",
      "epoch 1  | loss: 0.36451 | val_0_mse: 0.12539 |  0:00:23s\n",
      "epoch 2  | loss: 0.12258 | val_0_mse: 0.1695  |  0:00:34s\n",
      "epoch 3  | loss: 0.09769 | val_0_mse: 0.14462 |  0:00:45s\n",
      "epoch 4  | loss: 0.08605 | val_0_mse: 0.07606 |  0:00:57s\n",
      "epoch 5  | loss: 0.0867  | val_0_mse: 0.0707  |  0:01:09s\n",
      "epoch 6  | loss: 0.0801  | val_0_mse: 0.06885 |  0:01:20s\n",
      "epoch 7  | loss: 0.07379 | val_0_mse: 0.06228 |  0:01:31s\n",
      "epoch 8  | loss: 0.07323 | val_0_mse: 0.08618 |  0:01:41s\n",
      "epoch 9  | loss: 0.07282 | val_0_mse: 0.06656 |  0:01:52s\n",
      "epoch 10 | loss: 0.07414 | val_0_mse: 0.06011 |  0:02:02s\n",
      "epoch 11 | loss: 0.06198 | val_0_mse: 0.04958 |  0:02:13s\n",
      "epoch 12 | loss: 0.05823 | val_0_mse: 0.06213 |  0:02:23s\n",
      "epoch 13 | loss: 0.0595  | val_0_mse: 0.04888 |  0:02:33s\n",
      "epoch 14 | loss: 0.05676 | val_0_mse: 0.06419 |  0:02:44s\n",
      "epoch 15 | loss: 0.05231 | val_0_mse: 0.04323 |  0:02:55s\n",
      "epoch 16 | loss: 0.05214 | val_0_mse: 0.05265 |  0:03:06s\n",
      "epoch 17 | loss: 0.05143 | val_0_mse: 0.03941 |  0:03:18s\n",
      "epoch 18 | loss: 0.0444  | val_0_mse: 0.03446 |  0:03:29s\n",
      "epoch 19 | loss: 0.04063 | val_0_mse: 0.04877 |  0:03:40s\n",
      "epoch 20 | loss: 0.03905 | val_0_mse: 0.02755 |  0:03:51s\n",
      "epoch 21 | loss: 0.03501 | val_0_mse: 0.06439 |  0:04:01s\n",
      "epoch 22 | loss: 0.045   | val_0_mse: 0.03118 |  0:04:12s\n",
      "epoch 23 | loss: 0.03417 | val_0_mse: 0.01856 |  0:04:22s\n",
      "epoch 24 | loss: 0.03175 | val_0_mse: 0.03457 |  0:04:32s\n",
      "epoch 25 | loss: 0.02717 | val_0_mse: 0.02778 |  0:04:43s\n",
      "epoch 26 | loss: 0.02209 | val_0_mse: 0.01321 |  0:04:53s\n",
      "epoch 27 | loss: 0.01787 | val_0_mse: 0.02259 |  0:05:04s\n",
      "epoch 28 | loss: 0.01921 | val_0_mse: 0.0115  |  0:05:15s\n",
      "epoch 29 | loss: 0.02379 | val_0_mse: 0.01516 |  0:05:25s\n",
      "epoch 30 | loss: 0.0195  | val_0_mse: 0.02816 |  0:05:35s\n",
      "epoch 31 | loss: 0.01611 | val_0_mse: 0.0223  |  0:05:46s\n",
      "epoch 32 | loss: 0.01538 | val_0_mse: 0.00995 |  0:05:57s\n",
      "epoch 33 | loss: 0.02043 | val_0_mse: 0.01692 |  0:06:07s\n",
      "epoch 34 | loss: 0.01701 | val_0_mse: 0.00964 |  0:06:17s\n",
      "epoch 35 | loss: 0.01475 | val_0_mse: 0.01265 |  0:06:28s\n",
      "epoch 36 | loss: 0.01937 | val_0_mse: 0.01923 |  0:06:38s\n",
      "epoch 37 | loss: 0.01951 | val_0_mse: 0.02748 |  0:06:49s\n",
      "epoch 38 | loss: 0.02589 | val_0_mse: 0.05201 |  0:06:59s\n",
      "epoch 39 | loss: 0.018   | val_0_mse: 0.01581 |  0:07:10s\n",
      "epoch 40 | loss: 0.01498 | val_0_mse: 0.01262 |  0:07:20s\n",
      "epoch 41 | loss: 0.0135  | val_0_mse: 0.01365 |  0:07:31s\n",
      "epoch 42 | loss: 0.01559 | val_0_mse: 0.03516 |  0:07:41s\n",
      "epoch 43 | loss: 0.02064 | val_0_mse: 0.01009 |  0:07:52s\n",
      "epoch 44 | loss: 0.01355 | val_0_mse: 0.00795 |  0:08:02s\n",
      "epoch 45 | loss: 0.01005 | val_0_mse: 0.01898 |  0:08:13s\n",
      "epoch 46 | loss: 0.01206 | val_0_mse: 0.0109  |  0:08:24s\n",
      "epoch 47 | loss: 0.01218 | val_0_mse: 0.00866 |  0:08:34s\n",
      "epoch 48 | loss: 0.01394 | val_0_mse: 0.0083  |  0:08:44s\n",
      "epoch 49 | loss: 0.01225 | val_0_mse: 0.01544 |  0:08:55s\n",
      "epoch 50 | loss: 0.01104 | val_0_mse: 0.01074 |  0:09:06s\n",
      "epoch 51 | loss: 0.01255 | val_0_mse: 0.00829 |  0:09:16s\n",
      "epoch 52 | loss: 0.01398 | val_0_mse: 0.01005 |  0:09:27s\n",
      "epoch 53 | loss: 0.00928 | val_0_mse: 0.01414 |  0:09:37s\n",
      "epoch 54 | loss: 0.01175 | val_0_mse: 0.01566 |  0:09:48s\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_mse = 0.00795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008701 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.960747 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 36/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.42239 | val_0_mse: 0.83948 |  0:00:08s\n",
      "epoch 1  | loss: 0.62359 | val_0_mse: 0.88877 |  0:00:17s\n",
      "epoch 2  | loss: 0.50234 | val_0_mse: 0.36779 |  0:00:25s\n",
      "epoch 3  | loss: 0.17155 | val_0_mse: 0.15857 |  0:00:34s\n",
      "epoch 4  | loss: 0.24352 | val_0_mse: 0.27121 |  0:00:42s\n",
      "epoch 5  | loss: 0.11891 | val_0_mse: 0.08826 |  0:00:51s\n",
      "epoch 6  | loss: 0.08879 | val_0_mse: 0.09746 |  0:00:59s\n",
      "epoch 7  | loss: 0.07883 | val_0_mse: 0.08303 |  0:01:07s\n",
      "epoch 8  | loss: 0.08074 | val_0_mse: 0.1348  |  0:01:15s\n",
      "epoch 9  | loss: 0.08064 | val_0_mse: 0.0631  |  0:01:23s\n",
      "epoch 10 | loss: 0.07223 | val_0_mse: 0.07505 |  0:01:32s\n",
      "epoch 11 | loss: 0.06084 | val_0_mse: 0.05965 |  0:01:39s\n",
      "epoch 12 | loss: 0.06281 | val_0_mse: 0.04877 |  0:01:47s\n",
      "epoch 13 | loss: 0.05544 | val_0_mse: 0.0432  |  0:01:55s\n",
      "epoch 14 | loss: 0.0509  | val_0_mse: 0.04499 |  0:02:02s\n",
      "epoch 15 | loss: 0.05199 | val_0_mse: 0.04509 |  0:02:10s\n",
      "epoch 16 | loss: 0.04961 | val_0_mse: 0.04961 |  0:02:18s\n",
      "epoch 17 | loss: 0.05293 | val_0_mse: 0.04824 |  0:02:26s\n",
      "epoch 18 | loss: 0.04351 | val_0_mse: 0.03967 |  0:02:34s\n",
      "epoch 19 | loss: 0.04584 | val_0_mse: 0.03809 |  0:02:49s\n",
      "epoch 20 | loss: 0.04086 | val_0_mse: 0.03553 |  0:02:57s\n",
      "epoch 21 | loss: 0.03853 | val_0_mse: 0.03187 |  0:03:04s\n",
      "epoch 22 | loss: 0.03727 | val_0_mse: 0.04042 |  0:03:12s\n",
      "epoch 23 | loss: 0.03531 | val_0_mse: 0.02808 |  0:03:20s\n",
      "epoch 24 | loss: 0.03053 | val_0_mse: 0.02865 |  0:03:27s\n",
      "epoch 25 | loss: 0.03591 | val_0_mse: 0.03286 |  0:03:35s\n",
      "epoch 26 | loss: 0.03339 | val_0_mse: 0.0285  |  0:03:43s\n",
      "epoch 27 | loss: 0.03147 | val_0_mse: 0.03115 |  0:03:51s\n",
      "epoch 28 | loss: 0.03173 | val_0_mse: 0.02689 |  0:03:58s\n",
      "epoch 29 | loss: 0.02963 | val_0_mse: 0.02515 |  0:04:06s\n",
      "epoch 30 | loss: 0.02739 | val_0_mse: 0.02978 |  0:04:14s\n",
      "epoch 31 | loss: 0.02908 | val_0_mse: 0.03229 |  0:04:22s\n",
      "epoch 32 | loss: 0.02468 | val_0_mse: 0.03225 |  0:04:29s\n",
      "epoch 33 | loss: 0.02911 | val_0_mse: 0.02841 |  0:04:37s\n",
      "epoch 34 | loss: 0.02758 | val_0_mse: 0.0251  |  0:04:45s\n",
      "epoch 35 | loss: 0.02215 | val_0_mse: 0.01775 |  0:04:53s\n",
      "epoch 36 | loss: 0.01989 | val_0_mse: 0.02064 |  0:05:01s\n",
      "epoch 37 | loss: 0.01961 | val_0_mse: 0.02161 |  0:05:09s\n",
      "epoch 38 | loss: 0.03099 | val_0_mse: 0.03844 |  0:05:17s\n",
      "epoch 39 | loss: 0.02833 | val_0_mse: 0.02215 |  0:05:24s\n",
      "epoch 40 | loss: 0.0279  | val_0_mse: 0.02061 |  0:05:32s\n",
      "epoch 41 | loss: 0.02124 | val_0_mse: 0.01947 |  0:05:40s\n",
      "epoch 42 | loss: 0.02047 | val_0_mse: 0.0164  |  0:05:49s\n",
      "epoch 43 | loss: 0.02124 | val_0_mse: 0.01702 |  0:05:57s\n",
      "epoch 44 | loss: 0.01876 | val_0_mse: 0.02948 |  0:06:06s\n",
      "epoch 45 | loss: 0.02021 | val_0_mse: 0.0184  |  0:06:14s\n",
      "epoch 46 | loss: 0.0188  | val_0_mse: 0.02565 |  0:06:22s\n",
      "epoch 47 | loss: 0.02583 | val_0_mse: 0.02075 |  0:06:30s\n",
      "epoch 48 | loss: 0.01973 | val_0_mse: 0.01577 |  0:06:38s\n",
      "epoch 49 | loss: 0.0187  | val_0_mse: 0.01567 |  0:06:45s\n",
      "epoch 50 | loss: 0.02329 | val_0_mse: 0.03348 |  0:06:53s\n",
      "epoch 51 | loss: 0.01699 | val_0_mse: 0.01782 |  0:07:01s\n",
      "epoch 52 | loss: 0.01571 | val_0_mse: 0.01189 |  0:07:09s\n",
      "epoch 53 | loss: 0.01339 | val_0_mse: 0.01059 |  0:07:17s\n",
      "epoch 54 | loss: 0.01242 | val_0_mse: 0.01427 |  0:07:25s\n",
      "epoch 55 | loss: 0.01535 | val_0_mse: 0.01498 |  0:07:33s\n",
      "epoch 56 | loss: 0.01338 | val_0_mse: 0.01051 |  0:07:40s\n",
      "epoch 57 | loss: 0.01406 | val_0_mse: 0.01195 |  0:07:48s\n",
      "epoch 58 | loss: 0.01504 | val_0_mse: 0.01189 |  0:07:56s\n",
      "epoch 59 | loss: 0.01265 | val_0_mse: 0.0104  |  0:08:04s\n",
      "epoch 60 | loss: 0.01331 | val_0_mse: 0.01407 |  0:08:12s\n",
      "epoch 61 | loss: 0.01216 | val_0_mse: 0.00975 |  0:08:20s\n",
      "epoch 62 | loss: 0.01059 | val_0_mse: 0.01288 |  0:08:28s\n",
      "epoch 63 | loss: 0.01084 | val_0_mse: 0.00912 |  0:08:36s\n",
      "epoch 64 | loss: 0.0115  | val_0_mse: 0.01236 |  0:08:43s\n",
      "epoch 65 | loss: 0.01344 | val_0_mse: 0.01052 |  0:08:51s\n",
      "epoch 66 | loss: 0.00971 | val_0_mse: 0.00989 |  0:08:59s\n",
      "epoch 67 | loss: 0.00989 | val_0_mse: 0.0102  |  0:09:07s\n",
      "epoch 68 | loss: 0.01263 | val_0_mse: 0.01291 |  0:09:15s\n",
      "epoch 69 | loss: 0.01494 | val_0_mse: 0.00972 |  0:09:23s\n",
      "epoch 70 | loss: 0.01451 | val_0_mse: 0.01025 |  0:09:30s\n",
      "epoch 71 | loss: 0.01352 | val_0_mse: 0.00866 |  0:09:38s\n",
      "epoch 72 | loss: 0.01058 | val_0_mse: 0.01192 |  0:09:46s\n",
      "epoch 73 | loss: 0.01215 | val_0_mse: 0.00725 |  0:09:54s\n",
      "epoch 74 | loss: 0.00856 | val_0_mse: 0.00865 |  0:10:01s\n",
      "epoch 75 | loss: 0.01586 | val_0_mse: 0.01601 |  0:10:09s\n",
      "epoch 76 | loss: 0.01405 | val_0_mse: 0.02726 |  0:10:17s\n",
      "epoch 77 | loss: 0.01161 | val_0_mse: 0.00719 |  0:10:25s\n",
      "epoch 78 | loss: 0.01029 | val_0_mse: 0.00826 |  0:10:33s\n",
      "epoch 79 | loss: 0.00847 | val_0_mse: 0.00694 |  0:10:40s\n",
      "epoch 80 | loss: 0.01212 | val_0_mse: 0.01264 |  0:10:48s\n",
      "epoch 81 | loss: 0.00996 | val_0_mse: 0.02789 |  0:10:56s\n",
      "epoch 82 | loss: 0.01099 | val_0_mse: 0.00654 |  0:11:04s\n",
      "epoch 83 | loss: 0.01281 | val_0_mse: 0.01072 |  0:11:12s\n",
      "epoch 84 | loss: 0.00904 | val_0_mse: 0.00633 |  0:11:19s\n",
      "epoch 85 | loss: 0.00859 | val_0_mse: 0.01476 |  0:11:27s\n",
      "epoch 86 | loss: 0.01206 | val_0_mse: 0.00865 |  0:11:35s\n",
      "epoch 87 | loss: 0.01005 | val_0_mse: 0.00772 |  0:11:43s\n",
      "epoch 88 | loss: 0.00884 | val_0_mse: 0.00746 |  0:11:50s\n",
      "epoch 89 | loss: 0.00896 | val_0_mse: 0.00929 |  0:11:58s\n",
      "epoch 90 | loss: 0.01265 | val_0_mse: 0.00953 |  0:12:06s\n",
      "epoch 91 | loss: 0.01041 | val_0_mse: 0.01683 |  0:12:14s\n",
      "epoch 92 | loss: 0.01347 | val_0_mse: 0.00636 |  0:12:22s\n",
      "epoch 93 | loss: 0.00946 | val_0_mse: 0.00647 |  0:12:30s\n",
      "epoch 94 | loss: 0.00745 | val_0_mse: 0.00679 |  0:12:37s\n",
      "\n",
      "Early stopping occurred at epoch 94 with best_epoch = 84 and best_val_0_mse = 0.00633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006130 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.972347 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 37/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.93943 | val_0_mse: 1.1461  |  0:00:12s\n",
      "epoch 1  | loss: 0.24361 | val_0_mse: 0.35156 |  0:00:24s\n",
      "epoch 2  | loss: 0.1147  | val_0_mse: 0.20798 |  0:00:34s\n",
      "epoch 3  | loss: 0.08919 | val_0_mse: 0.19677 |  0:00:46s\n",
      "epoch 4  | loss: 0.09031 | val_0_mse: 0.0688  |  0:00:57s\n",
      "epoch 5  | loss: 0.0794  | val_0_mse: 0.0883  |  0:01:08s\n",
      "epoch 6  | loss: 0.07741 | val_0_mse: 0.07474 |  0:01:22s\n",
      "epoch 7  | loss: 0.07443 | val_0_mse: 0.0648  |  0:01:34s\n",
      "epoch 8  | loss: 0.07678 | val_0_mse: 0.06582 |  0:01:44s\n",
      "epoch 9  | loss: 0.0644  | val_0_mse: 0.13192 |  0:01:55s\n",
      "epoch 10 | loss: 0.08111 | val_0_mse: 0.06954 |  0:02:07s\n",
      "epoch 11 | loss: 0.06513 | val_0_mse: 0.05569 |  0:02:21s\n",
      "epoch 12 | loss: 0.05803 | val_0_mse: 0.06276 |  0:02:32s\n",
      "epoch 13 | loss: 0.05538 | val_0_mse: 0.04772 |  0:02:42s\n",
      "epoch 14 | loss: 0.05606 | val_0_mse: 0.04851 |  0:02:52s\n",
      "epoch 15 | loss: 0.05104 | val_0_mse: 0.06161 |  0:03:03s\n",
      "epoch 16 | loss: 0.04977 | val_0_mse: 0.04593 |  0:03:14s\n",
      "epoch 17 | loss: 0.04768 | val_0_mse: 0.04519 |  0:03:24s\n",
      "epoch 18 | loss: 0.04431 | val_0_mse: 0.04031 |  0:03:35s\n",
      "epoch 19 | loss: 0.04642 | val_0_mse: 0.04333 |  0:03:45s\n",
      "epoch 20 | loss: 0.0413  | val_0_mse: 0.03815 |  0:03:55s\n",
      "epoch 21 | loss: 0.04688 | val_0_mse: 0.04346 |  0:04:05s\n",
      "epoch 22 | loss: 0.04487 | val_0_mse: 0.04056 |  0:04:18s\n",
      "epoch 23 | loss: 0.04253 | val_0_mse: 0.04387 |  0:04:28s\n",
      "epoch 24 | loss: 0.03615 | val_0_mse: 0.04069 |  0:04:38s\n",
      "epoch 25 | loss: 0.04461 | val_0_mse: 0.0545  |  0:04:49s\n",
      "epoch 26 | loss: 0.04177 | val_0_mse: 0.03221 |  0:04:59s\n",
      "epoch 27 | loss: 0.03896 | val_0_mse: 0.0314  |  0:05:09s\n",
      "epoch 28 | loss: 0.03651 | val_0_mse: 0.05252 |  0:05:19s\n",
      "epoch 29 | loss: 0.0343  | val_0_mse: 0.03498 |  0:05:29s\n",
      "epoch 30 | loss: 0.0307  | val_0_mse: 0.03505 |  0:05:40s\n",
      "epoch 31 | loss: 0.03027 | val_0_mse: 0.02105 |  0:05:50s\n",
      "epoch 32 | loss: 0.0332  | val_0_mse: 0.04223 |  0:06:00s\n",
      "epoch 33 | loss: 0.02817 | val_0_mse: 0.02587 |  0:06:10s\n",
      "epoch 34 | loss: 0.02428 | val_0_mse: 0.02193 |  0:06:21s\n",
      "epoch 35 | loss: 0.02386 | val_0_mse: 0.01934 |  0:06:31s\n",
      "epoch 36 | loss: 0.02352 | val_0_mse: 0.06566 |  0:06:41s\n",
      "epoch 37 | loss: 0.02292 | val_0_mse: 0.01952 |  0:06:51s\n",
      "epoch 38 | loss: 0.02219 | val_0_mse: 0.03098 |  0:07:01s\n",
      "epoch 39 | loss: 0.01983 | val_0_mse: 0.01409 |  0:07:12s\n",
      "epoch 40 | loss: 0.0252  | val_0_mse: 0.03757 |  0:07:22s\n",
      "epoch 41 | loss: 0.02183 | val_0_mse: 0.03456 |  0:07:32s\n",
      "epoch 42 | loss: 0.01834 | val_0_mse: 0.01886 |  0:07:42s\n",
      "epoch 43 | loss: 0.01803 | val_0_mse: 0.01839 |  0:07:52s\n",
      "epoch 44 | loss: 0.01639 | val_0_mse: 0.01113 |  0:08:03s\n",
      "epoch 45 | loss: 0.01314 | val_0_mse: 0.01147 |  0:08:13s\n",
      "epoch 46 | loss: 0.01523 | val_0_mse: 0.00905 |  0:08:23s\n",
      "epoch 47 | loss: 0.01307 | val_0_mse: 0.01185 |  0:08:33s\n",
      "epoch 48 | loss: 0.01336 | val_0_mse: 0.01346 |  0:08:43s\n",
      "epoch 49 | loss: 0.01272 | val_0_mse: 0.01736 |  0:08:53s\n",
      "epoch 50 | loss: 0.0147  | val_0_mse: 0.00964 |  0:09:03s\n",
      "epoch 51 | loss: 0.01268 | val_0_mse: 0.03351 |  0:09:14s\n",
      "epoch 52 | loss: 0.01888 | val_0_mse: 0.01004 |  0:09:24s\n",
      "epoch 53 | loss: 0.01647 | val_0_mse: 0.02    |  0:09:34s\n",
      "epoch 54 | loss: 0.01434 | val_0_mse: 0.01084 |  0:09:44s\n",
      "epoch 55 | loss: 0.0145  | val_0_mse: 0.01721 |  0:09:54s\n",
      "epoch 56 | loss: 0.01396 | val_0_mse: 0.00831 |  0:10:04s\n",
      "epoch 57 | loss: 0.01277 | val_0_mse: 0.00946 |  0:10:15s\n",
      "epoch 58 | loss: 0.01365 | val_0_mse: 0.00751 |  0:10:25s\n",
      "epoch 59 | loss: 0.01456 | val_0_mse: 0.01027 |  0:10:35s\n",
      "epoch 60 | loss: 0.01241 | val_0_mse: 0.00854 |  0:10:45s\n",
      "epoch 61 | loss: 0.01514 | val_0_mse: 0.00688 |  0:10:55s\n",
      "epoch 62 | loss: 0.01102 | val_0_mse: 0.00975 |  0:11:06s\n",
      "epoch 63 | loss: 0.01072 | val_0_mse: 0.00965 |  0:11:16s\n",
      "epoch 64 | loss: 0.01233 | val_0_mse: 0.00899 |  0:11:26s\n",
      "epoch 65 | loss: 0.01431 | val_0_mse: 0.01063 |  0:11:36s\n",
      "epoch 66 | loss: 0.0121  | val_0_mse: 0.01418 |  0:11:47s\n",
      "epoch 67 | loss: 0.00991 | val_0_mse: 0.01363 |  0:11:57s\n",
      "epoch 68 | loss: 0.01091 | val_0_mse: 0.00566 |  0:12:07s\n",
      "epoch 69 | loss: 0.01278 | val_0_mse: 0.00792 |  0:12:17s\n",
      "epoch 70 | loss: 0.01258 | val_0_mse: 0.04508 |  0:12:27s\n",
      "epoch 71 | loss: 0.01483 | val_0_mse: 0.01096 |  0:12:38s\n",
      "epoch 72 | loss: 0.01052 | val_0_mse: 0.00595 |  0:12:48s\n",
      "epoch 73 | loss: 0.00844 | val_0_mse: 0.01253 |  0:12:58s\n",
      "epoch 74 | loss: 0.0091  | val_0_mse: 0.01056 |  0:13:08s\n",
      "epoch 75 | loss: 0.00922 | val_0_mse: 0.00662 |  0:13:19s\n",
      "epoch 76 | loss: 0.01073 | val_0_mse: 0.01144 |  0:13:29s\n",
      "epoch 77 | loss: 0.01039 | val_0_mse: 0.17088 |  0:13:39s\n",
      "epoch 78 | loss: 0.00919 | val_0_mse: 0.00932 |  0:13:50s\n",
      "\n",
      "Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_mse = 0.00566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.005920 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.973292 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 38/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.20599 | val_0_mse: 0.43211 |  0:00:08s\n",
      "epoch 1  | loss: 0.69587 | val_0_mse: 0.51976 |  0:00:16s\n",
      "epoch 2  | loss: 0.24164 | val_0_mse: 0.60873 |  0:00:24s\n",
      "epoch 3  | loss: 0.19461 | val_0_mse: 0.19313 |  0:00:33s\n",
      "epoch 4  | loss: 0.11754 | val_0_mse: 0.24456 |  0:00:41s\n",
      "epoch 5  | loss: 0.09259 | val_0_mse: 0.20745 |  0:00:49s\n",
      "epoch 6  | loss: 0.08685 | val_0_mse: 0.10331 |  0:00:57s\n",
      "epoch 7  | loss: 0.07611 | val_0_mse: 0.10754 |  0:01:05s\n",
      "epoch 8  | loss: 0.06887 | val_0_mse: 0.13687 |  0:01:13s\n",
      "epoch 9  | loss: 0.06937 | val_0_mse: 0.08012 |  0:01:21s\n",
      "epoch 10 | loss: 0.07286 | val_0_mse: 0.0906  |  0:01:29s\n",
      "epoch 11 | loss: 0.07782 | val_0_mse: 0.06243 |  0:01:39s\n",
      "epoch 12 | loss: 0.06132 | val_0_mse: 0.05425 |  0:01:47s\n",
      "epoch 13 | loss: 0.06084 | val_0_mse: 0.05508 |  0:01:55s\n",
      "epoch 14 | loss: 0.06229 | val_0_mse: 0.05406 |  0:02:03s\n",
      "epoch 15 | loss: 0.06155 | val_0_mse: 0.06747 |  0:02:11s\n",
      "epoch 16 | loss: 0.06991 | val_0_mse: 0.0511  |  0:02:19s\n",
      "epoch 17 | loss: 0.05888 | val_0_mse: 0.04965 |  0:02:27s\n",
      "epoch 18 | loss: 0.05507 | val_0_mse: 0.05646 |  0:02:35s\n",
      "epoch 19 | loss: 0.05538 | val_0_mse: 0.04201 |  0:02:43s\n",
      "epoch 20 | loss: 0.06412 | val_0_mse: 0.04862 |  0:02:51s\n",
      "epoch 21 | loss: 0.0642  | val_0_mse: 0.05557 |  0:02:59s\n",
      "epoch 22 | loss: 0.0551  | val_0_mse: 0.05269 |  0:03:07s\n",
      "epoch 23 | loss: 0.0549  | val_0_mse: 0.04616 |  0:03:15s\n",
      "epoch 24 | loss: 0.05713 | val_0_mse: 0.04725 |  0:03:23s\n",
      "epoch 25 | loss: 0.05553 | val_0_mse: 0.04587 |  0:03:31s\n",
      "epoch 26 | loss: 0.06007 | val_0_mse: 0.04698 |  0:03:39s\n",
      "epoch 27 | loss: 0.05202 | val_0_mse: 0.04821 |  0:03:52s\n",
      "epoch 28 | loss: 0.05604 | val_0_mse: 0.06148 |  0:04:00s\n",
      "epoch 29 | loss: 0.05239 | val_0_mse: 0.04402 |  0:04:08s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_mse = 0.04201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.045436 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.795024 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 39/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.19016 | val_0_mse: 0.84064 |  0:00:12s\n",
      "epoch 1  | loss: 0.28198 | val_0_mse: 0.47903 |  0:00:24s\n",
      "epoch 2  | loss: 0.14544 | val_0_mse: 0.12322 |  0:00:36s\n",
      "epoch 3  | loss: 0.10678 | val_0_mse: 0.10851 |  0:00:49s\n",
      "epoch 4  | loss: 0.11916 | val_0_mse: 0.08177 |  0:01:01s\n",
      "epoch 5  | loss: 0.0832  | val_0_mse: 0.07251 |  0:01:13s\n",
      "epoch 6  | loss: 0.0751  | val_0_mse: 0.09711 |  0:01:25s\n",
      "epoch 7  | loss: 0.06497 | val_0_mse: 0.06367 |  0:01:37s\n",
      "epoch 8  | loss: 0.05508 | val_0_mse: 0.15773 |  0:01:49s\n",
      "epoch 9  | loss: 0.05233 | val_0_mse: 0.03591 |  0:02:01s\n",
      "epoch 10 | loss: 0.04949 | val_0_mse: 0.05001 |  0:02:13s\n",
      "epoch 11 | loss: 0.0476  | val_0_mse: 0.03578 |  0:02:25s\n",
      "epoch 12 | loss: 0.03818 | val_0_mse: 0.0297  |  0:02:37s\n",
      "epoch 13 | loss: 0.03866 | val_0_mse: 0.03402 |  0:02:49s\n",
      "epoch 14 | loss: 0.05383 | val_0_mse: 0.03903 |  0:03:01s\n",
      "epoch 15 | loss: 0.03601 | val_0_mse: 0.06718 |  0:03:13s\n",
      "epoch 16 | loss: 0.03825 | val_0_mse: 0.02739 |  0:03:25s\n",
      "epoch 17 | loss: 0.03357 | val_0_mse: 0.03611 |  0:03:37s\n",
      "epoch 18 | loss: 0.02563 | val_0_mse: 0.03186 |  0:03:49s\n",
      "epoch 19 | loss: 0.02914 | val_0_mse: 0.01538 |  0:04:01s\n",
      "epoch 20 | loss: 0.0218  | val_0_mse: 0.01529 |  0:04:13s\n",
      "epoch 21 | loss: 0.02195 | val_0_mse: 0.01217 |  0:04:25s\n",
      "epoch 22 | loss: 0.01786 | val_0_mse: 0.05119 |  0:04:37s\n",
      "epoch 23 | loss: 0.02677 | val_0_mse: 0.00969 |  0:04:50s\n",
      "epoch 24 | loss: 0.01871 | val_0_mse: 0.02616 |  0:05:03s\n",
      "epoch 25 | loss: 0.02127 | val_0_mse: 0.03843 |  0:05:15s\n",
      "epoch 26 | loss: 0.01564 | val_0_mse: 0.0316  |  0:05:27s\n",
      "epoch 27 | loss: 0.01373 | val_0_mse: 0.05052 |  0:05:39s\n",
      "epoch 28 | loss: 0.02257 | val_0_mse: 0.0096  |  0:05:51s\n",
      "epoch 29 | loss: 0.02053 | val_0_mse: 0.00808 |  0:06:03s\n",
      "epoch 30 | loss: 0.01674 | val_0_mse: 0.0103  |  0:06:14s\n",
      "epoch 31 | loss: 0.01378 | val_0_mse: 0.02178 |  0:06:27s\n",
      "epoch 32 | loss: 0.01756 | val_0_mse: 0.00733 |  0:06:39s\n",
      "epoch 33 | loss: 0.01253 | val_0_mse: 0.01751 |  0:06:50s\n",
      "epoch 34 | loss: 0.01417 | val_0_mse: 0.01458 |  0:07:02s\n",
      "epoch 35 | loss: 0.01601 | val_0_mse: 0.01897 |  0:07:14s\n",
      "epoch 36 | loss: 0.01653 | val_0_mse: 0.01265 |  0:07:26s\n",
      "epoch 37 | loss: 0.01631 | val_0_mse: 0.01509 |  0:07:38s\n",
      "epoch 38 | loss: 0.01414 | val_0_mse: 0.01014 |  0:07:50s\n",
      "epoch 39 | loss: 0.01142 | val_0_mse: 0.02615 |  0:08:02s\n",
      "epoch 40 | loss: 0.01407 | val_0_mse: 0.01101 |  0:08:14s\n",
      "epoch 41 | loss: 0.01293 | val_0_mse: 0.0094  |  0:08:25s\n",
      "epoch 42 | loss: 0.02135 | val_0_mse: 0.01107 |  0:08:37s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 0.00733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007224 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.967409 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 40/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=32, n_a=32, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.13877 | val_0_mse: 1.79111 |  0:00:09s\n",
      "epoch 1  | loss: 0.93227 | val_0_mse: 0.33154 |  0:00:18s\n",
      "epoch 2  | loss: 0.40263 | val_0_mse: 0.29378 |  0:00:26s\n",
      "epoch 3  | loss: 0.37351 | val_0_mse: 0.2356  |  0:00:35s\n",
      "epoch 4  | loss: 0.12997 | val_0_mse: 0.11916 |  0:00:44s\n",
      "epoch 5  | loss: 0.10409 | val_0_mse: 0.1123  |  0:00:52s\n",
      "epoch 6  | loss: 0.09293 | val_0_mse: 0.10557 |  0:01:01s\n",
      "epoch 7  | loss: 0.13583 | val_0_mse: 0.11691 |  0:01:10s\n",
      "epoch 8  | loss: 0.08913 | val_0_mse: 0.09316 |  0:01:19s\n",
      "epoch 9  | loss: 0.09931 | val_0_mse: 0.0997  |  0:01:28s\n",
      "epoch 10 | loss: 0.09083 | val_0_mse: 0.10291 |  0:01:36s\n",
      "epoch 11 | loss: 0.08862 | val_0_mse: 0.09168 |  0:01:45s\n",
      "epoch 12 | loss: 0.0836  | val_0_mse: 0.10571 |  0:01:54s\n",
      "epoch 13 | loss: 0.08157 | val_0_mse: 0.08454 |  0:02:03s\n",
      "epoch 14 | loss: 0.0785  | val_0_mse: 0.07327 |  0:02:11s\n",
      "epoch 15 | loss: 0.07008 | val_0_mse: 0.06578 |  0:02:20s\n",
      "epoch 16 | loss: 0.07034 | val_0_mse: 0.06576 |  0:02:29s\n",
      "epoch 17 | loss: 0.07323 | val_0_mse: 0.07722 |  0:02:38s\n",
      "epoch 18 | loss: 0.07837 | val_0_mse: 0.08528 |  0:02:46s\n",
      "epoch 19 | loss: 0.07491 | val_0_mse: 0.07226 |  0:02:55s\n",
      "epoch 20 | loss: 0.07369 | val_0_mse: 0.06743 |  0:03:04s\n",
      "epoch 21 | loss: 0.06989 | val_0_mse: 0.06821 |  0:03:12s\n",
      "epoch 22 | loss: 0.07099 | val_0_mse: 0.06486 |  0:03:21s\n",
      "epoch 23 | loss: 0.07193 | val_0_mse: 0.05885 |  0:03:30s\n",
      "epoch 24 | loss: 0.06519 | val_0_mse: 0.06629 |  0:03:39s\n",
      "epoch 25 | loss: 0.0699  | val_0_mse: 0.07579 |  0:03:48s\n",
      "epoch 26 | loss: 0.06108 | val_0_mse: 0.05052 |  0:03:56s\n",
      "epoch 27 | loss: 0.0586  | val_0_mse: 0.05601 |  0:04:05s\n",
      "epoch 28 | loss: 0.05565 | val_0_mse: 0.04639 |  0:04:14s\n",
      "epoch 29 | loss: 0.05436 | val_0_mse: 0.05148 |  0:04:23s\n",
      "epoch 30 | loss: 0.05125 | val_0_mse: 0.04623 |  0:04:31s\n",
      "epoch 31 | loss: 0.05052 | val_0_mse: 0.05773 |  0:04:40s\n",
      "epoch 32 | loss: 0.04951 | val_0_mse: 0.03691 |  0:04:49s\n",
      "epoch 33 | loss: 0.04112 | val_0_mse: 0.03681 |  0:04:58s\n",
      "epoch 34 | loss: 0.03765 | val_0_mse: 0.03397 |  0:05:07s\n",
      "epoch 35 | loss: 0.03546 | val_0_mse: 0.02825 |  0:05:15s\n",
      "epoch 36 | loss: 0.03218 | val_0_mse: 0.02328 |  0:05:24s\n",
      "epoch 37 | loss: 0.02971 | val_0_mse: 0.02611 |  0:05:33s\n",
      "epoch 38 | loss: 0.02704 | val_0_mse: 0.02439 |  0:05:42s\n",
      "epoch 39 | loss: 0.0246  | val_0_mse: 0.02013 |  0:05:51s\n",
      "epoch 40 | loss: 0.02522 | val_0_mse: 0.03886 |  0:05:59s\n",
      "epoch 41 | loss: 0.02514 | val_0_mse: 0.01781 |  0:06:08s\n",
      "epoch 42 | loss: 0.02115 | val_0_mse: 0.0148  |  0:06:17s\n",
      "epoch 43 | loss: 0.02078 | val_0_mse: 0.01826 |  0:06:26s\n",
      "epoch 44 | loss: 0.02818 | val_0_mse: 0.0211  |  0:06:34s\n",
      "epoch 45 | loss: 0.02948 | val_0_mse: 0.01945 |  0:06:43s\n",
      "epoch 46 | loss: 0.02836 | val_0_mse: 0.02511 |  0:06:52s\n",
      "epoch 47 | loss: 0.02603 | val_0_mse: 0.01629 |  0:07:01s\n",
      "epoch 48 | loss: 0.02636 | val_0_mse: 0.02279 |  0:07:09s\n",
      "epoch 49 | loss: 0.02064 | val_0_mse: 0.01321 |  0:07:18s\n",
      "epoch 50 | loss: 0.0172  | val_0_mse: 0.01246 |  0:07:27s\n",
      "epoch 51 | loss: 0.0184  | val_0_mse: 0.01526 |  0:07:36s\n",
      "epoch 52 | loss: 0.02039 | val_0_mse: 0.0268  |  0:07:44s\n",
      "epoch 53 | loss: 0.0264  | val_0_mse: 0.01713 |  0:07:53s\n",
      "epoch 54 | loss: 0.02332 | val_0_mse: 0.05543 |  0:08:02s\n",
      "epoch 55 | loss: 0.02385 | val_0_mse: 0.01879 |  0:08:10s\n",
      "epoch 56 | loss: 0.0213  | val_0_mse: 0.01695 |  0:08:19s\n",
      "epoch 57 | loss: 0.01953 | val_0_mse: 0.01524 |  0:08:28s\n",
      "epoch 58 | loss: 0.01998 | val_0_mse: 0.01583 |  0:08:36s\n",
      "epoch 59 | loss: 0.021   | val_0_mse: 0.01895 |  0:08:46s\n",
      "epoch 60 | loss: 0.0183  | val_0_mse: 0.01993 |  0:08:54s\n",
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 0.01246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.013481 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.939184 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 41/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.01985 | val_0_mse: 0.23005 |  0:00:12s\n",
      "epoch 1  | loss: 0.7015  | val_0_mse: 0.14935 |  0:00:24s\n",
      "epoch 2  | loss: 0.18605 | val_0_mse: 0.40244 |  0:00:36s\n",
      "epoch 3  | loss: 0.12515 | val_0_mse: 0.10359 |  0:00:49s\n",
      "epoch 4  | loss: 0.12046 | val_0_mse: 0.09442 |  0:01:01s\n",
      "epoch 5  | loss: 0.08966 | val_0_mse: 0.07089 |  0:01:12s\n",
      "epoch 6  | loss: 0.06861 | val_0_mse: 0.079   |  0:01:24s\n",
      "epoch 7  | loss: 0.07674 | val_0_mse: 0.04828 |  0:01:36s\n",
      "epoch 8  | loss: 0.05685 | val_0_mse: 0.04888 |  0:01:47s\n",
      "epoch 9  | loss: 0.04902 | val_0_mse: 0.053   |  0:01:59s\n",
      "epoch 10 | loss: 0.06032 | val_0_mse: 0.0466  |  0:02:11s\n",
      "epoch 11 | loss: 0.05844 | val_0_mse: 0.0419  |  0:02:23s\n",
      "epoch 12 | loss: 0.04772 | val_0_mse: 0.04264 |  0:02:35s\n",
      "epoch 13 | loss: 0.04622 | val_0_mse: 0.04883 |  0:02:46s\n",
      "epoch 14 | loss: 0.0484  | val_0_mse: 0.05711 |  0:02:58s\n",
      "epoch 15 | loss: 0.04593 | val_0_mse: 0.03165 |  0:03:10s\n",
      "epoch 16 | loss: 0.03752 | val_0_mse: 0.02848 |  0:03:21s\n",
      "epoch 17 | loss: 0.03758 | val_0_mse: 0.02422 |  0:03:33s\n",
      "epoch 18 | loss: 0.03102 | val_0_mse: 0.05955 |  0:03:45s\n",
      "epoch 19 | loss: 0.02936 | val_0_mse: 0.02588 |  0:03:57s\n",
      "epoch 20 | loss: 0.02697 | val_0_mse: 0.02423 |  0:04:08s\n",
      "epoch 21 | loss: 0.02688 | val_0_mse: 0.03903 |  0:04:20s\n",
      "epoch 22 | loss: 0.02929 | val_0_mse: 0.02101 |  0:04:32s\n",
      "epoch 23 | loss: 0.02318 | val_0_mse: 0.01635 |  0:04:43s\n",
      "epoch 24 | loss: 0.02097 | val_0_mse: 0.02918 |  0:04:55s\n",
      "epoch 25 | loss: 0.02104 | val_0_mse: 0.0155  |  0:05:07s\n",
      "epoch 26 | loss: 0.02415 | val_0_mse: 0.01849 |  0:05:19s\n",
      "epoch 27 | loss: 0.02195 | val_0_mse: 0.02367 |  0:05:30s\n",
      "epoch 28 | loss: 0.02117 | val_0_mse: 0.0311  |  0:05:42s\n",
      "epoch 29 | loss: 0.02964 | val_0_mse: 0.03083 |  0:05:54s\n",
      "epoch 30 | loss: 0.01919 | val_0_mse: 0.01322 |  0:06:05s\n",
      "epoch 31 | loss: 0.01804 | val_0_mse: 0.01316 |  0:06:17s\n",
      "epoch 32 | loss: 0.01632 | val_0_mse: 0.01241 |  0:06:29s\n",
      "epoch 33 | loss: 0.02113 | val_0_mse: 0.01268 |  0:06:40s\n",
      "epoch 34 | loss: 0.01326 | val_0_mse: 0.00975 |  0:06:52s\n",
      "epoch 35 | loss: 0.0121  | val_0_mse: 0.01677 |  0:07:04s\n",
      "epoch 36 | loss: 0.01517 | val_0_mse: 0.00833 |  0:07:16s\n",
      "epoch 37 | loss: 0.0127  | val_0_mse: 0.01012 |  0:07:27s\n",
      "epoch 38 | loss: 0.01323 | val_0_mse: 0.01101 |  0:07:39s\n",
      "epoch 39 | loss: 0.01322 | val_0_mse: 0.00878 |  0:07:51s\n",
      "epoch 40 | loss: 0.01273 | val_0_mse: 0.01323 |  0:08:03s\n",
      "epoch 41 | loss: 0.01287 | val_0_mse: 0.01327 |  0:08:15s\n",
      "epoch 42 | loss: 0.01137 | val_0_mse: 0.01143 |  0:08:26s\n",
      "epoch 43 | loss: 0.00917 | val_0_mse: 0.01264 |  0:08:38s\n",
      "epoch 44 | loss: 0.01433 | val_0_mse: 0.00945 |  0:08:50s\n",
      "epoch 45 | loss: 0.01515 | val_0_mse: 0.02829 |  0:09:01s\n",
      "epoch 46 | loss: 0.01637 | val_0_mse: 0.0123  |  0:09:13s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_mse = 0.00833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008053 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.963671 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 42/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.87494 | val_0_mse: 0.45294 |  0:00:08s\n",
      "epoch 1  | loss: 0.82709 | val_0_mse: 0.35773 |  0:00:17s\n",
      "epoch 2  | loss: 0.34375 | val_0_mse: 0.31468 |  0:00:25s\n",
      "epoch 3  | loss: 0.47861 | val_0_mse: 0.14461 |  0:00:34s\n",
      "epoch 4  | loss: 0.24038 | val_0_mse: 0.11156 |  0:00:42s\n",
      "epoch 5  | loss: 0.08954 | val_0_mse: 0.1164  |  0:00:51s\n",
      "epoch 6  | loss: 0.06914 | val_0_mse: 0.09715 |  0:00:59s\n",
      "epoch 7  | loss: 0.06644 | val_0_mse: 0.09511 |  0:01:11s\n",
      "epoch 8  | loss: 0.069   | val_0_mse: 0.08294 |  0:01:19s\n",
      "epoch 9  | loss: 0.06447 | val_0_mse: 0.08369 |  0:01:28s\n",
      "epoch 10 | loss: 0.06058 | val_0_mse: 0.06564 |  0:01:36s\n",
      "epoch 11 | loss: 0.05852 | val_0_mse: 0.08412 |  0:01:44s\n",
      "epoch 12 | loss: 0.06353 | val_0_mse: 0.05902 |  0:01:52s\n",
      "epoch 13 | loss: 0.07113 | val_0_mse: 0.04723 |  0:02:00s\n",
      "epoch 14 | loss: 0.05584 | val_0_mse: 0.05369 |  0:02:08s\n",
      "epoch 15 | loss: 0.06039 | val_0_mse: 0.07029 |  0:02:16s\n",
      "epoch 16 | loss: 0.06351 | val_0_mse: 0.04891 |  0:02:24s\n",
      "epoch 17 | loss: 0.05411 | val_0_mse: 0.0465  |  0:02:33s\n",
      "epoch 18 | loss: 0.05555 | val_0_mse: 0.06111 |  0:02:41s\n",
      "epoch 19 | loss: 0.04985 | val_0_mse: 0.0529  |  0:02:49s\n",
      "epoch 20 | loss: 0.05401 | val_0_mse: 0.04988 |  0:02:57s\n",
      "epoch 21 | loss: 0.05492 | val_0_mse: 0.04827 |  0:03:05s\n",
      "epoch 22 | loss: 0.05252 | val_0_mse: 0.04552 |  0:03:13s\n",
      "epoch 23 | loss: 0.05122 | val_0_mse: 0.05678 |  0:03:21s\n",
      "epoch 24 | loss: 0.04855 | val_0_mse: 0.04366 |  0:03:29s\n",
      "epoch 25 | loss: 0.04993 | val_0_mse: 0.04715 |  0:03:37s\n",
      "epoch 26 | loss: 0.04958 | val_0_mse: 0.0444  |  0:03:45s\n",
      "epoch 27 | loss: 0.04793 | val_0_mse: 0.03829 |  0:03:53s\n",
      "epoch 28 | loss: 0.04572 | val_0_mse: 0.06525 |  0:04:01s\n",
      "epoch 29 | loss: 0.04792 | val_0_mse: 0.04023 |  0:04:09s\n",
      "epoch 30 | loss: 0.04504 | val_0_mse: 0.03896 |  0:04:17s\n",
      "epoch 31 | loss: 0.04492 | val_0_mse: 0.04365 |  0:04:26s\n",
      "epoch 32 | loss: 0.04258 | val_0_mse: 0.04701 |  0:04:34s\n",
      "epoch 33 | loss: 0.04503 | val_0_mse: 0.04343 |  0:04:42s\n",
      "epoch 34 | loss: 0.04336 | val_0_mse: 0.04029 |  0:04:50s\n",
      "epoch 35 | loss: 0.04288 | val_0_mse: 0.0386  |  0:04:58s\n",
      "epoch 36 | loss: 0.04373 | val_0_mse: 0.0347  |  0:05:06s\n",
      "epoch 37 | loss: 0.03909 | val_0_mse: 0.0377  |  0:05:14s\n",
      "epoch 38 | loss: 0.03899 | val_0_mse: 0.03358 |  0:05:22s\n",
      "epoch 39 | loss: 0.03937 | val_0_mse: 0.03017 |  0:05:31s\n",
      "epoch 40 | loss: 0.03839 | val_0_mse: 0.03431 |  0:05:39s\n",
      "epoch 41 | loss: 0.03778 | val_0_mse: 0.03161 |  0:05:47s\n",
      "epoch 42 | loss: 0.03654 | val_0_mse: 0.03411 |  0:05:55s\n",
      "epoch 43 | loss: 0.04153 | val_0_mse: 0.03905 |  0:06:04s\n",
      "epoch 44 | loss: 0.04328 | val_0_mse: 0.02895 |  0:06:13s\n",
      "epoch 45 | loss: 0.03949 | val_0_mse: 0.0366  |  0:06:22s\n",
      "epoch 46 | loss: 0.0393  | val_0_mse: 0.03035 |  0:06:31s\n",
      "epoch 47 | loss: 0.03861 | val_0_mse: 0.05678 |  0:06:39s\n",
      "epoch 48 | loss: 0.03529 | val_0_mse: 0.02475 |  0:06:48s\n",
      "epoch 49 | loss: 0.03104 | val_0_mse: 0.0374  |  0:06:56s\n",
      "epoch 50 | loss: 0.03197 | val_0_mse: 0.04402 |  0:07:04s\n",
      "epoch 51 | loss: 0.03255 | val_0_mse: 0.02605 |  0:07:12s\n",
      "epoch 52 | loss: 0.03196 | val_0_mse: 0.02431 |  0:07:21s\n",
      "epoch 53 | loss: 0.03174 | val_0_mse: 0.03072 |  0:07:29s\n",
      "epoch 54 | loss: 0.03731 | val_0_mse: 0.04073 |  0:07:37s\n",
      "epoch 55 | loss: 0.03711 | val_0_mse: 0.032   |  0:07:45s\n",
      "epoch 56 | loss: 0.034   | val_0_mse: 0.02996 |  0:07:53s\n",
      "epoch 57 | loss: 0.03926 | val_0_mse: 0.0379  |  0:08:01s\n",
      "epoch 58 | loss: 0.04424 | val_0_mse: 0.03394 |  0:08:09s\n",
      "epoch 59 | loss: 0.04213 | val_0_mse: 0.03956 |  0:08:17s\n",
      "epoch 60 | loss: 0.04171 | val_0_mse: 0.03583 |  0:08:25s\n",
      "epoch 61 | loss: 0.04377 | val_0_mse: 0.0475  |  0:08:33s\n",
      "epoch 62 | loss: 0.03964 | val_0_mse: 0.03233 |  0:08:41s\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_mse = 0.02431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.026952 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.878412 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 43/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.66555 | val_0_mse: 0.77233 |  0:00:13s\n",
      "epoch 1  | loss: 0.39575 | val_0_mse: 0.20523 |  0:00:26s\n",
      "epoch 2  | loss: 0.19748 | val_0_mse: 0.16293 |  0:00:38s\n",
      "epoch 3  | loss: 0.14796 | val_0_mse: 0.0859  |  0:00:50s\n",
      "epoch 4  | loss: 0.10047 | val_0_mse: 0.14517 |  0:01:03s\n",
      "epoch 5  | loss: 0.08479 | val_0_mse: 0.06616 |  0:01:17s\n",
      "epoch 6  | loss: 0.07374 | val_0_mse: 0.06174 |  0:01:30s\n",
      "epoch 7  | loss: 0.07291 | val_0_mse: 0.11176 |  0:01:43s\n",
      "epoch 8  | loss: 0.07257 | val_0_mse: 0.08206 |  0:01:58s\n",
      "epoch 9  | loss: 0.07093 | val_0_mse: 0.07107 |  0:02:11s\n",
      "epoch 10 | loss: 0.05874 | val_0_mse: 0.07777 |  0:02:23s\n",
      "epoch 11 | loss: 0.07028 | val_0_mse: 0.05625 |  0:02:35s\n",
      "epoch 12 | loss: 0.0566  | val_0_mse: 0.04846 |  0:02:46s\n",
      "epoch 13 | loss: 0.05412 | val_0_mse: 0.05808 |  0:02:58s\n",
      "epoch 14 | loss: 0.0619  | val_0_mse: 0.03826 |  0:03:10s\n",
      "epoch 15 | loss: 0.05048 | val_0_mse: 0.05477 |  0:03:22s\n",
      "epoch 16 | loss: 0.04889 | val_0_mse: 0.03233 |  0:03:34s\n",
      "epoch 17 | loss: 0.04251 | val_0_mse: 0.03718 |  0:03:46s\n",
      "epoch 18 | loss: 0.04311 | val_0_mse: 0.03229 |  0:03:58s\n",
      "epoch 19 | loss: 0.04145 | val_0_mse: 0.02921 |  0:04:10s\n",
      "epoch 20 | loss: 0.03938 | val_0_mse: 0.03217 |  0:04:22s\n",
      "epoch 21 | loss: 0.03802 | val_0_mse: 0.03448 |  0:04:34s\n",
      "epoch 22 | loss: 0.03713 | val_0_mse: 0.0259  |  0:04:46s\n",
      "epoch 23 | loss: 0.04502 | val_0_mse: 0.0413  |  0:04:58s\n",
      "epoch 24 | loss: 0.04094 | val_0_mse: 0.04225 |  0:05:09s\n",
      "epoch 25 | loss: 0.0412  | val_0_mse: 0.02528 |  0:05:21s\n",
      "epoch 26 | loss: 0.03955 | val_0_mse: 0.05429 |  0:05:34s\n",
      "epoch 27 | loss: 0.03779 | val_0_mse: 0.02426 |  0:05:46s\n",
      "epoch 28 | loss: 0.03473 | val_0_mse: 0.02706 |  0:05:57s\n",
      "epoch 29 | loss: 0.03454 | val_0_mse: 0.02231 |  0:06:09s\n",
      "epoch 30 | loss: 0.02964 | val_0_mse: 0.02027 |  0:06:21s\n",
      "epoch 31 | loss: 0.03016 | val_0_mse: 0.02568 |  0:06:33s\n",
      "epoch 32 | loss: 0.03483 | val_0_mse: 0.02808 |  0:06:47s\n",
      "epoch 33 | loss: 0.03321 | val_0_mse: 0.02408 |  0:06:59s\n",
      "epoch 34 | loss: 0.02744 | val_0_mse: 0.02642 |  0:07:11s\n",
      "epoch 35 | loss: 0.02521 | val_0_mse: 0.01969 |  0:07:23s\n",
      "epoch 36 | loss: 0.02815 | val_0_mse: 0.02018 |  0:07:35s\n",
      "epoch 37 | loss: 0.02892 | val_0_mse: 0.04604 |  0:07:47s\n",
      "epoch 38 | loss: 0.0349  | val_0_mse: 0.03217 |  0:07:59s\n",
      "epoch 39 | loss: 0.03047 | val_0_mse: 0.0382  |  0:08:11s\n",
      "epoch 40 | loss: 0.02839 | val_0_mse: 0.03763 |  0:08:23s\n",
      "epoch 41 | loss: 0.02566 | val_0_mse: 0.02196 |  0:08:35s\n",
      "epoch 42 | loss: 0.02686 | val_0_mse: 0.02176 |  0:08:47s\n",
      "epoch 43 | loss: 0.02282 | val_0_mse: 0.01546 |  0:08:59s\n",
      "epoch 44 | loss: 0.01858 | val_0_mse: 0.01917 |  0:09:11s\n",
      "epoch 45 | loss: 0.02306 | val_0_mse: 0.02823 |  0:09:23s\n",
      "epoch 46 | loss: 0.02906 | val_0_mse: 0.02187 |  0:09:35s\n",
      "epoch 47 | loss: 0.02407 | val_0_mse: 0.02254 |  0:09:47s\n",
      "epoch 48 | loss: 0.02516 | val_0_mse: 0.06528 |  0:09:58s\n",
      "epoch 49 | loss: 0.02399 | val_0_mse: 0.02096 |  0:10:11s\n",
      "epoch 50 | loss: 0.02567 | val_0_mse: 0.01351 |  0:10:22s\n",
      "epoch 51 | loss: 0.01905 | val_0_mse: 0.02347 |  0:10:35s\n",
      "epoch 52 | loss: 0.01606 | val_0_mse: 0.01027 |  0:10:47s\n",
      "epoch 53 | loss: 0.01717 | val_0_mse: 0.01527 |  0:10:59s\n",
      "epoch 54 | loss: 0.0168  | val_0_mse: 0.02101 |  0:11:11s\n",
      "epoch 55 | loss: 0.01349 | val_0_mse: 0.00896 |  0:11:23s\n",
      "epoch 56 | loss: 0.02297 | val_0_mse: 0.05358 |  0:11:34s\n",
      "epoch 57 | loss: 0.01544 | val_0_mse: 0.01562 |  0:11:46s\n",
      "epoch 58 | loss: 0.01415 | val_0_mse: 0.00977 |  0:11:59s\n",
      "epoch 59 | loss: 0.01523 | val_0_mse: 0.00853 |  0:12:11s\n",
      "epoch 60 | loss: 0.01332 | val_0_mse: 0.00711 |  0:12:23s\n",
      "epoch 61 | loss: 0.01106 | val_0_mse: 0.00857 |  0:12:35s\n",
      "epoch 62 | loss: 0.01607 | val_0_mse: 0.01069 |  0:12:47s\n",
      "epoch 63 | loss: 0.01343 | val_0_mse: 0.01098 |  0:12:59s\n",
      "epoch 64 | loss: 0.01432 | val_0_mse: 0.02625 |  0:13:11s\n",
      "epoch 65 | loss: 0.01229 | val_0_mse: 0.02423 |  0:13:23s\n",
      "epoch 66 | loss: 0.01637 | val_0_mse: 0.02318 |  0:13:35s\n",
      "epoch 67 | loss: 0.01224 | val_0_mse: 0.01147 |  0:13:47s\n",
      "epoch 68 | loss: 0.01352 | val_0_mse: 0.01124 |  0:13:58s\n",
      "epoch 69 | loss: 0.0131  | val_0_mse: 0.01557 |  0:14:10s\n",
      "epoch 70 | loss: 0.01234 | val_0_mse: 0.00696 |  0:14:22s\n",
      "epoch 71 | loss: 0.01615 | val_0_mse: 0.08219 |  0:14:35s\n",
      "epoch 72 | loss: 0.01445 | val_0_mse: 0.02979 |  0:14:46s\n",
      "epoch 73 | loss: 0.01894 | val_0_mse: 0.01189 |  0:14:58s\n",
      "epoch 74 | loss: 0.01642 | val_0_mse: 0.00972 |  0:15:10s\n",
      "epoch 75 | loss: 0.0123  | val_0_mse: 0.01031 |  0:15:22s\n",
      "epoch 76 | loss: 0.01649 | val_0_mse: 0.07675 |  0:15:34s\n",
      "epoch 77 | loss: 0.02253 | val_0_mse: 0.01637 |  0:15:46s\n",
      "epoch 78 | loss: 0.01614 | val_0_mse: 0.01438 |  0:15:57s\n",
      "epoch 79 | loss: 0.01086 | val_0_mse: 0.00829 |  0:16:09s\n",
      "epoch 80 | loss: 0.01149 | val_0_mse: 0.00786 |  0:16:21s\n",
      "\n",
      "Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 0.00696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006680 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.969863 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 44/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.34261 | val_0_mse: 0.68924 |  0:00:09s\n",
      "epoch 1  | loss: 0.48788 | val_0_mse: 0.4703  |  0:00:18s\n",
      "epoch 2  | loss: 0.55696 | val_0_mse: 0.98301 |  0:00:27s\n",
      "epoch 3  | loss: 0.27498 | val_0_mse: 0.29512 |  0:00:37s\n",
      "epoch 4  | loss: 0.13794 | val_0_mse: 0.2344  |  0:00:46s\n",
      "epoch 5  | loss: 0.11074 | val_0_mse: 0.13484 |  0:00:55s\n",
      "epoch 6  | loss: 0.11126 | val_0_mse: 0.13112 |  0:01:04s\n",
      "epoch 7  | loss: 0.09327 | val_0_mse: 0.09528 |  0:01:13s\n",
      "epoch 8  | loss: 0.07467 | val_0_mse: 0.10798 |  0:01:22s\n",
      "epoch 9  | loss: 0.08527 | val_0_mse: 0.09186 |  0:01:31s\n",
      "epoch 10 | loss: 0.07072 | val_0_mse: 0.08497 |  0:01:41s\n",
      "epoch 11 | loss: 0.06661 | val_0_mse: 0.07055 |  0:01:50s\n",
      "epoch 12 | loss: 0.06485 | val_0_mse: 0.05769 |  0:01:59s\n",
      "epoch 13 | loss: 0.06035 | val_0_mse: 0.05137 |  0:02:08s\n",
      "epoch 14 | loss: 0.06345 | val_0_mse: 0.04752 |  0:02:17s\n",
      "epoch 15 | loss: 0.06185 | val_0_mse: 0.04856 |  0:02:26s\n",
      "epoch 16 | loss: 0.06438 | val_0_mse: 0.04987 |  0:02:35s\n",
      "epoch 17 | loss: 0.05688 | val_0_mse: 0.05808 |  0:02:44s\n",
      "epoch 18 | loss: 0.05972 | val_0_mse: 0.05841 |  0:02:53s\n",
      "epoch 19 | loss: 0.05738 | val_0_mse: 0.04499 |  0:03:03s\n",
      "epoch 20 | loss: 0.04896 | val_0_mse: 0.03975 |  0:03:12s\n",
      "epoch 21 | loss: 0.04959 | val_0_mse: 0.05214 |  0:03:21s\n",
      "epoch 22 | loss: 0.04975 | val_0_mse: 0.04144 |  0:03:30s\n",
      "epoch 23 | loss: 0.06086 | val_0_mse: 0.04399 |  0:03:39s\n",
      "epoch 24 | loss: 0.05422 | val_0_mse: 0.05225 |  0:03:48s\n",
      "epoch 25 | loss: 0.05059 | val_0_mse: 0.046   |  0:03:58s\n",
      "epoch 26 | loss: 0.05079 | val_0_mse: 0.04136 |  0:04:07s\n",
      "epoch 27 | loss: 0.04859 | val_0_mse: 0.03763 |  0:04:16s\n",
      "epoch 28 | loss: 0.04436 | val_0_mse: 0.03794 |  0:04:25s\n",
      "epoch 29 | loss: 0.0398  | val_0_mse: 0.03991 |  0:04:34s\n",
      "epoch 30 | loss: 0.03711 | val_0_mse: 0.03584 |  0:04:43s\n",
      "epoch 31 | loss: 0.03925 | val_0_mse: 0.02875 |  0:04:52s\n",
      "epoch 32 | loss: 0.03821 | val_0_mse: 0.02999 |  0:05:01s\n",
      "epoch 33 | loss: 0.04017 | val_0_mse: 0.03123 |  0:05:10s\n",
      "epoch 34 | loss: 0.03048 | val_0_mse: 0.02501 |  0:05:20s\n",
      "epoch 35 | loss: 0.02794 | val_0_mse: 0.02097 |  0:05:29s\n",
      "epoch 36 | loss: 0.02795 | val_0_mse: 0.02208 |  0:05:38s\n",
      "epoch 37 | loss: 0.02723 | val_0_mse: 0.0182  |  0:05:47s\n",
      "epoch 38 | loss: 0.02397 | val_0_mse: 0.01795 |  0:05:56s\n",
      "epoch 39 | loss: 0.02354 | val_0_mse: 0.02119 |  0:06:05s\n",
      "epoch 40 | loss: 0.02277 | val_0_mse: 0.02313 |  0:06:14s\n",
      "epoch 41 | loss: 0.03059 | val_0_mse: 0.01825 |  0:06:23s\n",
      "epoch 42 | loss: 0.02518 | val_0_mse: 0.01917 |  0:06:32s\n",
      "epoch 43 | loss: 0.02293 | val_0_mse: 0.02685 |  0:06:41s\n",
      "epoch 44 | loss: 0.02482 | val_0_mse: 0.0207  |  0:06:51s\n",
      "epoch 45 | loss: 0.02464 | val_0_mse: 0.01822 |  0:07:00s\n",
      "epoch 46 | loss: 0.02478 | val_0_mse: 0.01607 |  0:07:09s\n",
      "epoch 47 | loss: 0.02335 | val_0_mse: 0.01762 |  0:07:23s\n",
      "epoch 48 | loss: 0.02362 | val_0_mse: 0.02389 |  0:07:33s\n",
      "epoch 49 | loss: 0.02447 | val_0_mse: 0.0133  |  0:07:41s\n",
      "epoch 50 | loss: 0.0214  | val_0_mse: 0.02276 |  0:07:50s\n",
      "epoch 51 | loss: 0.01995 | val_0_mse: 0.01265 |  0:08:00s\n",
      "epoch 52 | loss: 0.0181  | val_0_mse: 0.01224 |  0:08:09s\n",
      "epoch 53 | loss: 0.01626 | val_0_mse: 0.02476 |  0:08:18s\n",
      "epoch 54 | loss: 0.01821 | val_0_mse: 0.01567 |  0:08:27s\n",
      "epoch 55 | loss: 0.02157 | val_0_mse: 0.0133  |  0:08:36s\n",
      "epoch 56 | loss: 0.0163  | val_0_mse: 0.01288 |  0:08:45s\n",
      "epoch 57 | loss: 0.01271 | val_0_mse: 0.01143 |  0:08:54s\n",
      "epoch 58 | loss: 0.01838 | val_0_mse: 0.00917 |  0:09:03s\n",
      "epoch 59 | loss: 0.01339 | val_0_mse: 0.01769 |  0:09:12s\n",
      "epoch 60 | loss: 0.01732 | val_0_mse: 0.00845 |  0:09:21s\n",
      "epoch 61 | loss: 0.01313 | val_0_mse: 0.01042 |  0:09:30s\n",
      "epoch 62 | loss: 0.01177 | val_0_mse: 0.02461 |  0:09:39s\n",
      "epoch 63 | loss: 0.01402 | val_0_mse: 0.01309 |  0:09:48s\n",
      "epoch 64 | loss: 0.01686 | val_0_mse: 0.01147 |  0:09:57s\n",
      "epoch 65 | loss: 0.02162 | val_0_mse: 0.08998 |  0:10:06s\n",
      "epoch 66 | loss: 0.02148 | val_0_mse: 0.01856 |  0:10:16s\n",
      "epoch 67 | loss: 0.01452 | val_0_mse: 0.01743 |  0:10:24s\n",
      "epoch 68 | loss: 0.01535 | val_0_mse: 0.01058 |  0:10:34s\n",
      "epoch 69 | loss: 0.01436 | val_0_mse: 0.01598 |  0:10:43s\n",
      "epoch 70 | loss: 0.01456 | val_0_mse: 0.00741 |  0:10:52s\n",
      "epoch 71 | loss: 0.01069 | val_0_mse: 0.0134  |  0:11:01s\n",
      "epoch 72 | loss: 0.01122 | val_0_mse: 0.00936 |  0:11:10s\n",
      "epoch 73 | loss: 0.014   | val_0_mse: 0.01207 |  0:11:19s\n",
      "epoch 74 | loss: 0.01165 | val_0_mse: 0.00855 |  0:11:28s\n",
      "epoch 75 | loss: 0.01358 | val_0_mse: 0.02089 |  0:11:37s\n",
      "epoch 76 | loss: 0.01276 | val_0_mse: 0.01099 |  0:11:46s\n",
      "epoch 77 | loss: 0.01082 | val_0_mse: 0.00703 |  0:11:55s\n",
      "epoch 78 | loss: 0.01076 | val_0_mse: 0.00831 |  0:12:04s\n",
      "epoch 79 | loss: 0.01026 | val_0_mse: 0.02163 |  0:12:13s\n",
      "epoch 80 | loss: 0.01079 | val_0_mse: 0.00691 |  0:12:22s\n",
      "epoch 81 | loss: 0.01163 | val_0_mse: 0.00808 |  0:12:32s\n",
      "epoch 82 | loss: 0.01153 | val_0_mse: 0.01104 |  0:12:41s\n",
      "epoch 83 | loss: 0.00946 | val_0_mse: 0.00808 |  0:12:50s\n",
      "epoch 84 | loss: 0.01025 | val_0_mse: 0.0072  |  0:12:59s\n",
      "epoch 85 | loss: 0.00911 | val_0_mse: 0.00602 |  0:13:08s\n",
      "epoch 86 | loss: 0.01052 | val_0_mse: 0.00675 |  0:13:17s\n",
      "epoch 87 | loss: 0.01044 | val_0_mse: 0.0101  |  0:13:26s\n",
      "epoch 88 | loss: 0.00968 | val_0_mse: 0.01622 |  0:13:35s\n",
      "epoch 89 | loss: 0.01424 | val_0_mse: 0.00984 |  0:13:44s\n",
      "epoch 90 | loss: 0.0162  | val_0_mse: 0.01049 |  0:13:54s\n",
      "epoch 91 | loss: 0.01222 | val_0_mse: 0.00564 |  0:14:03s\n",
      "epoch 92 | loss: 0.00811 | val_0_mse: 0.00969 |  0:14:12s\n",
      "epoch 93 | loss: 0.01285 | val_0_mse: 0.02446 |  0:14:21s\n",
      "epoch 94 | loss: 0.01214 | val_0_mse: 0.00641 |  0:14:30s\n",
      "epoch 95 | loss: 0.00934 | val_0_mse: 0.00684 |  0:14:39s\n",
      "epoch 96 | loss: 0.00999 | val_0_mse: 0.00568 |  0:14:48s\n",
      "epoch 97 | loss: 0.00797 | val_0_mse: 0.00653 |  0:14:58s\n",
      "epoch 98 | loss: 0.0092  | val_0_mse: 0.00709 |  0:15:07s\n",
      "epoch 99 | loss: 0.00805 | val_0_mse: 0.0097  |  0:15:16s\n",
      "epoch 100| loss: 0.01079 | val_0_mse: 0.00545 |  0:15:25s\n",
      "epoch 101| loss: 0.0117  | val_0_mse: 0.00671 |  0:15:35s\n",
      "epoch 102| loss: 0.01091 | val_0_mse: 0.01512 |  0:15:44s\n",
      "epoch 103| loss: 0.00993 | val_0_mse: 0.01188 |  0:15:53s\n",
      "epoch 104| loss: 0.00791 | val_0_mse: 0.00743 |  0:16:02s\n",
      "epoch 105| loss: 0.01317 | val_0_mse: 0.0212  |  0:16:11s\n",
      "epoch 106| loss: 0.01305 | val_0_mse: 0.01543 |  0:16:21s\n",
      "epoch 107| loss: 0.01121 | val_0_mse: 0.01188 |  0:16:30s\n",
      "epoch 108| loss: 0.01274 | val_0_mse: 0.01491 |  0:16:39s\n",
      "epoch 109| loss: 0.01179 | val_0_mse: 0.01262 |  0:16:48s\n",
      "epoch 110| loss: 0.01257 | val_0_mse: 0.00736 |  0:16:57s\n",
      "\n",
      "Early stopping occurred at epoch 110 with best_epoch = 100 and best_val_0_mse = 0.00545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.005331 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.975952 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 45/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.03951 | val_0_mse: 1.36178 |  0:00:13s\n",
      "epoch 1  | loss: 0.4289  | val_0_mse: 0.19501 |  0:00:26s\n",
      "epoch 2  | loss: 0.14438 | val_0_mse: 0.11709 |  0:00:39s\n",
      "epoch 3  | loss: 0.10237 | val_0_mse: 0.08424 |  0:00:51s\n",
      "epoch 4  | loss: 0.07358 | val_0_mse: 0.06453 |  0:01:04s\n",
      "epoch 5  | loss: 0.07341 | val_0_mse: 0.06729 |  0:01:17s\n",
      "epoch 6  | loss: 0.06433 | val_0_mse: 0.05268 |  0:01:32s\n",
      "epoch 7  | loss: 0.05916 | val_0_mse: 0.04668 |  0:01:45s\n",
      "epoch 8  | loss: 0.05629 | val_0_mse: 0.04388 |  0:01:57s\n",
      "epoch 9  | loss: 0.0516  | val_0_mse: 0.07033 |  0:02:09s\n",
      "epoch 10 | loss: 0.04553 | val_0_mse: 0.06329 |  0:02:21s\n",
      "epoch 11 | loss: 0.04227 | val_0_mse: 0.02904 |  0:02:33s\n",
      "epoch 12 | loss: 0.0438  | val_0_mse: 0.02524 |  0:02:46s\n",
      "epoch 13 | loss: 0.04618 | val_0_mse: 0.02918 |  0:02:58s\n",
      "epoch 14 | loss: 0.03396 | val_0_mse: 0.03587 |  0:03:10s\n",
      "epoch 15 | loss: 0.03067 | val_0_mse: 0.02723 |  0:03:22s\n",
      "epoch 16 | loss: 0.03092 | val_0_mse: 0.03587 |  0:03:34s\n",
      "epoch 17 | loss: 0.03763 | val_0_mse: 0.02339 |  0:03:46s\n",
      "epoch 18 | loss: 0.02632 | val_0_mse: 0.01909 |  0:03:59s\n",
      "epoch 19 | loss: 0.02746 | val_0_mse: 0.02546 |  0:04:11s\n",
      "epoch 20 | loss: 0.02448 | val_0_mse: 0.02643 |  0:04:23s\n",
      "epoch 21 | loss: 0.03504 | val_0_mse: 0.03635 |  0:04:35s\n",
      "epoch 22 | loss: 0.02608 | val_0_mse: 0.01681 |  0:04:48s\n",
      "epoch 23 | loss: 0.02179 | val_0_mse: 0.01944 |  0:05:00s\n",
      "epoch 24 | loss: 0.01851 | val_0_mse: 0.01834 |  0:05:12s\n",
      "epoch 25 | loss: 0.02491 | val_0_mse: 0.0175  |  0:05:25s\n",
      "epoch 26 | loss: 0.02057 | val_0_mse: 0.01512 |  0:05:37s\n",
      "epoch 27 | loss: 0.01756 | val_0_mse: 0.01371 |  0:05:50s\n",
      "epoch 28 | loss: 0.01434 | val_0_mse: 0.01119 |  0:06:04s\n",
      "epoch 29 | loss: 0.01833 | val_0_mse: 0.02053 |  0:06:17s\n",
      "epoch 30 | loss: 0.01625 | val_0_mse: 0.01097 |  0:06:29s\n",
      "epoch 31 | loss: 0.02082 | val_0_mse: 0.04435 |  0:06:41s\n",
      "epoch 32 | loss: 0.02976 | val_0_mse: 0.02075 |  0:06:53s\n",
      "epoch 33 | loss: 0.01793 | val_0_mse: 0.02739 |  0:07:05s\n",
      "epoch 34 | loss: 0.01396 | val_0_mse: 0.01053 |  0:07:17s\n",
      "epoch 35 | loss: 0.01511 | val_0_mse: 0.01195 |  0:07:28s\n",
      "epoch 36 | loss: 0.01737 | val_0_mse: 0.02837 |  0:07:41s\n",
      "epoch 37 | loss: 0.01859 | val_0_mse: 0.01809 |  0:07:55s\n",
      "epoch 38 | loss: 0.01444 | val_0_mse: 0.02438 |  0:08:07s\n",
      "epoch 39 | loss: 0.01678 | val_0_mse: 0.01605 |  0:08:19s\n",
      "epoch 40 | loss: 0.01474 | val_0_mse: 0.0089  |  0:08:31s\n",
      "epoch 41 | loss: 0.01714 | val_0_mse: 0.00916 |  0:08:43s\n",
      "epoch 42 | loss: 0.01731 | val_0_mse: 0.00963 |  0:08:55s\n",
      "epoch 43 | loss: 0.01352 | val_0_mse: 0.0073  |  0:09:07s\n",
      "epoch 44 | loss: 0.01608 | val_0_mse: 0.00877 |  0:09:19s\n",
      "epoch 45 | loss: 0.01489 | val_0_mse: 0.01821 |  0:09:31s\n",
      "epoch 46 | loss: 0.00963 | val_0_mse: 0.00876 |  0:09:43s\n",
      "epoch 47 | loss: 0.01495 | val_0_mse: 0.00779 |  0:09:55s\n",
      "epoch 48 | loss: 0.01046 | val_0_mse: 0.00566 |  0:10:07s\n",
      "epoch 49 | loss: 0.01089 | val_0_mse: 0.01746 |  0:10:19s\n",
      "epoch 50 | loss: 0.01079 | val_0_mse: 0.01274 |  0:10:31s\n",
      "epoch 51 | loss: 0.0119  | val_0_mse: 0.00982 |  0:10:43s\n",
      "epoch 52 | loss: 0.01318 | val_0_mse: 0.00974 |  0:10:55s\n",
      "epoch 53 | loss: 0.01313 | val_0_mse: 0.01271 |  0:11:07s\n",
      "epoch 54 | loss: 0.01159 | val_0_mse: 0.00593 |  0:11:19s\n",
      "epoch 55 | loss: 0.00966 | val_0_mse: 0.00676 |  0:11:31s\n",
      "epoch 56 | loss: 0.01034 | val_0_mse: 0.00826 |  0:11:43s\n",
      "epoch 57 | loss: 0.01136 | val_0_mse: 0.0131  |  0:11:55s\n",
      "epoch 58 | loss: 0.00807 | val_0_mse: 0.00651 |  0:12:06s\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_mse = 0.00566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.005931 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.973244 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 46/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 9.09618 | val_0_mse: 1.87942 |  0:00:09s\n",
      "epoch 1  | loss: 0.49522 | val_0_mse: 0.57971 |  0:00:18s\n",
      "epoch 2  | loss: 0.28821 | val_0_mse: 0.20281 |  0:00:28s\n",
      "epoch 3  | loss: 0.35603 | val_0_mse: 0.18424 |  0:00:37s\n",
      "epoch 4  | loss: 0.18675 | val_0_mse: 0.13255 |  0:00:47s\n",
      "epoch 5  | loss: 0.09807 | val_0_mse: 0.14367 |  0:00:58s\n",
      "epoch 6  | loss: 0.09369 | val_0_mse: 0.09913 |  0:01:07s\n",
      "epoch 7  | loss: 0.07708 | val_0_mse: 0.12597 |  0:01:16s\n",
      "epoch 8  | loss: 0.0806  | val_0_mse: 0.08575 |  0:01:25s\n",
      "epoch 9  | loss: 0.06909 | val_0_mse: 0.08139 |  0:01:35s\n",
      "epoch 10 | loss: 0.06901 | val_0_mse: 0.06942 |  0:01:44s\n",
      "epoch 11 | loss: 0.09468 | val_0_mse: 0.07995 |  0:01:53s\n",
      "epoch 12 | loss: 0.07506 | val_0_mse: 0.06509 |  0:02:02s\n",
      "epoch 13 | loss: 0.07602 | val_0_mse: 0.05652 |  0:02:11s\n",
      "epoch 14 | loss: 0.06382 | val_0_mse: 0.0651  |  0:02:20s\n",
      "epoch 15 | loss: 0.06247 | val_0_mse: 0.05306 |  0:02:29s\n",
      "epoch 16 | loss: 0.06537 | val_0_mse: 0.0642  |  0:02:38s\n",
      "epoch 17 | loss: 0.06039 | val_0_mse: 0.05335 |  0:02:49s\n",
      "epoch 18 | loss: 0.06114 | val_0_mse: 0.05209 |  0:02:59s\n",
      "epoch 19 | loss: 0.06145 | val_0_mse: 0.05855 |  0:03:10s\n",
      "epoch 20 | loss: 0.06012 | val_0_mse: 0.04907 |  0:03:19s\n",
      "epoch 21 | loss: 0.05883 | val_0_mse: 0.056   |  0:03:28s\n",
      "epoch 22 | loss: 0.05914 | val_0_mse: 0.05507 |  0:03:37s\n",
      "epoch 23 | loss: 0.05453 | val_0_mse: 0.04949 |  0:03:46s\n",
      "epoch 24 | loss: 0.05153 | val_0_mse: 0.04153 |  0:03:56s\n",
      "epoch 25 | loss: 0.05266 | val_0_mse: 0.05069 |  0:04:05s\n",
      "epoch 26 | loss: 0.05664 | val_0_mse: 0.04113 |  0:04:14s\n",
      "epoch 27 | loss: 0.05058 | val_0_mse: 0.04095 |  0:04:23s\n",
      "epoch 28 | loss: 0.04562 | val_0_mse: 0.03626 |  0:04:32s\n",
      "epoch 29 | loss: 0.04891 | val_0_mse: 0.03513 |  0:04:41s\n",
      "epoch 30 | loss: 0.04145 | val_0_mse: 0.0348  |  0:04:50s\n",
      "epoch 31 | loss: 0.04018 | val_0_mse: 0.03273 |  0:04:59s\n",
      "epoch 32 | loss: 0.04152 | val_0_mse: 0.06021 |  0:05:08s\n",
      "epoch 33 | loss: 0.04305 | val_0_mse: 0.04007 |  0:05:17s\n",
      "epoch 34 | loss: 0.03774 | val_0_mse: 0.03074 |  0:05:26s\n",
      "epoch 35 | loss: 0.03542 | val_0_mse: 0.02659 |  0:05:35s\n",
      "epoch 36 | loss: 0.03308 | val_0_mse: 0.02366 |  0:05:44s\n",
      "epoch 37 | loss: 0.03077 | val_0_mse: 0.06483 |  0:05:53s\n",
      "epoch 38 | loss: 0.03951 | val_0_mse: 0.02107 |  0:06:02s\n",
      "epoch 39 | loss: 0.0307  | val_0_mse: 0.02108 |  0:06:11s\n",
      "epoch 40 | loss: 0.0344  | val_0_mse: 0.03875 |  0:06:20s\n",
      "epoch 41 | loss: 0.02504 | val_0_mse: 0.02219 |  0:06:30s\n",
      "epoch 42 | loss: 0.02195 | val_0_mse: 0.01852 |  0:06:39s\n",
      "epoch 43 | loss: 0.02158 | val_0_mse: 0.01908 |  0:06:48s\n",
      "epoch 44 | loss: 0.02466 | val_0_mse: 0.05143 |  0:06:57s\n",
      "epoch 45 | loss: 0.03081 | val_0_mse: 0.02087 |  0:07:06s\n",
      "epoch 46 | loss: 0.02484 | val_0_mse: 0.01802 |  0:07:15s\n",
      "epoch 47 | loss: 0.02265 | val_0_mse: 0.01669 |  0:07:24s\n",
      "epoch 48 | loss: 0.01929 | val_0_mse: 0.01514 |  0:07:33s\n",
      "epoch 49 | loss: 0.01966 | val_0_mse: 0.01672 |  0:07:42s\n",
      "epoch 50 | loss: 0.02189 | val_0_mse: 0.01242 |  0:07:51s\n",
      "epoch 51 | loss: 0.01512 | val_0_mse: 0.01417 |  0:08:00s\n",
      "epoch 52 | loss: 0.02021 | val_0_mse: 0.01293 |  0:08:09s\n",
      "epoch 53 | loss: 0.0172  | val_0_mse: 0.01323 |  0:08:17s\n",
      "epoch 54 | loss: 0.01501 | val_0_mse: 0.01471 |  0:08:26s\n",
      "epoch 55 | loss: 0.01392 | val_0_mse: 0.01222 |  0:08:35s\n",
      "epoch 56 | loss: 0.02298 | val_0_mse: 0.02103 |  0:08:44s\n",
      "epoch 57 | loss: 0.01705 | val_0_mse: 0.01331 |  0:08:53s\n",
      "epoch 58 | loss: 0.01558 | val_0_mse: 0.02581 |  0:09:02s\n",
      "epoch 59 | loss: 0.02292 | val_0_mse: 0.03188 |  0:09:11s\n",
      "epoch 60 | loss: 0.01887 | val_0_mse: 0.01645 |  0:09:20s\n",
      "epoch 61 | loss: 0.01743 | val_0_mse: 0.01367 |  0:09:29s\n",
      "epoch 62 | loss: 0.01636 | val_0_mse: 0.0105  |  0:09:38s\n",
      "epoch 63 | loss: 0.01279 | val_0_mse: 0.0113  |  0:09:48s\n",
      "epoch 64 | loss: 0.01454 | val_0_mse: 0.00955 |  0:09:57s\n",
      "epoch 65 | loss: 0.0135  | val_0_mse: 0.01008 |  0:10:06s\n",
      "epoch 66 | loss: 0.01236 | val_0_mse: 0.02121 |  0:10:15s\n",
      "epoch 67 | loss: 0.01961 | val_0_mse: 0.03623 |  0:10:24s\n",
      "epoch 68 | loss: 0.02407 | val_0_mse: 0.01216 |  0:10:33s\n",
      "epoch 69 | loss: 0.01346 | val_0_mse: 0.00812 |  0:10:42s\n",
      "epoch 70 | loss: 0.01269 | val_0_mse: 0.00814 |  0:10:51s\n",
      "epoch 71 | loss: 0.01232 | val_0_mse: 0.00955 |  0:11:00s\n",
      "epoch 72 | loss: 0.01225 | val_0_mse: 0.01745 |  0:11:09s\n",
      "epoch 73 | loss: 0.01113 | val_0_mse: 0.01736 |  0:11:19s\n",
      "epoch 74 | loss: 0.01478 | val_0_mse: 0.00702 |  0:11:28s\n",
      "epoch 75 | loss: 0.00983 | val_0_mse: 0.0091  |  0:11:37s\n",
      "epoch 76 | loss: 0.01223 | val_0_mse: 0.00801 |  0:11:46s\n",
      "epoch 77 | loss: 0.01298 | val_0_mse: 0.00666 |  0:11:55s\n",
      "epoch 78 | loss: 0.00911 | val_0_mse: 0.00913 |  0:12:04s\n",
      "epoch 79 | loss: 0.01262 | val_0_mse: 0.00984 |  0:12:13s\n",
      "epoch 80 | loss: 0.01019 | val_0_mse: 0.02448 |  0:12:22s\n",
      "epoch 81 | loss: 0.01311 | val_0_mse: 0.00957 |  0:12:31s\n",
      "epoch 82 | loss: 0.01084 | val_0_mse: 0.01876 |  0:12:41s\n",
      "epoch 83 | loss: 0.01002 | val_0_mse: 0.01082 |  0:12:50s\n",
      "epoch 84 | loss: 0.01305 | val_0_mse: 0.00735 |  0:12:59s\n",
      "epoch 85 | loss: 0.01271 | val_0_mse: 0.00719 |  0:13:08s\n",
      "epoch 86 | loss: 0.01038 | val_0_mse: 0.00738 |  0:13:17s\n",
      "epoch 87 | loss: 0.01479 | val_0_mse: 0.02522 |  0:13:26s\n",
      "\n",
      "Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_mse = 0.00666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006930 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.968737 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 47/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.16812 | val_0_mse: 0.47568 |  0:00:14s\n",
      "epoch 1  | loss: 0.42462 | val_0_mse: 0.16866 |  0:00:29s\n",
      "epoch 2  | loss: 0.20216 | val_0_mse: 0.21907 |  0:00:43s\n",
      "epoch 3  | loss: 0.14838 | val_0_mse: 0.15785 |  0:00:57s\n",
      "epoch 4  | loss: 0.1199  | val_0_mse: 0.19266 |  0:01:14s\n",
      "epoch 5  | loss: 0.11388 | val_0_mse: 0.11422 |  0:01:28s\n",
      "epoch 6  | loss: 0.0953  | val_0_mse: 0.08699 |  0:01:43s\n",
      "epoch 7  | loss: 0.08253 | val_0_mse: 0.11162 |  0:01:57s\n",
      "epoch 8  | loss: 0.08327 | val_0_mse: 0.07278 |  0:02:10s\n",
      "epoch 9  | loss: 0.07601 | val_0_mse: 0.06115 |  0:02:23s\n",
      "epoch 10 | loss: 0.06295 | val_0_mse: 0.05096 |  0:02:36s\n",
      "epoch 11 | loss: 0.06466 | val_0_mse: 0.08955 |  0:02:49s\n",
      "epoch 12 | loss: 0.05041 | val_0_mse: 0.06569 |  0:03:02s\n",
      "epoch 13 | loss: 0.05389 | val_0_mse: 0.0588  |  0:03:15s\n",
      "epoch 14 | loss: 0.04546 | val_0_mse: 0.04093 |  0:03:28s\n",
      "epoch 15 | loss: 0.04242 | val_0_mse: 0.03081 |  0:03:41s\n",
      "epoch 16 | loss: 0.03046 | val_0_mse: 0.02351 |  0:03:54s\n",
      "epoch 17 | loss: 0.0481  | val_0_mse: 0.02524 |  0:04:07s\n",
      "epoch 18 | loss: 0.03192 | val_0_mse: 0.02769 |  0:04:20s\n",
      "epoch 19 | loss: 0.03548 | val_0_mse: 0.10331 |  0:04:33s\n",
      "epoch 20 | loss: 0.04861 | val_0_mse: 0.06457 |  0:04:46s\n",
      "epoch 21 | loss: 0.03782 | val_0_mse: 0.03354 |  0:04:59s\n",
      "epoch 22 | loss: 0.02719 | val_0_mse: 0.02432 |  0:05:11s\n",
      "epoch 23 | loss: 0.02705 | val_0_mse: 0.01611 |  0:05:24s\n",
      "epoch 24 | loss: 0.01989 | val_0_mse: 0.02088 |  0:05:37s\n",
      "epoch 25 | loss: 0.02919 | val_0_mse: 0.01316 |  0:05:50s\n",
      "epoch 26 | loss: 0.01861 | val_0_mse: 0.01252 |  0:06:02s\n",
      "epoch 27 | loss: 0.01922 | val_0_mse: 0.02762 |  0:06:15s\n",
      "epoch 28 | loss: 0.01448 | val_0_mse: 0.0181  |  0:06:28s\n",
      "epoch 29 | loss: 0.01908 | val_0_mse: 0.00772 |  0:06:41s\n",
      "epoch 30 | loss: 0.01273 | val_0_mse: 0.02829 |  0:06:53s\n",
      "epoch 31 | loss: 0.01508 | val_0_mse: 0.01557 |  0:07:06s\n",
      "epoch 32 | loss: 0.01755 | val_0_mse: 0.02015 |  0:07:19s\n",
      "epoch 33 | loss: 0.01344 | val_0_mse: 0.0075  |  0:07:32s\n",
      "epoch 34 | loss: 0.01372 | val_0_mse: 0.01022 |  0:07:45s\n",
      "epoch 35 | loss: 0.01261 | val_0_mse: 0.0167  |  0:07:57s\n",
      "epoch 36 | loss: 0.01041 | val_0_mse: 0.01386 |  0:08:10s\n",
      "epoch 37 | loss: 0.01156 | val_0_mse: 0.00957 |  0:08:23s\n",
      "epoch 38 | loss: 0.01381 | val_0_mse: 0.00623 |  0:08:35s\n",
      "epoch 39 | loss: 0.01319 | val_0_mse: 0.00742 |  0:08:48s\n",
      "epoch 40 | loss: 0.01275 | val_0_mse: 0.02212 |  0:09:01s\n",
      "epoch 41 | loss: 0.01185 | val_0_mse: 0.00927 |  0:09:14s\n",
      "epoch 42 | loss: 0.01188 | val_0_mse: 0.00758 |  0:09:27s\n",
      "epoch 43 | loss: 0.01224 | val_0_mse: 0.00709 |  0:09:40s\n",
      "epoch 44 | loss: 0.01193 | val_0_mse: 0.00747 |  0:09:53s\n",
      "epoch 45 | loss: 0.01267 | val_0_mse: 0.00942 |  0:10:06s\n",
      "epoch 46 | loss: 0.01558 | val_0_mse: 0.01328 |  0:10:18s\n",
      "epoch 47 | loss: 0.01139 | val_0_mse: 0.03299 |  0:10:31s\n",
      "epoch 48 | loss: 0.01223 | val_0_mse: 0.01678 |  0:10:44s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_mse = 0.00623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006626 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.970109 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 48/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=32, n_a=32, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.74578 | val_0_mse: 0.78238 |  0:00:10s\n",
      "epoch 1  | loss: 0.72553 | val_0_mse: 0.64328 |  0:00:21s\n",
      "epoch 2  | loss: 0.9181  | val_0_mse: 0.29052 |  0:00:31s\n",
      "epoch 3  | loss: 0.26052 | val_0_mse: 0.2061  |  0:00:41s\n",
      "epoch 4  | loss: 0.16153 | val_0_mse: 0.17905 |  0:00:51s\n",
      "epoch 5  | loss: 0.12985 | val_0_mse: 0.13999 |  0:01:01s\n",
      "epoch 6  | loss: 0.09042 | val_0_mse: 0.10359 |  0:01:11s\n",
      "epoch 7  | loss: 0.09401 | val_0_mse: 0.11735 |  0:01:23s\n",
      "epoch 8  | loss: 0.07866 | val_0_mse: 0.10453 |  0:01:33s\n",
      "epoch 9  | loss: 0.07701 | val_0_mse: 0.10544 |  0:01:43s\n",
      "epoch 10 | loss: 0.08776 | val_0_mse: 0.08885 |  0:01:53s\n",
      "epoch 11 | loss: 0.07221 | val_0_mse: 0.07172 |  0:02:03s\n",
      "epoch 12 | loss: 0.0667  | val_0_mse: 0.07432 |  0:02:13s\n",
      "epoch 13 | loss: 0.07195 | val_0_mse: 0.06566 |  0:02:23s\n",
      "epoch 14 | loss: 0.06452 | val_0_mse: 0.06256 |  0:02:32s\n",
      "epoch 15 | loss: 0.06411 | val_0_mse: 0.05654 |  0:02:42s\n",
      "epoch 16 | loss: 0.06105 | val_0_mse: 0.05386 |  0:02:52s\n",
      "epoch 17 | loss: 0.06279 | val_0_mse: 0.05624 |  0:03:02s\n",
      "epoch 18 | loss: 0.05868 | val_0_mse: 0.05806 |  0:03:12s\n",
      "epoch 19 | loss: 0.06236 | val_0_mse: 0.05267 |  0:03:21s\n",
      "epoch 20 | loss: 0.05921 | val_0_mse: 0.05347 |  0:03:31s\n",
      "epoch 21 | loss: 0.06015 | val_0_mse: 0.05274 |  0:03:41s\n",
      "epoch 22 | loss: 0.05663 | val_0_mse: 0.04593 |  0:03:52s\n",
      "epoch 23 | loss: 0.06061 | val_0_mse: 0.06021 |  0:04:02s\n",
      "epoch 24 | loss: 0.06002 | val_0_mse: 0.08863 |  0:04:11s\n",
      "epoch 25 | loss: 0.06427 | val_0_mse: 0.0464  |  0:04:21s\n",
      "epoch 26 | loss: 0.05377 | val_0_mse: 0.04674 |  0:04:31s\n",
      "epoch 27 | loss: 0.05247 | val_0_mse: 0.04837 |  0:04:41s\n",
      "epoch 28 | loss: 0.052   | val_0_mse: 0.04624 |  0:04:51s\n",
      "epoch 29 | loss: 0.05697 | val_0_mse: 0.05584 |  0:05:01s\n",
      "epoch 30 | loss: 0.05186 | val_0_mse: 0.05185 |  0:05:11s\n",
      "epoch 31 | loss: 0.05544 | val_0_mse: 0.04278 |  0:05:21s\n",
      "epoch 32 | loss: 0.04948 | val_0_mse: 0.04549 |  0:05:31s\n",
      "epoch 33 | loss: 0.04828 | val_0_mse: 0.04535 |  0:05:41s\n",
      "epoch 34 | loss: 0.04564 | val_0_mse: 0.04586 |  0:05:51s\n",
      "epoch 35 | loss: 0.05121 | val_0_mse: 0.04048 |  0:06:03s\n",
      "epoch 36 | loss: 0.0473  | val_0_mse: 0.03953 |  0:06:14s\n",
      "epoch 37 | loss: 0.03995 | val_0_mse: 0.04795 |  0:06:23s\n",
      "epoch 38 | loss: 0.0378  | val_0_mse: 0.03144 |  0:06:33s\n",
      "epoch 39 | loss: 0.03658 | val_0_mse: 0.03657 |  0:06:43s\n",
      "epoch 40 | loss: 0.04019 | val_0_mse: 0.03317 |  0:06:53s\n",
      "epoch 41 | loss: 0.03291 | val_0_mse: 0.03641 |  0:07:03s\n",
      "epoch 42 | loss: 0.03649 | val_0_mse: 0.04246 |  0:07:13s\n",
      "epoch 43 | loss: 0.03539 | val_0_mse: 0.03519 |  0:07:23s\n",
      "epoch 44 | loss: 0.03319 | val_0_mse: 0.03498 |  0:07:33s\n",
      "epoch 45 | loss: 0.03104 | val_0_mse: 0.02551 |  0:07:42s\n",
      "epoch 46 | loss: 0.0289  | val_0_mse: 0.02684 |  0:07:52s\n",
      "epoch 47 | loss: 0.0258  | val_0_mse: 0.02332 |  0:08:02s\n",
      "epoch 48 | loss: 0.02748 | val_0_mse: 0.02006 |  0:08:12s\n",
      "epoch 49 | loss: 0.02192 | val_0_mse: 0.02414 |  0:08:22s\n",
      "epoch 50 | loss: 0.02537 | val_0_mse: 0.03035 |  0:08:32s\n",
      "epoch 51 | loss: 0.02381 | val_0_mse: 0.0233  |  0:08:42s\n",
      "epoch 52 | loss: 0.02478 | val_0_mse: 0.01667 |  0:08:52s\n",
      "epoch 53 | loss: 0.02005 | val_0_mse: 0.01817 |  0:09:02s\n",
      "epoch 54 | loss: 0.01806 | val_0_mse: 0.01635 |  0:09:11s\n",
      "epoch 55 | loss: 0.01923 | val_0_mse: 0.01827 |  0:09:21s\n",
      "epoch 56 | loss: 0.02038 | val_0_mse: 0.01436 |  0:09:31s\n",
      "epoch 57 | loss: 0.01764 | val_0_mse: 0.01699 |  0:09:41s\n",
      "epoch 58 | loss: 0.01975 | val_0_mse: 0.01495 |  0:09:51s\n",
      "epoch 59 | loss: 0.01698 | val_0_mse: 0.01318 |  0:10:01s\n",
      "epoch 60 | loss: 0.01742 | val_0_mse: 0.01324 |  0:10:12s\n",
      "epoch 61 | loss: 0.01763 | val_0_mse: 0.01219 |  0:10:22s\n",
      "epoch 62 | loss: 0.01673 | val_0_mse: 0.01246 |  0:10:32s\n",
      "epoch 63 | loss: 0.01591 | val_0_mse: 0.01883 |  0:10:42s\n",
      "epoch 64 | loss: 0.01889 | val_0_mse: 0.01411 |  0:10:52s\n",
      "epoch 65 | loss: 0.01569 | val_0_mse: 0.01135 |  0:11:02s\n",
      "epoch 66 | loss: 0.01713 | val_0_mse: 0.11101 |  0:11:12s\n",
      "epoch 67 | loss: 0.01725 | val_0_mse: 0.02345 |  0:11:22s\n",
      "epoch 68 | loss: 0.01308 | val_0_mse: 0.02023 |  0:11:32s\n",
      "epoch 69 | loss: 0.01957 | val_0_mse: 0.03131 |  0:11:42s\n",
      "epoch 70 | loss: 0.02118 | val_0_mse: 0.01781 |  0:11:52s\n",
      "epoch 71 | loss: 0.02156 | val_0_mse: 0.03127 |  0:12:02s\n",
      "epoch 72 | loss: 0.02835 | val_0_mse: 0.04377 |  0:12:12s\n",
      "epoch 73 | loss: 0.02444 | val_0_mse: 0.01965 |  0:12:22s\n",
      "epoch 74 | loss: 0.0181  | val_0_mse: 0.01674 |  0:12:32s\n",
      "epoch 75 | loss: 0.01925 | val_0_mse: 0.01585 |  0:12:41s\n",
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 65 and best_val_0_mse = 0.01135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.010706 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.951703 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 49/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.97742 | val_0_mse: 0.61192 |  0:00:11s\n",
      "epoch 1  | loss: 0.3884  | val_0_mse: 0.2047  |  0:00:22s\n",
      "epoch 2  | loss: 0.13506 | val_0_mse: 0.11962 |  0:00:33s\n",
      "epoch 3  | loss: 0.09588 | val_0_mse: 0.1094  |  0:00:44s\n",
      "epoch 4  | loss: 0.10005 | val_0_mse: 0.08879 |  0:00:55s\n",
      "epoch 5  | loss: 0.07366 | val_0_mse: 0.07766 |  0:01:06s\n",
      "epoch 6  | loss: 0.06343 | val_0_mse: 0.04659 |  0:01:16s\n",
      "epoch 7  | loss: 0.05511 | val_0_mse: 0.04399 |  0:01:27s\n",
      "epoch 8  | loss: 0.06739 | val_0_mse: 0.07351 |  0:01:38s\n",
      "epoch 9  | loss: 0.05492 | val_0_mse: 0.0435  |  0:01:49s\n",
      "epoch 10 | loss: 0.04803 | val_0_mse: 0.05651 |  0:02:00s\n",
      "epoch 11 | loss: 0.05144 | val_0_mse: 0.05809 |  0:02:11s\n",
      "epoch 12 | loss: 0.05266 | val_0_mse: 0.04698 |  0:02:22s\n",
      "epoch 13 | loss: 0.04728 | val_0_mse: 0.06353 |  0:02:33s\n",
      "epoch 14 | loss: 0.04564 | val_0_mse: 0.03764 |  0:02:44s\n",
      "epoch 15 | loss: 0.04795 | val_0_mse: 0.06586 |  0:02:55s\n",
      "epoch 16 | loss: 0.04013 | val_0_mse: 0.05199 |  0:03:06s\n",
      "epoch 17 | loss: 0.04479 | val_0_mse: 0.04159 |  0:03:16s\n",
      "epoch 18 | loss: 0.03451 | val_0_mse: 0.06362 |  0:03:27s\n",
      "epoch 19 | loss: 0.03008 | val_0_mse: 0.02694 |  0:03:38s\n",
      "epoch 20 | loss: 0.02966 | val_0_mse: 0.02892 |  0:03:49s\n",
      "epoch 21 | loss: 0.02514 | val_0_mse: 0.02642 |  0:04:00s\n",
      "epoch 22 | loss: 0.02962 | val_0_mse: 0.0296  |  0:04:10s\n",
      "epoch 23 | loss: 0.02411 | val_0_mse: 0.03758 |  0:04:21s\n",
      "epoch 24 | loss: 0.02728 | val_0_mse: 0.03602 |  0:04:32s\n",
      "epoch 25 | loss: 0.0251  | val_0_mse: 0.01195 |  0:04:43s\n",
      "epoch 26 | loss: 0.02635 | val_0_mse: 0.02869 |  0:04:54s\n",
      "epoch 27 | loss: 0.02004 | val_0_mse: 0.02154 |  0:05:04s\n",
      "epoch 28 | loss: 0.02043 | val_0_mse: 0.02296 |  0:05:15s\n",
      "epoch 29 | loss: 0.03402 | val_0_mse: 0.01631 |  0:05:26s\n",
      "epoch 30 | loss: 0.01697 | val_0_mse: 0.03181 |  0:05:37s\n",
      "epoch 31 | loss: 0.0171  | val_0_mse: 0.01799 |  0:05:48s\n",
      "epoch 32 | loss: 0.02015 | val_0_mse: 0.00782 |  0:05:59s\n",
      "epoch 33 | loss: 0.01235 | val_0_mse: 0.02971 |  0:06:10s\n",
      "epoch 34 | loss: 0.01773 | val_0_mse: 0.01256 |  0:06:20s\n",
      "epoch 35 | loss: 0.01157 | val_0_mse: 0.0107  |  0:06:31s\n",
      "epoch 36 | loss: 0.01464 | val_0_mse: 0.01317 |  0:06:42s\n",
      "epoch 37 | loss: 0.0171  | val_0_mse: 0.0155  |  0:06:53s\n",
      "epoch 38 | loss: 0.01853 | val_0_mse: 0.00965 |  0:07:04s\n",
      "epoch 39 | loss: 0.01205 | val_0_mse: 0.01326 |  0:07:15s\n",
      "epoch 40 | loss: 0.01158 | val_0_mse: 0.01223 |  0:07:26s\n",
      "epoch 41 | loss: 0.01257 | val_0_mse: 0.01097 |  0:07:37s\n",
      "epoch 42 | loss: 0.00966 | val_0_mse: 0.01718 |  0:07:48s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 0.00782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008319 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.962471 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 50/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.01703 | val_0_mse: 0.49536 |  0:00:08s\n",
      "epoch 1  | loss: 0.5791  | val_0_mse: 0.41603 |  0:00:17s\n",
      "epoch 2  | loss: 0.60176 | val_0_mse: 0.19609 |  0:00:25s\n",
      "epoch 3  | loss: 0.19505 | val_0_mse: 0.187   |  0:00:33s\n",
      "epoch 4  | loss: 0.16424 | val_0_mse: 0.17736 |  0:00:41s\n",
      "epoch 5  | loss: 0.13228 | val_0_mse: 0.17268 |  0:00:50s\n",
      "epoch 6  | loss: 0.12981 | val_0_mse: 0.13119 |  0:00:58s\n",
      "epoch 7  | loss: 0.12097 | val_0_mse: 0.13754 |  0:01:06s\n",
      "epoch 8  | loss: 0.1099  | val_0_mse: 0.1045  |  0:01:14s\n",
      "epoch 9  | loss: 0.10642 | val_0_mse: 0.11652 |  0:01:22s\n",
      "epoch 10 | loss: 0.09954 | val_0_mse: 0.12159 |  0:01:30s\n",
      "epoch 11 | loss: 0.10611 | val_0_mse: 0.10078 |  0:01:38s\n",
      "epoch 12 | loss: 0.10689 | val_0_mse: 0.11619 |  0:01:45s\n",
      "epoch 13 | loss: 0.08783 | val_0_mse: 0.09544 |  0:01:54s\n",
      "epoch 14 | loss: 0.11067 | val_0_mse: 0.11036 |  0:02:02s\n",
      "epoch 15 | loss: 0.10552 | val_0_mse: 0.08162 |  0:02:10s\n",
      "epoch 16 | loss: 0.10006 | val_0_mse: 0.06449 |  0:02:18s\n",
      "epoch 17 | loss: 0.07284 | val_0_mse: 0.07167 |  0:02:26s\n",
      "epoch 18 | loss: 0.07475 | val_0_mse: 0.07569 |  0:02:34s\n",
      "epoch 19 | loss: 0.08241 | val_0_mse: 0.07785 |  0:02:42s\n",
      "epoch 20 | loss: 0.06796 | val_0_mse: 0.0615  |  0:02:50s\n",
      "epoch 21 | loss: 0.0566  | val_0_mse: 0.05608 |  0:02:58s\n",
      "epoch 22 | loss: 0.05065 | val_0_mse: 0.05859 |  0:03:06s\n",
      "epoch 23 | loss: 0.04706 | val_0_mse: 0.0436  |  0:03:14s\n",
      "epoch 24 | loss: 0.0469  | val_0_mse: 0.04076 |  0:03:22s\n",
      "epoch 25 | loss: 0.04086 | val_0_mse: 0.03422 |  0:03:30s\n",
      "epoch 26 | loss: 0.03969 | val_0_mse: 0.04125 |  0:03:38s\n",
      "epoch 27 | loss: 0.04176 | val_0_mse: 0.04647 |  0:03:46s\n",
      "epoch 28 | loss: 0.04353 | val_0_mse: 0.03452 |  0:03:54s\n",
      "epoch 29 | loss: 0.03519 | val_0_mse: 0.03115 |  0:04:02s\n",
      "epoch 30 | loss: 0.0432  | val_0_mse: 0.02902 |  0:04:10s\n",
      "epoch 31 | loss: 0.03356 | val_0_mse: 0.02678 |  0:04:18s\n",
      "epoch 32 | loss: 0.02941 | val_0_mse: 0.05544 |  0:04:26s\n",
      "epoch 33 | loss: 0.03238 | val_0_mse: 0.02338 |  0:04:34s\n",
      "epoch 34 | loss: 0.03288 | val_0_mse: 0.03563 |  0:04:42s\n",
      "epoch 35 | loss: 0.03019 | val_0_mse: 0.02059 |  0:04:50s\n",
      "epoch 36 | loss: 0.02504 | val_0_mse: 0.02299 |  0:04:58s\n",
      "epoch 37 | loss: 0.02948 | val_0_mse: 0.02334 |  0:05:06s\n",
      "epoch 38 | loss: 0.02303 | val_0_mse: 0.01998 |  0:05:15s\n",
      "epoch 39 | loss: 0.02047 | val_0_mse: 0.02777 |  0:05:23s\n",
      "epoch 40 | loss: 0.02244 | val_0_mse: 0.02102 |  0:05:31s\n",
      "epoch 41 | loss: 0.01986 | val_0_mse: 0.01587 |  0:05:39s\n",
      "epoch 42 | loss: 0.01909 | val_0_mse: 0.01622 |  0:05:47s\n",
      "epoch 43 | loss: 0.01876 | val_0_mse: 0.01294 |  0:05:55s\n",
      "epoch 44 | loss: 0.01798 | val_0_mse: 0.01575 |  0:06:03s\n",
      "epoch 45 | loss: 0.01953 | val_0_mse: 0.03505 |  0:06:11s\n",
      "epoch 46 | loss: 0.03661 | val_0_mse: 0.03116 |  0:06:19s\n",
      "epoch 47 | loss: 0.01823 | val_0_mse: 0.01543 |  0:06:27s\n",
      "epoch 48 | loss: 0.01566 | val_0_mse: 0.01399 |  0:06:35s\n",
      "epoch 49 | loss: 0.01537 | val_0_mse: 0.00942 |  0:06:43s\n",
      "epoch 50 | loss: 0.0173  | val_0_mse: 0.02444 |  0:06:52s\n",
      "epoch 51 | loss: 0.01675 | val_0_mse: 0.01503 |  0:07:00s\n",
      "epoch 52 | loss: 0.01818 | val_0_mse: 0.01759 |  0:07:08s\n",
      "epoch 53 | loss: 0.01354 | val_0_mse: 0.01206 |  0:07:16s\n",
      "epoch 54 | loss: 0.01753 | val_0_mse: 0.01461 |  0:07:24s\n",
      "epoch 55 | loss: 0.01461 | val_0_mse: 0.01183 |  0:07:32s\n",
      "epoch 56 | loss: 0.01643 | val_0_mse: 0.02449 |  0:07:40s\n",
      "epoch 57 | loss: 0.0237  | val_0_mse: 0.05678 |  0:07:48s\n",
      "epoch 58 | loss: 0.01856 | val_0_mse: 0.01259 |  0:07:56s\n",
      "epoch 59 | loss: 0.01652 | val_0_mse: 0.01458 |  0:08:04s\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_mse = 0.00942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.010088 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.954489 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 51/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.1864  | val_0_mse: 1.00536 |  0:00:12s\n",
      "epoch 1  | loss: 0.51794 | val_0_mse: 0.46997 |  0:00:24s\n",
      "epoch 2  | loss: 0.15011 | val_0_mse: 0.17174 |  0:00:35s\n",
      "epoch 3  | loss: 0.11627 | val_0_mse: 0.12361 |  0:00:47s\n",
      "epoch 4  | loss: 0.09006 | val_0_mse: 0.07286 |  0:00:59s\n",
      "epoch 5  | loss: 0.08923 | val_0_mse: 0.06782 |  0:01:14s\n",
      "epoch 6  | loss: 0.08152 | val_0_mse: 0.05852 |  0:01:26s\n",
      "epoch 7  | loss: 0.06201 | val_0_mse: 0.04838 |  0:01:38s\n",
      "epoch 8  | loss: 0.05441 | val_0_mse: 0.04527 |  0:01:49s\n",
      "epoch 9  | loss: 0.04959 | val_0_mse: 0.04455 |  0:02:00s\n",
      "epoch 10 | loss: 0.05673 | val_0_mse: 0.05272 |  0:02:13s\n",
      "epoch 11 | loss: 0.0423  | val_0_mse: 0.06014 |  0:02:24s\n",
      "epoch 12 | loss: 0.04131 | val_0_mse: 0.0282  |  0:02:36s\n",
      "epoch 13 | loss: 0.03663 | val_0_mse: 0.0395  |  0:02:47s\n",
      "epoch 14 | loss: 0.0395  | val_0_mse: 0.04395 |  0:02:58s\n",
      "epoch 15 | loss: 0.04795 | val_0_mse: 0.0437  |  0:03:10s\n",
      "epoch 16 | loss: 0.03722 | val_0_mse: 0.02761 |  0:03:21s\n",
      "epoch 17 | loss: 0.0353  | val_0_mse: 0.02114 |  0:03:32s\n",
      "epoch 18 | loss: 0.02566 | val_0_mse: 0.02404 |  0:03:44s\n",
      "epoch 19 | loss: 0.03134 | val_0_mse: 0.02788 |  0:03:55s\n",
      "epoch 20 | loss: 0.02228 | val_0_mse: 0.02396 |  0:04:06s\n",
      "epoch 21 | loss: 0.02364 | val_0_mse: 0.02487 |  0:04:18s\n",
      "epoch 22 | loss: 0.01643 | val_0_mse: 0.0142  |  0:04:29s\n",
      "epoch 23 | loss: 0.01779 | val_0_mse: 0.01331 |  0:04:40s\n",
      "epoch 24 | loss: 0.01728 | val_0_mse: 0.01166 |  0:04:52s\n",
      "epoch 25 | loss: 0.01561 | val_0_mse: 0.0115  |  0:05:06s\n",
      "epoch 26 | loss: 0.01754 | val_0_mse: 0.04713 |  0:05:18s\n",
      "epoch 27 | loss: 0.01853 | val_0_mse: 0.02122 |  0:05:29s\n",
      "epoch 28 | loss: 0.01871 | val_0_mse: 0.01294 |  0:05:40s\n",
      "epoch 29 | loss: 0.01924 | val_0_mse: 0.04287 |  0:05:51s\n",
      "epoch 30 | loss: 0.0184  | val_0_mse: 0.02556 |  0:06:02s\n",
      "epoch 31 | loss: 0.01638 | val_0_mse: 0.00985 |  0:06:14s\n",
      "epoch 32 | loss: 0.01834 | val_0_mse: 0.01962 |  0:06:25s\n",
      "epoch 33 | loss: 0.01382 | val_0_mse: 0.0087  |  0:06:36s\n",
      "epoch 34 | loss: 0.02237 | val_0_mse: 0.01667 |  0:06:48s\n",
      "epoch 35 | loss: 0.01484 | val_0_mse: 0.01035 |  0:07:00s\n",
      "epoch 36 | loss: 0.01181 | val_0_mse: 0.00866 |  0:07:11s\n",
      "epoch 37 | loss: 0.01856 | val_0_mse: 0.01009 |  0:07:22s\n",
      "epoch 38 | loss: 0.0119  | val_0_mse: 0.01087 |  0:07:34s\n",
      "epoch 39 | loss: 0.01147 | val_0_mse: 0.00719 |  0:07:45s\n",
      "epoch 40 | loss: 0.01346 | val_0_mse: 0.00884 |  0:07:56s\n",
      "epoch 41 | loss: 0.01061 | val_0_mse: 0.00664 |  0:08:08s\n",
      "epoch 42 | loss: 0.0115  | val_0_mse: 0.0085  |  0:08:19s\n",
      "epoch 43 | loss: 0.01052 | val_0_mse: 0.00686 |  0:08:30s\n",
      "epoch 44 | loss: 0.01018 | val_0_mse: 0.01156 |  0:08:41s\n",
      "epoch 45 | loss: 0.01196 | val_0_mse: 0.01446 |  0:08:52s\n",
      "epoch 46 | loss: 0.01495 | val_0_mse: 0.01562 |  0:09:04s\n",
      "epoch 47 | loss: 0.02159 | val_0_mse: 0.01009 |  0:09:15s\n",
      "epoch 48 | loss: 0.01521 | val_0_mse: 0.00856 |  0:09:26s\n",
      "epoch 49 | loss: 0.00979 | val_0_mse: 0.00695 |  0:09:38s\n",
      "epoch 50 | loss: 0.01319 | val_0_mse: 0.01227 |  0:09:49s\n",
      "epoch 51 | loss: 0.01041 | val_0_mse: 0.01017 |  0:10:01s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_mse = 0.00664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006923 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.968766 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 52/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.19745 | val_0_mse: 1.29758 |  0:00:09s\n",
      "epoch 1  | loss: 0.74303 | val_0_mse: 0.48882 |  0:00:18s\n",
      "epoch 2  | loss: 0.41624 | val_0_mse: 0.1837  |  0:00:28s\n",
      "epoch 3  | loss: 0.16877 | val_0_mse: 0.13429 |  0:00:36s\n",
      "epoch 4  | loss: 0.10301 | val_0_mse: 0.11078 |  0:00:45s\n",
      "epoch 5  | loss: 0.07513 | val_0_mse: 0.13127 |  0:00:54s\n",
      "epoch 6  | loss: 0.10292 | val_0_mse: 0.10912 |  0:01:03s\n",
      "epoch 7  | loss: 0.06073 | val_0_mse: 0.08664 |  0:01:12s\n",
      "epoch 8  | loss: 0.05948 | val_0_mse: 0.08522 |  0:01:20s\n",
      "epoch 9  | loss: 0.05045 | val_0_mse: 0.04654 |  0:01:29s\n",
      "epoch 10 | loss: 0.04662 | val_0_mse: 0.07948 |  0:01:38s\n",
      "epoch 11 | loss: 0.05471 | val_0_mse: 0.04695 |  0:01:47s\n",
      "epoch 12 | loss: 0.04746 | val_0_mse: 0.09671 |  0:01:56s\n",
      "epoch 13 | loss: 0.04398 | val_0_mse: 0.03366 |  0:02:05s\n",
      "epoch 14 | loss: 0.0437  | val_0_mse: 0.03295 |  0:02:14s\n",
      "epoch 15 | loss: 0.04333 | val_0_mse: 0.04554 |  0:02:23s\n",
      "epoch 16 | loss: 0.04089 | val_0_mse: 0.05449 |  0:02:32s\n",
      "epoch 17 | loss: 0.04764 | val_0_mse: 0.04411 |  0:02:41s\n",
      "epoch 18 | loss: 0.04893 | val_0_mse: 0.0474  |  0:02:49s\n",
      "epoch 19 | loss: 0.04103 | val_0_mse: 0.04023 |  0:02:58s\n",
      "epoch 20 | loss: 0.04265 | val_0_mse: 0.04048 |  0:03:07s\n",
      "epoch 21 | loss: 0.04073 | val_0_mse: 0.03917 |  0:03:16s\n",
      "epoch 22 | loss: 0.03231 | val_0_mse: 0.03444 |  0:03:25s\n",
      "epoch 23 | loss: 0.03219 | val_0_mse: 0.03209 |  0:03:33s\n",
      "epoch 24 | loss: 0.03118 | val_0_mse: 0.02618 |  0:03:42s\n",
      "epoch 25 | loss: 0.03365 | val_0_mse: 0.0273  |  0:03:51s\n",
      "epoch 26 | loss: 0.03075 | val_0_mse: 0.04719 |  0:04:00s\n",
      "epoch 27 | loss: 0.03376 | val_0_mse: 0.0332  |  0:04:09s\n",
      "epoch 28 | loss: 0.03133 | val_0_mse: 0.03481 |  0:04:18s\n",
      "epoch 29 | loss: 0.04284 | val_0_mse: 0.04284 |  0:04:28s\n",
      "epoch 30 | loss: 0.03714 | val_0_mse: 0.05132 |  0:04:37s\n",
      "epoch 31 | loss: 0.03563 | val_0_mse: 0.02953 |  0:04:45s\n",
      "epoch 32 | loss: 0.03725 | val_0_mse: 0.03158 |  0:04:54s\n",
      "epoch 33 | loss: 0.03686 | val_0_mse: 0.0432  |  0:05:03s\n",
      "epoch 34 | loss: 0.03917 | val_0_mse: 0.04217 |  0:05:12s\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_mse = 0.02618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.024942 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.887478 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 53/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.50414 | val_0_mse: 0.7902  |  0:00:12s\n",
      "epoch 1  | loss: 0.32148 | val_0_mse: 0.17836 |  0:00:25s\n",
      "epoch 2  | loss: 0.20216 | val_0_mse: 0.20049 |  0:00:37s\n",
      "epoch 3  | loss: 0.1406  | val_0_mse: 0.16017 |  0:00:49s\n",
      "epoch 4  | loss: 0.10276 | val_0_mse: 0.09266 |  0:01:01s\n",
      "epoch 5  | loss: 0.08022 | val_0_mse: 0.06607 |  0:01:13s\n",
      "epoch 6  | loss: 0.08237 | val_0_mse: 0.04866 |  0:01:25s\n",
      "epoch 7  | loss: 0.07959 | val_0_mse: 0.06565 |  0:01:39s\n",
      "epoch 8  | loss: 0.06983 | val_0_mse: 0.04972 |  0:01:51s\n",
      "epoch 9  | loss: 0.06537 | val_0_mse: 0.05905 |  0:02:02s\n",
      "epoch 10 | loss: 0.06792 | val_0_mse: 0.05737 |  0:02:14s\n",
      "epoch 11 | loss: 0.05192 | val_0_mse: 0.0442  |  0:02:26s\n",
      "epoch 12 | loss: 0.05304 | val_0_mse: 0.04054 |  0:02:37s\n",
      "epoch 13 | loss: 0.04405 | val_0_mse: 0.03601 |  0:02:49s\n",
      "epoch 14 | loss: 0.03752 | val_0_mse: 0.04671 |  0:03:01s\n",
      "epoch 15 | loss: 0.0394  | val_0_mse: 0.03025 |  0:03:13s\n",
      "epoch 16 | loss: 0.03318 | val_0_mse: 0.02973 |  0:03:24s\n",
      "epoch 17 | loss: 0.027   | val_0_mse: 0.0358  |  0:03:36s\n",
      "epoch 18 | loss: 0.03314 | val_0_mse: 0.02448 |  0:03:48s\n",
      "epoch 19 | loss: 0.03143 | val_0_mse: 0.02361 |  0:04:00s\n",
      "epoch 20 | loss: 0.02954 | val_0_mse: 0.02691 |  0:04:11s\n",
      "epoch 21 | loss: 0.02612 | val_0_mse: 0.07381 |  0:04:23s\n",
      "epoch 22 | loss: 0.02509 | val_0_mse: 0.03182 |  0:04:35s\n",
      "epoch 23 | loss: 0.0265  | val_0_mse: 0.01922 |  0:04:47s\n",
      "epoch 24 | loss: 0.02254 | val_0_mse: 0.01627 |  0:04:59s\n",
      "epoch 25 | loss: 0.01833 | val_0_mse: 0.01705 |  0:05:10s\n",
      "epoch 26 | loss: 0.01862 | val_0_mse: 0.02543 |  0:05:22s\n",
      "epoch 27 | loss: 0.02585 | val_0_mse: 0.01556 |  0:05:34s\n",
      "epoch 28 | loss: 0.0137  | val_0_mse: 0.02652 |  0:05:46s\n",
      "epoch 29 | loss: 0.02051 | val_0_mse: 0.01324 |  0:06:01s\n",
      "epoch 30 | loss: 0.01654 | val_0_mse: 0.02618 |  0:06:12s\n",
      "epoch 31 | loss: 0.01491 | val_0_mse: 0.00669 |  0:06:24s\n",
      "epoch 32 | loss: 0.0135  | val_0_mse: 0.03956 |  0:06:35s\n",
      "epoch 33 | loss: 0.01473 | val_0_mse: 0.01004 |  0:06:46s\n",
      "epoch 34 | loss: 0.01374 | val_0_mse: 0.00781 |  0:06:58s\n",
      "epoch 35 | loss: 0.01113 | val_0_mse: 0.01076 |  0:07:09s\n",
      "epoch 36 | loss: 0.01652 | val_0_mse: 0.07544 |  0:07:21s\n",
      "epoch 37 | loss: 0.01931 | val_0_mse: 0.00822 |  0:07:32s\n",
      "epoch 38 | loss: 0.01094 | val_0_mse: 0.0106  |  0:07:44s\n",
      "epoch 39 | loss: 0.01288 | val_0_mse: 0.00813 |  0:07:55s\n",
      "epoch 40 | loss: 0.01042 | val_0_mse: 0.01007 |  0:08:07s\n",
      "epoch 41 | loss: 0.02304 | val_0_mse: 0.03399 |  0:08:18s\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_mse = 0.00669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006776 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.969434 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 54/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.65252 | val_0_mse: 0.89814 |  0:00:09s\n",
      "epoch 1  | loss: 0.5147  | val_0_mse: 0.52374 |  0:00:18s\n",
      "epoch 2  | loss: 0.28745 | val_0_mse: 0.19764 |  0:00:27s\n",
      "epoch 3  | loss: 0.23272 | val_0_mse: 0.17098 |  0:00:36s\n",
      "epoch 4  | loss: 0.13899 | val_0_mse: 0.12453 |  0:00:45s\n",
      "epoch 5  | loss: 0.11688 | val_0_mse: 0.14569 |  0:00:54s\n",
      "epoch 6  | loss: 0.10851 | val_0_mse: 0.12041 |  0:01:03s\n",
      "epoch 7  | loss: 0.08369 | val_0_mse: 0.11586 |  0:01:12s\n",
      "epoch 8  | loss: 0.07888 | val_0_mse: 0.11565 |  0:01:21s\n",
      "epoch 9  | loss: 0.07347 | val_0_mse: 0.09368 |  0:01:30s\n",
      "epoch 10 | loss: 0.08933 | val_0_mse: 0.08759 |  0:01:38s\n",
      "epoch 11 | loss: 0.10063 | val_0_mse: 0.07828 |  0:01:47s\n",
      "epoch 12 | loss: 0.08015 | val_0_mse: 0.07484 |  0:01:56s\n",
      "epoch 13 | loss: 0.07724 | val_0_mse: 0.07217 |  0:02:05s\n",
      "epoch 14 | loss: 0.07778 | val_0_mse: 0.05549 |  0:02:14s\n",
      "epoch 15 | loss: 0.06391 | val_0_mse: 0.04939 |  0:02:23s\n",
      "epoch 16 | loss: 0.05968 | val_0_mse: 0.07866 |  0:02:32s\n",
      "epoch 17 | loss: 0.05513 | val_0_mse: 0.03778 |  0:02:41s\n",
      "epoch 18 | loss: 0.04632 | val_0_mse: 0.03802 |  0:02:50s\n",
      "epoch 19 | loss: 0.0436  | val_0_mse: 0.0338  |  0:02:58s\n",
      "epoch 20 | loss: 0.05601 | val_0_mse: 0.09857 |  0:03:07s\n",
      "epoch 21 | loss: 0.05528 | val_0_mse: 0.04669 |  0:03:16s\n",
      "epoch 22 | loss: 0.04626 | val_0_mse: 0.05735 |  0:03:25s\n",
      "epoch 23 | loss: 0.04337 | val_0_mse: 0.0737  |  0:03:36s\n",
      "epoch 24 | loss: 0.03921 | val_0_mse: 0.03806 |  0:03:45s\n",
      "epoch 25 | loss: 0.03482 | val_0_mse: 0.04115 |  0:03:53s\n",
      "epoch 26 | loss: 0.03665 | val_0_mse: 0.03007 |  0:04:02s\n",
      "epoch 27 | loss: 0.03493 | val_0_mse: 0.03192 |  0:04:12s\n",
      "epoch 28 | loss: 0.03482 | val_0_mse: 0.03756 |  0:04:21s\n",
      "epoch 29 | loss: 0.03067 | val_0_mse: 0.0196  |  0:04:30s\n",
      "epoch 30 | loss: 0.0306  | val_0_mse: 0.02168 |  0:04:39s\n",
      "epoch 31 | loss: 0.0288  | val_0_mse: 0.07627 |  0:04:48s\n",
      "epoch 32 | loss: 0.03171 | val_0_mse: 0.01712 |  0:04:57s\n",
      "epoch 33 | loss: 0.02786 | val_0_mse: 0.01587 |  0:05:06s\n",
      "epoch 34 | loss: 0.01871 | val_0_mse: 0.01675 |  0:05:15s\n",
      "epoch 35 | loss: 0.01835 | val_0_mse: 0.0353  |  0:05:24s\n",
      "epoch 36 | loss: 0.01966 | val_0_mse: 0.01814 |  0:05:33s\n",
      "epoch 37 | loss: 0.02503 | val_0_mse: 0.01697 |  0:05:42s\n",
      "epoch 38 | loss: 0.02066 | val_0_mse: 0.01682 |  0:05:51s\n",
      "epoch 39 | loss: 0.01653 | val_0_mse: 0.01787 |  0:06:00s\n",
      "epoch 40 | loss: 0.01557 | val_0_mse: 0.01118 |  0:06:08s\n",
      "epoch 41 | loss: 0.0127  | val_0_mse: 0.00851 |  0:06:17s\n",
      "epoch 42 | loss: 0.0171  | val_0_mse: 0.01206 |  0:06:26s\n",
      "epoch 43 | loss: 0.01416 | val_0_mse: 0.01007 |  0:06:35s\n",
      "epoch 44 | loss: 0.01516 | val_0_mse: 0.02277 |  0:06:44s\n",
      "epoch 45 | loss: 0.01394 | val_0_mse: 0.01297 |  0:06:52s\n",
      "epoch 46 | loss: 0.01456 | val_0_mse: 0.01382 |  0:07:01s\n",
      "epoch 47 | loss: 0.01558 | val_0_mse: 0.01845 |  0:07:10s\n",
      "epoch 48 | loss: 0.01477 | val_0_mse: 0.01034 |  0:07:19s\n",
      "epoch 49 | loss: 0.01248 | val_0_mse: 0.00883 |  0:07:28s\n",
      "epoch 50 | loss: 0.01267 | val_0_mse: 0.00781 |  0:07:36s\n",
      "epoch 51 | loss: 0.01242 | val_0_mse: 0.01071 |  0:07:45s\n",
      "epoch 52 | loss: 0.01036 | val_0_mse: 0.00807 |  0:07:54s\n",
      "epoch 53 | loss: 0.01409 | val_0_mse: 0.01045 |  0:08:03s\n",
      "epoch 54 | loss: 0.01091 | val_0_mse: 0.00957 |  0:08:12s\n",
      "epoch 55 | loss: 0.00984 | val_0_mse: 0.00658 |  0:08:21s\n",
      "epoch 56 | loss: 0.01414 | val_0_mse: 0.00755 |  0:08:30s\n",
      "epoch 57 | loss: 0.011   | val_0_mse: 0.006   |  0:08:39s\n",
      "epoch 58 | loss: 0.01069 | val_0_mse: 0.01958 |  0:08:48s\n",
      "epoch 59 | loss: 0.01093 | val_0_mse: 0.00803 |  0:08:57s\n",
      "epoch 60 | loss: 0.01244 | val_0_mse: 0.00591 |  0:09:06s\n",
      "epoch 61 | loss: 0.00972 | val_0_mse: 0.00631 |  0:09:14s\n",
      "epoch 62 | loss: 0.00866 | val_0_mse: 0.0232  |  0:09:23s\n",
      "epoch 63 | loss: 0.01248 | val_0_mse: 0.00549 |  0:09:32s\n",
      "epoch 64 | loss: 0.01175 | val_0_mse: 0.02251 |  0:09:41s\n",
      "epoch 65 | loss: 0.00991 | val_0_mse: 0.0068  |  0:09:52s\n",
      "epoch 66 | loss: 0.01184 | val_0_mse: 0.00776 |  0:10:01s\n",
      "epoch 67 | loss: 0.01105 | val_0_mse: 0.01223 |  0:10:09s\n",
      "epoch 68 | loss: 0.01379 | val_0_mse: 0.01376 |  0:10:18s\n",
      "epoch 69 | loss: 0.01002 | val_0_mse: 0.01468 |  0:10:27s\n",
      "epoch 70 | loss: 0.01127 | val_0_mse: 0.01253 |  0:10:36s\n",
      "epoch 71 | loss: 0.00951 | val_0_mse: 0.00921 |  0:10:45s\n",
      "epoch 72 | loss: 0.01116 | val_0_mse: 0.00651 |  0:10:54s\n",
      "epoch 73 | loss: 0.01099 | val_0_mse: 0.00916 |  0:11:03s\n",
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 63 and best_val_0_mse = 0.00549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.005762 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.974006 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 55/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.1322  | val_0_mse: 1.13127 |  0:00:12s\n",
      "epoch 1  | loss: 0.33277 | val_0_mse: 0.18001 |  0:00:24s\n",
      "epoch 2  | loss: 0.13331 | val_0_mse: 0.12124 |  0:00:36s\n",
      "epoch 3  | loss: 0.09147 | val_0_mse: 0.07759 |  0:00:50s\n",
      "epoch 4  | loss: 0.09055 | val_0_mse: 0.0794  |  0:01:04s\n",
      "epoch 5  | loss: 0.06959 | val_0_mse: 0.06796 |  0:01:17s\n",
      "epoch 6  | loss: 0.08426 | val_0_mse: 0.08473 |  0:01:29s\n",
      "epoch 7  | loss: 0.06675 | val_0_mse: 0.04478 |  0:01:41s\n",
      "epoch 8  | loss: 0.06593 | val_0_mse: 0.03978 |  0:01:54s\n",
      "epoch 9  | loss: 0.04592 | val_0_mse: 0.03603 |  0:02:06s\n",
      "epoch 10 | loss: 0.04024 | val_0_mse: 0.02951 |  0:02:18s\n",
      "epoch 11 | loss: 0.03446 | val_0_mse: 0.02387 |  0:02:31s\n",
      "epoch 12 | loss: 0.03312 | val_0_mse: 0.02838 |  0:02:43s\n",
      "epoch 13 | loss: 0.03077 | val_0_mse: 0.03053 |  0:02:55s\n",
      "epoch 14 | loss: 0.02344 | val_0_mse: 0.01743 |  0:03:08s\n",
      "epoch 15 | loss: 0.0201  | val_0_mse: 0.02181 |  0:03:20s\n",
      "epoch 16 | loss: 0.02567 | val_0_mse: 0.0201  |  0:03:32s\n",
      "epoch 17 | loss: 0.02899 | val_0_mse: 0.02    |  0:03:45s\n",
      "epoch 18 | loss: 0.01965 | val_0_mse: 0.03835 |  0:03:57s\n",
      "epoch 19 | loss: 0.01943 | val_0_mse: 0.01066 |  0:04:09s\n",
      "epoch 20 | loss: 0.02032 | val_0_mse: 0.00998 |  0:04:21s\n",
      "epoch 21 | loss: 0.0179  | val_0_mse: 0.00849 |  0:04:33s\n",
      "epoch 22 | loss: 0.01643 | val_0_mse: 0.02423 |  0:04:46s\n",
      "epoch 23 | loss: 0.02285 | val_0_mse: 0.00957 |  0:04:58s\n",
      "epoch 24 | loss: 0.0185  | val_0_mse: 0.02337 |  0:05:11s\n",
      "epoch 25 | loss: 0.0164  | val_0_mse: 0.00919 |  0:05:23s\n",
      "epoch 26 | loss: 0.01849 | val_0_mse: 0.01411 |  0:05:35s\n",
      "epoch 27 | loss: 0.01573 | val_0_mse: 0.05192 |  0:05:47s\n",
      "epoch 28 | loss: 0.01778 | val_0_mse: 0.01171 |  0:06:00s\n",
      "epoch 29 | loss: 0.01568 | val_0_mse: 0.05121 |  0:06:12s\n",
      "epoch 30 | loss: 0.0159  | val_0_mse: 0.02206 |  0:06:25s\n",
      "epoch 31 | loss: 0.01562 | val_0_mse: 0.0101  |  0:06:37s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mse = 0.00849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008551 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.961424 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 56/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=64, n_a=64, n_step=6, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.57179 | val_0_mse: 1.25018 |  0:00:12s\n",
      "epoch 1  | loss: 0.54071 | val_0_mse: 0.44141 |  0:00:22s\n",
      "epoch 2  | loss: 0.31824 | val_0_mse: 0.32854 |  0:00:33s\n",
      "epoch 3  | loss: 0.15396 | val_0_mse: 0.14787 |  0:00:43s\n",
      "epoch 4  | loss: 0.1093  | val_0_mse: 0.20502 |  0:00:53s\n",
      "epoch 5  | loss: 0.13334 | val_0_mse: 0.14741 |  0:01:02s\n",
      "epoch 6  | loss: 0.08744 | val_0_mse: 0.1327  |  0:01:13s\n",
      "epoch 7  | loss: 0.08101 | val_0_mse: 0.13424 |  0:01:23s\n",
      "epoch 8  | loss: 0.07305 | val_0_mse: 0.08443 |  0:01:32s\n",
      "epoch 9  | loss: 0.07105 | val_0_mse: 0.0818  |  0:01:42s\n",
      "epoch 10 | loss: 0.06726 | val_0_mse: 0.0677  |  0:01:52s\n",
      "epoch 11 | loss: 0.0698  | val_0_mse: 0.05903 |  0:02:01s\n",
      "epoch 12 | loss: 0.05746 | val_0_mse: 0.05557 |  0:02:11s\n",
      "epoch 13 | loss: 0.0602  | val_0_mse: 0.05167 |  0:02:21s\n",
      "epoch 14 | loss: 0.05229 | val_0_mse: 0.04864 |  0:02:31s\n",
      "epoch 15 | loss: 0.05217 | val_0_mse: 0.05947 |  0:02:41s\n",
      "epoch 16 | loss: 0.05116 | val_0_mse: 0.05202 |  0:02:51s\n",
      "epoch 17 | loss: 0.05851 | val_0_mse: 0.05289 |  0:03:00s\n",
      "epoch 18 | loss: 0.05146 | val_0_mse: 0.07735 |  0:03:10s\n",
      "epoch 19 | loss: 0.05082 | val_0_mse: 0.05423 |  0:03:20s\n",
      "epoch 20 | loss: 0.04746 | val_0_mse: 0.0421  |  0:03:30s\n",
      "epoch 21 | loss: 0.04853 | val_0_mse: 0.04768 |  0:03:40s\n",
      "epoch 22 | loss: 0.04062 | val_0_mse: 0.03637 |  0:03:49s\n",
      "epoch 23 | loss: 0.03699 | val_0_mse: 0.03914 |  0:03:59s\n",
      "epoch 24 | loss: 0.03498 | val_0_mse: 0.03922 |  0:04:09s\n",
      "epoch 25 | loss: 0.03307 | val_0_mse: 0.0331  |  0:04:18s\n",
      "epoch 26 | loss: 0.03006 | val_0_mse: 0.0454  |  0:04:28s\n",
      "epoch 27 | loss: 0.02942 | val_0_mse: 0.02426 |  0:04:37s\n",
      "epoch 28 | loss: 0.02763 | val_0_mse: 0.02335 |  0:04:47s\n",
      "epoch 29 | loss: 0.03025 | val_0_mse: 0.03265 |  0:04:57s\n",
      "epoch 30 | loss: 0.02311 | val_0_mse: 0.02531 |  0:05:06s\n",
      "epoch 31 | loss: 0.02159 | val_0_mse: 0.01741 |  0:05:16s\n",
      "epoch 32 | loss: 0.0204  | val_0_mse: 0.01827 |  0:05:25s\n",
      "epoch 33 | loss: 0.02495 | val_0_mse: 0.01629 |  0:05:35s\n",
      "epoch 34 | loss: 0.01954 | val_0_mse: 0.0208  |  0:05:45s\n",
      "epoch 35 | loss: 0.01856 | val_0_mse: 0.0148  |  0:05:54s\n",
      "epoch 36 | loss: 0.02087 | val_0_mse: 0.01141 |  0:06:04s\n",
      "epoch 37 | loss: 0.01809 | val_0_mse: 0.01882 |  0:06:14s\n",
      "epoch 38 | loss: 0.02459 | val_0_mse: 0.03594 |  0:06:24s\n",
      "epoch 39 | loss: 0.02453 | val_0_mse: 0.03874 |  0:06:33s\n",
      "epoch 40 | loss: 0.01988 | val_0_mse: 0.02854 |  0:06:43s\n",
      "epoch 41 | loss: 0.01645 | val_0_mse: 0.01326 |  0:06:53s\n",
      "epoch 42 | loss: 0.02154 | val_0_mse: 0.01571 |  0:07:03s\n",
      "epoch 43 | loss: 0.02538 | val_0_mse: 0.01627 |  0:07:13s\n",
      "epoch 44 | loss: 0.0143  | val_0_mse: 0.01793 |  0:07:23s\n",
      "epoch 45 | loss: 0.01401 | val_0_mse: 0.01002 |  0:07:32s\n",
      "epoch 46 | loss: 0.01519 | val_0_mse: 0.01638 |  0:07:42s\n",
      "epoch 47 | loss: 0.01434 | val_0_mse: 0.01498 |  0:07:51s\n",
      "epoch 48 | loss: 0.01371 | val_0_mse: 0.0129  |  0:08:01s\n",
      "epoch 49 | loss: 0.01299 | val_0_mse: 0.01663 |  0:08:11s\n",
      "epoch 50 | loss: 0.01547 | val_0_mse: 0.01529 |  0:08:20s\n",
      "epoch 51 | loss: 0.01642 | val_0_mse: 0.01287 |  0:08:30s\n",
      "epoch 52 | loss: 0.0154  | val_0_mse: 0.02507 |  0:08:40s\n",
      "epoch 53 | loss: 0.02109 | val_0_mse: 0.03284 |  0:08:49s\n",
      "epoch 54 | loss: 0.02526 | val_0_mse: 0.0161  |  0:08:59s\n",
      "epoch 55 | loss: 0.01377 | val_0_mse: 0.01399 |  0:09:09s\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_mse = 0.01002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.009842 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.955602 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 57/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.79959 | val_0_mse: 1.44364 |  0:00:11s\n",
      "epoch 1  | loss: 0.73125 | val_0_mse: 0.30791 |  0:00:23s\n",
      "epoch 2  | loss: 0.23626 | val_0_mse: 0.3487  |  0:00:34s\n",
      "epoch 3  | loss: 0.13129 | val_0_mse: 0.17736 |  0:00:46s\n",
      "epoch 4  | loss: 0.10056 | val_0_mse: 0.07856 |  0:00:58s\n",
      "epoch 5  | loss: 0.08087 | val_0_mse: 0.14809 |  0:01:13s\n",
      "epoch 6  | loss: 0.08267 | val_0_mse: 0.0772  |  0:01:26s\n",
      "epoch 7  | loss: 0.07431 | val_0_mse: 0.05763 |  0:01:37s\n",
      "epoch 8  | loss: 0.07249 | val_0_mse: 0.06688 |  0:01:48s\n",
      "epoch 9  | loss: 0.06985 | val_0_mse: 0.07159 |  0:02:00s\n",
      "epoch 10 | loss: 0.06632 | val_0_mse: 0.05995 |  0:02:12s\n",
      "epoch 11 | loss: 0.0582  | val_0_mse: 0.054   |  0:02:23s\n",
      "epoch 12 | loss: 0.05891 | val_0_mse: 0.04819 |  0:02:35s\n",
      "epoch 13 | loss: 0.05971 | val_0_mse: 0.04442 |  0:02:46s\n",
      "epoch 14 | loss: 0.05868 | val_0_mse: 0.06631 |  0:02:58s\n",
      "epoch 15 | loss: 0.04645 | val_0_mse: 0.04593 |  0:03:09s\n",
      "epoch 16 | loss: 0.04802 | val_0_mse: 0.03977 |  0:03:21s\n",
      "epoch 17 | loss: 0.04479 | val_0_mse: 0.04136 |  0:03:33s\n",
      "epoch 18 | loss: 0.04085 | val_0_mse: 0.03257 |  0:03:44s\n",
      "epoch 19 | loss: 0.0408  | val_0_mse: 0.03132 |  0:03:56s\n",
      "epoch 20 | loss: 0.03445 | val_0_mse: 0.031   |  0:04:08s\n",
      "epoch 21 | loss: 0.03631 | val_0_mse: 0.0595  |  0:04:24s\n",
      "epoch 22 | loss: 0.03525 | val_0_mse: 0.02741 |  0:04:38s\n",
      "epoch 23 | loss: 0.02822 | val_0_mse: 0.0213  |  0:04:49s\n",
      "epoch 24 | loss: 0.02489 | val_0_mse: 0.02268 |  0:05:01s\n",
      "epoch 25 | loss: 0.0238  | val_0_mse: 0.02556 |  0:05:13s\n",
      "epoch 26 | loss: 0.02297 | val_0_mse: 0.01657 |  0:05:25s\n",
      "epoch 27 | loss: 0.022   | val_0_mse: 0.01667 |  0:05:37s\n",
      "epoch 28 | loss: 0.02973 | val_0_mse: 0.01315 |  0:05:49s\n",
      "epoch 29 | loss: 0.01889 | val_0_mse: 0.01576 |  0:06:01s\n",
      "epoch 30 | loss: 0.02317 | val_0_mse: 0.02581 |  0:06:12s\n",
      "epoch 31 | loss: 0.02419 | val_0_mse: 0.01123 |  0:06:24s\n",
      "epoch 32 | loss: 0.02084 | val_0_mse: 0.01349 |  0:06:37s\n",
      "epoch 33 | loss: 0.01684 | val_0_mse: 0.01405 |  0:06:49s\n",
      "epoch 34 | loss: 0.01801 | val_0_mse: 0.01834 |  0:07:01s\n",
      "epoch 35 | loss: 0.021   | val_0_mse: 0.01664 |  0:07:13s\n",
      "epoch 36 | loss: 0.01822 | val_0_mse: 0.0139  |  0:07:25s\n",
      "epoch 37 | loss: 0.01616 | val_0_mse: 0.00974 |  0:07:37s\n",
      "epoch 38 | loss: 0.01706 | val_0_mse: 0.0102  |  0:07:49s\n",
      "epoch 39 | loss: 0.01633 | val_0_mse: 0.01948 |  0:08:01s\n",
      "epoch 40 | loss: 0.01701 | val_0_mse: 0.0188  |  0:08:13s\n",
      "epoch 41 | loss: 0.01554 | val_0_mse: 0.01009 |  0:08:25s\n",
      "epoch 42 | loss: 0.01847 | val_0_mse: 0.00996 |  0:08:37s\n",
      "epoch 43 | loss: 0.01484 | val_0_mse: 0.00971 |  0:08:49s\n",
      "epoch 44 | loss: 0.01383 | val_0_mse: 0.02739 |  0:09:01s\n",
      "epoch 45 | loss: 0.01734 | val_0_mse: 0.02727 |  0:09:13s\n",
      "epoch 46 | loss: 0.01888 | val_0_mse: 0.0104  |  0:09:25s\n",
      "epoch 47 | loss: 0.01635 | val_0_mse: 0.00792 |  0:09:37s\n",
      "epoch 48 | loss: 0.01179 | val_0_mse: 0.00769 |  0:09:49s\n",
      "epoch 49 | loss: 0.01096 | val_0_mse: 0.00722 |  0:10:02s\n",
      "epoch 50 | loss: 0.01241 | val_0_mse: 0.01073 |  0:10:14s\n",
      "epoch 51 | loss: 0.01175 | val_0_mse: 0.00837 |  0:10:26s\n",
      "epoch 52 | loss: 0.01089 | val_0_mse: 0.01146 |  0:10:38s\n",
      "epoch 53 | loss: 0.01199 | val_0_mse: 0.0163  |  0:10:50s\n",
      "epoch 54 | loss: 0.01696 | val_0_mse: 0.00917 |  0:11:02s\n",
      "epoch 55 | loss: 0.0146  | val_0_mse: 0.00868 |  0:11:15s\n",
      "epoch 56 | loss: 0.01444 | val_0_mse: 0.03439 |  0:11:27s\n",
      "epoch 57 | loss: 0.0135  | val_0_mse: 0.01105 |  0:11:39s\n",
      "epoch 58 | loss: 0.01445 | val_0_mse: 0.00813 |  0:11:51s\n",
      "epoch 59 | loss: 0.01532 | val_0_mse: 0.00765 |  0:12:03s\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_mse = 0.00722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007367 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.966767 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 58/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=2, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.70785 | val_0_mse: 1.49713 |  0:00:10s\n",
      "epoch 1  | loss: 0.83632 | val_0_mse: 0.82658 |  0:00:19s\n",
      "epoch 2  | loss: 0.55782 | val_0_mse: 0.1299  |  0:00:29s\n",
      "epoch 3  | loss: 0.29157 | val_0_mse: 0.10981 |  0:00:38s\n",
      "epoch 4  | loss: 0.16285 | val_0_mse: 0.11544 |  0:00:47s\n",
      "epoch 5  | loss: 0.20463 | val_0_mse: 0.11622 |  0:00:56s\n",
      "epoch 6  | loss: 0.13311 | val_0_mse: 0.0949  |  0:01:06s\n",
      "epoch 7  | loss: 0.09609 | val_0_mse: 0.0788  |  0:01:15s\n",
      "epoch 8  | loss: 0.09065 | val_0_mse: 0.08857 |  0:01:24s\n",
      "epoch 9  | loss: 0.06772 | val_0_mse: 0.07211 |  0:01:34s\n",
      "epoch 10 | loss: 0.06219 | val_0_mse: 0.05413 |  0:01:43s\n",
      "epoch 11 | loss: 0.06457 | val_0_mse: 0.06519 |  0:01:52s\n",
      "epoch 12 | loss: 0.06627 | val_0_mse: 0.09072 |  0:02:01s\n",
      "epoch 13 | loss: 0.07676 | val_0_mse: 0.06195 |  0:02:10s\n",
      "epoch 14 | loss: 0.06256 | val_0_mse: 0.05511 |  0:02:19s\n",
      "epoch 15 | loss: 0.05976 | val_0_mse: 0.06353 |  0:02:28s\n",
      "epoch 16 | loss: 0.06553 | val_0_mse: 0.06032 |  0:02:37s\n",
      "epoch 17 | loss: 0.06231 | val_0_mse: 0.05671 |  0:02:45s\n",
      "epoch 18 | loss: 0.05738 | val_0_mse: 0.05773 |  0:02:54s\n",
      "epoch 19 | loss: 0.05917 | val_0_mse: 0.04928 |  0:03:03s\n",
      "epoch 20 | loss: 0.05445 | val_0_mse: 0.06843 |  0:03:13s\n",
      "epoch 21 | loss: 0.05402 | val_0_mse: 0.05778 |  0:03:22s\n",
      "epoch 22 | loss: 0.06086 | val_0_mse: 0.06918 |  0:03:31s\n",
      "epoch 23 | loss: 0.05801 | val_0_mse: 0.05048 |  0:03:40s\n",
      "epoch 24 | loss: 0.05534 | val_0_mse: 0.04708 |  0:03:50s\n",
      "epoch 25 | loss: 0.05713 | val_0_mse: 0.06012 |  0:03:59s\n",
      "epoch 26 | loss: 0.05952 | val_0_mse: 0.07819 |  0:04:08s\n",
      "epoch 27 | loss: 0.06207 | val_0_mse: 0.04518 |  0:04:17s\n",
      "epoch 28 | loss: 0.04851 | val_0_mse: 0.05032 |  0:04:26s\n",
      "epoch 29 | loss: 0.04895 | val_0_mse: 0.04386 |  0:04:35s\n",
      "epoch 30 | loss: 0.04854 | val_0_mse: 0.04244 |  0:04:44s\n",
      "epoch 31 | loss: 0.04875 | val_0_mse: 0.03647 |  0:04:54s\n",
      "epoch 32 | loss: 0.05039 | val_0_mse: 0.03886 |  0:05:03s\n",
      "epoch 33 | loss: 0.04568 | val_0_mse: 0.04436 |  0:05:12s\n",
      "epoch 34 | loss: 0.04153 | val_0_mse: 0.03661 |  0:05:21s\n",
      "epoch 35 | loss: 0.04041 | val_0_mse: 0.03287 |  0:05:30s\n",
      "epoch 36 | loss: 0.03751 | val_0_mse: 0.03967 |  0:05:39s\n",
      "epoch 37 | loss: 0.04071 | val_0_mse: 0.03276 |  0:05:48s\n",
      "epoch 38 | loss: 0.03758 | val_0_mse: 0.03313 |  0:05:57s\n",
      "epoch 39 | loss: 0.03453 | val_0_mse: 0.03951 |  0:06:06s\n",
      "epoch 40 | loss: 0.04294 | val_0_mse: 0.03502 |  0:06:15s\n",
      "epoch 41 | loss: 0.03949 | val_0_mse: 0.0324  |  0:06:24s\n",
      "epoch 42 | loss: 0.03623 | val_0_mse: 0.03056 |  0:06:34s\n",
      "epoch 43 | loss: 0.03552 | val_0_mse: 0.04219 |  0:06:43s\n",
      "epoch 44 | loss: 0.03611 | val_0_mse: 0.03651 |  0:06:52s\n",
      "epoch 45 | loss: 0.03383 | val_0_mse: 0.04113 |  0:07:01s\n",
      "epoch 46 | loss: 0.03312 | val_0_mse: 0.0488  |  0:07:10s\n",
      "epoch 47 | loss: 0.03346 | val_0_mse: 0.02455 |  0:07:19s\n",
      "epoch 48 | loss: 0.03725 | val_0_mse: 0.02495 |  0:07:28s\n",
      "epoch 49 | loss: 0.02901 | val_0_mse: 0.02476 |  0:07:37s\n",
      "epoch 50 | loss: 0.02714 | val_0_mse: 0.02548 |  0:07:47s\n",
      "epoch 51 | loss: 0.03278 | val_0_mse: 0.0244  |  0:07:56s\n",
      "epoch 52 | loss: 0.0272  | val_0_mse: 0.05292 |  0:08:05s\n",
      "epoch 53 | loss: 0.02626 | val_0_mse: 0.02184 |  0:08:14s\n",
      "epoch 54 | loss: 0.02595 | val_0_mse: 0.0221  |  0:08:23s\n",
      "epoch 55 | loss: 0.02497 | val_0_mse: 0.01884 |  0:08:32s\n",
      "epoch 56 | loss: 0.02226 | val_0_mse: 0.02386 |  0:08:42s\n",
      "epoch 57 | loss: 0.02186 | val_0_mse: 0.02657 |  0:08:51s\n",
      "epoch 58 | loss: 0.02167 | val_0_mse: 0.014   |  0:09:00s\n",
      "epoch 59 | loss: 0.01853 | val_0_mse: 0.013   |  0:09:09s\n",
      "epoch 60 | loss: 0.01777 | val_0_mse: 0.01255 |  0:09:18s\n",
      "epoch 61 | loss: 0.01653 | val_0_mse: 0.01022 |  0:09:28s\n",
      "epoch 62 | loss: 0.01351 | val_0_mse: 0.01473 |  0:09:37s\n",
      "epoch 63 | loss: 0.01397 | val_0_mse: 0.01725 |  0:09:46s\n",
      "epoch 64 | loss: 0.01397 | val_0_mse: 0.01    |  0:09:55s\n",
      "epoch 65 | loss: 0.01247 | val_0_mse: 0.00976 |  0:10:04s\n",
      "epoch 66 | loss: 0.01227 | val_0_mse: 0.00891 |  0:10:13s\n",
      "epoch 67 | loss: 0.01157 | val_0_mse: 0.00773 |  0:10:22s\n",
      "epoch 68 | loss: 0.01001 | val_0_mse: 0.00899 |  0:10:32s\n",
      "epoch 69 | loss: 0.00919 | val_0_mse: 0.00804 |  0:10:41s\n",
      "epoch 70 | loss: 0.01486 | val_0_mse: 0.00851 |  0:10:50s\n",
      "epoch 71 | loss: 0.00996 | val_0_mse: 0.01541 |  0:11:00s\n",
      "epoch 72 | loss: 0.012   | val_0_mse: 0.00779 |  0:11:09s\n",
      "epoch 73 | loss: 0.01264 | val_0_mse: 0.01571 |  0:11:18s\n",
      "epoch 74 | loss: 0.01976 | val_0_mse: 0.01833 |  0:11:27s\n",
      "epoch 75 | loss: 0.01825 | val_0_mse: 0.01426 |  0:11:36s\n",
      "epoch 76 | loss: 0.02113 | val_0_mse: 0.01828 |  0:11:45s\n",
      "epoch 77 | loss: 0.0182  | val_0_mse: 0.0182  |  0:11:55s\n",
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 67 and best_val_0_mse = 0.00773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007501 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.966160 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 59/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.44692 | val_0_mse: 1.35661 |  0:00:13s\n",
      "epoch 1  | loss: 0.67191 | val_0_mse: 0.2572  |  0:00:26s\n",
      "epoch 2  | loss: 0.21685 | val_0_mse: 0.32083 |  0:00:39s\n",
      "epoch 3  | loss: 0.15023 | val_0_mse: 0.12313 |  0:00:52s\n",
      "epoch 4  | loss: 0.12676 | val_0_mse: 0.09913 |  0:01:05s\n",
      "epoch 5  | loss: 0.10917 | val_0_mse: 0.09515 |  0:01:21s\n",
      "epoch 6  | loss: 0.0995  | val_0_mse: 0.08059 |  0:01:35s\n",
      "epoch 7  | loss: 0.08851 | val_0_mse: 0.07461 |  0:01:51s\n",
      "epoch 8  | loss: 0.09305 | val_0_mse: 0.07781 |  0:02:04s\n",
      "epoch 9  | loss: 0.08255 | val_0_mse: 0.04983 |  0:02:18s\n",
      "epoch 10 | loss: 0.05672 | val_0_mse: 0.0567  |  0:02:31s\n",
      "epoch 11 | loss: 0.05361 | val_0_mse: 0.05868 |  0:02:45s\n",
      "epoch 12 | loss: 0.0387  | val_0_mse: 0.0362  |  0:02:58s\n",
      "epoch 13 | loss: 0.03975 | val_0_mse: 0.02437 |  0:03:11s\n",
      "epoch 14 | loss: 0.03599 | val_0_mse: 0.03584 |  0:03:24s\n",
      "epoch 15 | loss: 0.03211 | val_0_mse: 0.03838 |  0:03:38s\n",
      "epoch 16 | loss: 0.02919 | val_0_mse: 0.02208 |  0:03:52s\n",
      "epoch 17 | loss: 0.02712 | val_0_mse: 0.02882 |  0:04:05s\n",
      "epoch 18 | loss: 0.03225 | val_0_mse: 0.02284 |  0:04:18s\n",
      "epoch 19 | loss: 0.03121 | val_0_mse: 0.0332  |  0:04:31s\n",
      "epoch 20 | loss: 0.02751 | val_0_mse: 0.01895 |  0:04:45s\n",
      "epoch 21 | loss: 0.02747 | val_0_mse: 0.02994 |  0:04:59s\n",
      "epoch 22 | loss: 0.02112 | val_0_mse: 0.01228 |  0:05:12s\n",
      "epoch 23 | loss: 0.04193 | val_0_mse: 0.01509 |  0:05:25s\n",
      "epoch 24 | loss: 0.02174 | val_0_mse: 0.02933 |  0:05:39s\n",
      "epoch 25 | loss: 0.02322 | val_0_mse: 0.01478 |  0:05:52s\n",
      "epoch 26 | loss: 0.02154 | val_0_mse: 0.03826 |  0:06:05s\n",
      "epoch 27 | loss: 0.02508 | val_0_mse: 0.01354 |  0:06:19s\n",
      "epoch 28 | loss: 0.01755 | val_0_mse: 0.01265 |  0:06:32s\n",
      "epoch 29 | loss: 0.01708 | val_0_mse: 0.02139 |  0:06:46s\n",
      "epoch 30 | loss: 0.02435 | val_0_mse: 0.04066 |  0:06:59s\n",
      "epoch 31 | loss: 0.02247 | val_0_mse: 0.02188 |  0:07:12s\n",
      "epoch 32 | loss: 0.01997 | val_0_mse: 0.01069 |  0:07:26s\n",
      "epoch 33 | loss: 0.01548 | val_0_mse: 0.02947 |  0:07:39s\n",
      "epoch 34 | loss: 0.0162  | val_0_mse: 0.01425 |  0:07:52s\n",
      "epoch 35 | loss: 0.0167  | val_0_mse: 0.03834 |  0:08:06s\n",
      "epoch 36 | loss: 0.01339 | val_0_mse: 0.03856 |  0:08:20s\n",
      "epoch 37 | loss: 0.01461 | val_0_mse: 0.00832 |  0:08:34s\n",
      "epoch 38 | loss: 0.02013 | val_0_mse: 0.02181 |  0:08:47s\n",
      "epoch 39 | loss: 0.0146  | val_0_mse: 0.01184 |  0:09:01s\n",
      "epoch 40 | loss: 0.01135 | val_0_mse: 0.01134 |  0:09:14s\n",
      "epoch 41 | loss: 0.01111 | val_0_mse: 0.02602 |  0:09:28s\n",
      "epoch 42 | loss: 0.01918 | val_0_mse: 0.00774 |  0:09:41s\n",
      "epoch 43 | loss: 0.01851 | val_0_mse: 0.06111 |  0:09:54s\n",
      "epoch 44 | loss: 0.02303 | val_0_mse: 0.07372 |  0:10:08s\n",
      "epoch 45 | loss: 0.02323 | val_0_mse: 0.03107 |  0:10:21s\n",
      "epoch 46 | loss: 0.01612 | val_0_mse: 0.01357 |  0:10:34s\n",
      "epoch 47 | loss: 0.01531 | val_0_mse: 0.02359 |  0:10:48s\n",
      "epoch 48 | loss: 0.01616 | val_0_mse: 0.01185 |  0:11:01s\n",
      "epoch 49 | loss: 0.01284 | val_0_mse: 0.01378 |  0:11:14s\n",
      "epoch 50 | loss: 0.01429 | val_0_mse: 0.01038 |  0:11:27s\n",
      "epoch 51 | loss: 0.0141  | val_0_mse: 0.01397 |  0:11:40s\n",
      "epoch 52 | loss: 0.01178 | val_0_mse: 0.01262 |  0:11:53s\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_mse = 0.00774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007567 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.965861 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 60/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=2, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.65352 | val_0_mse: 0.69497 |  0:00:11s\n",
      "epoch 1  | loss: 0.79307 | val_0_mse: 0.7004  |  0:00:22s\n",
      "epoch 2  | loss: 0.65173 | val_0_mse: 0.21652 |  0:00:32s\n",
      "epoch 3  | loss: 0.21395 | val_0_mse: 0.2705  |  0:00:42s\n",
      "epoch 4  | loss: 0.19613 | val_0_mse: 0.14506 |  0:00:53s\n",
      "epoch 5  | loss: 0.09963 | val_0_mse: 0.08926 |  0:01:06s\n",
      "epoch 6  | loss: 0.08723 | val_0_mse: 0.09466 |  0:01:21s\n",
      "epoch 7  | loss: 0.09184 | val_0_mse: 0.0714  |  0:01:32s\n",
      "epoch 8  | loss: 0.0927  | val_0_mse: 0.08372 |  0:01:43s\n",
      "epoch 9  | loss: 0.07159 | val_0_mse: 0.07006 |  0:01:53s\n",
      "epoch 10 | loss: 0.06713 | val_0_mse: 0.05291 |  0:02:03s\n",
      "epoch 11 | loss: 0.0548  | val_0_mse: 0.06386 |  0:02:14s\n",
      "epoch 12 | loss: 0.04933 | val_0_mse: 0.0621  |  0:02:24s\n",
      "epoch 13 | loss: 0.0568  | val_0_mse: 0.04474 |  0:02:35s\n",
      "epoch 14 | loss: 0.05187 | val_0_mse: 0.0527  |  0:02:45s\n",
      "epoch 15 | loss: 0.06671 | val_0_mse: 0.09793 |  0:02:56s\n",
      "epoch 16 | loss: 0.05063 | val_0_mse: 0.03863 |  0:03:07s\n",
      "epoch 17 | loss: 0.04341 | val_0_mse: 0.03185 |  0:03:17s\n",
      "epoch 18 | loss: 0.04382 | val_0_mse: 0.03383 |  0:03:27s\n",
      "epoch 19 | loss: 0.04284 | val_0_mse: 0.03156 |  0:03:38s\n",
      "epoch 20 | loss: 0.04393 | val_0_mse: 0.02882 |  0:03:49s\n",
      "epoch 21 | loss: 0.03475 | val_0_mse: 0.0313  |  0:03:59s\n",
      "epoch 22 | loss: 0.03792 | val_0_mse: 0.03024 |  0:04:10s\n",
      "epoch 23 | loss: 0.04136 | val_0_mse: 0.03221 |  0:04:20s\n",
      "epoch 24 | loss: 0.03554 | val_0_mse: 0.05217 |  0:04:31s\n",
      "epoch 25 | loss: 0.03971 | val_0_mse: 0.02889 |  0:04:41s\n",
      "epoch 26 | loss: 0.03647 | val_0_mse: 0.03635 |  0:04:52s\n",
      "epoch 27 | loss: 0.03245 | val_0_mse: 0.02427 |  0:05:03s\n",
      "epoch 28 | loss: 0.03007 | val_0_mse: 0.02417 |  0:05:14s\n",
      "epoch 29 | loss: 0.03074 | val_0_mse: 0.02741 |  0:05:24s\n",
      "epoch 30 | loss: 0.02708 | val_0_mse: 0.03011 |  0:05:35s\n",
      "epoch 31 | loss: 0.03019 | val_0_mse: 0.02965 |  0:05:45s\n",
      "epoch 32 | loss: 0.0295  | val_0_mse: 0.02797 |  0:05:57s\n",
      "epoch 33 | loss: 0.0212  | val_0_mse: 0.01577 |  0:06:08s\n",
      "epoch 34 | loss: 0.02276 | val_0_mse: 0.01525 |  0:06:20s\n",
      "epoch 35 | loss: 0.02322 | val_0_mse: 0.01979 |  0:06:32s\n",
      "epoch 36 | loss: 0.02581 | val_0_mse: 0.01486 |  0:06:42s\n",
      "epoch 37 | loss: 0.02295 | val_0_mse: 0.02174 |  0:06:53s\n",
      "epoch 38 | loss: 0.02519 | val_0_mse: 0.02974 |  0:07:04s\n",
      "epoch 39 | loss: 0.02173 | val_0_mse: 0.01431 |  0:07:14s\n",
      "epoch 40 | loss: 0.01819 | val_0_mse: 0.01477 |  0:07:25s\n",
      "epoch 41 | loss: 0.0232  | val_0_mse: 0.01471 |  0:07:35s\n",
      "epoch 42 | loss: 0.01924 | val_0_mse: 0.01402 |  0:07:46s\n",
      "epoch 43 | loss: 0.02459 | val_0_mse: 0.01422 |  0:07:56s\n",
      "epoch 44 | loss: 0.0162  | val_0_mse: 0.01483 |  0:08:07s\n",
      "epoch 45 | loss: 0.02171 | val_0_mse: 0.0247  |  0:08:17s\n",
      "epoch 46 | loss: 0.02348 | val_0_mse: 0.01886 |  0:08:28s\n",
      "epoch 47 | loss: 0.0189  | val_0_mse: 0.02153 |  0:08:38s\n",
      "epoch 48 | loss: 0.01702 | val_0_mse: 0.01578 |  0:08:49s\n",
      "epoch 49 | loss: 0.01681 | val_0_mse: 0.01101 |  0:09:00s\n",
      "epoch 50 | loss: 0.01574 | val_0_mse: 0.0127  |  0:09:10s\n",
      "epoch 51 | loss: 0.01711 | val_0_mse: 0.01065 |  0:09:21s\n",
      "epoch 52 | loss: 0.01476 | val_0_mse: 0.00922 |  0:09:32s\n",
      "epoch 53 | loss: 0.01532 | val_0_mse: 0.00837 |  0:09:42s\n",
      "epoch 54 | loss: 0.0141  | val_0_mse: 0.0159  |  0:09:53s\n",
      "epoch 55 | loss: 0.01353 | val_0_mse: 0.01202 |  0:10:03s\n",
      "epoch 56 | loss: 0.01923 | val_0_mse: 0.00822 |  0:10:14s\n",
      "epoch 57 | loss: 0.01581 | val_0_mse: 0.00847 |  0:10:25s\n",
      "epoch 58 | loss: 0.01751 | val_0_mse: 0.01408 |  0:10:36s\n",
      "epoch 59 | loss: 0.0124  | val_0_mse: 0.01011 |  0:10:46s\n",
      "epoch 60 | loss: 0.01477 | val_0_mse: 0.00732 |  0:10:57s\n",
      "epoch 61 | loss: 0.01186 | val_0_mse: 0.00758 |  0:11:07s\n",
      "epoch 62 | loss: 0.01385 | val_0_mse: 0.00735 |  0:11:18s\n",
      "epoch 63 | loss: 0.01515 | val_0_mse: 0.0438  |  0:11:28s\n",
      "epoch 64 | loss: 0.01832 | val_0_mse: 0.00939 |  0:11:39s\n",
      "epoch 65 | loss: 0.01281 | val_0_mse: 0.04172 |  0:11:49s\n",
      "epoch 66 | loss: 0.01368 | val_0_mse: 0.00984 |  0:12:00s\n",
      "epoch 67 | loss: 0.01086 | val_0_mse: 0.00829 |  0:12:10s\n",
      "epoch 68 | loss: 0.00905 | val_0_mse: 0.00608 |  0:12:21s\n",
      "epoch 69 | loss: 0.01089 | val_0_mse: 0.00682 |  0:12:31s\n",
      "epoch 70 | loss: 0.01198 | val_0_mse: 0.00742 |  0:12:42s\n",
      "epoch 71 | loss: 0.01404 | val_0_mse: 0.01187 |  0:12:52s\n",
      "epoch 72 | loss: 0.01435 | val_0_mse: 0.02143 |  0:13:02s\n",
      "epoch 73 | loss: 0.01456 | val_0_mse: 0.01341 |  0:13:13s\n",
      "epoch 74 | loss: 0.011   | val_0_mse: 0.00722 |  0:13:24s\n",
      "epoch 75 | loss: 0.01172 | val_0_mse: 0.00928 |  0:13:34s\n",
      "epoch 76 | loss: 0.01481 | val_0_mse: 0.01954 |  0:13:44s\n",
      "epoch 77 | loss: 0.00904 | val_0_mse: 0.00696 |  0:13:56s\n",
      "epoch 78 | loss: 0.00963 | val_0_mse: 0.0083  |  0:14:08s\n",
      "\n",
      "Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_mse = 0.00608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006104 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.972464 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 61/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.01875 | val_0_mse: 0.88124 |  0:00:13s\n",
      "epoch 1  | loss: 0.91435 | val_0_mse: 0.13829 |  0:00:26s\n",
      "epoch 2  | loss: 0.16375 | val_0_mse: 0.13032 |  0:00:40s\n",
      "epoch 3  | loss: 0.11057 | val_0_mse: 0.09849 |  0:00:53s\n",
      "epoch 4  | loss: 0.09527 | val_0_mse: 0.08185 |  0:01:05s\n",
      "epoch 5  | loss: 0.09095 | val_0_mse: 0.07349 |  0:01:18s\n",
      "epoch 6  | loss: 0.08016 | val_0_mse: 0.08759 |  0:01:34s\n",
      "epoch 7  | loss: 0.07573 | val_0_mse: 0.06502 |  0:01:51s\n",
      "epoch 8  | loss: 0.06923 | val_0_mse: 0.07716 |  0:02:05s\n",
      "epoch 9  | loss: 0.06095 | val_0_mse: 0.06539 |  0:02:18s\n",
      "epoch 10 | loss: 0.05394 | val_0_mse: 0.04541 |  0:02:31s\n",
      "epoch 11 | loss: 0.05343 | val_0_mse: 0.03268 |  0:02:44s\n",
      "epoch 12 | loss: 0.04206 | val_0_mse: 0.03155 |  0:02:57s\n",
      "epoch 13 | loss: 0.03893 | val_0_mse: 0.04635 |  0:03:11s\n",
      "epoch 14 | loss: 0.04483 | val_0_mse: 0.02595 |  0:03:24s\n",
      "epoch 15 | loss: 0.03992 | val_0_mse: 0.02334 |  0:03:37s\n",
      "epoch 16 | loss: 0.02951 | val_0_mse: 0.03394 |  0:03:51s\n",
      "epoch 17 | loss: 0.02915 | val_0_mse: 0.02087 |  0:04:04s\n",
      "epoch 18 | loss: 0.02559 | val_0_mse: 0.04971 |  0:04:17s\n",
      "epoch 19 | loss: 0.02375 | val_0_mse: 0.01534 |  0:04:30s\n",
      "epoch 20 | loss: 0.025   | val_0_mse: 0.01947 |  0:04:43s\n",
      "epoch 21 | loss: 0.02479 | val_0_mse: 0.01843 |  0:04:57s\n",
      "epoch 22 | loss: 0.02115 | val_0_mse: 0.01182 |  0:05:10s\n",
      "epoch 23 | loss: 0.01843 | val_0_mse: 0.02144 |  0:05:23s\n",
      "epoch 24 | loss: 0.019   | val_0_mse: 0.0324  |  0:05:37s\n",
      "epoch 25 | loss: 0.01565 | val_0_mse: 0.01536 |  0:05:51s\n",
      "epoch 26 | loss: 0.01627 | val_0_mse: 0.01076 |  0:06:04s\n",
      "epoch 27 | loss: 0.01899 | val_0_mse: 0.00899 |  0:06:17s\n",
      "epoch 28 | loss: 0.01342 | val_0_mse: 0.03231 |  0:06:30s\n",
      "epoch 29 | loss: 0.01271 | val_0_mse: 0.01259 |  0:06:44s\n",
      "epoch 30 | loss: 0.01714 | val_0_mse: 0.02266 |  0:06:57s\n",
      "epoch 31 | loss: 0.014   | val_0_mse: 0.02253 |  0:07:09s\n",
      "epoch 32 | loss: 0.01381 | val_0_mse: 0.01097 |  0:07:23s\n",
      "epoch 33 | loss: 0.01745 | val_0_mse: 0.01119 |  0:07:36s\n",
      "epoch 34 | loss: 0.01315 | val_0_mse: 0.0154  |  0:07:49s\n",
      "epoch 35 | loss: 0.01484 | val_0_mse: 0.03895 |  0:08:02s\n",
      "epoch 36 | loss: 0.01331 | val_0_mse: 0.01038 |  0:08:15s\n",
      "epoch 37 | loss: 0.01343 | val_0_mse: 0.01015 |  0:08:28s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_mse = 0.00899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.008705 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.960729 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 62/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=3, n_shared=2, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.18183 | val_0_mse: 1.13564 |  0:00:11s\n",
      "epoch 1  | loss: 1.19797 | val_0_mse: 0.64903 |  0:00:22s\n",
      "epoch 2  | loss: 0.45413 | val_0_mse: 0.7601  |  0:00:32s\n",
      "epoch 3  | loss: 0.17965 | val_0_mse: 0.22072 |  0:00:42s\n",
      "epoch 4  | loss: 0.1462  | val_0_mse: 0.12175 |  0:00:52s\n",
      "epoch 5  | loss: 0.12815 | val_0_mse: 0.18598 |  0:01:05s\n",
      "epoch 6  | loss: 0.12992 | val_0_mse: 0.22876 |  0:01:16s\n",
      "epoch 7  | loss: 0.10526 | val_0_mse: 0.1571  |  0:01:26s\n",
      "epoch 8  | loss: 0.08371 | val_0_mse: 0.0696  |  0:01:36s\n",
      "epoch 9  | loss: 0.0693  | val_0_mse: 0.08524 |  0:01:46s\n",
      "epoch 10 | loss: 0.08024 | val_0_mse: 0.08714 |  0:01:56s\n",
      "epoch 11 | loss: 0.07294 | val_0_mse: 0.07257 |  0:02:06s\n",
      "epoch 12 | loss: 0.07319 | val_0_mse: 0.09797 |  0:02:16s\n",
      "epoch 13 | loss: 0.07432 | val_0_mse: 0.07434 |  0:02:26s\n",
      "epoch 14 | loss: 0.08088 | val_0_mse: 0.09224 |  0:02:39s\n",
      "epoch 15 | loss: 0.0761  | val_0_mse: 0.0568  |  0:02:51s\n",
      "epoch 16 | loss: 0.07393 | val_0_mse: 0.08308 |  0:03:01s\n",
      "epoch 17 | loss: 0.07951 | val_0_mse: 0.07227 |  0:03:12s\n",
      "epoch 18 | loss: 0.0598  | val_0_mse: 0.05514 |  0:03:22s\n",
      "epoch 19 | loss: 0.05848 | val_0_mse: 0.05096 |  0:03:32s\n",
      "epoch 20 | loss: 0.05534 | val_0_mse: 0.04644 |  0:03:43s\n",
      "epoch 21 | loss: 0.05043 | val_0_mse: 0.05696 |  0:03:53s\n",
      "epoch 22 | loss: 0.04676 | val_0_mse: 0.04392 |  0:04:07s\n",
      "epoch 23 | loss: 0.04583 | val_0_mse: 0.0441  |  0:04:18s\n",
      "epoch 24 | loss: 0.05012 | val_0_mse: 0.03813 |  0:04:30s\n",
      "epoch 25 | loss: 0.04348 | val_0_mse: 0.04075 |  0:04:40s\n",
      "epoch 26 | loss: 0.04361 | val_0_mse: 0.03987 |  0:04:50s\n",
      "epoch 27 | loss: 0.04406 | val_0_mse: 0.03686 |  0:05:00s\n",
      "epoch 28 | loss: 0.04876 | val_0_mse: 0.03855 |  0:05:10s\n",
      "epoch 29 | loss: 0.03953 | val_0_mse: 0.0388  |  0:05:19s\n",
      "epoch 30 | loss: 0.0469  | val_0_mse: 0.0993  |  0:05:29s\n",
      "epoch 31 | loss: 0.04303 | val_0_mse: 0.03781 |  0:05:38s\n",
      "epoch 32 | loss: 0.04118 | val_0_mse: 0.04024 |  0:05:48s\n",
      "epoch 33 | loss: 0.03892 | val_0_mse: 0.03323 |  0:06:00s\n",
      "epoch 34 | loss: 0.03682 | val_0_mse: 0.03085 |  0:06:09s\n",
      "epoch 35 | loss: 0.03881 | val_0_mse: 0.08074 |  0:06:19s\n",
      "epoch 36 | loss: 0.03911 | val_0_mse: 0.02908 |  0:06:29s\n",
      "epoch 37 | loss: 0.03362 | val_0_mse: 0.03282 |  0:06:38s\n",
      "epoch 38 | loss: 0.03094 | val_0_mse: 0.02966 |  0:06:48s\n",
      "epoch 39 | loss: 0.03092 | val_0_mse: 0.02566 |  0:06:58s\n",
      "epoch 40 | loss: 0.02896 | val_0_mse: 0.02536 |  0:07:08s\n",
      "epoch 41 | loss: 0.03366 | val_0_mse: 0.03148 |  0:07:17s\n",
      "epoch 42 | loss: 0.02832 | val_0_mse: 0.02326 |  0:07:28s\n",
      "epoch 43 | loss: 0.03067 | val_0_mse: 0.03195 |  0:07:38s\n",
      "epoch 44 | loss: 0.02925 | val_0_mse: 0.02374 |  0:07:47s\n",
      "epoch 45 | loss: 0.03282 | val_0_mse: 0.03476 |  0:07:57s\n",
      "epoch 46 | loss: 0.02764 | val_0_mse: 0.02025 |  0:08:07s\n",
      "epoch 47 | loss: 0.02358 | val_0_mse: 0.02383 |  0:08:17s\n",
      "epoch 48 | loss: 0.02444 | val_0_mse: 0.01916 |  0:08:27s\n",
      "epoch 49 | loss: 0.02592 | val_0_mse: 0.01886 |  0:08:36s\n",
      "epoch 50 | loss: 0.02769 | val_0_mse: 0.02402 |  0:08:46s\n",
      "epoch 51 | loss: 0.0257  | val_0_mse: 0.03092 |  0:08:56s\n",
      "epoch 52 | loss: 0.0236  | val_0_mse: 0.02323 |  0:09:06s\n",
      "epoch 53 | loss: 0.02237 | val_0_mse: 0.02381 |  0:09:15s\n",
      "epoch 54 | loss: 0.02109 | val_0_mse: 0.01585 |  0:09:25s\n",
      "epoch 55 | loss: 0.02116 | val_0_mse: 0.01563 |  0:09:35s\n",
      "epoch 56 | loss: 0.02034 | val_0_mse: 0.01509 |  0:09:45s\n",
      "epoch 57 | loss: 0.01813 | val_0_mse: 0.02123 |  0:09:55s\n",
      "epoch 58 | loss: 0.01713 | val_0_mse: 0.01582 |  0:10:05s\n",
      "epoch 59 | loss: 0.01613 | val_0_mse: 0.01176 |  0:10:14s\n",
      "epoch 60 | loss: 0.01739 | val_0_mse: 0.01298 |  0:10:24s\n",
      "epoch 61 | loss: 0.01743 | val_0_mse: 0.01001 |  0:10:33s\n",
      "epoch 62 | loss: 0.01366 | val_0_mse: 0.0113  |  0:10:43s\n",
      "epoch 63 | loss: 0.01597 | val_0_mse: 0.01012 |  0:10:53s\n",
      "epoch 64 | loss: 0.01404 | val_0_mse: 0.0305  |  0:11:03s\n",
      "epoch 65 | loss: 0.01869 | val_0_mse: 0.01161 |  0:11:12s\n",
      "epoch 66 | loss: 0.01316 | val_0_mse: 0.01929 |  0:11:22s\n",
      "epoch 67 | loss: 0.01671 | val_0_mse: 0.01265 |  0:11:32s\n",
      "epoch 68 | loss: 0.01432 | val_0_mse: 0.01254 |  0:11:42s\n",
      "epoch 69 | loss: 0.01141 | val_0_mse: 0.01169 |  0:11:52s\n",
      "epoch 70 | loss: 0.01285 | val_0_mse: 0.00761 |  0:12:03s\n",
      "epoch 71 | loss: 0.01171 | val_0_mse: 0.02034 |  0:12:12s\n",
      "epoch 72 | loss: 0.01308 | val_0_mse: 0.02042 |  0:12:22s\n",
      "epoch 73 | loss: 0.01401 | val_0_mse: 0.03124 |  0:12:31s\n",
      "epoch 74 | loss: 0.00953 | val_0_mse: 0.01388 |  0:12:41s\n",
      "epoch 75 | loss: 0.01033 | val_0_mse: 0.00853 |  0:12:50s\n",
      "epoch 76 | loss: 0.01025 | val_0_mse: 0.00691 |  0:13:00s\n",
      "epoch 77 | loss: 0.01804 | val_0_mse: 0.01314 |  0:13:10s\n",
      "epoch 78 | loss: 0.01202 | val_0_mse: 0.00789 |  0:13:19s\n",
      "epoch 79 | loss: 0.01083 | val_0_mse: 0.00899 |  0:13:29s\n",
      "epoch 80 | loss: 0.00928 | val_0_mse: 0.00616 |  0:13:39s\n",
      "epoch 81 | loss: 0.00973 | val_0_mse: 0.01033 |  0:13:49s\n",
      "epoch 82 | loss: 0.00853 | val_0_mse: 0.01013 |  0:13:59s\n",
      "epoch 83 | loss: 0.00997 | val_0_mse: 0.00665 |  0:14:09s\n",
      "epoch 84 | loss: 0.00958 | val_0_mse: 0.00994 |  0:14:19s\n",
      "epoch 85 | loss: 0.00935 | val_0_mse: 0.00817 |  0:14:29s\n",
      "epoch 86 | loss: 0.00965 | val_0_mse: 0.00993 |  0:14:38s\n",
      "epoch 87 | loss: 0.00924 | val_0_mse: 0.00761 |  0:14:48s\n",
      "epoch 88 | loss: 0.01263 | val_0_mse: 0.02763 |  0:14:58s\n",
      "epoch 89 | loss: 0.01285 | val_0_mse: 0.00832 |  0:15:08s\n",
      "epoch 90 | loss: 0.00956 | val_0_mse: 0.01437 |  0:15:17s\n",
      "\n",
      "Early stopping occurred at epoch 90 with best_epoch = 80 and best_val_0_mse = 0.00616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.005967 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.973080 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 63/64 - Hyperparameters:  batch_sizes=128, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.22196 | val_0_mse: 1.27889 |  0:00:15s\n",
      "epoch 1  | loss: 0.45572 | val_0_mse: 0.39651 |  0:00:30s\n",
      "epoch 2  | loss: 0.17542 | val_0_mse: 0.15741 |  0:00:45s\n",
      "epoch 3  | loss: 0.11764 | val_0_mse: 0.11767 |  0:01:00s\n",
      "epoch 4  | loss: 0.10186 | val_0_mse: 0.16902 |  0:01:15s\n",
      "epoch 5  | loss: 0.08264 | val_0_mse: 0.09103 |  0:01:30s\n",
      "epoch 6  | loss: 0.07563 | val_0_mse: 0.05528 |  0:01:45s\n",
      "epoch 7  | loss: 0.06591 | val_0_mse: 0.04954 |  0:02:00s\n",
      "epoch 8  | loss: 0.05665 | val_0_mse: 0.06215 |  0:02:15s\n",
      "epoch 9  | loss: 0.05399 | val_0_mse: 0.0459  |  0:02:30s\n",
      "epoch 10 | loss: 0.05521 | val_0_mse: 0.04569 |  0:02:45s\n",
      "epoch 11 | loss: 0.04153 | val_0_mse: 0.03786 |  0:03:00s\n",
      "epoch 12 | loss: 0.04352 | val_0_mse: 0.04191 |  0:03:15s\n",
      "epoch 13 | loss: 0.03467 | val_0_mse: 0.06188 |  0:03:30s\n",
      "epoch 14 | loss: 0.04315 | val_0_mse: 0.02599 |  0:03:45s\n",
      "epoch 15 | loss: 0.03463 | val_0_mse: 0.02886 |  0:04:00s\n",
      "epoch 16 | loss: 0.02681 | val_0_mse: 0.0516  |  0:04:15s\n",
      "epoch 17 | loss: 0.02902 | val_0_mse: 0.02057 |  0:04:29s\n",
      "epoch 18 | loss: 0.02567 | val_0_mse: 0.0168  |  0:04:44s\n",
      "epoch 19 | loss: 0.02475 | val_0_mse: 0.01405 |  0:04:59s\n",
      "epoch 20 | loss: 0.02724 | val_0_mse: 0.0386  |  0:05:14s\n",
      "epoch 21 | loss: 0.02963 | val_0_mse: 0.01878 |  0:05:29s\n",
      "epoch 22 | loss: 0.0186  | val_0_mse: 0.01275 |  0:05:44s\n",
      "epoch 23 | loss: 0.02128 | val_0_mse: 0.01298 |  0:05:59s\n",
      "epoch 24 | loss: 0.01707 | val_0_mse: 0.01878 |  0:06:14s\n",
      "epoch 25 | loss: 0.02454 | val_0_mse: 0.01145 |  0:06:29s\n",
      "epoch 26 | loss: 0.01371 | val_0_mse: 0.03514 |  0:06:44s\n",
      "epoch 27 | loss: 0.0288  | val_0_mse: 0.02014 |  0:06:58s\n",
      "epoch 28 | loss: 0.02007 | val_0_mse: 0.01876 |  0:07:13s\n",
      "epoch 29 | loss: 0.01722 | val_0_mse: 0.01131 |  0:07:28s\n",
      "epoch 30 | loss: 0.01711 | val_0_mse: 0.02285 |  0:07:43s\n",
      "epoch 31 | loss: 0.01774 | val_0_mse: 0.01615 |  0:07:57s\n",
      "epoch 32 | loss: 0.0182  | val_0_mse: 0.06094 |  0:08:12s\n",
      "epoch 33 | loss: 0.02387 | val_0_mse: 0.02006 |  0:08:27s\n",
      "epoch 34 | loss: 0.01691 | val_0_mse: 0.06865 |  0:08:42s\n",
      "epoch 35 | loss: 0.01855 | val_0_mse: 0.01599 |  0:08:57s\n",
      "epoch 36 | loss: 0.01843 | val_0_mse: 0.01045 |  0:09:12s\n",
      "epoch 37 | loss: 0.02302 | val_0_mse: 0.01329 |  0:09:26s\n",
      "epoch 38 | loss: 0.01566 | val_0_mse: 0.00993 |  0:09:41s\n",
      "epoch 39 | loss: 0.01451 | val_0_mse: 0.01162 |  0:09:56s\n",
      "epoch 40 | loss: 0.01237 | val_0_mse: 0.00747 |  0:10:11s\n",
      "epoch 41 | loss: 0.01192 | val_0_mse: 0.00727 |  0:10:25s\n",
      "epoch 42 | loss: 0.01347 | val_0_mse: 0.00869 |  0:10:40s\n",
      "epoch 43 | loss: 0.01421 | val_0_mse: 0.01025 |  0:10:55s\n",
      "epoch 44 | loss: 0.01617 | val_0_mse: 0.01989 |  0:11:10s\n",
      "epoch 45 | loss: 0.01227 | val_0_mse: 0.00747 |  0:11:25s\n",
      "epoch 46 | loss: 0.01418 | val_0_mse: 0.0294  |  0:11:40s\n",
      "epoch 47 | loss: 0.02006 | val_0_mse: 0.01885 |  0:11:54s\n",
      "epoch 48 | loss: 0.01916 | val_0_mse: 0.073   |  0:12:09s\n",
      "epoch 49 | loss: 0.02033 | val_0_mse: 0.23052 |  0:12:24s\n",
      "epoch 50 | loss: 0.02229 | val_0_mse: 0.02492 |  0:12:39s\n",
      "epoch 51 | loss: 0.01395 | val_0_mse: 0.01652 |  0:12:54s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_mse = 0.00727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007998 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.963917 - Best R2 Score: 0.976475\n",
      "\n",
      "Iterations 64/64 - Hyperparameters:  batch_sizes=256, nums_epochs=200, n_d=64, n_a=64, n_step=7, n_indipendent=3, n_shared=3, gamma=1.3, epsilon=1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.88743 | val_0_mse: 0.60239 |  0:00:12s\n",
      "epoch 1  | loss: 1.07909 | val_0_mse: 0.50813 |  0:00:24s\n",
      "epoch 2  | loss: 1.02317 | val_0_mse: 0.72019 |  0:00:36s\n",
      "epoch 3  | loss: 0.25128 | val_0_mse: 0.18627 |  0:00:47s\n",
      "epoch 4  | loss: 0.17371 | val_0_mse: 0.09739 |  0:00:58s\n",
      "epoch 5  | loss: 0.11213 | val_0_mse: 0.15406 |  0:01:10s\n",
      "epoch 6  | loss: 0.10459 | val_0_mse: 0.14579 |  0:01:21s\n",
      "epoch 7  | loss: 0.09893 | val_0_mse: 0.09503 |  0:01:33s\n",
      "epoch 8  | loss: 0.10949 | val_0_mse: 0.18796 |  0:01:44s\n",
      "epoch 9  | loss: 0.09987 | val_0_mse: 0.08511 |  0:01:55s\n",
      "epoch 10 | loss: 0.08621 | val_0_mse: 0.08724 |  0:02:06s\n",
      "epoch 11 | loss: 0.09484 | val_0_mse: 0.0931  |  0:02:18s\n",
      "epoch 12 | loss: 0.08334 | val_0_mse: 0.08933 |  0:02:29s\n",
      "epoch 13 | loss: 0.09329 | val_0_mse: 0.06533 |  0:02:41s\n",
      "epoch 14 | loss: 0.07275 | val_0_mse: 0.08371 |  0:02:52s\n",
      "epoch 15 | loss: 0.06773 | val_0_mse: 0.0747  |  0:03:03s\n",
      "epoch 16 | loss: 0.06959 | val_0_mse: 0.05949 |  0:03:15s\n",
      "epoch 17 | loss: 0.06809 | val_0_mse: 0.07549 |  0:03:26s\n",
      "epoch 18 | loss: 0.06999 | val_0_mse: 0.06215 |  0:03:37s\n",
      "epoch 19 | loss: 0.06523 | val_0_mse: 0.05706 |  0:03:49s\n",
      "epoch 20 | loss: 0.06291 | val_0_mse: 0.05335 |  0:04:00s\n",
      "epoch 21 | loss: 0.06204 | val_0_mse: 0.06521 |  0:04:11s\n",
      "epoch 22 | loss: 0.06924 | val_0_mse: 0.07785 |  0:04:23s\n",
      "epoch 23 | loss: 0.05977 | val_0_mse: 0.06106 |  0:04:34s\n",
      "epoch 24 | loss: 0.05667 | val_0_mse: 0.05136 |  0:04:46s\n",
      "epoch 25 | loss: 0.05956 | val_0_mse: 0.05597 |  0:04:57s\n",
      "epoch 26 | loss: 0.05813 | val_0_mse: 0.06417 |  0:05:09s\n",
      "epoch 27 | loss: 0.06293 | val_0_mse: 0.07238 |  0:05:21s\n",
      "epoch 28 | loss: 0.06181 | val_0_mse: 0.05368 |  0:05:34s\n",
      "epoch 29 | loss: 0.05878 | val_0_mse: 0.0508  |  0:05:45s\n",
      "epoch 30 | loss: 0.05366 | val_0_mse: 0.05605 |  0:05:57s\n",
      "epoch 31 | loss: 0.05354 | val_0_mse: 0.05067 |  0:06:09s\n",
      "epoch 32 | loss: 0.05057 | val_0_mse: 0.06906 |  0:06:20s\n",
      "epoch 33 | loss: 0.05103 | val_0_mse: 0.05686 |  0:06:32s\n",
      "epoch 34 | loss: 0.04731 | val_0_mse: 0.03988 |  0:06:44s\n",
      "epoch 35 | loss: 0.04416 | val_0_mse: 0.03354 |  0:06:56s\n",
      "epoch 36 | loss: 0.04397 | val_0_mse: 0.03339 |  0:07:07s\n",
      "epoch 37 | loss: 0.03665 | val_0_mse: 0.03813 |  0:07:19s\n",
      "epoch 38 | loss: 0.03557 | val_0_mse: 0.03328 |  0:07:31s\n",
      "epoch 39 | loss: 0.03394 | val_0_mse: 0.03218 |  0:07:42s\n",
      "epoch 40 | loss: 0.03111 | val_0_mse: 0.02399 |  0:07:54s\n",
      "epoch 41 | loss: 0.02959 | val_0_mse: 0.02772 |  0:08:06s\n",
      "epoch 42 | loss: 0.02906 | val_0_mse: 0.02622 |  0:08:17s\n",
      "epoch 43 | loss: 0.02336 | val_0_mse: 0.01841 |  0:08:29s\n",
      "epoch 44 | loss: 0.02456 | val_0_mse: 0.01897 |  0:08:40s\n",
      "epoch 45 | loss: 0.02308 | val_0_mse: 0.02471 |  0:08:52s\n",
      "epoch 46 | loss: 0.02017 | val_0_mse: 0.01732 |  0:09:04s\n",
      "epoch 47 | loss: 0.02001 | val_0_mse: 0.03367 |  0:09:15s\n",
      "epoch 48 | loss: 0.02076 | val_0_mse: 0.01377 |  0:09:27s\n",
      "epoch 49 | loss: 0.01806 | val_0_mse: 0.02871 |  0:09:39s\n",
      "epoch 50 | loss: 0.02473 | val_0_mse: 0.01306 |  0:09:50s\n",
      "epoch 51 | loss: 0.01663 | val_0_mse: 0.0197  |  0:10:03s\n",
      "epoch 52 | loss: 0.01605 | val_0_mse: 0.01354 |  0:10:15s\n",
      "epoch 53 | loss: 0.01446 | val_0_mse: 0.01133 |  0:10:29s\n",
      "epoch 54 | loss: 0.01652 | val_0_mse: 0.02836 |  0:10:40s\n",
      "epoch 55 | loss: 0.01312 | val_0_mse: 0.01492 |  0:10:51s\n",
      "epoch 56 | loss: 0.01451 | val_0_mse: 0.01012 |  0:11:03s\n",
      "epoch 57 | loss: 0.01388 | val_0_mse: 0.02024 |  0:11:15s\n",
      "epoch 58 | loss: 0.01383 | val_0_mse: 0.02419 |  0:11:26s\n",
      "epoch 59 | loss: 0.0138  | val_0_mse: 0.01011 |  0:11:38s\n",
      "epoch 60 | loss: 0.01474 | val_0_mse: 0.01947 |  0:11:50s\n",
      "epoch 61 | loss: 0.02002 | val_0_mse: 0.01614 |  0:12:02s\n",
      "epoch 62 | loss: 0.01703 | val_0_mse: 0.01646 |  0:12:15s\n",
      "epoch 63 | loss: 0.01829 | val_0_mse: 0.01695 |  0:12:27s\n",
      "epoch 64 | loss: 0.01887 | val_0_mse: 0.01428 |  0:12:39s\n",
      "epoch 65 | loss: 0.01764 | val_0_mse: 0.0088  |  0:12:50s\n",
      "epoch 66 | loss: 0.01063 | val_0_mse: 0.00823 |  0:13:02s\n",
      "epoch 67 | loss: 0.01166 | val_0_mse: 0.01026 |  0:13:14s\n",
      "epoch 68 | loss: 0.01225 | val_0_mse: 0.00946 |  0:13:25s\n",
      "epoch 69 | loss: 0.01342 | val_0_mse: 0.00953 |  0:13:37s\n",
      "epoch 70 | loss: 0.01577 | val_0_mse: 0.00697 |  0:13:49s\n",
      "epoch 71 | loss: 0.01826 | val_0_mse: 0.00855 |  0:14:00s\n",
      "epoch 72 | loss: 0.01118 | val_0_mse: 0.01404 |  0:14:12s\n",
      "epoch 73 | loss: 0.01079 | val_0_mse: 0.0104  |  0:14:24s\n",
      "epoch 74 | loss: 0.01022 | val_0_mse: 0.01388 |  0:14:35s\n",
      "epoch 75 | loss: 0.0107  | val_0_mse: 0.01072 |  0:14:47s\n",
      "epoch 76 | loss: 0.0098  | val_0_mse: 0.0109  |  0:14:58s\n",
      "epoch 77 | loss: 0.01084 | val_0_mse: 0.02285 |  0:15:10s\n",
      "epoch 78 | loss: 0.01005 | val_0_mse: 0.00948 |  0:15:22s\n",
      "epoch 79 | loss: 0.01133 | val_0_mse: 0.0121  |  0:15:34s\n",
      "epoch 80 | loss: 0.0181  | val_0_mse: 0.01297 |  0:15:45s\n",
      "\n",
      "Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 0.00697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.007122 - Best MSE: 0.005215\n",
      "Model R2 Score: 0.967873 - Best R2 Score: 0.976475\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('tabularML/training'):\n",
    "    os.system('rm -r tabularM/training')\n",
    "else:\n",
    "    os.makedirs('tabularML/training')\n",
    "\n",
    "current_iter = 0\n",
    "\n",
    "best_mse = float('inf')\n",
    "best_model = None\n",
    "best_n_d = None\n",
    "best_n_a = None\n",
    "best_n_step = None\n",
    "best_n_indipendent = None\n",
    "best_n_shared = None\n",
    "best_gamma = None\n",
    "best_batch_size = None\n",
    "\n",
    "for n_d_a, n_step,n_indipendent,n_shared, gamma, epsilon,nums_epochs, batch_sizes in hyperparameters:\n",
    "    current_iter += 1\n",
    "\n",
    "    print(\"\\nIterations {}/{} - Hyperparameters:  batch_sizes={}, nums_epochs={}, n_d={}, n_a={}, n_step={}, n_indipendent={}, n_shared={}, gamma={}, epsilon={}\".format(\n",
    "        current_iter, n_comb, batch_sizes, nums_epochs, n_d_a, n_d_a, n_step, n_indipendent, n_shared, gamma, epsilon ))\n",
    "\n",
    "    model = get_model(n_d_a, n_step, n_indipendent, n_shared, gamma, epsilon)\n",
    "    \n",
    "    log_name = \"n_d:\"+str(n_d_a)+\"n_a:\"+str(n_d_a)+\"n_step:\"+str(n_step)+\"n_indipendent:\"+str(n_indipendent)+\"n_shared:\"+str(n_shared)+\"gamma:\"+str(gamma)+\"epsilon:\"+str(epsilon)\n",
    "    \n",
    "    # start tensorboard\n",
    "    writer = SummaryWriter('tabularML/training/'+log_name)\n",
    "    \n",
    "    # train\n",
    "    model.fit(\n",
    "                X_train=X_train,\n",
    "                y_train=Y_train,\n",
    "                eval_set=[(X_val, Y_val)],\n",
    "                eval_metric=['mse'],\n",
    "                # patience: the number of epochs to wait without improvement in validation loss before early stopping (default 10)\n",
    "                patience=10,\n",
    "                # batch_size: the number of samples per batch (default 1024)\n",
    "                batch_size=batch_sizes,\n",
    "                # virtual_batch_size: the number of samples per virtual batch (default 128)\n",
    "                virtual_batch_size=128,\n",
    "                # num_workers: the number of worker processes to use for data loading (default 0)\n",
    "                num_workers=0,\n",
    "                # drop_last: whether to drop the last incomplete batch if the dataset size is not divisible by the batch size (default False)\n",
    "                drop_last=False,\n",
    "                # max_epochs: the maximum number of epochs to train for (default 100)\n",
    "                max_epochs=nums_epochs,\n",
    "            )\n",
    "    \n",
    "    writer.add_hparams({'n_d':n_d_a, 'n_a':n_d_a, 'n_step':n_step, 'n_indipendent':n_indipendent, 'n_shared':n_shared, 'gamma':gamma, 'epsilon':epsilon, 'batch_sizes':batch_sizes, 'nums_epochs':nums_epochs }, {'hparam/mse': model.best_cost})\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, preds)\n",
    "    \n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_n_d = n_d_a\n",
    "        best_n_a = n_d_a\n",
    "        best_n_step = n_step\n",
    "        best_n_indipendent = n_indipendent\n",
    "        best_n_shared = n_shared\n",
    "        best_gamma = gamma\n",
    "        best_batch_size = batch_sizes\n",
    "        best_model = copy.deepcopy(model) \n",
    "        \n",
    "    writer.flush()            \n",
    "            \n",
    "    print(\"Model MSE: {:.6f} - Best MSE: {:.6f}\".format(mse, best_mse))\n",
    "    print(\"Model R2 Score: {:.6f} - Best R2 Score: {:.6f}\".format(r2_score(Y_test, preds), r2_score(Y_test, best_model.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "history = best_model.history\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['loss'], label='train')\n",
    "plt.plot(history['val_0_mse'], label='validation')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid')\n",
    "sns.set_context('talk')\n",
    "sns.set_palette('colorblind')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(Y_test, preds, s=1)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('True Values vs Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training and validation losses\n",
    "train_losses = history['loss']\n",
    "valid_losses = history['val_0_mse']\n",
    "\n",
    "train_array = np.array(train_losses)\n",
    "valid_array = np.array(valid_losses)\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame({'training loss': train_array, 'validation loss': valid_array})\n",
    "\n",
    "df.to_csv('tabularML/training/loss.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
