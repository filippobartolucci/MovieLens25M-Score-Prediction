{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML_25M Deep ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def fix_random(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower\n",
    "\n",
    "fix_random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# PyTorch Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_previous = True\n",
    "\n",
    "if delete_previous:\n",
    "    try:\n",
    "        os.system('rm -rf runs')\n",
    "        os.system('rm -rf models')\n",
    "        os.system('rm -rf best_model.pth')\n",
    "        os.system('rm -rf best_model_config.json')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('rating', axis=1)\n",
    "Y = df['rating']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "Y_train = Y_train.to_numpy()\n",
    "Y_val = Y_val.to_numpy()\n",
    "Y_test = Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "# pca = PCA(n_components=0.95)\n",
    "# pca.fit(X_train)\n",
    "# X_train = pca.transform(X_train)\n",
    "# X_val = pca.transform(X_val)\n",
    "# X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 9946\n",
      "Number of validation samples: 1106\n",
      "Number of testing samples: 2764\n",
      "\n",
      "Number of features: 1128\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training samples: {X_train.shape[0]}')\n",
    "print(f'Number of validation samples: {X_val.shape[0]}')\n",
    "print(f'Number of testing samples: {X_test.shape[0]}')\n",
    "print(f'\\nNumber of features: {X_train.shape[1]}')\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(Y_val, dtype=torch.float32)), batch_size=Y_val.shape[0], shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(Y_test, dtype=torch.float32)), batch_size=Y_test.shape[0], shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size, hidden_size, dropout_prob=0, depth=1):\n",
    "    model = [\n",
    "        torch.nn.Linear(input_size, hidden_size),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(dropout_prob)\n",
    "    ]\n",
    "\n",
    "    for i in range(depth):\n",
    "        model.append(torch.nn.Linear(hidden_size, hidden_size))\n",
    "        model.append(torch.nn.ReLU())\n",
    "        model.append(torch.nn.Dropout(dropout_prob))\n",
    "\n",
    "    model.append(torch.nn.Linear(hidden_size, 1))\n",
    "    return torch.nn.Sequential(*model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hyperparameter combinations: 2\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "hidden_sizes =  [ 1024]\n",
    "nums_epochs = [200]\n",
    "depth = [4]\n",
    "batch_sizes = [32]\n",
    "learning_rate = [ 0.01]\n",
    "step_size_lr_decay = [10, 20]\n",
    "momentum = [0.9]\n",
    "dropout_prob = 0.2\n",
    "patience = 10\n",
    "\n",
    "hyperparameters = itertools.product(hidden_sizes, depth, nums_epochs, batch_sizes, learning_rate, step_size_lr_decay, momentum)\n",
    "n_comb = len(hidden_sizes)*len(depth)*len(nums_epochs)*len(batch_sizes)*len(learning_rate)*len(step_size_lr_decay)*len(momentum)\n",
    "print (f'Number of hyperparameter combinations: {n_comb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, criterion, loader):\n",
    "    loss = 0\n",
    "    y_pred = torch.tensor([]).to(device)\n",
    "    y_true = torch.tensor([]).to(device)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    for data in loader:\n",
    "        data, targets = data[0].to(device), data[1].to(device)\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred.squeeze(), targets)\n",
    "        val_loss += loss.item()\n",
    "        y_pred = torch.cat((y_pred, pred.squeeze()))\n",
    "        y_true = torch.cat((y_true, targets.detach()))\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    return loss / len(loader), y_pred.squeeze(), y_true.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training process\n",
    "def train_model(model, criterion, optimizer, scheduler, epochs, data_loader, val_loader, device, writer, log_name):\n",
    "    n_iter = 0\n",
    "\n",
    "    best_model = None\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_since_last_improvement = 0\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        start_epoch = time.time()\n",
    "\n",
    "        loss_train = 0\n",
    "        for data, targets in data_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            y_pred = model(data)\n",
    "            loss = criterion(y_pred.squeeze(), targets)\n",
    "            optimizer.zero_grad()\n",
    "            writer.add_scalar(\"Loss/train_iter\", loss, n_iter)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            n_iter += 1\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        loss_train /= len(data_loader)\n",
    "        writer.add_scalar(\"Loss/train\", loss_train, epoch)\n",
    "\n",
    "        # Compute Val Loss\n",
    "        val_loss, _ , _ = test_model(model, criterion, val_loader)\n",
    "\n",
    "        writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "\n",
    "        loss_history.append(loss_train)\n",
    "        val_loss_history.append(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            epochs_since_last_improvement = 0\n",
    "        elif epochs_since_last_improvement >= patience:\n",
    "            break\n",
    "        else:\n",
    "            epochs_since_last_improvement += 1\n",
    "\n",
    "        print('Epoch [{}/{}] - {:.2f} seconds - val_loss: {:.6f} - patience: {}'.format(epoch+1,\n",
    "              epochs, time.time() - start_epoch, val_loss, epochs_since_last_improvement), end='\\r')\n",
    "\n",
    "    print('\\nTraining ended after {:.2f} seconds - Best val_loss: {:.6f}'.format(time.time() - start, best_val_loss))\n",
    "\n",
    "    return best_model, loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iterations 1/2 - Training with hidden_size=1024, depth=4, num_epochs=200, batch=32, lr=0.01, step_size=10, momentum=0.9\n",
      "Epoch [41/200] - 2.92 seconds - val_loss: 0.008010 - patience: 10\n",
      "Training ended after 122.37 seconds - Best val_loss: 0.007699\n",
      "Model MSE: 0.008712 - Best MSE: 0.008712\n",
      "\n",
      "Iterations 2/2 - Training with hidden_size=1024, depth=4, num_epochs=200, batch=32, lr=0.01, step_size=20, momentum=0.9\n",
      "Epoch [57/200] - 3.02 seconds - val_loss: 0.006792 - patience: 10\n",
      "Training ended after 173.99 seconds - Best val_loss: 0.006734\n",
      "Model MSE: 0.006954 - Best MSE: 0.006954\n"
     ]
    }
   ],
   "source": [
    "current_iter = 0\n",
    "\n",
    "best_model = None\n",
    "best_mse = float('inf')\n",
    "criterion = torch.nn.MSELoss()\n",
    "history_loss = []\n",
    "history_val_loss = []\n",
    "\n",
    "if os.path.exists('best_model.pth'):\n",
    "    # read best model config\n",
    "    with open('best_model_config.json', 'r') as f:\n",
    "        best_model_config = json.load(f)\n",
    "\n",
    "    # load best model\n",
    "    best_model = get_model(X_train.shape[1], best_model_config['hidden_size'], dropout_prob, best_model_config['depth'])\n",
    "    best_model.load_state_dict(torch.load('best_model.pth'))\n",
    "    best_model.to(device)\n",
    "    best_model.eval()\n",
    "\n",
    "    # evaluate best model\n",
    "    best_mse, _, _ = test_model(best_model, criterion, test_loader)\n",
    "    \n",
    "    print(\"Best model - MSE: {:.6f}\".format(best_mse))\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "for hidden_size, depth, num_epochs, batch, lr, step_size, momentum in hyperparameters:\n",
    "    current_iter += 1\n",
    "\n",
    "    print(\"\\nIterations {}/{} - Training with hidden_size={}, depth={}, num_epochs={}, batch={}, lr={}, step_size={}, momentum={}\".format(\n",
    "        current_iter, n_comb, hidden_size, depth, num_epochs, batch, lr, step_size, momentum))\n",
    "    \n",
    "    log_name = \"dim:\"+str(hidden_size)+\"_depth:\"+str(depth)+\"_batch:\" + \\\n",
    "        str(batch)+\"_lr:\"+str(lr)+\"_step_size:\" + \\\n",
    "        str(step_size)\n",
    "\n",
    "    if os.path.exists('runs/'+log_name):\n",
    "        print(\"Model already trained, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # start tensorboard\n",
    "    writer = SummaryWriter('runs/'+log_name)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(Y_train, dtype=torch.float32)), batch_size=batch, shuffle=True)\n",
    "\n",
    "    model = get_model(X_train.shape[1], hidden_size, dropout_prob, depth=depth)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
    "\n",
    "    # train\n",
    "    model, hl, hvl = train_model(model, criterion, optimizer, scheduler, num_epochs, train_loader, val_loader, device, writer, log_name)\n",
    "\n",
    "    # validate model on test set\n",
    "    mse, _, _ = test_model(model, criterion, test_loader)\n",
    "    writer.add_hparams({'hidden_size': hidden_size, 'depth': depth, 'batch': batch,'lr': lr, 'step_size': step_size, 'momentum': momentum}, {'hparam/mse': mse})\n",
    "\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_model = model\n",
    "        \n",
    "        history_loss = hl\n",
    "        history_val_loss = hvl\n",
    "\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        # save config\n",
    "        with open('best_model_config.json', 'w') as f:\n",
    "            json.dump({'name':log_name,'hidden_size': hidden_size, 'depth': depth, 'num_epochs': num_epochs, 'batch': batch,\n",
    "                       'lr': lr, 'step_size': step_size}, f)\n",
    "            \n",
    "    print(\"Model MSE: {:.6f} - Best MSE: {:.6f}\".format(mse, best_mse))\n",
    "    torch.save(model.state_dict(), 'models/'+log_name+'.pth')\n",
    "    writer.flush()\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y_pred, y_true = test_model(best_model, criterion, test_loader)\n",
    "y_pred = y_pred.squeeze().cpu().detach().numpy()\n",
    "y_true = y_true.squeeze().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.969404 - MSE: 0.006782\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(\"R2: {:.6f} - MSE: {:.6f}\".format(r2, mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
