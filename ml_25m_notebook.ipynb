{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics - ML25M "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def fix_random(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "    Args:\n",
    "        seed: the seed to use. \n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower\n",
    "\n",
    "fix_random(42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movies.csv contains the following fields:\n",
    "\n",
    "* movieId - a unique identifier for each movie.\n",
    "* title - the title of the movie.\n",
    "* genres - a pipe-separated list of genres for the movie.\n",
    "\n",
    "It will be used to get the movie title and the genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                    title  (no genres listed)  Action  Adventure  \\\n",
       "0        1         Toy Story (1995)                   0       0          1   \n",
       "1        2           Jumanji (1995)                   0       0          1   \n",
       "2        3  Grumpier Old Men (1995)                   0       0          0   \n",
       "\n",
       "   Animation  Children  Comedy  Crime  Documentary  ...  Film-Noir  Horror  \\\n",
       "0          1         1       1      0            0  ...          0       0   \n",
       "1          0         1       0      0            0  ...          0       0   \n",
       "2          0         0       1      0            0  ...          0       0   \n",
       "\n",
       "   IMAX  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0     0        0        0        0       0         0    0        0  \n",
       "1     0        0        0        0       0         0    0        0  \n",
       "2     0        0        0        1       0         0    0        0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = pd.read_csv('./ml-25m/movies.csv')\n",
    "genres = movies_df['genres'].str.get_dummies(sep='|')\n",
    "movies_df = pd.concat([movies_df, genres], axis=1)\n",
    "movies_df.drop('genres', axis=1, inplace=True)\n",
    "movies_df.head(3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "genome-scores.csv contains the following fields:\n",
    "\n",
    "* movieId - a unique identifier for each movie.\n",
    "* tagId - a unique identifier for each tag.\n",
    "* relevance - a score from 0.0 to 1.0 representing the relevance of the tag to the movie.\n",
    "\n",
    "Combined with the tags.csv file, this will be used to assign tags and their relevance to each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.read_csv('./ml-25m/genome-scores.csv')\n",
    "tags_df = pd.read_csv('./ml-25m/genome-tags.csv')\n",
    "ratings_df = pd.read_csv('./ml-25m/ratings.csv')\n",
    "\n",
    "df = movies_df.merge(scores_df, on='movieId')\n",
    "df = df.merge(tags_df, on='tagId')\n",
    "df = df.pivot_table(index=['movieId', 'title'], columns='tag', values='relevance', fill_value=0).reset_index().rename_axis(None, axis=1)\n",
    "\n",
    "# average rating for each movie\n",
    "ratings_df = ratings_df.groupby(['movieId'])['rating'].mean().reset_index()\n",
    "# round ratings to the nearest 0.5\n",
    "ratings_df['rating'] = ratings_df['rating'].apply(lambda x: round(x * 2) / 2)\n",
    "\n",
    "# # mode rating for each movie\n",
    "# ratings_df = ratings_df.groupby(['movieId'])['rating'].agg(lambda x: x.value_counts().index[0]).reset_index()\n",
    "\n",
    "df = ratings_df.merge(df, on='movieId')\n",
    "\n",
    "# movieId and title are not needed for the model\n",
    "df.drop(['movieId', 'title'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 13816\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>007</th>\n",
       "      <th>007 (series)</th>\n",
       "      <th>18th century</th>\n",
       "      <th>1920s</th>\n",
       "      <th>1930s</th>\n",
       "      <th>1950s</th>\n",
       "      <th>1960s</th>\n",
       "      <th>1970s</th>\n",
       "      <th>1980s</th>\n",
       "      <th>...</th>\n",
       "      <th>world politics</th>\n",
       "      <th>world war i</th>\n",
       "      <th>world war ii</th>\n",
       "      <th>writer's life</th>\n",
       "      <th>writers</th>\n",
       "      <th>writing</th>\n",
       "      <th>wuxia</th>\n",
       "      <th>wwii</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.02875</td>\n",
       "      <td>0.02375</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.07575</td>\n",
       "      <td>0.14075</td>\n",
       "      <td>0.14675</td>\n",
       "      <td>0.06350</td>\n",
       "      <td>0.20375</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04050</td>\n",
       "      <td>0.01425</td>\n",
       "      <td>0.03050</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.14125</td>\n",
       "      <td>0.05775</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.02975</td>\n",
       "      <td>0.08475</td>\n",
       "      <td>0.02200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.04125</td>\n",
       "      <td>0.04050</td>\n",
       "      <td>0.06275</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.09100</td>\n",
       "      <td>0.06125</td>\n",
       "      <td>0.06925</td>\n",
       "      <td>0.09600</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05250</td>\n",
       "      <td>0.01575</td>\n",
       "      <td>0.01250</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.12225</td>\n",
       "      <td>0.03275</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.01100</td>\n",
       "      <td>0.10525</td>\n",
       "      <td>0.01975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.04675</td>\n",
       "      <td>0.05550</td>\n",
       "      <td>0.02925</td>\n",
       "      <td>0.08700</td>\n",
       "      <td>0.04750</td>\n",
       "      <td>0.04775</td>\n",
       "      <td>0.04600</td>\n",
       "      <td>0.14275</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06275</td>\n",
       "      <td>0.01950</td>\n",
       "      <td>0.02225</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.12200</td>\n",
       "      <td>0.03475</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.09100</td>\n",
       "      <td>0.01775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating      007  007 (series)  18th century    1920s    1930s    1950s  \\\n",
       "0     4.0  0.02875       0.02375       0.06250  0.07575  0.14075  0.14675   \n",
       "1     3.5  0.04125       0.04050       0.06275  0.08275  0.09100  0.06125   \n",
       "2     3.0  0.04675       0.05550       0.02925  0.08700  0.04750  0.04775   \n",
       "\n",
       "     1960s    1970s   1980s  ...  world politics  world war i  world war ii  \\\n",
       "0  0.06350  0.20375  0.2020  ...         0.04050      0.01425       0.03050   \n",
       "1  0.06925  0.09600  0.0765  ...         0.05250      0.01575       0.01250   \n",
       "2  0.04600  0.14275  0.0285  ...         0.06275      0.01950       0.02225   \n",
       "\n",
       "   writer's life  writers  writing  wuxia     wwii   zombie  zombies  \n",
       "0          0.035  0.14125  0.05775  0.039  0.02975  0.08475  0.02200  \n",
       "1          0.020  0.12225  0.03275  0.021  0.01100  0.10525  0.01975  \n",
       "2          0.023  0.12200  0.03475  0.017  0.01800  0.09100  0.01775  \n",
       "\n",
       "[3 rows x 1129 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Number of samples: {df.shape[0]}')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode:  0    3.5\n",
      "Name: rating, dtype: float64\n",
      "Median: 3.50\n",
      "Std: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Ratings distribution\n",
    "sns.countplot(x='rating', data=df, palette='flare')\n",
    "plt.title('Ratings distribution')\n",
    "for p in plt.gca().patches:\n",
    "    plt.gca().annotate('{:.0f}'.format(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "plt.show()\n",
    "\n",
    "# mean, median, and standard deviation of ratings\n",
    "print(\"Mode: \", df['rating'].mode())\n",
    "print('Median: {:.2f}'.format(df['rating'].median()))\n",
    "print('Std: {:.2f}'.format(df['rating'].std()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 8\n",
      "Nan:  0\n",
      "Duplicates:  0\n"
     ]
    }
   ],
   "source": [
    "N_LABELS = df.rating.nunique()\n",
    "print(f'Number of labels: {N_LABELS}')\n",
    "\n",
    "# looking for missing values and duplicates\n",
    "print(\"Nan: \", df.isna().sum().sum())\n",
    "print(\"Duplicates: \", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: (11052, 7)\n",
      "Number of testing samples: (2764, 7)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('rating', axis=1)\n",
    "Y = df['rating']\n",
    "\n",
    "# encode Y\n",
    "Y = LabelEncoder().fit_transform(Y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalization \n",
    "\n",
    "\n",
    "# PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# pca.fit(X_train)\n",
    "# X_train = pca.transform(X_train)\n",
    "# X_test = pca.transform(X_test)\n",
    "\n",
    "# LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, Y_train)\n",
    "X_train = lda.transform(X_train)\n",
    "X_test = lda.transform(X_test)\n",
    "\n",
    "print(f'Number of training samples: {X_train.shape}')\n",
    "print(f'Number of testing samples: {X_test.shape}')\n",
    "\n",
    "results = pd.DataFrame(columns=['Model', 'Accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.863603473227207\n"
     ]
    }
   ],
   "source": [
    "# Create the model with 100 trees\n",
    "random_forest = RandomForestClassifier(n_estimators=50,\n",
    "                                bootstrap = True,\n",
    "                                max_features = 'sqrt')\n",
    "\n",
    "# Fit on training data\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy\n",
    "accuracy = random_forest.score(X_test, Y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "results = pd.concat([results, pd.DataFrame({'Model': 'Random Forest', 'Accuracy': accuracy}, index=[0])], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8607091172214182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_classifier = LogisticRegression()\n",
    "logistic_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy\n",
    "accuracy = logistic_classifier.score(X_test, Y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "results = pd.concat([results, pd.DataFrame({'Model': 'Logistic Regression', 'Accuracy': accuracy}, index=[0])], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8418958031837916\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy\n",
    "accuracy = naive_bayes.score(X_test, Y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "results = pd.concat([results, pd.DataFrame({'Model': 'Naive Bayes', 'Accuracy': accuracy}, index=[0])], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8440665701881331\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy\n",
    "accuracy = knn.score(X_test, Y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "results = pd.concat([results, pd.DataFrame({'Model': 'KNN', 'Accuracy': accuracy}, index=[0])], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8614327062228654\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy\n",
    "accuracy = svm.score(X_test, Y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "results = pd.concat([results, pd.DataFrame({'Model': 'SVM', 'Accuracy': accuracy}, index=[0])], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 9946\n",
      "Number of validation samples: 1106\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f'Number of training samples: {X_train.shape[0]}')\n",
    "print(f'Number of validation samples: {X_val.shape[0]}')\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(Y_train, dtype=torch.long)), batch_size=batch, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(Y_val, dtype=torch.long)), batch_size= 64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(Y_test, dtype=torch.long)), batch_size= 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effective Number of Samples\n",
    "def get_weights_effective_num_of_samples(no_of_classes, beta, samples_per_cls):\n",
    "    effective_num = 1.0 - np.power(beta, samples_per_cls)\n",
    "    class_weights = (1.0 - beta) / np.array(effective_num)\n",
    "    class_weights = class_weights / np.sum(class_weights)*no_of_classes\n",
    "    return {i: w for i, w in enumerate(class_weights)}\n",
    "\n",
    "weights = get_weights_effective_num_of_samples(N_LABELS, 0.999, np.bincount(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_model(input_size, hidden_size, num_classes, dropout_prob=0, depth=1):\n",
    "    model = [\n",
    "        torch.nn.Linear(input_size, hidden_size),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(dropout_prob)\n",
    "    ]\n",
    "\n",
    "    for i in range(depth):\n",
    "        model.append(torch.nn.Linear(hidden_size, hidden_size))\n",
    "        model.append(torch.nn.ReLU())\n",
    "        model.append(torch.nn.Dropout(dropout_prob))\n",
    "\n",
    "    model.append(torch.nn.Linear(hidden_size, num_classes))\n",
    "    model.append(torch.nn.Softmax(dim=1))\n",
    "\n",
    "    return torch.nn.Sequential(*model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_sizes = [64, 128, 256]\n",
    "nums_epochs = [100]\n",
    "depth = [2, 3, 4]\n",
    "batch_sizes = [16, 32, 64, 128]\n",
    "learning_rate = [0.01]\n",
    "step_size_lr_decay = [10, 25, 50]\n",
    "momentum = [0, 0.99]\n",
    "dropout_prob = 0.2\n",
    "patience = 10\n",
    "\n",
    "hyperparameters = itertools.product(hidden_sizes, depth, nums_epochs, batch_sizes, learning_rate, step_size_lr_decay, momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training process\n",
    "def train_model(model, criterion, optimizer, scheduler, epochs, data_loader, val_loader, device, writer):\n",
    "    n_iter = 0\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_since_last_improvement = 0\n",
    " \n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        start_epoch = time.time()\n",
    "\n",
    "        for data, targets in data_loader:\n",
    "            data, targets = data.to(device), targets.to(device) \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(data)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(y_pred, targets)\n",
    "            writer.add_scalar(\"Loss/train\", loss, n_iter)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            n_iter += 1\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Compute Val Loss\n",
    "        labels, _, y_pred = test_model(model, val_loader, device)\n",
    "        val_loss = criterion(y_pred, labels)\n",
    "        writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'models/best_model.pth')\n",
    "            epochs_since_last_improvement = 0\n",
    "        else:\n",
    "            epochs_since_last_improvement += 1\n",
    "\n",
    "        if epochs_since_last_improvement >= patience:\n",
    "            break\n",
    "\n",
    "        print('Epoch [{}/{}] - {:.2f} seconds - loss: {:.4f} - val_loss: {:.4f} - patience: {}'.format(epoch+1, epochs, time.time() - start_epoch, loss.item(), val_loss.item(), epochs_since_last_improvement), end='\\r')\n",
    "        \n",
    "    print('\\nTraining ended after {:.2f} seconds'.format(time.time() - start))\n",
    "\n",
    "    # Restore best model\n",
    "    model.load_state_dict(torch.load('models/best_model.pth'))\n",
    "    return model\n",
    "\n",
    "# evaluation process\n",
    "def test_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in data_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "            y_pred.append(model(data))\n",
    "            y_test.append(targets)\n",
    "\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_test = torch.cat(y_test, dim=0)\n",
    "\n",
    "    y_pred_c = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "    return y_test, y_pred_c, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 3.27 seconds - loss: 1.6306 - val_loss: 1.4627 - patience: 2\n",
      "Training ended after 168.28 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/50] - 3.65 seconds - loss: 1.8983 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 39.58 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 3.36 seconds - loss: 1.3390 - val_loss: 1.4490 - patience: 4\n",
      "Training ended after 166.41 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/50] - 3.39 seconds - loss: 1.8246 - val_loss: 1.9479 - patience: 9\n",
      "Training ended after 41.96 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [35/50] - 3.43 seconds - loss: 1.6050 - val_loss: 1.3875 - patience: 9\n",
      "Training ended after 123.05 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/50] - 3.77 seconds - loss: 1.7432 - val_loss: 1.7661 - patience: 9\n",
      "Training ended after 39.94 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 1.79 seconds - loss: 1.3627 - val_loss: 1.4580 - patience: 0\n",
      "Training ended after 89.36 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [27/50] - 1.90 seconds - loss: 1.3037 - val_loss: 1.6630 - patience: 9\n",
      "Training ended after 52.89 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 1.79 seconds - loss: 1.4924 - val_loss: 1.3943 - patience: 0\n",
      "Training ended after 89.19 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/50] - 1.91 seconds - loss: 1.6892 - val_loss: 1.7426 - patience: 9\n",
      "Training ended after 22.65 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 1.75 seconds - loss: 1.4411 - val_loss: 1.3846 - patience: 0\n",
      "Training ended after 88.16 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [12/50] - 1.85 seconds - loss: 1.6910 - val_loss: 1.7373 - patience: 9\n",
      "Training ended after 24.17 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.92 seconds - loss: 1.7859 - val_loss: 1.7399 - patience: 0\n",
      "Training ended after 45.12 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [14/50] - 1.00 seconds - loss: 1.6668 - val_loss: 1.6189 - patience: 9\n",
      "Training ended after 14.42 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.90 seconds - loss: 1.4542 - val_loss: 1.4340 - patience: 5\n",
      "Training ended after 45.57 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [12/50] - 0.92 seconds - loss: 1.4053 - val_loss: 1.5755 - patience: 9\n",
      "Training ended after 12.34 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.93 seconds - loss: 1.4139 - val_loss: 1.4045 - patience: 0\n",
      "Training ended after 46.20 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [18/50] - 0.91 seconds - loss: 2.1721 - val_loss: 1.6578 - patience: 9\n",
      "Training ended after 18.68 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.45 seconds - loss: 2.0314 - val_loss: 2.0370 - patience: 0\n",
      "Training ended after 22.52 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [40/50] - 0.45 seconds - loss: 1.8032 - val_loss: 1.4358 - patience: 9\n",
      "Training ended after 19.04 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.41 seconds - loss: 1.7581 - val_loss: 1.6955 - patience: 0\n",
      "Training ended after 21.35 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [14/50] - 0.46 seconds - loss: 1.5465 - val_loss: 1.5631 - patience: 9\n",
      "Training ended after 6.98 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.45 seconds - loss: 1.4248 - val_loss: 1.4781 - patience: 0\n",
      "Training ended after 21.17 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [13/50] - 0.47 seconds - loss: 1.5692 - val_loss: 1.5919 - patience: 9\n",
      "Training ended after 6.71 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [70/100] - 3.13 seconds - loss: 1.3182 - val_loss: 1.4597 - patience: 9\n",
      "Training ended after 231.24 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/100] - 3.26 seconds - loss: 1.8438 - val_loss: 1.7583 - patience: 9\n",
      "Training ended after 35.23 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [41/100] - 3.20 seconds - loss: 1.3752 - val_loss: 1.4496 - patience: 9\n",
      "Training ended after 132.64 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/100] - 3.25 seconds - loss: 2.0044 - val_loss: 1.8155 - patience: 9\n",
      "Training ended after 35.53 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [49/100] - 3.09 seconds - loss: 1.4280 - val_loss: 1.4467 - patience: 9\n",
      "Training ended after 158.44 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [12/100] - 3.40 seconds - loss: 1.9005 - val_loss: 2.0131 - patience: 9\n",
      "Training ended after 43.80 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [79/100] - 1.63 seconds - loss: 1.5335 - val_loss: 1.5055 - patience: 9\n",
      "Training ended after 127.90 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/100] - 1.76 seconds - loss: 1.5176 - val_loss: 1.6349 - patience: 9\n",
      "Training ended after 19.03 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [56/100] - 1.63 seconds - loss: 1.4645 - val_loss: 1.3983 - patience: 9\n",
      "Training ended after 92.05 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/100] - 1.60 seconds - loss: 1.7782 - val_loss: 1.7501 - patience: 9\n",
      "Training ended after 19.68 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [62/100] - 1.61 seconds - loss: 1.2849 - val_loss: 1.3845 - patience: 9\n",
      "Training ended after 101.22 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/100] - 1.65 seconds - loss: 1.8590 - val_loss: 1.8988 - patience: 9\n",
      "Training ended after 17.46 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [59/100] - 0.81 seconds - loss: 1.9489 - val_loss: 1.9264 - patience: 9\n",
      "Training ended after 49.53 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/100] - 0.86 seconds - loss: 1.4812 - val_loss: 1.6148 - patience: 9\n",
      "Training ended after 10.19 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.84 seconds - loss: 1.5013 - val_loss: 1.4347 - patience: 0\n",
      "Training ended after 82.21 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/100] - 0.87 seconds - loss: 1.6342 - val_loss: 1.7461 - patience: 9\n",
      "Training ended after 10.22 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.83 seconds - loss: 1.5000 - val_loss: 1.4083 - patience: 1\n",
      "Training ended after 82.40 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/100] - 0.85 seconds - loss: 1.4882 - val_loss: 1.5414 - patience: 9\n",
      "Training ended after 9.23 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [67/100] - 0.40 seconds - loss: 2.0396 - val_loss: 1.9923 - patience: 9\n",
      "Training ended after 26.78 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [12/100] - 0.42 seconds - loss: 1.7623 - val_loss: 1.6906 - patience: 9\n",
      "Training ended after 5.65 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.40 seconds - loss: 1.8235 - val_loss: 1.7769 - patience: 0\n",
      "Training ended after 39.42 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [12/100] - 0.43 seconds - loss: 1.7040 - val_loss: 1.6968 - patience: 9\n",
      "Training ended after 5.54 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.41 seconds - loss: 1.4057 - val_loss: 1.4508 - patience: 0\n",
      "Training ended after 39.43 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [17/100] - 0.42 seconds - loss: 1.6768 - val_loss: 1.5317 - patience: 9\n",
      "Training ended after 7.73 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [38/50] - 3.27 seconds - loss: 1.3787 - val_loss: 1.5890 - patience: 9\n",
      "Training ended after 128.77 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/50] - 3.96 seconds - loss: 1.9005 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 47.34 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [48/50] - 3.19 seconds - loss: 1.5816 - val_loss: 1.4501 - patience: 9\n",
      "Training ended after 160.76 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/50] - 3.92 seconds - loss: 1.9491 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 43.20 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [46/50] - 3.33 seconds - loss: 1.7545 - val_loss: 1.5718 - patience: 9\n",
      "Training ended after 154.93 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [12/50] - 3.94 seconds - loss: 1.5105 - val_loss: 1.7598 - patience: 9\n",
      "Training ended after 51.06 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 1.71 seconds - loss: 1.8001 - val_loss: 1.8029 - patience: 0\n",
      "Training ended after 83.63 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/50] - 1.94 seconds - loss: 2.0071 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 21.75 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 1.64 seconds - loss: 1.3492 - val_loss: 1.4877 - patience: 0\n",
      "Training ended after 83.63 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [14/50] - 1.97 seconds - loss: 1.9603 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 29.80 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 1.62 seconds - loss: 1.5018 - val_loss: 1.5717 - patience: 0\n",
      "Training ended after 83.50 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/50] - 1.95 seconds - loss: 2.1142 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 21.81 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.87 seconds - loss: 2.0199 - val_loss: 1.9809 - patience: 0\n",
      "Training ended after 43.13 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [16/50] - 1.01 seconds - loss: 1.6824 - val_loss: 1.7383 - patience: 9\n",
      "Training ended after 17.36 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.87 seconds - loss: 1.6099 - val_loss: 1.5797 - patience: 0\n",
      "Training ended after 43.27 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/50] - 1.03 seconds - loss: 1.7859 - val_loss: 1.7143 - patience: 9\n",
      "Training ended after 11.22 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.83 seconds - loss: 1.6038 - val_loss: 1.5178 - patience: 0\n",
      "Training ended after 43.26 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/50] - 1.02 seconds - loss: 1.9439 - val_loss: 1.7409 - patience: 9\n",
      "Training ended after 11.17 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.42 seconds - loss: 2.0608 - val_loss: 2.0623 - patience: 0\n",
      "Training ended after 22.06 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [12/50] - 0.50 seconds - loss: 1.5113 - val_loss: 1.6114 - patience: 9\n",
      "Training ended after 6.73 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.42 seconds - loss: 2.0444 - val_loss: 1.9921 - patience: 0\n",
      "Training ended after 21.77 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [16/50] - 0.53 seconds - loss: 1.8973 - val_loss: 1.7406 - patience: 9\n",
      "Training ended after 8.78 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.45 seconds - loss: 1.7598 - val_loss: 1.7391 - patience: 0\n",
      "Training ended after 21.81 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [15/50] - 0.49 seconds - loss: 1.6317 - val_loss: 1.5446 - patience: 9\n",
      "Training ended after 8.31 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [59/100] - 3.33 seconds - loss: 1.4466 - val_loss: 1.5913 - patience: 9\n",
      "Training ended after 197.15 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [14/100] - 3.89 seconds - loss: 1.7591 - val_loss: 1.7578 - patience: 9\n",
      "Training ended after 59.01 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [34/100] - 3.27 seconds - loss: 1.8119 - val_loss: 1.5730 - patience: 9\n",
      "Training ended after 116.42 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/100] - 3.98 seconds - loss: 2.2740 - val_loss: 2.1469 - patience: 9\n",
      "Training ended after 43.96 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [56/100] - 3.33 seconds - loss: 1.9420 - val_loss: 1.5709 - patience: 9\n",
      "Training ended after 187.77 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [15/100] - 3.96 seconds - loss: 2.1700 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 62.82 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [71/100] - 1.60 seconds - loss: 2.1302 - val_loss: 1.6974 - patience: 9\n",
      "Training ended after 119.70 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [12/100] - 1.97 seconds - loss: 1.8017 - val_loss: 1.7505 - patience: 9\n",
      "Training ended after 25.66 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 1.68 seconds - loss: 1.5487 - val_loss: 1.4549 - patience: 0\n",
      "Training ended after 166.64 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/100] - 1.99 seconds - loss: 1.7429 - val_loss: 1.7484 - patience: 9\n",
      "Training ended after 21.80 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [52/100] - 1.64 seconds - loss: 1.5691 - val_loss: 1.5106 - patience: 9\n",
      "Training ended after 88.48 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/100] - 2.01 seconds - loss: 1.7295 - val_loss: 1.7447 - patience: 9\n",
      "Training ended after 22.01 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [61/100] - 0.84 seconds - loss: 2.0483 - val_loss: 2.0342 - patience: 9\n",
      "Training ended after 53.57 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [17/100] - 1.03 seconds - loss: 1.7650 - val_loss: 1.7341 - patience: 9\n",
      "Training ended after 18.46 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.87 seconds - loss: 1.3943 - val_loss: 1.6661 - patience: 0\n",
      "Training ended after 87.24 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [22/100] - 1.00 seconds - loss: 1.4661 - val_loss: 1.5157 - patience: 9\n",
      "Training ended after 23.12 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [92/100] - 0.84 seconds - loss: 1.6237 - val_loss: 1.5316 - patience: 9\n",
      "Training ended after 78.62 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [12/100] - 1.01 seconds - loss: 1.6140 - val_loss: 1.7353 - patience: 9\n",
      "Training ended after 13.11 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [59/100] - 0.42 seconds - loss: 2.0591 - val_loss: 2.0546 - patience: 9\n",
      "Training ended after 25.76 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [17/100] - 0.50 seconds - loss: 1.9854 - val_loss: 1.6603 - patience: 9\n",
      "Training ended after 9.06 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.42 seconds - loss: 1.9119 - val_loss: 1.8827 - patience: 0\n",
      "Training ended after 42.59 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [17/100] - 0.64 seconds - loss: 1.6035 - val_loss: 1.7371 - patience: 9\n",
      "Training ended after 9.54 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.50 seconds - loss: 1.9091 - val_loss: 1.6783 - patience: 0\n",
      "Training ended after 49.70 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [33/100] - 0.53 seconds - loss: 1.9506 - val_loss: 1.8776 - patience: 9\n",
      "Training ended after 18.91 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 4.13 seconds - loss: 1.5452 - val_loss: 1.7123 - patience: 0\n",
      "Training ended after 198.74 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/50] - 4.15 seconds - loss: 1.9938 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 52.35 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 3.53 seconds - loss: 1.5213 - val_loss: 1.5685 - patience: 0\n",
      "Training ended after 192.76 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/50] - 4.28 seconds - loss: 1.8218 - val_loss: 1.9495 - patience: 9\n",
      "Training ended after 47.93 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 3.72 seconds - loss: 1.3675 - val_loss: 1.4396 - patience: 2\n",
      "Training ended after 194.60 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [11/50] - 4.17 seconds - loss: 1.7953 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 54.83 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 1.87 seconds - loss: 1.8961 - val_loss: 1.8896 - patience: 0\n",
      "Training ended after 98.63 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [22/50] - 2.07 seconds - loss: 1.7653 - val_loss: 1.6330 - patience: 9\n",
      "Training ended after 47.87 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 1.96 seconds - loss: 1.5977 - val_loss: 1.5953 - patience: 0\n",
      "Training ended after 94.39 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [21/50] - 2.37 seconds - loss: 1.9283 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 49.37 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 1.97 seconds - loss: 1.4189 - val_loss: 1.4515 - patience: 1\n",
      "Training ended after 101.21 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [14/50] - 2.40 seconds - loss: 1.9814 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 35.14 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 1.04 seconds - loss: 2.0900 - val_loss: 2.0219 - patience: 0\n",
      "Training ended after 55.45 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [12/50] - 1.13 seconds - loss: 1.6250 - val_loss: 1.7530 - patience: 9\n",
      "Training ended after 15.47 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.99 seconds - loss: 1.8192 - val_loss: 1.8148 - patience: 0\n",
      "Training ended after 50.01 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [19/50] - 1.35 seconds - loss: 1.6856 - val_loss: 1.7409 - patience: 9\n",
      "Training ended after 23.95 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 1.01 seconds - loss: 1.6555 - val_loss: 1.6283 - patience: 0\n",
      "Training ended after 54.46 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [13/50] - 1.12 seconds - loss: 1.7306 - val_loss: 1.7366 - patience: 9\n",
      "Training ended after 15.75 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.52 seconds - loss: 2.0578 - val_loss: 2.0616 - patience: 1\n",
      "Training ended after 26.30 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [35/50] - 0.59 seconds - loss: 1.6256 - val_loss: 1.6187 - patience: 9\n",
      "Training ended after 21.48 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.53 seconds - loss: 2.0370 - val_loss: 2.0149 - patience: 0\n",
      "Training ended after 26.34 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [21/50] - 0.59 seconds - loss: 1.8622 - val_loss: 1.7404 - patience: 9\n",
      "Training ended after 13.18 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.52 seconds - loss: 1.8471 - val_loss: 1.8209 - patience: 0\n",
      "Training ended after 26.42 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [29/50] - 0.58 seconds - loss: 2.0032 - val_loss: 1.6347 - patience: 9\n",
      "Training ended after 17.78 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [62/100] - 3.66 seconds - loss: 1.5675 - val_loss: 1.6668 - patience: 9\n",
      "Training ended after 234.05 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [12/100] - 4.21 seconds - loss: 1.7092 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 54.84 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [32/100] - 3.67 seconds - loss: 1.5356 - val_loss: 1.5758 - patience: 9\n",
      "Training ended after 121.04 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/100] - 4.26 seconds - loss: 2.0723 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 46.58 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [51/100] - 3.47 seconds - loss: 1.6244 - val_loss: 1.6564 - patience: 9\n",
      "Training ended after 180.81 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [12/100] - 4.01 seconds - loss: 1.7953 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 52.15 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [66/100] - 1.75 seconds - loss: 1.9593 - val_loss: 1.9035 - patience: 9\n",
      "Training ended after 119.15 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [12/100] - 2.04 seconds - loss: 1.8151 - val_loss: 1.7485 - patience: 9\n",
      "Training ended after 26.44 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 1.75 seconds - loss: 1.7525 - val_loss: 1.6056 - patience: 2\n",
      "Training ended after 178.35 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/100] - 2.03 seconds - loss: 2.0433 - val_loss: 1.6616 - patience: 9\n",
      "Training ended after 24.39 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [59/100] - 1.80 seconds - loss: 1.3283 - val_loss: 1.4466 - patience: 9\n",
      "Training ended after 106.71 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [22/100] - 2.03 seconds - loss: 1.4975 - val_loss: 1.6352 - patience: 9\n",
      "Training ended after 46.80 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [61/100] - 0.95 seconds - loss: 2.0603 - val_loss: 2.0410 - patience: 9\n",
      "Training ended after 58.89 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [26/100] - 1.03 seconds - loss: 1.9116 - val_loss: 1.7367 - patience: 9\n",
      "Training ended after 28.11 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.96 seconds - loss: 1.9033 - val_loss: 1.8692 - patience: 0\n",
      "Training ended after 95.57 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [15/100] - 1.03 seconds - loss: 1.7095 - val_loss: 1.7411 - patience: 9\n",
      "Training ended after 16.71 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.98 seconds - loss: 1.5984 - val_loss: 1.6096 - patience: 0\n",
      "Training ended after 95.97 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [16/100] - 1.05 seconds - loss: 1.6577 - val_loss: 1.7964 - patience: 9\n",
      "Training ended after 17.93 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [59/100] - 0.50 seconds - loss: 2.0687 - val_loss: 2.0641 - patience: 9\n",
      "Training ended after 30.05 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [15/100] - 0.56 seconds - loss: 1.7287 - val_loss: 1.7562 - patience: 9\n",
      "Training ended after 9.04 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.50 seconds - loss: 1.9907 - val_loss: 1.9866 - patience: 0\n",
      "Training ended after 50.21 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [12/100] - 0.57 seconds - loss: 1.8992 - val_loss: 1.7397 - patience: 9\n",
      "Training ended after 7.35 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.50 seconds - loss: 1.8697 - val_loss: 1.8596 - patience: 0\n",
      "Training ended after 50.17 seconds\n",
      "\n",
      "Training with hidden_size=64, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [33/100] - 0.56 seconds - loss: 1.7767 - val_loss: 1.6345 - patience: 9\n",
      "Training ended after 19.17 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [47/50] - 3.10 seconds - loss: 1.3446 - val_loss: 1.3932 - patience: 9\n",
      "Training ended after 149.31 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [15/50] - 3.09 seconds - loss: 1.6383 - val_loss: 1.7644 - patience: 9\n",
      "Training ended after 49.70 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 3.11 seconds - loss: 1.4883 - val_loss: 1.3780 - patience: 2\n",
      "Training ended after 155.10 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/50] - 3.07 seconds - loss: 2.0768 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 37.16 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 3.09 seconds - loss: 1.3456 - val_loss: 1.4438 - patience: 8\n",
      "Training ended after 155.12 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/50] - 3.15 seconds - loss: 2.0339 - val_loss: 1.9467 - patience: 9\n",
      "Training ended after 34.60 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 1.58 seconds - loss: 1.3895 - val_loss: 1.4092 - patience: 1\n",
      "Training ended after 80.05 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/50] - 1.61 seconds - loss: 1.6580 - val_loss: 1.7437 - patience: 9\n",
      "Training ended after 19.50 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [33/50] - 1.59 seconds - loss: 1.4266 - val_loss: 1.3863 - patience: 9\n",
      "Training ended after 53.64 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/50] - 1.58 seconds - loss: 1.6726 - val_loss: 1.8708 - patience: 9\n",
      "Training ended after 19.04 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 1.57 seconds - loss: 1.4321 - val_loss: 1.3768 - patience: 7\n",
      "Training ended after 78.72 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [12/50] - 1.57 seconds - loss: 1.7985 - val_loss: 1.8585 - patience: 9\n",
      "Training ended after 20.62 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.70 seconds - loss: 1.6712 - val_loss: 1.6459 - patience: 0\n",
      "Training ended after 35.09 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/50] - 0.79 seconds - loss: 2.1524 - val_loss: 1.6522 - patience: 9\n",
      "Training ended after 8.74 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [42/50] - 0.70 seconds - loss: 1.5104 - val_loss: 1.4054 - patience: 9\n",
      "Training ended after 29.99 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [15/50] - 0.79 seconds - loss: 1.4646 - val_loss: 1.5493 - patience: 9\n",
      "Training ended after 12.67 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.69 seconds - loss: 1.4185 - val_loss: 1.3875 - patience: 0\n",
      "Training ended after 35.15 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/50] - 0.78 seconds - loss: 1.5553 - val_loss: 1.5822 - patience: 9\n",
      "Training ended after 8.78 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.38 seconds - loss: 1.9310 - val_loss: 1.9564 - patience: 0\n",
      "Training ended after 19.49 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [21/50] - 0.42 seconds - loss: 1.5451 - val_loss: 1.4612 - patience: 9\n",
      "Training ended after 9.42 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.38 seconds - loss: 1.6018 - val_loss: 1.4801 - patience: 0\n",
      "Training ended after 19.47 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [20/50] - 0.42 seconds - loss: 1.8619 - val_loss: 1.5384 - patience: 9\n",
      "Training ended after 8.93 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.38 seconds - loss: 1.4207 - val_loss: 1.4160 - patience: 0\n",
      "Training ended after 19.35 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [20/50] - 0.42 seconds - loss: 1.5274 - val_loss: 1.5449 - patience: 9\n",
      "Training ended after 8.90 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [58/100] - 3.09 seconds - loss: 1.5058 - val_loss: 1.4535 - patience: 9\n",
      "Training ended after 183.11 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [13/100] - 3.13 seconds - loss: 1.3953 - val_loss: 1.7494 - patience: 9\n",
      "Training ended after 43.99 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [57/100] - 3.12 seconds - loss: 1.2950 - val_loss: 1.4450 - patience: 9\n",
      "Training ended after 180.98 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [13/100] - 3.12 seconds - loss: 1.5978 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 43.35 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [43/100] - 3.11 seconds - loss: 1.5441 - val_loss: 1.5038 - patience: 9\n",
      "Training ended after 136.48 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/100] - 3.08 seconds - loss: 1.7731 - val_loss: 1.8791 - patience: 9\n",
      "Training ended after 34.11 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [60/100] - 1.57 seconds - loss: 1.3127 - val_loss: 1.4096 - patience: 9\n",
      "Training ended after 96.17 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [29/100] - 1.57 seconds - loss: 1.7601 - val_loss: 1.6338 - patience: 9\n",
      "Training ended after 47.57 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [71/100] - 1.57 seconds - loss: 1.3824 - val_loss: 1.3846 - patience: 9\n",
      "Training ended after 113.40 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/100] - 1.61 seconds - loss: 1.7724 - val_loss: 1.8800 - patience: 9\n",
      "Training ended after 17.82 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [67/100] - 1.57 seconds - loss: 1.3626 - val_loss: 1.3782 - patience: 9\n",
      "Training ended after 107.60 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [16/100] - 1.61 seconds - loss: 1.6929 - val_loss: 1.7447 - patience: 9\n",
      "Training ended after 27.50 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [59/100] - 0.70 seconds - loss: 1.5560 - val_loss: 1.5967 - patience: 9\n",
      "Training ended after 42.68 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/100] - 0.80 seconds - loss: 1.5179 - val_loss: 1.7038 - patience: 9\n",
      "Training ended after 8.87 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [58/100] - 0.70 seconds - loss: 1.3840 - val_loss: 1.4106 - patience: 9\n",
      "Training ended after 41.94 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/100] - 0.79 seconds - loss: 1.4777 - val_loss: 1.6493 - patience: 9\n",
      "Training ended after 9.56 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.70 seconds - loss: 1.4360 - val_loss: 1.3870 - patience: 1\n",
      "Training ended after 69.82 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [14/100] - 0.80 seconds - loss: 1.7923 - val_loss: 1.6606 - patience: 9\n",
      "Training ended after 11.93 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [60/100] - 0.38 seconds - loss: 1.6583 - val_loss: 1.9811 - patience: 9\n",
      "Training ended after 23.68 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [29/100] - 0.43 seconds - loss: 1.5080 - val_loss: 1.5343 - patience: 9\n",
      "Training ended after 12.78 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.38 seconds - loss: 1.5272 - val_loss: 1.5616 - patience: 0\n",
      "Training ended after 38.79 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [13/100] - 0.42 seconds - loss: 1.7776 - val_loss: 1.6381 - patience: 9\n",
      "Training ended after 5.98 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [58/100] - 0.38 seconds - loss: 1.3529 - val_loss: 1.4183 - patience: 9\n",
      "Training ended after 22.86 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [21/100] - 0.44 seconds - loss: 1.4246 - val_loss: 1.4715 - patience: 9\n",
      "Training ended after 9.36 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [33/50] - 3.24 seconds - loss: 1.3983 - val_loss: 1.5775 - patience: 9\n",
      "Training ended after 109.98 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [15/50] - 3.80 seconds - loss: 2.1068 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 60.86 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [31/50] - 3.27 seconds - loss: 1.9979 - val_loss: 1.5742 - patience: 9\n",
      "Training ended after 103.71 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [13/50] - 3.83 seconds - loss: 1.9443 - val_loss: 1.7688 - patience: 9\n",
      "Training ended after 53.58 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [37/50] - 3.28 seconds - loss: 1.4264 - val_loss: 1.5754 - patience: 9\n",
      "Training ended after 123.88 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [11/50] - 3.85 seconds - loss: 1.8296 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 46.14 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 1.62 seconds - loss: 1.6628 - val_loss: 1.6955 - patience: 0\n",
      "Training ended after 81.55 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/50] - 1.91 seconds - loss: 1.7152 - val_loss: 1.7645 - patience: 9\n",
      "Training ended after 21.13 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 1.61 seconds - loss: 1.4943 - val_loss: 1.5273 - patience: 2\n",
      "Training ended after 81.26 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/50] - 1.92 seconds - loss: 2.2306 - val_loss: 1.8791 - patience: 9\n",
      "Training ended after 21.19 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 1.62 seconds - loss: 1.4765 - val_loss: 1.5025 - patience: 2\n",
      "Training ended after 81.33 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [15/50] - 1.91 seconds - loss: 1.6955 - val_loss: 1.7548 - patience: 9\n",
      "Training ended after 30.91 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.83 seconds - loss: 1.9763 - val_loss: 1.8361 - patience: 0\n",
      "Training ended after 41.62 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/50] - 0.94 seconds - loss: 1.8179 - val_loss: 1.7539 - patience: 9\n",
      "Training ended after 11.36 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.83 seconds - loss: 1.4178 - val_loss: 1.4292 - patience: 0\n",
      "Training ended after 41.75 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [13/50] - 0.97 seconds - loss: 1.9141 - val_loss: 1.7518 - patience: 9\n",
      "Training ended after 13.34 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.85 seconds - loss: 1.4497 - val_loss: 1.3954 - patience: 0\n",
      "Training ended after 41.97 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [49/50] - 0.95 seconds - loss: 1.6364 - val_loss: 1.6284 - patience: 9\n",
      "Training ended after 47.82 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.43 seconds - loss: 2.0666 - val_loss: 2.0595 - patience: 1\n",
      "Training ended after 22.03 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [17/50] - 0.50 seconds - loss: 1.5581 - val_loss: 1.6368 - patience: 9\n",
      "Training ended after 9.14 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.44 seconds - loss: 1.7965 - val_loss: 1.8509 - patience: 0\n",
      "Training ended after 21.92 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [36/50] - 0.51 seconds - loss: 1.5604 - val_loss: 1.6255 - patience: 9\n",
      "Training ended after 18.78 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.44 seconds - loss: 1.7184 - val_loss: 1.6605 - patience: 0\n",
      "Training ended after 21.95 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [17/50] - 0.51 seconds - loss: 1.6631 - val_loss: 1.6548 - patience: 9\n",
      "Training ended after 9.13 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [69/100] - 3.23 seconds - loss: 1.3439 - val_loss: 1.4537 - patience: 9\n",
      "Training ended after 226.39 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/100] - 3.83 seconds - loss: 1.6636 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 45.85 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [32/100] - 3.21 seconds - loss: 1.6343 - val_loss: 1.5739 - patience: 9\n",
      "Training ended after 106.59 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/100] - 3.80 seconds - loss: 1.7308 - val_loss: 1.7867 - patience: 9\n",
      "Training ended after 45.51 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [43/100] - 3.24 seconds - loss: 1.2864 - val_loss: 1.4429 - patience: 9\n",
      "Training ended after 142.81 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [13/100] - 3.81 seconds - loss: 2.2427 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 53.56 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [66/100] - 1.63 seconds - loss: 1.5496 - val_loss: 1.5897 - patience: 9\n",
      "Training ended after 109.88 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/100] - 1.95 seconds - loss: 1.5995 - val_loss: 1.7407 - patience: 9\n",
      "Training ended after 23.27 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [34/100] - 1.61 seconds - loss: 1.3789 - val_loss: 1.4533 - patience: 9\n",
      "Training ended after 56.92 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/100] - 1.92 seconds - loss: 1.7968 - val_loss: 1.7569 - patience: 9\n",
      "Training ended after 21.14 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [69/100] - 1.62 seconds - loss: 1.5574 - val_loss: 1.5024 - patience: 9\n",
      "Training ended after 113.64 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [12/100] - 1.92 seconds - loss: 1.6796 - val_loss: 1.7586 - patience: 9\n",
      "Training ended after 24.99 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [72/100] - 0.82 seconds - loss: 1.6319 - val_loss: 1.9117 - patience: 9\n",
      "Training ended after 60.47 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/100] - 0.94 seconds - loss: 1.9850 - val_loss: 1.7411 - patience: 9\n",
      "Training ended after 11.34 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.83 seconds - loss: 1.5421 - val_loss: 1.4345 - patience: 0\n",
      "Training ended after 82.95 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [13/100] - 0.95 seconds - loss: 1.6042 - val_loss: 1.6442 - patience: 9\n",
      "Training ended after 13.45 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [62/100] - 0.83 seconds - loss: 1.3522 - val_loss: 1.4595 - patience: 9\n",
      "Training ended after 52.75 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [11/100] - 0.96 seconds - loss: 2.2740 - val_loss: 2.1996 - patience: 9\n",
      "Training ended after 11.46 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [59/100] - 0.43 seconds - loss: 2.0586 - val_loss: 2.0551 - patience: 9\n",
      "Training ended after 26.20 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [16/100] - 0.50 seconds - loss: 2.0249 - val_loss: 1.6603 - patience: 9\n",
      "Training ended after 8.63 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.44 seconds - loss: 1.7772 - val_loss: 1.8582 - patience: 0\n",
      "Training ended after 43.80 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [28/100] - 0.52 seconds - loss: 1.3946 - val_loss: 1.5218 - patience: 9\n",
      "Training ended after 14.72 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.43 seconds - loss: 1.5047 - val_loss: 1.4448 - patience: 0\n",
      "Training ended after 43.85 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [14/100] - 0.51 seconds - loss: 1.7079 - val_loss: 1.7410 - patience: 9\n",
      "Training ended after 7.61 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [37/50] - 3.57 seconds - loss: 1.6382 - val_loss: 1.5884 - patience: 9\n",
      "Training ended after 133.90 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [16/50] - 4.07 seconds - loss: 1.9142 - val_loss: 1.9760 - patience: 9\n",
      "Training ended after 69.62 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [35/50] - 3.49 seconds - loss: 1.4680 - val_loss: 1.5691 - patience: 9\n",
      "Training ended after 126.17 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/50] - 4.11 seconds - loss: 1.7953 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 45.16 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 3.55 seconds - loss: 1.4702 - val_loss: 1.4523 - patience: 0\n",
      "Training ended after 178.25 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/50] - 4.17 seconds - loss: 2.0107 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 45.76 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 1.89 seconds - loss: 1.7732 - val_loss: 1.8401 - patience: 0\n",
      "Training ended after 95.38 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/50] - 2.21 seconds - loss: 1.8468 - val_loss: 1.7885 - patience: 9\n",
      "Training ended after 26.29 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 1.87 seconds - loss: 1.5784 - val_loss: 1.5838 - patience: 0\n",
      "Training ended after 94.50 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [13/50] - 2.18 seconds - loss: 1.9496 - val_loss: 1.8267 - patience: 9\n",
      "Training ended after 30.16 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 1.87 seconds - loss: 1.4580 - val_loss: 1.5693 - patience: 3\n",
      "Training ended after 94.30 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [11/50] - 2.15 seconds - loss: 1.6841 - val_loss: 1.7414 - patience: 9\n",
      "Training ended after 25.84 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.89 seconds - loss: 2.0479 - val_loss: 2.0335 - patience: 0\n",
      "Training ended after 45.19 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [23/50] - 1.06 seconds - loss: 1.8876 - val_loss: 1.7415 - patience: 9\n",
      "Training ended after 25.69 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.91 seconds - loss: 1.9118 - val_loss: 1.7356 - patience: 0\n",
      "Training ended after 45.46 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/50] - 1.11 seconds - loss: 1.9300 - val_loss: 1.7455 - patience: 9\n",
      "Training ended after 13.05 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.91 seconds - loss: 1.5869 - val_loss: 1.5224 - patience: 0\n",
      "Training ended after 45.79 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [12/50] - 1.11 seconds - loss: 1.6122 - val_loss: 1.7460 - patience: 9\n",
      "Training ended after 14.26 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.50 seconds - loss: 2.0644 - val_loss: 2.0639 - patience: 1\n",
      "Training ended after 25.51 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [27/50] - 0.58 seconds - loss: 1.6003 - val_loss: 1.6562 - patience: 9\n",
      "Training ended after 16.33 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.52 seconds - loss: 2.0239 - val_loss: 2.0317 - patience: 0\n",
      "Training ended after 25.62 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [31/50] - 0.58 seconds - loss: 1.5448 - val_loss: 1.6577 - patience: 9\n",
      "Training ended after 18.63 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.51 seconds - loss: 1.8532 - val_loss: 1.7988 - patience: 0\n",
      "Training ended after 25.61 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [15/50] - 0.58 seconds - loss: 1.9019 - val_loss: 1.7350 - patience: 9\n",
      "Training ended after 9.35 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [17/100] - 3.50 seconds - loss: 1.4453 - val_loss: 1.6364 - patience: 9\n",
      "Training ended after 64.02 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/100] - 4.13 seconds - loss: 1.7100 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 49.45 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [34/100] - 3.50 seconds - loss: 2.1508 - val_loss: 1.5709 - patience: 9\n",
      "Training ended after 122.64 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [16/100] - 4.10 seconds - loss: 1.9802 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 69.86 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [59/100] - 3.51 seconds - loss: 1.5246 - val_loss: 1.5685 - patience: 9\n",
      "Training ended after 212.75 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [16/100] - 4.22 seconds - loss: 2.0022 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 70.99 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [71/100] - 1.88 seconds - loss: 1.9389 - val_loss: 1.8512 - patience: 9\n",
      "Training ended after 137.33 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [24/100] - 2.18 seconds - loss: 1.7888 - val_loss: 1.7411 - patience: 9\n",
      "Training ended after 54.23 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [57/100] - 1.89 seconds - loss: 1.7681 - val_loss: 1.5811 - patience: 9\n",
      "Training ended after 109.56 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [17/100] - 2.17 seconds - loss: 2.0116 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 38.81 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [59/100] - 1.89 seconds - loss: 1.4579 - val_loss: 1.4446 - patience: 9\n",
      "Training ended after 113.09 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [11/100] - 2.17 seconds - loss: 1.7479 - val_loss: 1.7789 - patience: 9\n",
      "Training ended after 25.82 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [59/100] - 0.91 seconds - loss: 2.0419 - val_loss: 2.0309 - patience: 9\n",
      "Training ended after 55.10 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/100] - 1.09 seconds - loss: 2.1219 - val_loss: 1.7524 - patience: 9\n",
      "Training ended after 13.11 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.92 seconds - loss: 1.8104 - val_loss: 1.7654 - patience: 0\n",
      "Training ended after 91.72 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [19/100] - 1.09 seconds - loss: 1.7700 - val_loss: 1.7465 - patience: 9\n",
      "Training ended after 21.85 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.92 seconds - loss: 1.4813 - val_loss: 1.5723 - patience: 0\n",
      "Training ended after 91.57 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [12/100] - 1.09 seconds - loss: 1.7576 - val_loss: 1.7418 - patience: 9\n",
      "Training ended after 14.20 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [59/100] - 0.52 seconds - loss: 2.0579 - val_loss: 2.0604 - patience: 9\n",
      "Training ended after 30.60 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [26/100] - 0.57 seconds - loss: 1.6449 - val_loss: 1.5270 - patience: 9\n",
      "Training ended after 15.59 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.52 seconds - loss: 2.0011 - val_loss: 2.0084 - patience: 0\n",
      "Training ended after 50.42 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [18/100] - 0.57 seconds - loss: 1.6093 - val_loss: 1.6316 - patience: 9\n",
      "Training ended after 10.99 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.50 seconds - loss: 1.6681 - val_loss: 1.6295 - patience: 0\n",
      "Training ended after 50.87 seconds\n",
      "\n",
      "Training with hidden_size=128, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [22/100] - 0.58 seconds - loss: 1.7672 - val_loss: 1.7534 - patience: 9\n",
      "Training ended after 13.31 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [26/50] - 2.86 seconds - loss: 1.4124 - val_loss: 1.3863 - patience: 9\n",
      "Training ended after 77.49 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [42/50] - 3.19 seconds - loss: 1.8354 - val_loss: 1.7344 - patience: 9\n",
      "Training ended after 141.71 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [28/50] - 2.81 seconds - loss: 1.3453 - val_loss: 1.3785 - patience: 9\n",
      "Training ended after 81.98 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/50] - 3.21 seconds - loss: 1.8016 - val_loss: 1.8253 - patience: 9\n",
      "Training ended after 35.79 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 2.84 seconds - loss: 1.2828 - val_loss: 1.4425 - patience: 0\n",
      "Training ended after 142.50 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [11/50] - 3.37 seconds - loss: 1.8104 - val_loss: 1.7781 - patience: 9\n",
      "Training ended after 40.16 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 1.36 seconds - loss: 1.5019 - val_loss: 1.3995 - patience: 0\n",
      "Training ended after 66.74 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [13/50] - 1.57 seconds - loss: 2.0692 - val_loss: 1.8809 - patience: 9\n",
      "Training ended after 22.10 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 1.32 seconds - loss: 1.3904 - val_loss: 1.4532 - patience: 0\n",
      "Training ended after 66.01 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/50] - 1.56 seconds - loss: 1.5799 - val_loss: 1.7223 - patience: 9\n",
      "Training ended after 17.29 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 1.29 seconds - loss: 1.3858 - val_loss: 1.3771 - patience: 3\n",
      "Training ended after 65.32 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/50] - 1.55 seconds - loss: 1.8816 - val_loss: 1.8733 - patience: 9\n",
      "Training ended after 17.22 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.69 seconds - loss: 1.4315 - val_loss: 1.4429 - patience: 0\n",
      "Training ended after 34.65 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/50] - 0.81 seconds - loss: 1.6766 - val_loss: 1.7381 - patience: 9\n",
      "Training ended after 9.82 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.70 seconds - loss: 1.4186 - val_loss: 1.3965 - patience: 0\n",
      "Training ended after 34.63 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [12/50] - 0.81 seconds - loss: 1.4679 - val_loss: 1.6194 - patience: 9\n",
      "Training ended after 10.61 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.69 seconds - loss: 1.3511 - val_loss: 1.3881 - patience: 0\n",
      "Training ended after 34.59 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [21/50] - 0.82 seconds - loss: 1.4530 - val_loss: 1.6368 - patience: 9\n",
      "Training ended after 17.96 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.38 seconds - loss: 1.8449 - val_loss: 1.8155 - patience: 0\n",
      "Training ended after 19.36 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/50] - 0.43 seconds - loss: 1.6319 - val_loss: 1.5889 - patience: 9\n",
      "Training ended after 4.79 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.38 seconds - loss: 1.4452 - val_loss: 1.4301 - patience: 0\n",
      "Training ended after 19.19 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [14/50] - 0.43 seconds - loss: 1.7413 - val_loss: 1.6763 - patience: 9\n",
      "Training ended after 6.50 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.38 seconds - loss: 1.3706 - val_loss: 1.4051 - patience: 3\n",
      "Training ended after 19.19 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [20/50] - 0.45 seconds - loss: 1.6545 - val_loss: 1.6028 - patience: 9\n",
      "Training ended after 9.13 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [68/100] - 2.87 seconds - loss: 1.4722 - val_loss: 1.4545 - patience: 9\n",
      "Training ended after 195.79 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/100] - 3.32 seconds - loss: 2.1514 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 36.65 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [32/100] - 2.85 seconds - loss: 1.3709 - val_loss: 1.4465 - patience: 9\n",
      "Training ended after 94.45 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [12/100] - 3.34 seconds - loss: 2.0867 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 43.44 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [63/100] - 2.84 seconds - loss: 1.4015 - val_loss: 1.4419 - patience: 9\n",
      "Training ended after 181.29 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/100] - 3.22 seconds - loss: 2.1348 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 35.69 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [22/100] - 1.31 seconds - loss: 1.5643 - val_loss: 1.4538 - patience: 9\n",
      "Training ended after 30.14 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/100] - 1.59 seconds - loss: 1.6076 - val_loss: 1.7383 - patience: 9\n",
      "Training ended after 17.21 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [45/100] - 1.31 seconds - loss: 1.4440 - val_loss: 1.3843 - patience: 9\n",
      "Training ended after 60.25 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [14/100] - 1.55 seconds - loss: 1.5073 - val_loss: 1.6554 - patience: 9\n",
      "Training ended after 23.43 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [87/100] - 1.31 seconds - loss: 1.3693 - val_loss: 1.3741 - patience: 9\n",
      "Training ended after 115.94 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [12/100] - 1.57 seconds - loss: 1.7460 - val_loss: 1.7880 - patience: 9\n",
      "Training ended after 20.51 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [59/100] - 0.70 seconds - loss: 1.4132 - val_loss: 1.4469 - patience: 9\n",
      "Training ended after 41.89 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/100] - 0.81 seconds - loss: 1.9003 - val_loss: 1.6652 - patience: 9\n",
      "Training ended after 9.81 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [58/100] - 0.69 seconds - loss: 1.4019 - val_loss: 1.3995 - patience: 9\n",
      "Training ended after 41.13 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/100] - 0.81 seconds - loss: 1.6416 - val_loss: 1.6035 - patience: 9\n",
      "Training ended after 9.02 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [59/100] - 0.70 seconds - loss: 1.3982 - val_loss: 1.3863 - patience: 9\n",
      "Training ended after 41.76 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/100] - 0.81 seconds - loss: 1.6407 - val_loss: 1.6377 - patience: 9\n",
      "Training ended after 9.03 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [59/100] - 0.38 seconds - loss: 2.0722 - val_loss: 1.8200 - patience: 9\n",
      "Training ended after 23.23 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [16/100] - 0.44 seconds - loss: 1.4629 - val_loss: 1.5195 - patience: 9\n",
      "Training ended after 7.41 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.38 seconds - loss: 1.4642 - val_loss: 1.4307 - patience: 0\n",
      "Training ended after 38.73 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [12/100] - 0.43 seconds - loss: 1.7337 - val_loss: 1.6388 - patience: 9\n",
      "Training ended after 5.67 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.38 seconds - loss: 1.3969 - val_loss: 1.3977 - patience: 0\n",
      "Training ended after 38.24 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=2, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [22/100] - 0.43 seconds - loss: 1.9221 - val_loss: 1.4719 - patience: 9\n",
      "Training ended after 9.98 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [26/50] - 3.22 seconds - loss: 1.2774 - val_loss: 1.4498 - patience: 9\n",
      "Training ended after 85.92 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/50] - 3.81 seconds - loss: 1.9234 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 41.76 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [37/50] - 3.19 seconds - loss: 1.9473 - val_loss: 1.5737 - patience: 9\n",
      "Training ended after 120.67 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [13/50] - 3.79 seconds - loss: 1.9082 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 53.23 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [43/50] - 3.19 seconds - loss: 1.3934 - val_loss: 1.4440 - patience: 9\n",
      "Training ended after 141.69 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [12/50] - 3.85 seconds - loss: 2.0503 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 50.08 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 1.60 seconds - loss: 1.4135 - val_loss: 1.4068 - patience: 0\n",
      "Training ended after 79.48 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/50] - 1.88 seconds - loss: 2.0601 - val_loss: 1.9256 - patience: 9\n",
      "Training ended after 20.76 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [40/50] - 1.59 seconds - loss: 1.3492 - val_loss: 1.3858 - patience: 9\n",
      "Training ended after 65.11 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/50] - 1.88 seconds - loss: 1.8453 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 20.64 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [41/50] - 1.56 seconds - loss: 1.3572 - val_loss: 1.5035 - patience: 9\n",
      "Training ended after 66.33 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [11/50] - 1.86 seconds - loss: 1.9234 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 22.46 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.83 seconds - loss: 1.6438 - val_loss: 1.6465 - patience: 0\n",
      "Training ended after 41.29 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/50] - 0.96 seconds - loss: 1.6926 - val_loss: 1.8252 - patience: 9\n",
      "Training ended after 10.69 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.82 seconds - loss: 1.6003 - val_loss: 1.5227 - patience: 0\n",
      "Training ended after 41.25 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/50] - 0.96 seconds - loss: 1.8763 - val_loss: 1.8800 - patience: 9\n",
      "Training ended after 10.64 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.82 seconds - loss: 1.3713 - val_loss: 1.3859 - patience: 0\n",
      "Training ended after 41.21 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [15/50] - 0.96 seconds - loss: 1.6782 - val_loss: 1.6810 - patience: 9\n",
      "Training ended after 15.50 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.44 seconds - loss: 2.0372 - val_loss: 2.0364 - patience: 0\n",
      "Training ended after 22.22 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/50] - 0.52 seconds - loss: 1.4935 - val_loss: 1.5966 - patience: 9\n",
      "Training ended after 6.11 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.44 seconds - loss: 1.7090 - val_loss: 1.6721 - patience: 0\n",
      "Training ended after 22.23 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/50] - 0.50 seconds - loss: 1.8854 - val_loss: 1.6630 - patience: 9\n",
      "Training ended after 6.15 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.44 seconds - loss: 1.4356 - val_loss: 1.4240 - patience: 3\n",
      "Training ended after 22.32 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [15/50] - 0.51 seconds - loss: 1.5243 - val_loss: 1.5590 - patience: 9\n",
      "Training ended after 8.18 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [28/100] - 3.27 seconds - loss: 1.2873 - val_loss: 1.5744 - patience: 9\n",
      "Training ended after 94.12 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [15/100] - 3.78 seconds - loss: 1.6922 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 61.65 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [34/100] - 3.29 seconds - loss: 1.8890 - val_loss: 1.4453 - patience: 9\n",
      "Training ended after 113.05 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/100] - 3.84 seconds - loss: 2.1366 - val_loss: 2.1469 - patience: 9\n",
      "Training ended after 42.40 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [69/100] - 3.16 seconds - loss: 1.2745 - val_loss: 1.4389 - patience: 9\n",
      "Training ended after 222.92 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/100] - 3.83 seconds - loss: 1.9229 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 42.19 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [61/100] - 1.58 seconds - loss: 1.3390 - val_loss: 1.4184 - patience: 9\n",
      "Training ended after 98.44 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/100] - 1.90 seconds - loss: 1.6866 - val_loss: 1.7465 - patience: 9\n",
      "Training ended after 20.82 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/100] - 1.58 seconds - loss: 1.5385 - val_loss: 1.5069 - patience: 9\n",
      "Training ended after 81.07 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/100] - 1.90 seconds - loss: 1.9063 - val_loss: 1.8245 - patience: 9\n",
      "Training ended after 22.70 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [51/100] - 1.59 seconds - loss: 1.3729 - val_loss: 1.3781 - patience: 9\n",
      "Training ended after 82.75 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/100] - 1.88 seconds - loss: 1.8125 - val_loss: 1.7468 - patience: 9\n",
      "Training ended after 20.73 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [68/100] - 0.84 seconds - loss: 1.8000 - val_loss: 1.7927 - patience: 9\n",
      "Training ended after 57.57 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [15/100] - 0.99 seconds - loss: 1.5876 - val_loss: 1.6342 - patience: 9\n",
      "Training ended after 15.70 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [59/100] - 0.82 seconds - loss: 1.4836 - val_loss: 1.5184 - patience: 9\n",
      "Training ended after 49.58 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/100] - 0.97 seconds - loss: 1.6323 - val_loss: 1.7279 - patience: 9\n",
      "Training ended after 10.68 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [88/100] - 0.83 seconds - loss: 1.4293 - val_loss: 1.5083 - patience: 9\n",
      "Training ended after 73.35 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [15/100] - 0.97 seconds - loss: 1.6138 - val_loss: 1.6747 - patience: 9\n",
      "Training ended after 15.52 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [59/100] - 0.44 seconds - loss: 2.0515 - val_loss: 2.0453 - patience: 9\n",
      "Training ended after 26.70 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [12/100] - 0.50 seconds - loss: 1.6595 - val_loss: 1.8260 - patience: 9\n",
      "Training ended after 6.63 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.44 seconds - loss: 1.5590 - val_loss: 1.5397 - patience: 0\n",
      "Training ended after 44.47 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [14/100] - 0.51 seconds - loss: 1.6580 - val_loss: 1.6921 - patience: 9\n",
      "Training ended after 7.61 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.44 seconds - loss: 1.4070 - val_loss: 1.4065 - patience: 1\n",
      "Training ended after 44.46 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=3, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [26/100] - 0.51 seconds - loss: 1.5979 - val_loss: 1.6498 - patience: 9\n",
      "Training ended after 13.72 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [35/50] - 3.63 seconds - loss: 1.2758 - val_loss: 1.6338 - patience: 9\n",
      "Training ended after 130.83 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [14/50] - 4.32 seconds - loss: 1.8102 - val_loss: 2.0285 - patience: 9\n",
      "Training ended after 64.73 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [40/50] - 3.64 seconds - loss: 1.5825 - val_loss: 1.5713 - patience: 9\n",
      "Training ended after 149.14 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/50] - 4.30 seconds - loss: 2.0888 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 47.34 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [31/50] - 3.62 seconds - loss: 1.3986 - val_loss: 1.5755 - patience: 9\n",
      "Training ended after 115.69 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/50] - 4.27 seconds - loss: 2.0902 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 47.20 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 1.81 seconds - loss: 1.7769 - val_loss: 1.7503 - patience: 0\n",
      "Training ended after 91.26 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [10/50] - 2.16 seconds - loss: 1.8304 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 23.71 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 1.84 seconds - loss: 1.5640 - val_loss: 1.5742 - patience: 0\n",
      "Training ended after 92.11 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [12/50] - 2.20 seconds - loss: 2.0092 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 28.72 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 1.84 seconds - loss: 1.5885 - val_loss: 1.5693 - patience: 2\n",
      "Training ended after 92.64 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [11/50] - 2.19 seconds - loss: 1.9469 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 26.30 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.95 seconds - loss: 1.9932 - val_loss: 2.0223 - patience: 0\n",
      "Training ended after 47.19 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [13/50] - 1.10 seconds - loss: 1.8132 - val_loss: 1.7300 - patience: 9\n",
      "Training ended after 15.57 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.94 seconds - loss: 1.6952 - val_loss: 1.5873 - patience: 0\n",
      "Training ended after 47.12 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/50] - 1.10 seconds - loss: 1.7227 - val_loss: 1.7359 - patience: 9\n",
      "Training ended after 12.16 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.93 seconds - loss: 1.5223 - val_loss: 1.5768 - patience: 1\n",
      "Training ended after 46.79 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [11/50] - 1.10 seconds - loss: 1.6818 - val_loss: 1.6408 - patience: 9\n",
      "Training ended after 13.30 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [50/50] - 0.50 seconds - loss: 2.0812 - val_loss: 2.0610 - patience: 0\n",
      "Training ended after 25.09 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [27/50] - 0.57 seconds - loss: 1.6374 - val_loss: 1.7334 - patience: 9\n",
      "Training ended after 16.15 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [50/50] - 0.50 seconds - loss: 1.9691 - val_loss: 1.9960 - patience: 0\n",
      "Training ended after 25.12 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [30/50] - 0.57 seconds - loss: 1.6946 - val_loss: 1.6316 - patience: 9\n",
      "Training ended after 17.87 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [50/50] - 0.51 seconds - loss: 1.7720 - val_loss: 1.7145 - patience: 0\n",
      "Training ended after 25.06 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=50, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [17/50] - 0.57 seconds - loss: 1.7546 - val_loss: 1.7365 - patience: 9\n",
      "Training ended after 10.37 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [31/100] - 3.60 seconds - loss: 1.4900 - val_loss: 1.5782 - patience: 9\n",
      "Training ended after 115.78 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [12/100] - 4.30 seconds - loss: 1.7215 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 55.92 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [34/100] - 3.64 seconds - loss: 1.9196 - val_loss: 1.5698 - patience: 9\n",
      "Training ended after 127.44 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [10/100] - 4.31 seconds - loss: 2.0510 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 47.58 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [38/100] - 3.63 seconds - loss: 1.2759 - val_loss: 1.5743 - patience: 9\n",
      "Training ended after 141.93 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=16, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/100] - 4.29 seconds - loss: 2.2082 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 47.29 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [76/100] - 1.81 seconds - loss: 1.5566 - val_loss: 1.6987 - patience: 9\n",
      "Training ended after 140.61 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [31/100] - 2.15 seconds - loss: 1.6285 - val_loss: 1.7583 - patience: 9\n",
      "Training ended after 69.19 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [53/100] - 1.86 seconds - loss: 1.7318 - val_loss: 1.5727 - patience: 9\n",
      "Training ended after 98.85 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [20/100] - 2.18 seconds - loss: 1.9709 - val_loss: 1.9509 - patience: 9\n",
      "Training ended after 45.93 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [58/100] - 1.85 seconds - loss: 2.0468 - val_loss: 1.5690 - patience: 9\n",
      "Training ended after 109.06 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=32, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [10/100] - 2.17 seconds - loss: 1.8675 - val_loss: 2.0292 - patience: 9\n",
      "Training ended after 24.08 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [70/100] - 0.96 seconds - loss: 1.9664 - val_loss: 1.9410 - patience: 9\n",
      "Training ended after 66.89 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [11/100] - 1.12 seconds - loss: 2.1411 - val_loss: 1.7841 - patience: 9\n",
      "Training ended after 13.39 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.93 seconds - loss: 1.3850 - val_loss: 1.5578 - patience: 0\n",
      "Training ended after 94.36 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [11/100] - 1.10 seconds - loss: 1.7940 - val_loss: 1.7450 - patience: 9\n",
      "Training ended after 13.26 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.93 seconds - loss: 1.5590 - val_loss: 1.5088 - patience: 0\n",
      "Training ended after 93.40 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=64, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [22/100] - 1.10 seconds - loss: 1.8072 - val_loss: 1.7427 - patience: 9\n",
      "Training ended after 25.40 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0\n",
      "Epoch [59/100] - 0.49 seconds - loss: 2.0672 - val_loss: 2.0629 - patience: 9\n",
      "Training ended after 30.03 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=10, momentum=0.99\n",
      "Epoch [18/100] - 0.58 seconds - loss: 1.8965 - val_loss: 1.6646 - patience: 9\n",
      "Training ended after 10.95 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0\n",
      "Epoch [100/100] - 0.51 seconds - loss: 1.9492 - val_loss: 1.9536 - patience: 0\n",
      "Training ended after 50.19 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=25, momentum=0.99\n",
      "Epoch [31/100] - 0.58 seconds - loss: 1.4965 - val_loss: 1.5883 - patience: 9\n",
      "Training ended after 18.44 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0\n",
      "Epoch [100/100] - 0.51 seconds - loss: 1.6978 - val_loss: 1.6085 - patience: 0\n",
      "Training ended after 50.18 seconds\n",
      "\n",
      "Training with hidden_size=256, depth=4, num_epochs=100, batch=128, lr=0.01, step_size=50, momentum=0.99\n",
      "Epoch [24/100] - 0.59 seconds - loss: 1.7295 - val_loss: 1.7383 - patience: 9\n",
      "Training ended after 14.51 seconds\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_model = None\n",
    "\n",
    "if os.path.exists('best_model.pth'):\n",
    "    # load best model\n",
    "    best_model = get_nn_model(X_train.shape[1], 64, N_LABELS, dropout_prob=dropout_prob, depth=2)\n",
    "    best_model.load_state_dict(torch.load('best_model.pth'))\n",
    "    best_model.to(device)\n",
    "    best_model.eval()\n",
    "    y_test, y_pred_c, y_pred = test_model(best_model, test_loader, device)\n",
    "    metrics = classification_report(y_test.cpu(), y_pred_c.cpu(), output_dict=True, zero_division=0)\n",
    "    best_acc = metrics['accuracy']\n",
    "\n",
    "\n",
    "for hidden_size, depth, num_epochs, batch, lr, step_size, momentum in hyperparameters:\n",
    "    \n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "\n",
    "    print(\"\\nTraining with hidden_size={}, depth={}, num_epochs={}, batch={}, lr={}, step_size={}, momentum={}\".format(hidden_size, depth, num_epochs, batch, lr, step_size, momentum))\n",
    "    log_name = \"dim:\"+str(hidden_size)+\"_depth:\"+str(depth)+\"_epochs:\"+str(num_epochs)+\"_batch:\"+str(batch)+\"_lr:\"+str(lr)+\"_step_size:\"+str(step_size)+\"_momentum:\"+str(momentum)\n",
    "    \n",
    "    if os.path.exists('runs/'+log_name):\n",
    "        print(\"Model already trained, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # start tensorboard\n",
    "    writer = SummaryWriter('runs/'+log_name)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(Y_train, dtype=torch.long)), batch_size=batch, shuffle=True)\n",
    "\n",
    "    model = get_nn_model(X_train.shape[1], hidden_size, N_LABELS, dropout_prob, depth=depth)\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(list(weights.values()), dtype=torch.float32).to(device))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
    "\n",
    "    # train\n",
    "    model = train_model(model, criterion, optimizer, scheduler, num_epochs, train_loader, val_loader, device, writer)\n",
    "\n",
    "    # validate\n",
    "    y_test, y_pred_c, y_pred = test_model(model, test_loader, device)\n",
    "\n",
    "    metrics = classification_report(y_test.cpu(), y_pred_c.cpu(), output_dict=True, zero_division=0)\n",
    "    writer.add_scalar('metrics/test accuracy', metrics['accuracy'])\n",
    "\n",
    "    writer.add_hparams({'hidden_size': hidden_size, 'depth': depth, 'num_epochs': num_epochs, 'batch': batch, 'lr': lr, 'step_size': step_size, 'momentum': momentum}, {'hparam/accuracy': metrics['accuracy']})\n",
    "\n",
    "    if metrics['accuracy'] > best_acc:\n",
    "        best_acc = metrics['accuracy']\n",
    "        best_model = model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    print(\"Best accuracy so far: {:.2f}\".format(best_acc))\n",
    "    \n",
    "    torch.save(model.state_dict(), 'models/'+log_name+'.pth')\n",
    "\n",
    "    writer.flush()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.73      0.79      0.76        80\n",
      "           3       0.79      0.75      0.77       284\n",
      "           4       0.84      0.86      0.85       804\n",
      "           5       0.89      0.87      0.88      1159\n",
      "           6       0.83      0.88      0.85       426\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.85      2764\n",
      "   macro avg       0.51      0.52      0.51      2764\n",
      "weighted avg       0.85      0.85      0.85      2764\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "y_test, y_pred_c, y_pred = test_model(best_model, test_loader, device)\n",
    "print(classification_report(y_test.cpu(), y_pred_c.cpu()))\n",
    "accuracy = accuracy_score(y_test.cpu(), y_pred_c.cpu())\n",
    "\n",
    "results = pd.concat([results, pd.DataFrame({'Model': 'NeuralNetwork', 'Accuracy': accuracy}, index=[0])], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning for Tabular Data\n",
    "\n",
    "[PyTorch Tabular](https://github.com/manujosephv/pytorch_tabular#installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
